---

title: Method and system for query transformation for managing information from multiple datasets
abstract: A method and system for users to connect, extract, query and transform data from multiple databases, independent of their format, type, and location. The system comprises a setup portion, a meta database, and a user portion. The setup portion establishes datasets for use by the system with the user portion. The meta database stores the datasets. The user portion allows a user to input a query and processes the query to gather information from at least one data source and generate a response.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08694532&OS=08694532&RS=08694532
owner: First American Data Co., LLC
number: 08694532
owner_city: Santa Ana
owner_country: US
publication_date: 20050919
---
The present invention claims priority from U.S. Patent Application Ser. No. 60 610 790 filed on Sep. 17 2004 the entire disclosure of which incorporated herein by reference.

This invention relates generally to a system and method for managing data. More specifically the invention relates to a method and system for users to connect extract query and transform data from multiple databases independent of their format type and location as well as to write data to multiple databases independent of their format type and location.

A system and method for managing data. The system and method may be used to manage data to and or from multiple data sources independent of their format type and location. Managing data may comprise for example connecting extracting querying transforming interpreting and writing data. The system comprises a setup portion a meta database and a user portion. The setup portion comprises a configuration tool and obtains collected metadata of the underlying data sources and develops datasets for use with the user portion. A meta database is provided to which the datasets developed by the setup portion are saved. The user portion uses the datasets in the meta database as a foundation for managing data in accordance with a user request. The user portion comprises a communication system and a data processing component. The data processing component comprises at least one adapter for managing data to and or from at least one data source.

While multiple embodiments are disclosed still other embodiments of the present invention will become apparent to those skilled in the art from the following detailed description. As will be apparent the invention is capable of modifications in various obvious aspects all without departing from the spirit and scope of the present invention. Accordingly the drawings and detailed description are to be regarded as illustrative in nature and not restrictive.

A system and method for managing data is provided. More specifically a system and method that may be used to manage data to and or from multiple data sources independent of their format type and location. Managing data may comprise for example connecting extracting querying transforming interpreting and writing data. As will be discussed more fully below the system comprises a setup portion and a user portion. The setup portion establishes datasets for use with the user portion. The user portion manages data from and or to at least one system or data source.

Using the setup portion the midware system may be particularly configured according to user requirements. Thus for example if the midware system is to be used to manage information related to real estate the setup portion develops a dataset related to real estate information. The setup portion recites the categories of that real estate information. Thus the setup portion establishes a dataset including fields for each type of information to be queried such as owner name address plat etc. The dataset developed by the setup portion is then integrated into and acts as a foundation for the user portion of the midware system . The developed dataset is stored in a meta database .

As shown in a user submits a request to the midware system and the midware system manages data with or to at least one data source in accordance with the user request. As shown in the user may submit the user request using the user portion of the midware system . This may be done by submitting a request such as an XML request. Alternatively any suitable manner of submitting a request may be used. In one embodiment the user uses a personal computer to request the information. The request is processed by the user portion of the midware system . The midware system manages the requested data with an at least one data source . For example the midware system may extract data from or write data to the at least one data source . In the case of data extraction the extracted data is formatted as a report and transmitted to the user . The report may be designed for viewing on a screen of the personal computer used by the user.

Thus the user portion includes a service component that manages data with at least one data source based on the gathered description meta of the data developed as a dataset by the setup portion .

Generally the midware system gathers data across or writes data to several disparate data sources such as systems and databases and consolidates the results in a user friendly comprehensive view. Each of the data sources may communicate in a different language and as will be described more fully below the midware system need not know in what language the data source communicates in order to manage data with the data source . Thus the midware system may provide a data abstraction layer to other applications. A user in another application can use the midware system to collect data in a language foreign to the application or can write to another system without knowing the language of that system.

The setup portion of the midware system is processed prior to user use of the system . During setup foundation datasets are built. Thus example data desired by a user of the midware system is established. For example if the specific embodiment of the midware system is to be used in a library data that may be desired by a user may include title author genre date of publication etc. The various data items are used to create a dataset. The dataset thus may reflect a sort of form to be filled by the user portion of the midware system when the midware system is processing a user request. A configuration tool may be provided with the setup portion of the midware system to create the dataset or datasets. illustrates an example configuration tool .

Generally the setup phase is performed once for each installation of the midware system . Thus the setup phase is performed prior to installation of the midware system at a user facility. Users at the facility may then run multiple requests using the dataset or datasets created in the setup phase. Alternatively the setup phase may be periodically run to update the dataset or datasets are desired.

Data sources of different types tend to be arranged in similar hierarchical fashion. Whether the data source is a database defined by a schema of tables and columns or a GIS service containing layers and features the ability exists in most systems to travel that hierarchy by asking questions. By asking appropriate questions the structure of the data source can be obtained in addition to the actual data. This improves the understanding of the data itself. Thus in the setup phase the data source is explored to better understand the data contained within the data source and the gathered information is used to develop a dataset.

The research discovery and dataset building may be carried out by personnel using the configuration tool of the midware system . A configuration tool may be provided with the midware system to help and assist personnel to research explore and understand data sources such as databases soap web services legacy data sources and other midware systems thus as will be described more fully below one midware system may use another midware system as a data source . The configuration tool may be used to generate datasets and store them in a meta database of the midware system . Building of the datasets based on the metadata of the underlying data sources may be achieved in any suitable manner. Generally metadata is the definition or description of the data. The metadata of the underlying data sources is explored to determine the type of data held by those sources.

As shown in in one embodiment of a configuration tool the process of creating datasets includes developing a datasets tree . Thus for example the configuration tool may allow a developer to expand a datasources tree and drag the desired field to a dataset on the datasets tree . Alternatively the desired fields may be directly entered into a datasets tree . The definition of the desired field is stored in the meta database . In one embodiment the creation of a dataset using the configuration tool is a graphical user interface GUI toolset that allows a user to configure or maintain the dataset definitions. Drag and drop features may be provided in the toolset specifically for dataset fields and related properties to be accumulated from one or many data sources.

The meta database of the midware system stores metadata collected from the data sources for example databases legacy data sources soap web services imaging systems GIS systems or other midware systems. Thus the meta database stores the information known about the data in order to provide access to the data but does not store copies of the data itself. The meta database may store the definition of datasets such that the service component of the user portion may produce queries and execute them against the data sources.

In lieu of developing datasets during the setup phase carried out by the midware system the midware system may use a meta database created by another tool to manage data. Thus the foundation datasets need not be established by the midware system but may be imported into the midware system during the setup phase.

In a specific embodiment a user requests information from the midware system by submitting a request. The request may be communicated directly to the midware system or may be communicated to the midware system from another application. Further the request may be in any suitable form. For example the request may be an XML request. The request is sent to a user portion of the midware system and is evaluated and processed by a service component of the user portion . The service component executes the dataset or datasets established by the setup portion and performs related orchestration processing. In one embodiment the service component is a web service. The service component of the midware system manages data with data sources via a data processing component . Additionally the service component may extract data from or write data to another midware system.

The extraction of data may be done by producing queries and executing them against the various data sources . Once the information is gathered the service component returns a response to the user and the information may be displayed on the screen. The user may send multiple requests to the midware system with several responses being returned.

Alternatively the midware system may be used to write data to a data source . For example a user may submit a user request to record information about her mortgage. Based on one or more of the request s parameters the midware system uses the request to update information in one or more data sources . The request triggers formulation of an appropriate query UPDATE INSERT and others depending on the SQL or other language dialect or type of data storage for each destination and source of the data . As will be understood to one skilled in the art several commands may be programmed into the midware system to provide a comprehensive coverage to extract and write data in data storage systems.

As shown in in one embodiment the service component comprises a communication system and a processing component. The communication system may be any suitable system for exchanging messages between a user and the midware system . Thus for example the communication system may be a system web service. Alternatively the communication system may be integral to the application wherein the application uses direct API application programming interface using the midware components directly or open protocol such as OLEDB to request and receive data from the midware system . Two example open protocols are OLE DB and ODBC. OLE DB is a set of COM based interfaces that expose data from a variety of sources. OLE DB interfaces provide applications with uniform access to data stored in diverse information sources or data stores. The Microsoft Open Database Connectivity ODBC interface is a C programming language interface that makes it possible for applications to access data from a variety of database management systems DBMSs .

In the embodiment wherein the communication system is a system web service the system web service encapsulates the functionality of the processing component such that it can provide services as a web service. Generally speaking a web service is a software application whose interfaces and bindings are capable of being defined described and discovered as for example XML artifacts. A web service supports direct interactions with other software agents using for example XML based messages exchanged via Internet based protocols.

The communication system receives the user request and generates the response via interaction with the processing component . The user request is forwarded to the processing component and processed in a manner shown in . The user response is sent from the processing component to the communication service for output to the user. The processing component combines the user request with an API request and compiles a user response based on an API response .

A workflow manager may be constructed using execution steps defined in the meta database or another data repository such as an XML file. Each step may have stored actions such as run other programs execute another set of workflow steps send notifications retry the operation log the results execute another step or the same set recursively store information retrieve information or other stored action. These actions may be triggered by conditions also stored in the meta database or another data repository such as an XML file.

The workflow manager may use a transformation manager to perform transformations on the user request . These transformations may be for example converting dates to numbers numbers to text etc. using dataset definitions provided by the configuration manager . Of course other transformations may be performed and or the transformations may be performed other than by a transformation manager . For example custom extendable transformation types may be added using XSLT files. After the workflow manager processes the user request including parsing checking and making query level transformations the user request becomes a system request .

The workflow manager redirects the system request to one or more adapters depending on the sources to be queried to fulfill the request. In alternate embodiments the system request may be otherwise directed to one or more adapters . The adapters are open architectural devices for communicating between the midware system and other data source s . A plurality of adapters may be provided each adapter being configured for communicating with a specific type of data source . For example an SQL adapter a web service adapter and a legacy adapter may be provided. Other adapters may be included for other data sources .

Example adapters may include an SQL adapter a web scrapper an XML parser a terminal stream a GIS adapter an imaging adapter or a file system adapter. Each of these example adapters is discussed in the Example Adapter Table below.

While the adapters are conceptually split into a plurality of adapters one for each data source they may be combined into a single adapter.

The adapter whichever adapter is relevant to the data source to which the request is redirected receives the system request and creates a query to obtain the data from the underlying data source . The adapter retrieves the data from the underlying data source and returns it for processing into a response. In one embodiment the adapter transmits the data to the transformation manager .

In an alternative embodiment shown in the workflow manager forwards the system request to an adapter factory . The adapter factory returns an adapter for the underlying data source s . Thus the adapter factory determines the adapter associated with the data source to which a data query is sent. Each of the adapters works based on the same framework each can explore the data source retrieve object hierarchy and read and write data based on a request. As described more fully below each adapter may have a query generator or builder to build queries to interact with the data source . For example a query generator may build SQL queries ARCXML queries for GIS systems or other types of query. Depending on the request any number of adapters may be used to read or write distinctly or in group and the resultant data may then compiled in a response.

In addition to communicating with a data source as described above the midware system may communicate with another midware system. This may be achieved via an adapter or by other suitable means. Thus the midware system receiving the user request acts as a master midware system and the midware system acting as a data source acts as a subservient midware system. During setup the master meta database is created with meta data information from the subservient midware system. During the user phase the master midware system communicates a user request as a query to the subservient midware system. This may be done in the same manner as communication of a user request to another data source . Thus the user request may be transformed to a system request which in turn is converted to a dataset request sent to the data source this process is described more fully below . The subservient midware system processes that data query as it would process a user request and communicates the query processed as a user request to another midware system or to other underlying data sources. The subservient midware system generates a response and transmits that to the master midware system . Thus the master midware system meta database may be created having information about other installed midware systems. The master midware system may access the subservient midware system through several methods remoting web services and others and have them to forward the original request gather results and pass them back up on the hierarchy.

The transformation manager receives data from the adapter as raw data. The transformation manager may perform one or more transformations to the data. Further the transformation manager may make query level transforms such as converting a date to a number before the query and converting the number back to the date after the query is run. The query level transforms thus may be used to display results in a meaningful way. This may be useful to query date related or filtered information such as when a user enters date information. Example one illustrates such transformation. In alternative embodiments data may be returned to the user in raw format.

In framing a user request the user enters dates such as 1 3 1993 and 1 4 1993. The transformation manager transforms the dates on the query level such that the underlying query may be 

A notification manager may be included in the processing component to send notifications to the user and or to personnel . The notifications may be sent via emails SMS Short Messages IM Instant Message display on a computer screen web site pop up windows or any other suitable method. The workflow manager may request the notification manager to provide notifications triggered by parameterized and data driven conditions set in the configuration manager . These conditions may be for example errors timeouts other execution conditions or a cascade of conditions. Alternatively no notification manager may be provided.

A log manager may be included in the processing component to record or log operations executed by the workflow manager . Thus for example the log manager may record successful or unsuccessful queries time outs errors or any other process results on the meta database or any other data repository such as text files XML files flat files etc. The log manager may record performance information about queries and the midware system as a whole such that this information may be used as feedback for the workflow manager to improve the performance of the execution processes. Alternatively no log manager may be provided.

A process information manager may be included in the processing component to collect information about the querying process. Example information includes the actual query for example an actual SQL query the time taken to execute the request the number of records returned the status of the operation errors notifications or others etc. The process information manager may also inject the collected process information into the response directly using the transformation manager or as a pass thru. Generally no alterations or format transformations are conducted on the result from the data source response. The response may be created as shown in after the process information manager injection.

A system schema may be included in the processing component to retrieve information about the metadata from the data sources e.g. databases and store the information in the meta database or other data repository. Other data repositories may be for example databases flat files text files XML files etc. This information may be used by the configuration manager to supply information system wide.

A client user interface manager may be included in the processing component to provide a common interface to applications designed to use the processing component s API to manage its user interface operations. These interfaces may be meta database maintenance user interface clues loading datasets to trees displaying data sources etc.

A catalog manager may be included in the processing component to track changes on data sources used in datasets. Notifications may then be triggered to avoid system difficulties and down time. The workflow manager may be programmed to monitor and track these changes and perform notifications thru the notification manager . The workflow manager may be programmed to log these changes thru the log manager such that they may be used to adjust the dataset in response to changes in the data source . Further the workflow manager may be programmed to adjust datasets automatically to reflect changes in the underlying data sources and to avoid or reduce down time.

Process flow of the workflow manager is illustrated in . As shown the workflow manager comprises a dataset manager see and an execution manager see . In the embodiment of process flow is illustrated serially. In alternative embodiments process flow may be done in parallel or concurrently as will be described more fully below. As stated above the user request from the communication system may be directed to a workflow manager . While a workflow manager is described as an example means for developing a user request other means will be obvious to one skilled in the art and are within the scope of the present invention. The workflow manager parses checks and makes query level transformations on the user request . The workflow manager thus develops the user request into a system request . A dataset manager may be provided within the workflow manager . The dataset established in the setup phase sets the shape of the response. The dataset may have nested datasets and transformation sets that are defined and executed by the transformation manager . A dataset is generally executed recursively by a triggered request coordinated by the workflow manager . The dataset manager validates the system request and completes it with information from the dataset design. The information may be paging information information to display the correct page within several pages the number of records to be returned sorting information filtering information or other information. After being validated and completed with the information needed to retrieve the data described more fully with reference to the system request is thus converted to a dataset request . The dataset request is then processed through the execution manager to the data source adapter s .

Thus the user request is an external request submitted by a user to the midware system . The user request is transformed to a system request by the workflow manager . The system request in turn is converted to a dataset request . A dataset request is one or many executions of dataset definitions. After execution of the dataset request the workflow manager responds to the system request with the results of the dataset request . The workflow manager may also note the status of the processing within the service component execution for example timeout success error etc. .

As referenced above the dataset requests may be executed in parallel. Thus dataset requests may be sent to multiple data sources at the same time. Further when data for a portion of the dataset has been retrieved from one or more data sources that portion of the request may be considered fulfilled. Thus redundant data may be avoided when the same data is sought in redundant or same content sources.

An execution manager may be provided within the workflow manager to take the dataset request and execute it based on the workflow rules and settings. The execution of the dataset request may extend across multiple data sources .

After the execution of the dataset request is completed or times out the execution manager gathers results if any and or exceptions if occurred evaluates them and proceeds to the next step until the request as a whole is completed or fails. As stated above the workflow manager responds to the system request with the results of the dataset request . The execution manager may also supply process information to a process information manager if provided.

A definitions loader may be provided within the dataset manager to load definitions from the configuration manager and temporarily store them for example in a columns bucket .

A request s parameters parser see may be provided within the dataset manager to check the requested columns from the system request and match them with the ones in the columns bucket . In one embodiment the columns comprise fields to be retrieved within the SELECT section of the SQL statement and or the fields to utilize in a JOIN WHERE clause. The request s parameters parser adds the requested parameterized information such as sorting visibility filtering distinct records paging etc. to the system request. The requested parameterized information is generated with the system request and is processed by a parameter parser. The parameters at the column level may be integrated to the column objects in the columns bucket . The request s parameters parser may also identify and parse the parameters of the request which are at the dataset level and add them to the dataset definitions bucket . Dataset definitions generally are stored persisted in the meta database . Example parameters at the dataset level include WHERE clause values against a dataset definition property.

As stated above after being validated and completed with the information needed to retrieve the data the system request becomes a dataset request . Thus after the parsing and matching by the request s parameters parser the system request is a dataset request . The dataset request is communicated to the at least one adapter . This communication may be done for example via the execution manager .

A serializer may also be included in the dataset manager to maintain the dataset s definitions in the meta database through the configuration manager .

As shown in the request s parameters parser may include two main functional blocks a column names parser and a parameters parser . The columns names parser identifies parses and selects the column information packaged in the system request . This information is stored in the column object s properties. The parameters parser identifies validates parses and selects the dataset level information packaged in the system request . This information is stored in the dataset object s properties. The parameters parser and the functional blocks of the parameters parser are example means for developing dataset object s properties. Other means may alternatively be used. and illustrates example information included in the dataset properties and the column properties with reference to the relational database adapter.

The dataset object s properties where the dataset level information is stored as described in relation to may include a collection of connectors. illustrates example datasetconnector properties . The connectors store information on how to connect or link one table to another. Generally data from two tables may be combined to form a third joined table for example via SQL Join. Further operations may be performed on the third table. One dataset may go across several tables. Information from a dataset may include several tables views stored procedure results physical files Web Service responses or API results. Multiple connections or combinations may be necessary. Further one dataset may group other datasets. That is datasets may be nested. For one dataset to group another dataset the one dataset must store enough information to connect to the data source file and produce and run heterogenous queries hosting the join process in one of the data sources or store temporary data in memory or any other repository thus creating the resultant virtual joined table. Examples of a database server service database file include Access MDB files text files XML files etc.

An example of combining or joining two tables is as follows. A query may run across two disparate data sources one running on Microsoft SQL Server and the other an AS400 DB2 Universal Database. The following query demonstrates how to join or combine a first table with document on the Microsoft SQL Server database with a second table on a DB2 table. The first table is called SpiderDemo . dbo . RcdocnPF the second table is called TRACTDBF.RCNAMEPF. The matching field between the two tables is the field DCDOC on the SQL side and the field NMDOC on the DB2 side.

As shown a database connector holds information on how to link database tables. It comprises one or more groups of keys linking every two tables. The dataset connector may also provide several data transformation operations such as data conversions parsing formatting casting etc. on a key level to be able to link all types of tables to each other. The key level may comprise normalized relationships from one table to another via a primary key. Based on these transformations the database connector may link tables which don t have necessarily the same type of data on the link fields. If a 2345 and b 2.3.4.5 transformation foo xxxx x.x.x.x enables linking foo a .

Returning to the workflow manager may include a dataset manager and an execution manager with the dataset request being passed from the dataset manager to the execution manager . illustrates process flow through an execution manager in accordance with one embodiment. The execution manager receives a dataset request identifies the underlying type of data source the request runs against executes the request and takes the correct actions after the request s execution or failure. In the embodiment of the execution manager processes the request serially. That is the execution manager checks for each type of data source serially before proceeding to another. In alternative embodiments the execution manager processes the request in parallel.

The dataset request is received from the dataset manager and verified to identify an adapter for handling the request . Dataset requests may include multiple types of sources in which case the request is broken into corresponding subrequests that are then forwarded to the appropriate adapter . The adapter communicates between the midware system and the data source . The adapter executes the part of the request on its domain. Once the queries are executed results such as data exceptions timeouts etc. are analyzed and sent to a dispatcher see to generate logging notifications and the data is returned to the user. The dispatcher if provided may communicate with the notification manager the log manager and or the process information manager .

Thus if the dataset request includes SQL data to extract the dataset request is sent to the SQL adapter where SQL queries are generated and run against the data sources where the data resides. If the dataset request has SOAP web services data to extract the dataset request is sent to the web service adapter where the SOAP request is generated and run against the web service provider . If the dataset request has legacy data to extract the dataset request is sent to the legacy adapter where the correspondent requests are generated and run against the systems where the data resides. The forwarding of the dataset request to the appropriate adapter and subsequent extraction of the data from the appropriate data source may be referred to as data extraction.

As noted above a dispatcher may be provided to generate logging notifications regarding results such as data exceptions timeouts etc. illustrates an example process flow of such a dispatcher . The dispatcher interacts with several components such as the notification manager the log manager the process information manager the transformation manager and or the configuration manager . These components are described more fully in reference to . Reference is thus made to during the following discussion. The dispatcher may be configured as a common generic module used by several data drivers to analyze the results of execution of requests against data sources . A data driver is one or many classes that are used based on a data source type. For example SQL Server Oracle DB2 FoxPro Paradox Web Service etc. After the data extraction attempt is made if successful data is sent to the transformation manager where the process is finalized as a whole. If notifications are necessary the correspondent information is sent to an email driver where the data to be sent is collected from the execution process and the addresses are passed by the configuration manager .

If exceptions or errors occurred the log manager may be used to collect information and build messages to be logged. The log manager may also log performance information such as query results time to execute exception tracking etc.

A process information controller may collect format and send information about the execution of the requests to the process information manager which may then be attached to the results for evaluation and debugging purposes. The process information controller may act as an interface to the process information manager preparing the messages queries and request descriptions. The process information controller may receive information about successful executed requests and post it back to the user for clarification or debugging purposes.

Timeouts and exceptions may be analyzed and if there were assigned backup datasets to run the dataset request may be transformed back into a system request . Sequential backup data sources may have separate dataset definitions. The workflow manager may execute a backup dataset if the primary dataset response is unsuccessful. Information about the exception may be added to the system request the system request being sent back to the workflow manager for another cycle of execution. The cycle of execution is shown in .

If a user entity desires to use the midware system on a Windows interface a windows registry controller may be included in the configuration manager to handle configuration information stored on Microsoft Windows computers. The windows registry controller then wrap via a code base surrounding an existing collection of components all the maintenance storage and retrieval of Microsoft Windows Registry s based information for the other modules of the midware system . Alternatively the midware system may be run in a non Windows environment.

The processing component shown in may store configuration and metadata information on a data source such as datasets schema information configuration information logs performance information etc. The configuration manager may include a SystemDB controller to wrap and manage storage retrieval and maintenance of information on the meta database . Other modules of the processing component may use the SystemDb controller to access this information.

Further the configuration manager may offer an API with several functions to be used for other modules system wide.

An example process flow of a query builder is shown more specifically in . In some situations the order of tables is relevant in a query. For example a database management system can not parse queries where the use of the data is from an undeclared join. A specific example is set forth below. As shown in the example if Table3 is joined before Table2 is joined the query will not run.

While not only one order can be successful at least one is. Any suitable process may be used for generating a query. illustrates a process flow of one process for generating a query. In this process logic based on the weight of each table in the query is used to build the joins in the correct order. As shown a query is received at block . An initial inquiry is performed to determine if there are disparate sources shown at block . If there are disparate sources a series of clauses are built. At block the Where clause is built. At block the Select clause is built. At block the Order By clause is built. At block the Group By clause is built. At block preparation is done for building the From clause. After the clauses are built the tables are counted shown at block . If there is only one table the From clause is built at and the process returns to block where it is determined whether there are more disparate sources. If there is more than one table the next table in the bucket table1 is gathered shown at block . Thereafter the next table in the bucket table2 is gathered shown at block . A Link is determined among table1 and table 2 shown at block . Based on the link the tables rank is incremented shown at block . Table2 Table1 is developed at block . If there are more tables the process returns to block . If there are no remaining tables the tables are sorted based on rank shown at block . Thereafter the From clause is built shown at block and the process returns to block where it is determined whether there are more disparate sources. Once there are no remaining disparate sources it is determined wither there is a unique source shown at block . If there is a unique source the query is returned at block . If there is not a unique source each query is treated as a Main Query s sub queries shown at block . The Grouped query is then treated as a unique data source and the process returns to block .

While the process of is less likely to fail than the process of it is much more time consuming. Generally the process of is used if the process of fails. Thus as shown in a query is requested from the adapter using the method Method of shown at block . The query is tested at block and it is determined whether they query was successful at block . If yes the query is returned at block . If no the query is requested from the adapter using the method Method shown in .

As shown in the query builder may build SQL queries or queries based on another language based on the dataset request . specifically illustrates the query builder in relation to SQL queries. However queries may be built in any suitable language using the query builder . Alternatively the query builder may build Web Service requests application executions parsing routines etc. The query builder includes an ORDER BY clause builder a WHERE clause builder a SELECT clause builder a FROM clause builder a join builder and a query optimizer . The flow of the query may be for example WHERE SELECT ORDERBY GROUPBY WHERE yes again and FROM.

The dataset request is received by the ORDER BY clause builder of the query builder . The ORDER BY clause builder validates the columns in the dataset request and searches for columns with Sort property assigned. A Sort property is the completion of an ORDER BY clause statement passed as a parameter by the system request. For each column that has values for the Sort property the ORDER BY clause is concatenated in a plain SQL format using SQL delimiters and . These delimiters are generally used because they are unique for each side of the delimitation and may be easily replaced with the data source delimiter. Of course other delimiters may be used. For every column used it s containing table is added a tables bucket . When added to the tables bucket an alias is created for the table generally using simple one two or three characters. All columns are checked and the clause built and stored. If the column s table is already in the tables bucket its already assigned alias is used to keep building the query.

After the ORDER BY clause builder the WHERE clause builder is invoked. The dataset request columns are scanned for columns with values assigned. Each group of values is translated to filters in the WHERE clause. Also any column s table not in the table bucket is added to the table bucket and has an alias assigned. As the columns are scanned the WHERE clause is completely built.

Once the WHERE clause is built the SELECT clause builder builds the SELECT clause in a similar manner. Tables are added to the table bucket and all columns which are not set to not be selected are added to the query. Selected columns are returned in the system response while columns that are not selected may be utilized in the WHERE clause.

The join builder takes all tables in the tables bucket and evaluates all possible link paths to link the tables in the query. Several tables may be in the tables bucket and the tables may be linked in several different ways. When multiple connection paths may be used to join various of the tables the one used is determined by a number of factors. These factors include the number of records the existence of indexes data sources etc. These factors are defined and weighted in the meta database and are evaluated during every query generation process by the join builder . The join builder chooses a link path adds the tables which are not in the tables bucket and sets a numeric property on each table in the table bucket with the order in which the join should be made.

The FROM clause builder builds the FROM clause of the query based on the tables bucket information. The query optimizer takes the query clauses and replaces simple SQL clauses with syntax based on the provider and includes heterogenous query syntax based on the host server.

A query dispatcher of the query manager of is shown in . The query dispatcher takes the query built by the query builder and executes it. The query dispatcher may include a connection manager for taking information from the data source manager of and connecting it to the underlying data source . The database connections may be shared to avoid the misuse of the servers resources. The connection timeout is managed by the connection manager . Once connected to the data source an execution controller of the query dispatcher may optionally generate execution threads to run the queries asynchronously such that the timeout settings are shared by the threads in the same pool thereby avoiding fulfilling the total timeout for the request.

The query dispatcher may further include a paging controller . A paging controller may be desirable in a web application where pages with a preset number of records are illustrated separately. The paging controller returns the page number and records as requested. The paging controller may have its technique laid out in a repository such as the meta database such that disparate paging techniques may be used depending on the environment and request. In many embodiments a paging controller is not provided.

A transformation manager of the processing component is illustrated in . The transformation manager shown comprises a transformer a query level transformer and a packager . The transformation manager may have several types of transformation schemes depending on the type of transformation. If the transformation is aesthetic a transformer may be used to do several transformations such as format aggregate clean parse conversions etc. If the transformation is at the query level such as selecting records by a non standard date transformations are performed by a query level transformer . The query level transformer may be used to transform the user request s filters before the query is generated and then transform the results using the same techniques in the opposite direction. Other transformations such as transforming a stream of bytes in a jpg image or a pdf file may be performed by a specialized transformer. After the transformations are done a packager of the transformation manager may take information from the process information manager merge with information about the execution of the queries and inject them in the resultant response and deliver it to the user .

The method of the midware system of the present invention is shown in . As shown a user submits a user request to the midware system through a user interface . The user request is sent to and received by the service component of the midware system . More specifically the user request may be received by and processed by a workflow manager of the midware system . As explained previously the workflow manager converts the user request into a system request . The workflow manager interacts with one or more adapters and a transformation manager . The system request may be further converted into one or more dataset requests . The one or more adapters are used to communicate the dataset request with one or more data sources .

Thus the system request is transmitted via the workflow manager to one or more adapters and queries are created to obtain data from underlying data sources . A raw response is provided by the adapters in response to the user request . The transformation manager performs transformations on the response for example converting dates to numbers numbers to text etc. The transformations may operate to display the response in a meaningful way. The transformed response is transmitted to the user . Alternatively a raw response may be transmitted to the user or the response may be otherwise transformed.

Various other managers and components as described previously may be included in the midware system of the present invention. Other means for performing various tasks herein described will be obvious to one skilled in the art and are within the scope of the invention. Further while various tasks are herein described not all of these tasks need to be performed.

In an example embodiment the method and system of the present invention may be used to gather information regarding property. illustrate screen shots of such a request and the corresponding gathered and compiled information as well as the XML code for the request and the XML response to the request. While illustrate the request and response in XML format other languages may be used for the request and the response.

As shown in the request may be searched by PIN or legal description by parcel ID number by owner s name and or property address or by plat. In the example information is input regarding the payable tax year 2004 the view Parcel ID Info the roll type Real Property R and the parcel number 05.03050.000 . illustrates an XML request generated from the screen shown in .

Although the present invention has been described with reference to preferred embodiments persons skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention.

