---

title: Adaptive flow control protocol
abstract: A method and system for directing data transfers between applications and devices residing on different computers or devices using an adaptive flow control protocol has been described. When an application or device requests to transfer data with another application or device, adaptive flow control protocol adapts the way data is transferred by observing when an application that is receiving data posts a receive buffer and detects the receive buffer's size. Based upon the application's or device's behavior, the adaptive flow control protocol transfers the data in a mode that is best suited for the application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07418516&OS=07418516&RS=07418516
owner: Microsoft Corporation
number: 07418516
owner_city: Redmond
owner_country: US
publication_date: 20051012
---
This application is a continuation of U.S. application Ser. No. 09 844 098 filed Apr. 27 2001 which is a continuation in part of U.S. application Ser. No. 09 453 781 filed Dec. 3 1999 which claims the benefit of U.S. Provisional Application No. 60 112 777 filed Dec. 18 1998 and U.S. Provisional Application No. 60 159 316 filed Oct. 14 1999.

This invention relates generally to networked communications and more particularly relates to a flow control protocol for use with transport providers.

Computer networking allows applications residing on separate computers or devices to communicate with each other by passing data across the network connecting the computers. Traditional network media such as Ethernet and ATM are not reliable for application to application communication and provide only machine to machine datagram delivery service. In order to provide reliable application to application communication transport protocol software run on the host machine must provide the missing functionality.

Typically the protocol software for network communication is implemented as a combination of a kernel mode driver and a user mode library. All application communication passes through these components. As a result application communication consumes a significant amount of the host processor s resources and incurs additional latency. Both of these effects degrade application communication performance. This degradation significantly limits the overall performance of communication intensive applications such as distributed databases.

Recently a new class of communication interconnects called System Area Networks SANs has emerged to address the performance requirements of communication intensive distributed applications. SANs provide very high bandwidth communication multi gigabytes per second with very low latency. SANs differ from existing media such as Gigabit Ethernet and ATM because they implement reliable transport functionality directly in hardware. Each SAN network interface controller NIC exposes individual transport endpoint contexts and demultiplexes incoming packets accordingly. Each endpoint is usually represented by a set of memory based queues and registers that are shared by the host processor and the NIC. Many SAN NICs permit these endpoint resources to be mapped directly into the address space of a user mode process. This allows application processes to post messaging requests directly to the hardware. This design consumes very little of the host processor s resources and adds little latency to communication. As a result SANs can deliver extremely good communication performance to applications.

In general SAN hardware does not perform any buffering or flow control. Most distributed applications are designed to communicate using a specific transport protocol and a specific application programming interface API . A large number of existing distributed applications are designed to utilize the Transmission Control Protocol Internet Protocol TCP IP suite and some variant of the Berkeley Sockets API such as Windows Sockets. Since existing applications are usually designed to use one primary transport protocol and API most often TCP IP and Sockets there have been relatively few applications that can take advantage of the performance offered by SANs. In order for existing applications to use a SAN the TCP IP protocol software must currently be run on top of it eliminating the performance benefits of this media.

In order to emulate the data transfer behavior of the primary transport provider when utilizing an alternative transport provider such as a SAN without running TCP IP protocol software on top of it a protocol must be implemented that controls the transfer of data from source memory buffers supplied by a first application into destination memory buffers supplied by a second application. This aspect of data transfer is known as flow control. The TCP IP protocol provides for data transfer in the form of an unstructured stream of bytes. It is the responsibility of the applications using the TCP IP protocol to encode the data stream to mark the boundaries of messages records or other structures. The Berkeley Sockets and Windows Sockets communication APIs offer applications a great deal of flexibility for receiving data. Applications may request to receive data directly into a specified memory buffer request to receive a copy of a prefix of the data directly into a specified buffer without removing the original data from the byte stream peek or request to be notified when data is available to be received and only then request to receive the data or peek at it. Since TCP IP provides an unstructured byte stream an application may request to receive data from the stream into a specified memory buffer in any size portion e.g. a single byte or thousands of bytes. The flexibility of these communication APIs and the unstructured nature of the TCP IP data stream make it difficult to implement a flow control protocol that works efficiently for all applications. What is needed is a flow control protocol that emulates many of the features of TCP IP and that allows applications to take advantage of the performance benefits of alternative transport providers.

The present invention provides an adaptive flow control protocol to enable applications designed for a primary transport provider to use one of a plurality of alternative transport providers that offer some benefit over the primary transport provider such as higher performance. When using an alternative transport provider the adaptive flow control protocol adjusts its data transfer strategy based on the behavior of the communicating applications. The adaptive flow control protocol monitors the receiving application to determine when the receiving application posts buffers to receive the data and also detects the size of the buffers and then changes the way it directs data to be transferred between the applications based on when buffers were posted and buffer size. Large data blocks are transferred using remote direct memory access transfers if the receiving application s receiving buffers are of sufficient size or through messages if the receiving buffers are not large enough. Through this adaptive mechanism the adaptive flow control protocol attempts to maximize the communication bandwidth and minimize the communication latency observed by the communicating applications.

Additional features and advantages of the invention will be made apparent from the following detailed description of illustrative embodiments that proceeds with reference to the accompanying figures.

Turning to the drawings wherein like reference numerals refer to like elements the invention is illustrated as being implemented in a suitable computing environment. Although not required the invention will be described in the general context of computer executable instructions such as program modules being executed by a personal computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the invention may be practiced with other computer system configurations including hand held devices multi processor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional personal computer including a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the personal computer such as during start up is stored in ROM . The personal computer further includes a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media.

The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical disk drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the personal computer . Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it will be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges random access memories read only memories and the like may also be used in the exemplary operating environment.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more applications programs other program modules and program data . A user may enter commands and information into the personal computer through input devices such as a keyboard and a pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor personal computers typically include other peripheral output devices not shown such as speakers and printers.

The personal computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the personal computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the personal computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment the person computer typically includes a modem or other means for establishing communications over the WAN . The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

In the description that follows the invention will be described with reference to acts and symbolic representations of operations that are performed by one or more computers unless indicated otherwise. As such it will be understood that such acts and operations which are at times referred to as being computer executed include the manipulation by the processing unit of the computer of electrical signals representing data in a structured form. This manipulation transforms the data or maintains it at locations in the memory system of the computer which reconfigures or otherwise alters the operation of the computer in a manner well understood by those skilled in the art. The data structures where data is maintained are physical locations of the memory that have particular properties defined by the format of the data. However while the invention is being described in the foregoing context it is not meant to be limiting as those of skill in the art will appreciate that various of the acts and operation described hereinafter may also be implemented in hardware.

The present invention is directed to the use of an adaptive flow control protocol that adjusts its data transfer strategy based on the behavior of the communicating applications. shows a representative environment in which the adaptive flow control protocol of the invention may operate. The environment includes a distributed system having local sub networks . Local sub network has computers and local sub networks have computers and respectively. It should be noted that distributed system may have additional local sub networks and local sub networks may have additional computers. Each computer is served by a transport provider for providing communication between computers and between applications residing on computers. Each transport provider may be a primary transport provider such as TCP IP or an alternative transport provider. When an application makes a call to communicate with another application using an alternate transport provider that is capable of providing the communication service the adaptive flow control protocol is used.

For purposes of illustration illustrates a data transfer between two applications connected to transport providers using the adaptive flow control protocol. While shows the transport providers using the adaptive flow control protocol those skilled in the art will recognize that the adaptive flow control protocol may be implemented in operating system application program or other program modules . The transport providers arrange a session for the applications. The local transport provider associates i.e. registers a set of receive buffers and send buffers with the connection and sends a message to the remote transport provider . A message can be sent by either transport provider. The message includes the number of buffers in the set of receive buffers . The remote transport provider also associates a set of receive buffers and send buffers with the connection. It should be appreciated that the receive buffers and send buffers can be combined into a single set of buffers. The local transport provider buffers the first message sent if the remote transport provider does not post the receive set buffers before the first message is sent. It should be appreciated that the local transport provider could also buffer other messages. The remote transport provider sends a response to the message and the response includes the number of buffers in the set of receive buffers .

Each transport provider provides a flow control protocol to synchronize data transfer for small data transfers and large data transfers. One reason for this is that the applications may exhibit different behavior when receiving data. The application may not post a set of receiving buffers until it is informed that data is available to be received or the application may post a set of receiving buffers when it requests to receive data. The application s set of receiving buffers may also be large or small. The set of receiving buffers could be a single buffer or an array of buffers. If the receiving buffer set is large enough bulk data transfer through Remote Direct Memory Access RDMA as known by those skilled in the art is used. The threshold size for using bulk data transfer is based upon justifying the cost of initiating RDMA. Each RDMA operation has a cost which is a function of the control messages exchanged by the transport providers and the SAN NIC hardware operations needed to support RDMA operation. The transport provider queries the SAN provider for the threshold size. Typically the threshold size for a SAN provider is in the range of 2 KB to 4 KB. It should be noted that RDMA could be used for smaller data sizes than the threshold size.

After the connection is established one of the applications requests that data be sent to or received from the other application. For purposes of illustration application issues a request to the transport provider to receive data from application . Application becomes a receiving application and application becomes a sending application. Application may post an initial receiving buffer set or it may wait until it gets notice that data is available to be received.

When application makes a request to transport provider to send the data the application posts the data in a transmission buffer . The transport provider detects the data size and decides whether to use RDMA data transfer or messages to transfer the data to application .

The transport provider copies an initial portion of the data to a message buffer and sends the initial portion of the data in an initial message to transport provider via message buffer step . The initial message includes information to indicate the size of the data to be transferred.

Transport provider then checks whether application has posted receive buffers step . Transport provider will not send any additional data until transport provider notifies it through a message that application has posted receive buffers . To avoid a possible deadlock where transport provider is waiting for an indication that application has posted receive buffers and application has not posted receive buffers each transport provider periodically scans connections it is overseeing to see if a deadlock exists.

The transport provider waits for the application to post receive buffers step . If the periodic scan has occurred a number of times preferably two and the application has still not posted receive buffers the transport provider will send the remainder of the data in messages step .

If the application has posted receive buffers the transport provider determines if the size of the receive buffers is large enough to justify the cost of RDMA step . If the size of the receive buffers is not large enough the transport provider sends a message to transport provider instructing transport provider to send the remainder of the data in messages step . If the size of the receive buffers is large enough for RDMA transport provider and transport provider transfer data into the receive buffer step as described below.

If the size of the receive buffers is large enough to justify the cost of RDMA then local transport provider sends a message to remote transport provider . The message includes the location of the application s set of receiving buffers and whether the application posted the set of receiving buffers directly or waited until it received an indication that data was available to be received. Remote transport provider transfers an amount of data equal to the size of the set of receiving buffers from the set of transmission buffers into the set of receiving buffers using one or more RDMA write operations. Remote transport provider continues to transfer data into the set of receiving buffers as more buffers are posted into the set of receiving buffers until all of the data is transferred. The remote transport provider then sends a message to local transport provider indicating that the data transfer is complete and also notifies application that the data transfer is complete. Local transport provider then signals the application that the data transfer is complete.

The transport providers then determine the behavior of the application step . There are three representative modes in which the application could receive data. One mode is the large receive mode where the application posted the set of receiving buffers directly when it accepted the request to receive data. Another mode is the small receive large receive mode where the application waited until it received an indication that data was available to be received before it posted the set of receiving buffers . Another mode is the small receive mode where the application posted the set of receiving buffers but the size of the set of receiving buffers is not large enough to justify the cost of RDMA operations.

For subsequent data transfers the transport providers repeat steps to while the application s behavior is determined. The remote transport provider determines if the application s behavior during the data transfer is the same representative mode as the previous data transfer step . The transport providers repeat steps to until the application s behavior is determined to be the same representative mode for a predetermined number of times preferably three steps and .

If the application s behavior is determined to be the same representative mode for the predetermined number of times the transport providers adapt the way data is transferred on subsequent data transfers according to the application s behavior step . If the application s behavior changes during subsequent data transfers the transport providers reenter the discovery mode step . Otherwise the transport providers continue to transfer data according to the application s behavior step .

If the remote transport provider determines that the application s behavior is the small receive mode remote transport provider sends all data in messages. If the application posts a set of receiving buffers that is large enough for RDMA local transport provider sends a message to remote transport provider to reenter discovery mode.

Many applications only need to exchange messages that are a few hundred bytes in size. In order to conserve resources in one embodiment the size of messages in small receive mode is set to a default buffer size that is relatively small. For example the size can be set to 1.5 kB sized buffers. For applications that regularly exchange data larger than the default buffer size but smaller than the RDMA size the data will be exchanged in multiple messages which increases overhead. The adaptive flow control protocol provides the capability to increase the default size if needed.

The transport provider gathers statistics on whether the data sent had to be fragmented and keeps track of the largest data size sent. If the number of fragmentations is above a predetermined level the transport provider sends a Resize request message to transport provider asking transport provider to increase the size of its receive buffers from an old size to a new size. The transport provider waits for all of its posted receive buffers to complete and then registers larger sized buffers set to the size of the largest data size sent. If there is not enough memory available to use the larger sized buffers the transport provider continues to use the old size of receive buffers and sends a message to transport provider telling transport provider the resized buffer size which is the same size as the old size. If there is enough memory available to use the larger sized buffers transport provider deregisters the old size buffers and sends a message to transport provider indicating the resized buffer size which is the new size.

Once the transport provider receives the message about the resized buffer size it determines if the resized buffer size is greater than the old size. If the resized buffer size is not greater than the old size the transport provider continues to use buffer sizes equal to the old size. If the resized buffer size is greater than the old size the transport provider waits for all pending messages to the transport provider to complete then registers new buffers sized to the resized buffer size. If both transport providers concurrently send each other Resize request messages a deadlock may occur. In order to avoid a deadlock the transport provider that accepted when the connection was initially established i.e. the accepting peer disregards the Resize request message while the transport provider that did connect when the connection was initially established i.e. the connecting peer proceeds to responds to the Resize request message. The connecting peer may re send a Resize request message after sending the message about the resized buffer size.

In an alternative embodiment the default buffer size is set to a fixed size. If the fixed size is smaller than the size of the data to be sent the data is sent in multiple messages i.e. the data is fragmented of the fixed size. The fixed size may also be set to a large value. This avoids the need for fragmented data.

If the remote transport provider determines that the application s behavior is the small receive large receive mode then the transport providers can transfer the data in one of two ways. The first way is only available if the transport provider supports transferring data directly from a remote buffer to a specified local buffer through RDMA read operations. If the transport provider supports RDMA read operations remote transport provider sends a message to local transport provider . The message contains an initial portion of the data and also includes the location of the application s set of transmission buffers and the size of the data to be transferred. Local transport provider uses the initial portion of the data received through message to satisfy the application s initial small receive request. Application then posts a large receive buffer. Local transport provider then transfers the data from the set of transmission buffers directly into the application s set of receiving buffers using one or more RDMA read operations. Local transport provider transfers an amount of data equal to the size of the set of receiving buffers from the set of transmission buffers into the set of receiving buffers . Local transport provider continues to transfer data into the set of receiving buffers as more buffers are posted into the set of receiving buffers until all of the data is transferred. Once all of the data is transferred the local transport provider sends a message to remote transport provider indicating that the data transfer is complete. The remote transport provider then signals the application that the data transfer is complete. If the application requests to send a small amount of data that is not large enough for RDMA remote transport provider sends data through a message and not through RDMA. The data is then copied by local transport provider to the set of receiving buffers and on subsequent data transfers the transport providers continue in the small receive large receive mode.

If RDMA read is not supported then the transport providers transfer data using RDMA write operations. If the size of the set of receiving buffers is large enough then local transport provider sends a message to remote transport provider . The message includes the location of the application s set of receiving buffers . Remote transport provider transfers an amount of data equal to the size of the set of receiving buffers from the set of transmission buffers into the set of receiving buffers using one or more RDMA write operations. As more receiving buffers are posted by the application local transport provider informs remote transport provider of these buffers through messages . Remote transport provider continues to transfer data into the set of receiving buffers as more buffers are posted into the set of receiving buffers until all of the data is transferred. The remote transport provider then sends a message to local transport provider indicating that the data transfer is complete and also notifies application that the data transfer is complete. Local transport provider then signals the application that the data transfer is complete.

If the remote transport provider determines that the application s behavior is the large receive mode remote transport provider sends a message informing the local transport provider to change modes. After sending this message the remote transport provider becomes passive in the sense that it will not initiate data transfers any more. Instead all data transfers are initiated by the local transport provider . When application posts a set of receive buffers local transport provider sends a message to remote transport provider which includes the size of the set of receive buffers and the location of the set of receive buffers .

When application requests that a large block of data be sent remote transport provider transfers an amount of data equal to the size of the set of receiving buffers from the set of transmission buffers into the set of receiving buffers using one or more RDMA write operations. Remote transport provider continues to transfer data into the set of receiving buffers as more buffers are posted into the set of receiving buffers until all of the data is transferred. The remote transport provider then sends a message to local transport provider indicating that the data transfer is complete and also notifies application that the data transfer is complete. Local transport provider then signals the application that the data transfer is complete.

If the application requests to send a small amount of data that is not large enough for RDMA remote transport provider sends data through a message via message buffers and not through RDMA. The data is then copied by local transport provider from a message buffer to the set of receiving buffers . On subsequent data transfers the transport providers continue to transfer data in large receive mode. If the application changes its behavior and instead of directly posting a set of receive buffers it posts a set of receive buffers that is not large enough for RDMA operations or waits for an indication that data is available to be received before posting a set of receive buffers then the local transport provider sends a message to the remote transport provider to go back to discovery mode. If the application does not post a set of receiving buffers or wait for incoming data a deadlock could occur. The periodic scan detects this and the transport provider sends a message to transport provider to reenter the discovery mode and transport provider sends the remainder of the data in messages.

In one embodiment RDMA read is also used in the large receive mode using the same procedure discussed above for the small receive large receive mode. In this mode of operation the receiving transport provider e.g. transport provider may advertise receive buffers to the sending transport provider e.g. transport provider by sending a RDMA receive advertisement in a message. If transport provider receives a RDMA receive advertisement message it must use RDMA write operations that are initiated by the transport provider to transfer data. In this case if the transport provider has already sent out a message to inform the transport provider that data is available to be sent then the transport provider must ignore the RDMA information e.g. the location of the application s set of transmission buffers and the size of the data to be transferred in that message. If the transport provider receives the message that data is available to be sent and it has not already sent a RDMA receive advertisement message then it must refrain from doing so and proceed to transfer data using the RDMA Read operation.

The RDMA receive advertisement message requires an additional message to be exchanged. In one embodiment the RDMA receive advertisement message is combined with a data transfer message sent from application to application . In order to combine the message the transport provider first determines if the application posts large receive buffers before or after the request to send data through messages.

If the large receive buffers are posted before application s request to send data i.e. receive send mode the transport provider takes the following actions.

If the large receive buffers are posted after the application s request to send data i.e. send receive mode the transport provider takes the following actions.

The adaptive flow control protocol automatically detects whether an application is in the send receive mode or the receive send mode. The protocol determines that an application is in send receive mode if 1 the application posts a large receive buffer 2 the application does a send causing the receive posted by application to complete and 3 the application does a small send. The protocol determines that an application is in receive send mode if 1 the application posts a large receive buffer 2 the application performs a small send and 3 the application does a send causing the receive posted by application to complete. Those skilled in the art will appreciate that application may post multiple receive buffers to completely receive the data sent by application .

During data transfers in any of the modes the transport providers send messages to each other concerning both applications requests and responses to send or receive data. There can be instances where these messages become outdated. To account for outdated messages the transport provider on the side that has an application that has already posted a set of receiving buffers of sufficient size to receive multiple messages will only allow one message to be transferred into that set of receiving buffers. Then the transport providers detect outdated information by the steps as follows. 1 The transport provider on the side that is sending data to an application keeps track of the number of messages sent which contain an application s data. 2 The transport provider on the side that is receiving data keeps track of the number of messages received which contain application data and includes this number when it sends a message to the sending side transport provider indicating that the application that is receiving data has a set of receiving buffers posted and the size of the set of receiving buffers posted is large enough for RDMA. 3 The transport provider on the side that is sending data then uses the difference in the number of data messages sent and the number received at the time the transport provider on the side that is receiving data sent the message in step 2 to decide if the set of receiving buffers under question is still available or has been satisfied using data from messages. If it has been satisfied using data from messages then the send side simply discards this message as being outdated.

If the transport providers decide that messages should be used to transfer data or when the transport providers send messages during RDMA data transfers the transport providers must ensure that when one transport provider sends a message the other transport provider has a set of receiving buffers posted to accept the message as the SAN hardware may not have the capability to buffer data.

Turning now to the flow control protocol to synchronize data transfer for messages ensures that a receiving buffer is available when a message is sent by using credits as explained below. For purposes of explanation transport provider is on the side where application is receiving data and transport provider is on the side where application is sending data. The transport provider provides a credit to the transport provider equal to the number of message buffers transport provider has currently posted. Transport provider will not send more messages than this number until it receives more credit. This ensures that a message buffer is always posted when the transport provider sends a message . If no credit is available and the application tries to send data then this operation will either be blocked or data will be buffered internally by the transport provider . If the transport provider needs to send a message when no credit is available then the transport provider will buffer the message until credit becomes available.

The transport provider in the header of each message that it sends includes the number of currently posted message buffers denoted by initials PR for posted receives as indicated by step . If the transport provider is multithreaded it may gain performance advantages by not using locks to synchronize operations on the same socket by different threads. As a result data can become misordered despite the fact that the SAN provider delivers data in order. To account for this each message is also assigned a sequence number to ensure that data is put back into the correct order using the sequence numbers.

The header also includes the sequence number of the last message the transport provider has received before sending this message denoted by the initials LRSQ for last received sequence number . Upon receiving this message the transport provider uses this information to update its send credit as indicated in step according to the formula New send credit where LSSQ last sent sequence number is the sequence number of the last message sent by the transport provider .

In some instances such as sustained uni directional data flow transport provider may run out of send credit and credit cannot be refreshed as part of the data transfer process. In such situations the transport provider on the side where an application is receiving data will send a special credit update control message to transport provider .

There can be situations where transport provider sends a message and runs out of credit. Transport provider realizes that transport provider is out of credit so as soon as one receive buffer is freed up it sends a credit update control message back to transport provider but this only gives transport provider one credit. The cycle keeps repeating and results in high overhead one control message for each data transfer message .

To avoid this situation each transport provider needs to track the other transport provider s send credit. Each transport provider maintains a variable OtherSidesSendCredit which is updated as follows When a transport provider sends a message to the other transport provider then the transport provider sets OtherSidesSendCredit the PR value in the outgoing message s header Upon receiving a message OtherSidesSendCredit OtherSidesSendCredit 1

A credit update message is sent only when the OtherSidesSendCredit falls below a predetermined threshold T and the number of receive buffers posted at the side receiving data is greater than OtherSidesSendCredit by a predetermined threshold T.

If the OtherSidesSendCredit is greater than the predetermined threshold T then no credit update message is required as indicated by step . If the OtherSidesSendCredit is less than the predetermined threshold T then the number of receive buffers is checked. If the number of receive buffers is greater than the predetermined threshold T the transport provider will send a credit update control message to transport provider as indicated by step and step . This ensures that every credit update message causes the sending transport provider s credit to increase by at least T and this avoids the one control message for each data transfer message scenario as long as T is greater than 1.

The value of T is based on the total number of receive buffers allocated per connection. For 10 12 receive buffers a value of 5 6 is exemplary.

The value of T should be chosen so that in case of a unidirectional data flow the receiving side has sufficient time to send a credit update message to the sending side before the sending side blocks the message from being sent due to insufficient send credit. A value of 3 4 is exemplary.

Credit update messages need to be flow controlled themselves to avoid a deadlock where both transport providers end up with zero send credit and even though they have receives posted they cannot update each other s send credit. This deadlock is avoided by only allowing a credit update message to be sent if send credit falls to 1 as indicated by step . If send credit is 1 all messages containing application data are blocked and all other messages other than a credit update message are buffered and queued internally by the transport providers. Then when all the conditions to send a credit update message are satisfied the final credit is used up to update the other transport provider s send credit.

One of the operating systems in which the present invention may be used is the Windows operating system as provided by Microsoft Corporation. In the Windows operating system a socket implementation is required to notify an application through some form of select API e.g. BSD sockets select API Winsock WSAEventSelect or WSAAsyncSelect if the application has registered to be notified when certain events occur. These events are when normal or out of band data is received and no data is buffered on behalf of the application or when data can be sent after it was previously blocked due to flow control a window is closed no credits are available etc. . The select API typically associate a kernel object e.g. a thread to wake up for the case of BSD sockets select API an event to signal in the case of WSAEventSelect or a windows message queue in which to deliver a message in the case of WSAAsyncSelect with the socket implementation for these events. When a socket implementation in the user mode of Windows learns about one of these events it needs to make a call to the kernel mode of Windows i.e. a kernel call just to verify that no select requests are currently outstanding. The net effect of these kernel calls is that a kernel transition is added to nearly every send and receive operation.

The present invention minimizes the number of kernel calls by maintaining a count of select requests that are outstanding. The count is incremented every time a kernel object for the select request is associated with the socket implementation. The count is decremented whenever an association between a kernel object and the socket implementation is broken which occurs whenever the socket implementation signals the kernel object or when the select request association is canceled or undone. A separate counter is used on a per socket basis for each select request associated with sending or receiving data. These select requests are FD READ data is available to receive FD OOB out of band OOB data is available to receive and FD WRITE a window is opening for send e.g. a send is possible .

Turning now to the steps taken to minimize the number of kernel transitions are illustrated. For purposes of illustration the invention will be described for an FD READ select request and the steps will be described sequentially. Additionally the component that implements the socket shall be called a socket application. It should be noted that the steps can be performed sequentially in parallel or a combination of sequential and parallel and that the same or similar steps are performed for the other select requests. Furthermore those skilled in the art will recognize that the socket application may be part of the operating system applications programs or other program modules .

Whenever an application submits an FD READ select request the socket application detects it step and increments a select request counter for the FD READ event on the given socket step . The socket application then takes lock that protects the select request association for the socket and checks to see if the select request has been satisfied step . If the select request has not been satisfied step the socket application associates the select request with the socket releases the lock and then informs the application to wait for the FD READ event of interest step . If the select request has been satisfied the lock is released and the select request counter is decremented. The application select request is then satisfied step . Steps are then repeated whenever a select request has been submitted.

The socket application also determines when an event occurs that triggers a select request step One example of an event occurring is that a sending application sends a message to a receiving application that there is data available to be received. If an event occurs that triggers the select request a flag is set that identifies the FD READ condition so that further requests can be satisfied step . The socket application checks the select request counter to determine if there are any outstanding select requests for the triggered condition e.g. FD READ event step . If the counter is zero the socket application continues to monitor for select requests and events. If the counter is above zero the socket application makes a kernel call to satisfy the select request takes the lock and checks it to see if there are any select request associated with the socket for the event of interest e.g. FD READ and satisfies all of them step . The counter of the outstanding request is then decremented by the number of select requests satisfied step . Steps are then repeated whenever an event occurs.

All of the references cited herein including patents patent applications and publications are hereby incorporated in their entireties by reference.

In view of the many possible embodiments to which the principles of this invention may be applied it should be recognized that the embodiment described herein with respect to the drawing figures is meant to be illustrative only and should not be taken as limiting the scope of invention. For example those of skill in the art will recognize that the elements of the illustrated embodiment shown in software may be implemented in hardware and vice versa or that the illustrated embodiment can be modified in arrangement and detail without departing from the spirit of the invention. Therefore the invention as described herein contemplates all such embodiments as may come within the scope of the following claims and equivalents thereof.

