---

title: Hydra: high-performance data recording architecture for streaming media
abstract: A data stream recorder system, for multi-stream recording and retrieval of utilizes a number of gateways, each for sending and receiving packets containing streaming multimedia content data at real-time rates via a packet data network. A session manager communicates via the network with source client devices and receiver client devices, to establish and control recording and retrieval sessions. The manager assigns sessions to the gateways for the sending and receiving of the packets to and from client devices. Content is distributed across storage devices associated in storage nodes. Each of the gateways receives packets containing content data at real time rates during a recording session and distributes the received packets from the session across all of the storage nodes. A scheduler of each respective storage node distributes content data from packets distributed to the respective storage node, across all of the digital storage devices of the respective storage node.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08370888&OS=08370888&RS=08370888
owner: University of Southern California
number: 08370888
owner_city: Los Angeles
owner_country: US
publication_date: 20050621
---
This application claims the benefit of U.S. Provisional Application No. 60 581 888 filed Jun. 22 2004 entitled HYDRA HIGH PERFORMANCE DATA RECORDING ARCHITECTURE FOR STREAMING MEDIA the disclosure of which also is entirely incorporated herein by reference.

This invention was made with government support under Grant No. EEC 9529152 and IIS 0082826 awarded by the National Science Foundation. The government has certain rights in the invention.

The present subject matter relates to techniques and equipment to provide scalable multi stream digital recording and playback of streaming media type content material capable of efficient handling of multiple concurrent sessions. The recording playback system may also be configured to handle any of a variety of different types of digital streaming media content.

Presently digital continuous media CM are well established as an integral part of many applications. Common applications facilitate distribution of content material prepared off line e.g. movies or TV programs for communication over the Internet. There also is an increasing interest in such communication for a number of different applications areas such as business communications e.g. teleconferencing social interactions entertainment and more. However current implementations of streaming media systems suffer from a number of limitations particularly for such live applications. For example due to processing or bandwidth constraints the picture resolution and quality is limited. Consequently the small rendering of the remote participants does not convey a good sense of presence in the local environment. Current technological trends point towards continued improvements in broadband bandwidth availability and computing resources. As a result high quality live audio and video streaming are becoming feasible. The Integrated Media Systems Center IMSC at the University of Southern California explores such applications in the education communication and entertainment spaces in addition to pursuing basic research.

Two of the main characteristics of digital continuous media CM are that 1 they require real time storage and retrieval and 2 they require high bandwidths and space. Over the last decade a considerable amount of research has focused on the efficient retrieval of such media for many concurrent users for communication of streaming content material prepared and stored in non real time typically off line . Algorithms to optimize issues such as data placement disk scheduling admission control transmission smoothing etc. for efficient retrieval have been reported in the literature.

Almost without exception these prior research efforts assumed that the CM streams were readily available as pre existing files and could be loaded onto the servers offline without the real time constraints that the complementary stream retrieval required. This is certainly a reasonable assumption for many applications where the multimedia streams are produced offline e.g. movies commercials educational lectures etc. . In such an environment streams may originally be captured onto tape or film. Sometimes the tapes store analog data e.g. VHS video and sometimes they store digital data e.g. DV camcorders .

However the current technological trends are such that more and more sensor devices e.g. cameras can directly produce digital data streams. Furthermore some of these new devices are network capable either via wired SDI Firewire or wireless Bluetooth IEEE 802.11x connections. Hence the need arises to capture and store these streams with an efficient data stream recorder that can handle both recording and playback of many streams simultaneously and provide a central repository for all data.

The applications for such a recorder start at the low end with small personal systems. For example the digital hub in the living room envisioned by several companies will in the future go beyond recording and playing back a single stream as is currently done by TiVo and ReplayTV units. Multiple camcorders receivers televisions and audio amplifiers will all connect to the digital hub to either store or retrieve data streams. At the higher end movie production will move to digital cameras and storage devices. For example George Lucas Star Wars Episode II Attack of the Clones was shot entirely with high definition digital cameras. Additionally there are many sensor networks that produce continuous streams of data. For example NASA continuously receives data from space probes. Earthquake and weather sensors produce data streams as do web sites and telephone systems. Systems capable of concurrent recording and playback distribution of high quality streams will also support a variety of real time interactive applications such as videophone and video conferencing.

For large scale data stream recorders a goal is to produce a unified architecture that integrates multi stream recording and retrieval in a coherent paradigm. Existing multi disk continuous media server designs can largely be classified into two different paradigms 1 Data blocks are striped in a round robin manner across the disks and blocks are retrieved in cycles or rounds on behalf of all streams. 2 Data blocks are placed randomly across all disks and the data retrieval is based on a deadline for each block. The first paradigm attempts to guarantee the retrieval or storage of all data. It is often referred to as deterministic. With the second paradigm by its very nature of randomly assigning blocks to disks no absolute guarantees can be made. For example a disk may briefly be overloaded resulting in one or more missed deadlines. This approach is often called statistical.

One might at first be tempted to declare the deterministic approach intuitively superior. However the statistical approach has many advantages. For example the resource utilization achieved can be much higher because the deterministic approach must use worst case values for all parameters such as seek times disk transfer rates and stream data rates whereas the statistical approach may use average values. Moreover the statistical approach can be implemented on widely available platforms such as Windows or Linux which do not provide hard real time guarantees. It also lends itself very naturally to supporting a variety of different media types that require different data rates both constant CBR or variable VBR as well as interactive functions such as pause fast forward and fast rewind. Finally it has been shown that the performance of a system based on the statistical method is on par with that of a deterministic system.

For these reasons further discussion here will focus largely on the statistical approach. It has been shown that the probability of missed deadlines in such a system follows roughly an exponential curve. Hence up to a certain system utilization say 80 a very low stream hiccup probability can be achieved. By the same token it is very important to know how every additional stream will affect the system utilization. Consequently there is a need for a comprehensive admission control algorithm that enables an accurate calculation of the stream hiccup probability and system utilization.

Several issues have been addressed by themselves in academic research. For example the purpose of the Multicast Multimedia Conference Recorder MMCR project was to capture and play back multicast MBone sessions. The authors for that project focused more on the higher level aspects such as indexing and browsing the available sessions while assuming only a small number of concurrent sessions. The MMCR literature did not specifically develop a scalable high performance architecture where resources memory disk space and bandwidth need to be carefully scheduled.

1. Streaming media systems e.g. Microsoft s Windows Media Apple s QuickTime RealNetworks RealOne . These systems are optimized for streaming of previously offline stored content. Some of them also allow real time live streaming i.e. forwarding with no recording . They are designed for multi user access and multiple media types. They cannot usually take advantage of a cluster of server nodes.

2. Personal Video Recorders PVR for example the TiVo and ReplayTV models and the SnapStream software. These systems allow real time recording and playback of standard broadcast quality video. Some of the limitations are that they are designed as single user systems. Furthermore they are optimized for a single media type NTSC PAL SECAM video with two channels of audio . Local playback is supported and with newer models file sharing is enabled over a network. However they do not provide streaming playback over a network.

3. Editing systems and broadcast servers. These systems are the professional cousins of the PVRs. They are used for the production and distribution of video content e.g. to TV stations and they are designed to interface via professional I O standards usually not Ethernet . Their use is for local environments not distributed streaming setups. Most of the time they handle only a few media types and one or a few streams at a time. Their special purpose hardware and elaborate control interfaces to other studio equipment places them into a price category that makes them not cost effective for use as a more general purpose stream recorder.

As indicated none of these categories of available systems provides the full functionality that would be desirable. Each one of them only provides a subset of the desired functionalities.

The Integrated Media Systems Center IMSC at the University of Southern California developed a high performance data recording system as described in Roger Zimmermann Kun Fu and Wei Shinn Ku Integrated Media Systems Center University of Southern California presented at the 5th International Conference on Enterprise Information Systems ICES 2003 Apr. 23 26 2003. However even that system did not provide the full functionality with the desired level of performance and scalability.

In that proposed system the data stream recorder receives the data at a single receiver unit which provides admission control for new streams and optional time stamping of packets. Of particular note the one receiver also provides packet to storage node assignment and routing as well as storage node coordination and communication. The one receiver distributes the incoming data to multiple storage nodes. Each storage node manages one or more local disk storage devices. For incoming packets from the receiver the storage node performs such functions as packet to block aggregation memory buffer management block data placement on each storage device and real time disk head scheduling. Outgoing packets for communication of retrieved content apparently go directly from the storage nodes to the wide area network and thence to the receiving client device s . For example an added function performed as a distributed function by the storage nodes is the retrieval scheduling for each outgoing stream which is assembled from content data retrieved from devices at multiple storage nodes.

The use of a central receiver to process all incoming stream creates a bottleneck at that receiver. Although the architecture can be scaled to store more data by adding storage nodes it is difficult to address issues of bandwidth and session management at the receiver when attempting to handle increased numbers of incoming streams. The coordination of scheduling across multiple storage nodes for each outgoing stream also may present issues as the system scales up to handle more traffic.

A data stream recorder system is provided for real time multi stream recording retrieval and control of multimedia content via a packet data network. The examples provide a unified architecture that integrates multi stream recording and retrieval. To efficiently handle multiple sessions streams and provide a readily scalable architecture the exemplary recorder system utilizes a number of gateways each for sending and receiving packets containing streaming multimedia content data at real time rates via the packet data network. A session manager communicates via the network with source client devices and receiver client devices to establish and control sessions through the packet data network. The manager assigns sessions to the gateways for the sending and receiving of the packets to and from client devices.

The system also includes a number of storage nodes for storing multimedia content data from received packets and for providing stored multimedia content data to the gateways for communication to the receiving client devices. Each respective storage node includes digital storage devices for storage and retrieval of distributed portions of multimedia content data for multiple sessions and a scheduler. The scheduler controls distribution of content data from packets received at the respective node for storage across the digital storage devices of the respective storage node. In such a multimedia recording retrieval system each of the gateways receives packets containing content data at real time rates during a recording session and distributes the received packets from the session across all of the storage nodes. Each scheduler of a respective storage node distributes content data from packets distributed to the respective storage node across all of the digital storage devices of the respective storage node.

In such an architecture the session manager can provide central high level control of all recording and retrieval functions. However the packet streams for the sessions are actually processed through the gateways. For example different gateways handle different groups of sessions. Scaling the system to handle more sessions only requires adding one or more new gateways and appropriately provisioning the session manager to assign sessions to the new gateway s . For large numbers of sessions the gateways also offer a single point of contact and coordination e.g. for each outgoing stream and thus can coordinate retrieval scheduling for each outgoing stream.

Also the session manager may be configured to monitor resource utilization at each of the gateways. In turn the session manager will assign different sessions for sending or receiving different streams to respective gateways based on the current workload and resources available at each of the gateways. For example this assignment can provide load balancing between the gateways. The session manager also implements an admission control algorithm. In the example the session manager uses statistical admission control with respect to each new session to assign each new station to one of the gateways in such a manner as to accommodate variable bit rate VBR streams and multizone disk drives as the digital storage devices.

Examples are disclosed in which the gateways and storage nodes are configured to receive store retrieve and send streaming multimedia content data of multiple different digital media types. Different types of continuous media discussed below include CD quality audio NTSC quality MPEG encoded video HD quality MPEG encoded video digital video DV DVCPRO50 DVCPROHD and high definition camera HDCAM video.

In the disclosed examples of the system each respective storage node includes an element for aggregating content data from received packets into data blocks for storage on the digital storage devices of the respective storage node. This element aggregates content data sequentially from the received packets into the data blocks. In such an implementation the scheduler of each respective storage node randomly assigns the data blocks in sequence to the digital storage devices of the respective storage node. The scheduler may also randomly assign content data from the received packets to the digital storage devices of the respective storage node.

The random distribution by the scheduler may provide block level randomization however the example uses packet level randomization. The randomization by the scheduler may be sufficient to randomly place blocks within the surface of a storage disk in each of the digital storage devices of the respective storage node.

The example may also provide deadline driven scheduling. In such an example the scheduler of each respective storage node provides deadline driven data reading and writing across all of the digital storage devices of the respective storage node. A deadline for each block is formed from a time stamp of the last packet contained in the block plus an offset. For deadline driven retrieval the offset is the time when the retrieval request was admitted into the system. The deadline driven retrieval allows data blocks for an outgoing stream to be retrieved in order of their deadlines and if some deadlines are identical then in scan order. For deadline driven writing to a storage device the offset is determined from the delay that a block is allowed to stay in a main memory buffer until it must output to a digital storage device.

In the example the gateways also provide random distribution. Each gateway receiving streaming multimedia content data for recording in the system via an assigned session randomly distributes blocks of packets received via the assigned session to each of the storage nodes for processing and storage of the streaming multimedia content data from those packets.

The description below also discusses buffer memory management. For example the system may include a shared pool of memory buffers for assembly of incoming packets into the data blocks and for the partitioning of retrieved data blocks into outgoing packets.

The teachings herein also encompass methods of receiving recording and distributing multimedia content at real time rates via a packet data network. An example of such a method might entail establishing first sessions between multiple gateways and source client devices and second sessions between the gateways and receiver client devices via the packet data network. One of the gateways receives a stream of packets containing real time streaming multimedia content data via each first session through the packet data network. The receiving gateway distributes the packets from the received stream to storage nodes. At each storage node payload content data from received packets of the stream is distributed across all of the digital storage devices associated with the respective storage node. For each second session the method involves retrieving the stored content from the storage devices and transmitting packets containing the retrieved content as a real time outgoing stream via one of the gateways and one of the second sessions through the packet data network to at least one of the receiver client devices.

Another disclosed method involves receiving requests to establish sessions for incoming and outgoing streaming media communications via the packet data network and assigning sessions to gateways for establishing first communication sessions through the packet network with source client devices and for establishing second communication sessions through the packet network with receiver client devices. Here the method also involves receiving a stream of packets containing real time streaming multimedia content data via each respective first communication session through the packet data network at the gateway assigned the respective first session. The appropriate gateway distributes the packets from each received stream to the storage nodes where the payload content data from the packets is distributed across the digital storage devices associated with the respective storage node. For each respective second session this method also involves retrieving the stored content from the storage devices and transmitting packets containing the retrieved content as a real time outgoing stream via the gateway assigned the respective second session and through the packet data network to at least one of the receiver client devices.

The methods outlined above can support live interactive communications via the recorder retrieval system. Hence for at least one of the second communication sessions the transmitting of the packets containing the retrieved content as the real time outgoing stream occurs while reception of the particular content data is ongoing via one of the first communication sessions from one of the source client devices. In a video conference example a stream from one location is received stored and relayed to one or more other locations for presentation to other participants in real time to facilitate live viewing. When the conference provides two way communication the parties can view and participate live.

Additional objects advantages and novel features will be set forth in part in the description which follows and in part will become apparent to those skilled in the art upon examination of the following and the accompanying drawings or may be learned by production or operation of the examples. The objects and advantages of the present teachings may be realized and attained by practice or use of the methodologies instrumentalities and combinations particularly pointed out in the appended claims.

In the following detailed description numerous specific details are set forth by way of examples in order to provide a thorough understanding of the relevant teachings. However it should be apparent to those skilled in the art that the present teachings may be practiced without such details. In other instances well known methods procedures components and circuitry have been described at a relatively high level without detail in order to avoid unnecessarily obscuring aspects of the present teachings.

A data stream recorder system is provided for real time multi stream recording retrieval and control of multimedia content via a packet data network. The exemplary recorder provides a unified architecture that integrates multi stream recording and retrieval in a coherent paradigm. We term this architecture HYDRA High performance Data Recording Architecture. The system is optimized to handle multiple concurrent recording and playback sessions. The system also is configured to handle an array of different types of continuous media content. Table 1 illustrates a sampling of continuous media types with their respective bandwidth requirements.

The need for high performance and scalable data stream recorders will arise for many applications. In the discussion of examples below we will describe an architecture that is flexible scalable and incorporates solutions to practical issues. We will outline an admission control algorithm that considers the multizoning the variable seek and rotational latency overhead and the varying read and write performance of the current generation of disk drives. Additionally incoming streams with variable bit rate requirements are supported.

The disclosed system with a data stream recorder enables transmission storage and retrieval playback of video at 1280 720 pixel resolution in HDV format at approximately 20 Mb s over traditional IP networks such as the Internet. For example an MPEG 2 transport stream video may be acquired from a camera via FireWire packetized transmitted and rendered with a software or hardware decoder. Additionally two or more audio channels may be transmitted with the video content. In the past achieving this level of media quality required very costly equipment. However improvements in information technology now permit more cost effective hardware and hence enable many more interesting applications. This live streaming component is part of the high performance data recording architecture HYDRA which enables new applications by acting as an efficient media stream coordinator that manages the transmission recording and playback of many different data streams simultaneously. HYDRA aims to provide the same services for all media independent of their bandwidth requirements resolution or modality. One of the possible applications for the technology is a Distributed Immersive Performance where musicians and audiences are geographically dispersed in different locations. We will also outline additional issues such as the main memory buffer management with a unified pool of buffers synchronization of multiple streams and the write deadline determination of incoming data.

Reference now is made in detail to the examples illustrated in the accompanying drawings and discussed below.

A suitable protocol for audio and video data traffic would be the Real time Transport Protocol RTP on top of the Universal Datagram Protocol UDP . The client recorder dialog that includes control commands such as record pause resume and stop is commonly handled via the Real time Streaming Protocol RTSP . The sources communicate packets to from the recorded via a network such as the wide area network WAN commonly known as the Internet .

The data stream recorder includes two interfaces to interact with data sources 1 a session manager to handle RTSP communications and 2 multiple recording gateways to receive RTP data streams. A data source connects to the recorder by initiating an RTSP session with the session manager .

The session manager utilizes general purposes computer hardware one or more PCs servers or other computer platforms having appropriate Internet connectivity and local area network connectivity for communications within the data stream recorder . In addition to the software implement the function of the session manager the computer platform running the session manager also runs programming for admission control and programming for gateway management. Gateway management and admission control are discussed in more detail later. In this way the session manager performs the following functions within the environment of the recorder system 1 admission control for new streams 2 maintaining RTSP sessions with sources and 3 managing the recording gateways . As part of the session establishment the data source receives detailed information about which recording gateway will handle its data stream. Media packets are then sent directly to this designated gateway bypassing the manager .

The utilization of multiple recording gateways within each stream recorder provides scalability to a large number of concurrent streams and removes the bottleneck caused by having a single entry point for all packets containing data to be recorded within the system. Although two gateways are shown in the example for convenience there may be more such gateways.

The typical recording gateway hardware consists of a computer with two high speed network interfaces. One interface is connected to the network for example the Internet with the source and receiver client devices . The second network interface is used for communication with the gateway manager and storage nodes within the recorder system . The latter type of communication will normally be provided through a high speed LAN.

The recording gateway functionality is implemented in a collection of software modules that are executed in real time. Each recording gateway or performs the following functions a handling of errors during transmissions b time stamping of packets c packet to storage node assignment and routing and d storage node coordination and communication. Although router hardware could be provided in the example the communications to from the storage nodes is implemented as node coordination and packet router programming R R running on the computer that implements the respective gateway functionality .

A recording gateway or handling the stream of incoming continuous media content for a particular recording session forwards distributes incoming data packets from that stream to the storage nodes available within the particular recorder system . The recorder includes a number N that is to say one or more of the storage nodes. In the example there are three such nodes and although there may be only two or more often there will be higher numbers of nodes. Each storage node is a general purpose commuter connected to the LAN in the system which manages one or more local disk storage devices. In the example each node manages two disk devices. Hence storage node manages disk storage devices and . The storage node manages disk storage devices and and the storage node N manages disk storage devices and . Although other storage technologies may be used for purposes of discussion the examples use magnetic disk type devices.

The computer implementing each storage node runs software for aggregation and segregation of content data from and to packets as well as memory management and scheduler software. Those skilled in the art will recognize that the functions of the node e.g. the scheduler and storage devices may utilize different combinations of software and hardware. Hence the functions performed in the storage nodes include i packet to block P2B aggregation ii memory buffer management iii block data placement on each storage device iv real time disk head scheduling and v retrieval scheduling for outgoing streams.

As will be apparent from the above discussion of the architecture aspects of the techniques discussed herein encompass hardware and programmed equipment as well as software programming for performing the relevant functions of the HYDRA type system . The components contained within the computers used to implement the various elements of the system are those typically found in general purpose computer systems used as servers workstations personal computers network terminals and the like. In fact these computers and their components are intended to represent a broad category of such equipment that is well known in the art. The hardware elements operating systems and programming languages of such servers are conventional in nature and it is presumed that those skilled in the art are adequately familiar therewith.

A software or program product may take the form of code or executable instructions for causing a computer or other programmable equipment to perform the relevant steps where the code or instructions are carried by or otherwise embodied in a medium readable by a computer or other machine. Instructions or code for implementing such operations may be in the form of computer instruction in any form e.g. source code object code interpreted code etc. stored in or carried by any readable medium. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media include for example optical or magnetic disks such as typically used to implement any of the digital storage devices storage nodes of the system . Volatile media include dynamic memory such as typically used to implement main memory in any of the relevant computers. Transmission media include coaxial cables copper wire and fiber optics including the wires that comprise a bus within a computer system. Transmission media can also take the form of electric or electromagnetic signals or acoustic or light waves such as those generated during radio frequency or infrared data communications. In addition to storing programming in network or system elements various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to a processor for execution for example to install appropriate software or upgrades thereof in the session manager platform any of the gateway platforms or in any of the storage nodes of the system .

The following is a summary some of the features of the illustrated architecture of the data stream recorder system for real time multi stream recording retrieval and control of multimedia content via a packet data network.

We will now discuss each function in turn. The discussion of the admission control algorithm is deferred because it is an overarching component that relies on many of the other concepts which will be introduced first.

The Real Time Streaming Protocol RTSP provides a well defined set of commands for managing recording sessions. shows a sample RTSP request response exchange for establishing a recording with one audio and one video stream. Once an RTSP session is successfully set up the session manager informs the recording gateways of session details such as port numbers expected bandwidth etc.

The gateway manager coordinates the stream load among the different recording gateways and which are the media stream entry points into the recorder . Each gateway or keeps track of its own resource utilization for example the network bandwidth the CPU utilization and the memory utilization . As part of the stream admission control function the gateway manager is aware of the resource utilization and the current workload of every gateway. A newly entering stream must announce how much bandwidth it expects to use and the gateway manager will assign it to the most appropriate gateway or through a dynamic load balancing algorithm. In turn the assigned gateway will allocate the necessary resources to the incoming stream so that there is no loss of data because of resource over utilization. The session manager works in conjunction with the gateway manager and informs a gateway or whenever a new stream is assigned to it gateways ignore packets that do not have a recognized session ID . If a session is paused resumed or stopped the gateway is also notified by the session manager . The gateway and the managers will typically be implemented as real time software components executing on a networked computer.

The recording gateways are the media stream entry points into the recorder . Each gateway maintains its own available network bandwidth. Different streams are assigned to different gateways based on the current workload and the resources available. The session manager informs a gateway or whenever a new stream is assigned to it. Gateways ignore packets that do not have a recognized session ID. If a session is paused resumed or stopped the serving gateway is also notified by the session manager .

As part of the stream admission control the session manager is aware of the resource utilization of every gateway. A newly entering stream must announce how much bandwidth it expects to use and the session manager will assign it to the most appropriate gateway. In turn the assigned gateway or will allocate the necessary resources to the incoming stream so that there is no loss of data because of resource over utilization.

The recorder architecture accepts data in the form of RTP packets which are usually based on UDP datagrams. UDP is a best effort delivery mechanism and does not provide any guarantees to ensure packet delivery. Since we may be recording content from an original source lost packets are not acceptable as they will be permanently missing from the stored data. There are a number of methods to minimize losses during packet transmission such as Forward Error Control FEC and Retransmission Based Error Control RBEC . There are tradeoffs between the different techniques in terms of the overhead and delay introduced. As an alternative the reliable TCP protocol guarantees packet delivery however it is usually not suitable for real time traffic.

We address this challenge in the exemplary recorder system with a two pronged approach as follows. The original RTP packets are acquired at the server and made available for playback immediately. Therefore live monitoring of sources can be accomplished with minimal end to end delay. At the same time the source client devices contain a sliding buffer of the most recent data such that a retransmission scheme can be used to effectively close the holes missing packets in the stored data after a slight delay. Hence the system can support applications that do not tolerate any missing data in their archived streams e.g. medical imaging . We are also considering an adaptive hybrid approach where a minimal FEC is applied as the first tier and retransmissions are used as a second tier. To allow missing packets to be retransmitted and hence data gaps to be filled will also require that data blocks be kept in memory long enough before they are flushed to persistent storage. Therefore the write deadlines need to be adjusted accordingly and coordination with the memory manager is required. The goal is to achieve a network friendly protocol that is both flexible and provides high performance.

In the example the gateway serving a recording session also functions to time stamp incoming media packets accurately.

With continuous data streams packets need to be time stamped such that the temporal relationship between different parts of a stream can be preserved and later reproduced intra stream synchronization . Such time stamps also help to establish the synchronization between multiple streams inter stream synchronization .

Packets may be time stamped directly at the source. In that case intra stream synchronization will not be affected by any network jitter that a stream experiences during its network transmission to the recorder. However inter stream synchronization with other data originating from geographically different locations requires precise clock synchronization of all locations. One possible solution is to use clock information from GPS Global Positioning System receivers if very precise timing is needed e.g. on the order of microseconds . For synchronization on the order of tens of milliseconds a solution such as the network time protocol NTP may suffice.

If packets are time stamped once they reach the data recorder then the temporal relationship is established between packets that arrive concurrently. Hence if stream A has a longer transmission time than stream B the time difference will be implicitly recorded and if the transmission delays are not identical during playback then any combined rendering of A B will be out of sync. Furthermore with this approach any packet jitter that was introduced by the network will be permanently recorded as part of the stream.

In the illustrated architecture it is possible to record both types of time stamps whenever possible to allow maximum flexibility during playback. In the software implementation we address the synchronization challenges on two levels. First the media server engine functionality of the gateway or is augmented with end to end time code support i.e. from packet generation to block storage. The scheduling mechanism in the storage nodes for retrievals is modified to allow disk retrievals at specific times relative to each other. However synchronized disk block retrieval is no guarantee that the end user display will be synchronized as well especially in the face of network jitters as is common on the Internet. Hence a feedback control mechanism in the gateways and a VBR stream smoothing protocol ensures that synchronization is maintained in a distributed environment and at the rendering locations.

We discuss packet to block aggregation before the packet to storage node assignment even though the two steps happen in reversed order in the actual system. However we believe that from a conceptual point of view the discussion will be easier to understand.

Packet switched networks such as the Internet generally use relatively small quanta of data per packet for example 1400 bytes . On the other hand magnetic disk drives operate very inefficiently when data is read or written in small amounts. This is due to the fact that disk drives are mechanical devices that require a transceiver head to be positioned in the correct location over a spinning platter before any data can be transferred. shows the relative overhead experienced with a current generation disk drive Seagate Cheetah X15 as a function of the retrieval block size. The disk parameters used are shown in Table 2.

The overhead was calculated based on the seek time needed to traverse half of the disk s surface plus the average rotational latency. As illustrated only large block sizes beyond one or two megabytes allow a significant fraction of the maximum bandwidth to be used the fraction is also called effective bandwidth . Consequently incoming packets need to be aggregated into larger data blocks for efficient storage and retrieval. There are two ways this can be accomplished.

Sequential With this scheme incoming packets are aggregated in sequence into blocks. For example if m packets fit into one block then the receiver routing algorithm will send m sequential packets to one storage node e.g. or in the exemplary recorder before selecting another node as the target for the next m packets. As a result each block contains sequentially numbered packets. The advantage of this technique is that only one buffer at a time per stream needs to be available in memory across all the storage nodes. The buffer memory may reside in the computers providing the management at the respective storage nodes controlled as part of the memory management functionality. A pool of buffers also may be provided in each of the gateways.

Random With this scheme each incoming packet is randomly assigned to one of the storage nodes where they are further collected into blocks. One advantage of this technique is that during playback data is sent randomly from all storage nodes at the granularity of a packet. Therefore load balancing is achieved at a small data granularity. The disadvantage is that in the computer s implementing the node control and management functions the memory management software needs to allocate one buffer in the node memory per stream. Furthermore the latency until the first data block can be written to a storage device is about N times longer than in the sequential case where N is the number of storage nodes.

Generally the advantage of needing only 1 N times the memory for the sequential case outweighs the load balancing advantages of the random technique. When many streams are retrieved simultaneously load balancing with the sequential approach i.e. at the granularity of a block should be sufficient.

Random placement of data blocks has been proven to be an effective approach to balance heterogeneous workload in multi disk steaming architectures. However the main disadvantage of this technique is that statistical variation can still result in short term load imbalances in disk utilization. We propose a packet level randomization PLR technique to solve this challenge. We quantify the exact performance trade off between PLR approach and the traditional block level randomization BLR technique through both theoretical analysis and extensive simulation. Our results show that the PLR technique can achieve much better load balancing in scalable streaming architectures by using more memory space.

Packet switched networks such as the Internet transmit relatively small quanta of data per packet for example 1400 bytes . On the other hand magnetic disk drives operate very inefficiently when data is accessed in small amounts. This is due to the fact that disk drives are mechanical devices that require a transceiver head to be positioned in the correct location over a spinning platter before any data can be transferred. The seek time and rotational latency are wasteful. Consequently media packets need to be aggregated into larger data blocks for efficient storage and retrieval. Traditionally this is accomplished as follows.

Media packets are aggregated in sequence into blocks see . For example if m packets fit into one block then the data distribution algorithm will place the first m sequential packets into block X the next m packets into block X and so on. As a result each block contains sequentially numbered packets. Blocks are then assigned randomly to the available disk drives. During retrieval the deadline of the first packet in each block is essentially the retrieval deadline for the whole block. The advantage of BLR is that only one buffer at a time per stream needs to be available in memory across all the storage nodes. In order to allow high disk utilization while still reducing the probability of hot spots we propose a novel technique as follows.

Each media packet is randomly assigned to one of the storage nodes where they are further collected into blocks . One advantage is that during playback data is retrieved randomly from all storage nodes at the granularity of a packet. Therefore load balancing is achieved at a very small data granularity. The disadvantage is that memory buffers need to be allocated concurrently on all nodes per stream.

The difference between the BLR and PLR techniques are illustrated in and . With the traditional BLR technique packets are first aggregated into blocks D. Hence packets appear in sequence in each block D here a block consists of three packets . Subsequently the blocks are randomly assigned to the storage nodes. With PLR however the randomized assignment of packets to the storage nodes takes place first at E. Packets are aggregated into blocks at each storage node individually E and hence packets appear out of sequence in each block E.

To present a single point of contact for each streaming source packets are collected at a recording gateway as indicated earlier. However to ensure load balancing these packets need to be distributed across all N the storage nodes. Storing individual packets is very inefficient and hence they need to be aggregated into larger data blocks as described later.

Once the data is collected into blocks there are two basic techniques to assign the data blocks to the magnetic disk drives to that form the storage system in a round robin sequence or in a random manner. Traditionally the round robin placement utilizes a cycle based approach to scheduling of resources to guarantee a continuous display while the random placement utilizes a deadline driven approach. There has been extensive research investigating both techniques in the context of continuous media stream retrievals. The basic characteristics of these techniques still apply with a mixed workload of reading and writing streams.

In general the round robin cycle based approach provides high throughput with little wasted bandwidth for video objects that are stored and retrieved sequentially e.g. a feature length movie . Block retrievals can be scheduled in advance by employing optimized disk scheduling algorithms during each cycle. Furthermore the load imposed by a display is distributed evenly across all disks. However the initial start up latency for an object might be large under heavy load because the disk on which the starting block of the object resides might be busy for several cycles. Additionally supporting variable bit rate VBR streams and interactive operations such as pause and resume are complex to implement. The random deadline driven approach on the other hand naturally supports interactive functions and VBR streams. Furthermore the start up latency is generally shorter making it more suitable for a real time stream recorder.

Block Size The block size to use in a continuous media server is usually determined in one of two ways a the block size represents a constant data length CDL or b the block size represents a constant time length CTL . With CTL the size in bytes varies if the media stream is encoded with a variable bit rate. Conversely with CDL the amount of playback time per block is variable. A system that utilizes a cycle based scheduling technique works well with CTL whereas a deadline driven system can use either approach. For an actual implementation the fixed block size of CDL makes the design of the file system and buffer manager much easier. Hence a CDL design with random placement and deadline driven scheduling provides an efficient and flexible platform for recording and retrieving streams.

Managing the available memory efficiently is a crucial aspect of any multimedia streaming system. A number of studies have investigated buffer cache management. These techniques can be classified into three groups server buffer management network proxy cache management and client buffer management. illustrates where memory resources are located in a distributed environment.

In a client server architecture memory buffers are located both at the server side F and at the client side for example a playback client device F and a recording client device F . Additional memory buffers may exist within the network infrastructure F. However these buffers appear opaque to end user applications and cannot be utilized as part of the streaming media recording and playback architecture.

When designing an efficient memory buffer management module for a large scale data stream recorder we may classify the problems of interest into two categories 1 resource partitioning and 2 performance optimization. In the resource partitioning category a representative class of problems are What is the minimum memory or buffer size that is needed to satisfy certain streaming and recording service requirements The requirements usually depend on the quality of service expectations of the end user or application environment. In the performance optimization category a representative class of problems are Given certain amount of memory or buffer how to maximize our system performance in terms of certain performance metrics Some typical performance metrics are as follows 

The assembly of incoming packets into data blocks and conversely the partitioning of blocks into outgoing packets requires main memory buffers. In a traditional retrieval only server double buffering is often used. One buffer is filled with a data block that is retrieved from a disk drive while the content of the second buffer is emptied i.e. streamed out over the network. Once the buffers are full empty their roles are reversed. In a retrieval only system more than two buffers per stream are not necessary. However if additional buffers are available they can be used to keep data in memory longer such that two or more streams of the same content started at just a slight temporal offset may share the data. As a result only one disk stream is consumed and more displays can be supported.

With a stream recorder double buffering is still the minimum that is required. However with additional buffers available incoming data can be held in memory longer and the deadline by which a data block must be written to disk can be extended. This can reduce disk contention and hence the probability of missed deadlines see W. Aref I. Kamel T. N. Niranjan and S. Ghandeharizadeh Disk Scheduling for Displaying and Recording Video in Non Linear News Editing Systems Conference pages 228 239 San Jose Calif. February 1997 . SPIE Proceedings Series Volume 3020 introduced an analytical model to calculate the write deadline of a block as a function of the size of the available buffer pool. However their model does not use a shared buffer pool between readers and writers. In a large scale stream recorder the number of streams to be retrieved versus the number to be recorded may vary significantly over time. Furthermore the write performance of a disk is usually significantly less than its read bandwidth see . These factors should be considered in the design model for the memory buffer management module.

The placement of data blocks on a magnetic disk has become an issue for real time applications since disk manufacturers have introduced multizoned disk drives. A disk drive with multiple zones partitions its space into a number of regions that each have a different number of data sectors per cylinder. The purpose of this partitioning is to increase the storage space and allocate more data to the outer regions of a disk platter as compared with the inner regions. Because disk platters spin at a constant angular velocity e.g. 10 000 revolutions per minute this results in a data transfer rate that is higher in the outer zones than it is in the inner ones.

Consequently the time to retrieve or store a data block varies and real time applications must handle this phenomenon. A conservative solution is to assume the slowest transfer rate for all regions. As a result the scheduler in the storage node or need not be aware of the location where a block is to be stored or retrieved. However this approach might waste a significant fraction of the possible throughput. The transfer rate ratio between the innermost and outermost zones sometimes exceeds a factor of 1.5.

A number of techniques have been proposed to improve the situation and harness more of a disk s potential which all attempt to utilize the average transfer rate instead of the minimum. These approaches were designed to work with deterministic scheduling techniques with the assumption that every block access must not exceed a given time span.

However in the context of random assignments of blocks to disks and stochastic dead line driven scheduling this assumption can be relaxed. By randomly placing blocks into the different zones of a disk drive the average transfer rate can easily be achieved. However now the block retrieval times vary significantly. By observing that the retrieval time is a random variable with a mean value and a standard deviation we can incorporate it into the admission control module such that an overall statistical service guarantee can still be achieved. An advantage of the random block to zone data placement is its simplicity and the elegance of using the same random algorithm both within a disk and across multiple disks.

Recall that the effective bandwidth of a magnetic disk drive depends to a large degree on the overhead the seek time and rotational latency that is spent on each block retrieval. The effect of the overhead can be reduced by increasing the block size. However this will result in a higher memory requirement. Conversely we can lower the overhead by reducing the seek time. Disk scheduling algorithms traditionally achieve this by ordering block retrievals according to their physical locations and hence minimize the seek distance between blocks. However in real time systems such optimizations are limited by the requirement that data needs to be retrieved in a timely manner.

In a multimedia server that utilizes random data placement dead line driven scheduling is a well suited approach. Furthermore for a system that supports the recording and retrieval of variable bit rate streams dead line driven scheduling is an efficient way with medium complexity. Cycle based scheduling becomes very complex if different media types are to be supported that require fractional amounts of blocks per round to be accessed.

The deadline driven retrieval allows data blocks for an outgoing stream to be retrieved in order of their deadlines and if some deadlines are identical then in scan order. The scan order refers to the disk head movement across a disk platter. To minimize the seek time between block retrievals blocks with identical deadlines will be picked up in the order in which they pass under the disk head moving from the outermost track to the innermost or vice versa .

For example the SCAN EDF algorithm see A. L. Narashimha Reddy and James C. Wyllie Disk Scheduling in a Multimedia I O System pages 225 233 Anaheim Calif. August 1993 combines earliest deadline first disk head scheduling with a scan optimization. Data blocks are retrieved in order of their deadlines and if some deadlines are identical then the scan order is used. The deadline of a block can be obtained from the time stamp of the last packet that it contains plus an offset. For data retrieval the offset is commonly the time when the retrieval request was admitted into the system. For stream writing the offset needs to be determined from the delay that a block is allowed to stay in a main memory buffer until it must be flushed to a physical disk drive. The SCANRT RW algorithm see W. Aref I. Kamel T. N. Niranjan and S. Ghandeharizadeh Disk Scheduling for Displaying and Recording Video in Non Linear News Editing Systems pages 228 239 San Jose Calif. February 1997 and SPIE Proceedings Series Volume 3020 treats both read and writes in a uniform way and computes the writing deadlines based on the amount of buffer memory available. However it assumes a partitioned buffer pool where some space is allocated exclusively for writing. It should be investigated how a unified buffer pool affects the scheduling performance.

The task of the admission control algorithm implemented in the software is to ensure that no more streams are admitted than the system can handle with a predefined quality. A number of studies have investigated admission control techniques in multimedia server designs. classifies these admission control techniques into two categories measurement based control C and parameter based control C. The parameter based approach can be further divided into deterministic control and statistical control algorithms C and C respectively.

With measurement based algorithms the utilization of critical system resources is measured continually and the results are used in the admission control module. Measurement based algorithms can only work online and cannot be used to offline configure a system or estimate its capacity. Furthermore it is difficult to obtain an accurate estimation of dynamically changing system resources. For example the time window during which the load is measured influences the result. A long time window smoothes out load fluctuations but may overlap with several streams being started and stopped while a short measurement interval may over or underestimate the current load.

With deterministic admission control the worst case must be assumed for the following parameters stream bandwidth requirements disk transfer rate and seek overhead. Because compressed streams such as MPEG 2 may require quite variable bit rates see and the disk transfer rates of today s multizoned disk drives also vary by a factor of up to 1.5 to 1 assuming worst case parameters will result in a significant underutilization of resources in the average case. Furthermore if an operating system without real time capabilities is used service guarantees may be violated even with conservative calculations. Consequently for a more practical approach we focus on statistical admission control where service is guaranteed with a certain probability to not exceed a threshold requested by the user.

Next we describe the statistical admission control algorithm used in our examples. The algorithm called TRAC Three Random variable Admission Control models a much more comprehensive set of features of real time storage and retrieval than previous work. For example this approach provides support for variable bit rate VBR streams illustrates the variability of a sample MPEG 2 movie . The TRAC control algorithm also offers support for concurrent reading and writing of streams. The distinguishing issue for a mixed workload is that disk drives generally provide less write than read bandwidth see . Therefore the combined available bandwidth is a function of the read write mix. We propose a dynamic bandwidth sharing mechanism as part of the admission control.

As another feature TRAC type control provides support for multi zoned disks. illustrates that the disk transfer rates of current generation drives is platter location dependent. The outermost zone provides up to 30 more bandwidth than the innermost one. Modeling of the variable seek time and variable rotational latency that is naturally part of every data block read and write operation. TRAC also offers efficient random data placement.

Consider a server recording n variable bit rate streams using deadline driven scheduling and movie blocks are allocated to disks using a random placement policy. The server activity is observed over time intervals with duration T. Our model is characterized by three random variables 1 D i denotes the amount of data to be retrieved or recorded for client i during observation window T 2 denotes the average disk read bandwidth during Twith no bandwidth allocation to writing and 3 denotes the average disk seek time during each observation time interval T.

Let T i denote the disk seek time for client i during T. Let nand ndenote the number of retrieval and recording streams served respectively i.e. n n n. Also circumflex over R represents the average disk bandwidth in MB s allocated for writing during T while circumflex over R represents the average bandwidth for reading. With such a mixed load of both retrieving and recording clients the average combined disk bandwidth is constrained by circumflex over R circumflex over R Consequently the maximum amount of data that can be read and written during each interval Tcan be expressed by

Note that a missed deadline of a disk access does not necessarily cause a hiccup for the affected stream because data buffering may hide the delay. However we consider the worst case scenario for our computations.

where m denotes the number of seeks and is the average seek time both during T. Because every seek operation is followed by a data block read or write m can also be expressed by

Because of space constraints we do not include all the equations that produce the final calculation of the stream disruption probability for detailed discussions see . Rather we include some of the experimental results that we obtained with a Seagate Cheetah X15 disk drive see Table 3 for parameter values .

The results for the VCD movie Charlie s Angels are shown in . Because of the lower bandwidth requirement of this video a much higher number of streams 150 resp. 200 can be supported. The improvement of 3RV over 1RV is similar to the Twister case.

Any stream recorder will naturally have to support the retrieval of streams as well. Hence it needs to include all the functionality that traditional continuous media servers contain. The framework that we presented so far was deliberately designed to be very complementary to the functionality required for stream retrieval. The combination of random data placement and dead line driven scheduling has been shown previously to be an efficient platform for serving media streams.

For a fully functional data stream recorder a number of additional functions would need to be provided. Such functions include authentication of users and devices editing facilities to create new content browsing facilities to quickly find the content of interest and remote control of recorder functions. These functions are also necessary in a playback only system and therefore are not discussed here in detail.

While the foregoing has described what are considered to be the best mode and or other examples it is understood that various modifications may be made therein and that the subject matter disclosed herein may be implemented in various forms and examples and that the teachings may be applied in numerous applications only some of which have been described herein. It is intended by the following claims to claim any and all applications modifications and variations that fall within the true scope of the present teachings.

