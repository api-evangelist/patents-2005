---

title: Method of allocating bandwidth in an optical network
abstract: A method is provided to allocate bandwidth from a first node to a second node in a optical network. The method begins by accepting a request from an end-user, who requests a virtual path between the first node and the second node. The first and second nodes are ones of a number of such nodes. Each one of the nodes is coupled to at least one other node by at least one of a number of optical links. The nodes and links form the optical network. The virtual path has a bandwidth requirement associated therewith. Next, the service provider determines an amount of bandwidth available between the first and the second nodes. The service provider then allocates at least a portion of the amount of bandwidth available between the first and second nodes equal to the bandwidth requirement, so long as the bandwidth requirement is not greater than the amount of bandwidth available between the first and second nodes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07602807&OS=07602807&RS=07602807
owner: Cisco Technology, Inc.
number: 07602807
owner_city: San Jose
owner_country: US
publication_date: 20050927
---
The present patent application is a continuation of Ser. No. 10 680 940 filed Oct. 7 2003 now U.S. Pat. No. 6 950 391 issued on Sep. 27 2005 entitled METHOD OF ALLOCATING BANDWIDTH IN AN OPTICAL NETWORK which in turn is a continuation of Ser. No. 09 232 396 filed Jan. 15 1999 now U.S. Pat. No. 6 631 134 issued on Oct. 7 2003 entitled METHOD OF ALLOCATING BANDWIDTH IN AN OPTICAL NETWORK and is related to U.S. Pat. No. 6 724 757 issued on Apr. 20 2004 entitled CONFIGURABLE NETWORK ROUTER and U.S. Pat. No. 6 856 627 issued on Feb. 15 2005 entitled A METHOD FOR ROUTING INFORMATION OVER A NETWORK . These related applications are assigned to Cisco Technology Inc. the assignee of the present invention and are hereby incorporated by reference in their entirety and for all purposes.

This invention relates to the field of information networks and more particularly relates to a method for allocating bandwidth in a network.

Today s networks carry vast amounts of information. High bandwidth applications supported by these networks include streaming video streaming audio and large aggregations of voice traffic. In the future these bandwidth demands are certain to increase. To meet such demands an increasingly popular alternative is the use of lightwave communications carried over fiber optic cables. The use of lightwave communications provides several benefits including high bandwidth ease of installation and capacity for future growth.

The synchronous optical network SONET protocol is among those protocols employing an optical infrastructure. SONET is a physical transmission vehicle capable of transmission speeds in the gigabit range and is defined by a set of electrical as well as optical standards. SONET s ability to use currently installed fiber optic cabling coupled with the fact that SONET significantly reduces complexity and equipment functionality requirements gives local and interexchange carriers incentive to employ SONET. Also attractive is the immediate savings in operational cost that this reduction in complexity provides. SONET thus allows the realization of a new generation of high bandwidth services in a more economical manner than previously existed.

SONET networks have traditionally been protected from failures by using topologies that dedicate something on the order of half the network s available bandwidth for protection such as a ring or mesh topology. Two approaches in common use today are diverse protection and self healing rings SHR both of which offer relatively fast restoration times with relatively simple control logic but do not scale well for large data networks. This is mostly due to their inefficiency in capacity allocation. Their fast restoration time however makes most failures transparent to the end user which is important in applications such as telephony and other voice communications. The existing schemes rely on 1 plus 1 and 1 for 1 topologies that carry active traffic over two separate fibers line switched or signals path switched and use a protocol Automatic Protection Switching or APS or hardware diverse protection to detect propagate and restore failures.

A SONET network using an SHR topology provides very fast restoration of failed links by using redundant links between the nodes of each ring. Thus each ring actually consists of two rings a ring supporting information transfer in a clockwise direction and a ring supporting information transfer in a counter clockwise direction. The terms east and west are also commonly used in this regard. Each direction employs it s own set of fiber optic cables with traffic between nodes assigned a certain direction either clockwise or counter clockwise . If a cable in one of these sub rings is damaged the SONET ring heals itself by changing the direction of information flow from the direction taken by the information transferred over the failed link to the sub ring having information flow in the opposite direction.

The detection of such faults and the restoration of information flow thus occurs very quickly on the order of 10 ms for detection and 50 ms for restoration for most ring implementations. The short restoration time is critical in supporting applications such as current telephone networks that are sensitive to quality of service QoS because it prevents old digital terminals and switches from generating red alarms and initiating Carrier Group Alarms CGA . These alarms are undesirable because such alarms usually result in dropped calls causing users down time aggravation. Restoration times that exceed 10 seconds can lead to timeouts at higher protocol layers while those that exceed 1 minute lead to disastrous results for the entire network. However the price of such quickly restored information flow is the high bandwidth requirements of such systems. By maintaining completely redundant sub rings an SHR topology requires 100 excess bandwidth.

An alternative to the ring topology is the mesh topology. The mesh topology is similar to the point to point topology used in internetworking. Each node in such a network is connected to one or more other nodes. Thus each node is connected to the rest of the network by one or more links. In this manner a path from a first node to a second node uses all or a portion of the capacity of the links between those two nodes.

Networks based on mesh type restoration are inherently more capacity efficient than ring based designs mainly because each network link can potentially provide protection for fiber cuts on several different links. By sharing the capacity between links a SONET network using a mesh topology can provide redundancy for failure restoration at less than 100 of the bandwidth capacity originally required. Such networks are even more efficient when traffic transits several links. One study found that for an 11 node 22 span network only 51 redundant net capacity was required for 100 restorability as reported in The design and simulation of an intelligent transport network with distributed control by T. Chujo H. Komine K. Miyazaki T. Ogura and T. Soejima presented at the Network Operations Management Symposium San Diego Feb. 11 14 1990 which is incorporated herein by reference in its entirety and for all purposes. The corresponding ring based design required five rings and a total DS 3 redundancy of 330 . However path restoration often consumes several minutes in such a topology. This is much slower than the restoration times exhibited by ring topologies and is so long that connections are often lost during the outage.

Various kinds of networking equipment can be used to support the ring and mesh topologies just described. Options include 

WDMs may be connected in back to back configurations to allow the connection of various wavelength routes to one another also known as patching or nailing up connections . Provisioning paths in such architectures is done manually using a patch panel. Thus provisioning is slow and prone to mistakes due to human error and equipment failure. In the event of a failure restoration is performed manually in such architectures and is again slow and error prone. Such architectures scale poorly because additional bandwidth is added by either adding to the number of wavelengths supported requiring the replacement of equipment at nodes and possibly the replacement of fiber optic cables as well or adding new fiber optic cables and supporting node equipment. Such architectures are also inherently unmanageable due to the lack of centralized control. And while the initial capital investment tends to be relatively low as a result of their simplicity operating expenses for such architectures tend to be relatively high because of the costs associated with configuration expansion and management. Thus a mesh topology employing back to back WDM s will tend to be slow to deploy and difficult to manage due to the need for manually nailing up paths and lack of centralization.

Another architectural element that may be used to create a mesh topology is the optical cross connect OXC . OXCs allow provisioning using a centralized scheme to accomplish provisioning in a matter of minutes. Restoration in the event of a failure may be performed manually or may be effected using a centralized management system. However restoration still requires on the order of minutes per wavelength route restored. As with the back to back WDM architecture a mesh topology that employs OXCs scales poorly. This is due in part to the exponential increase in the physical size experienced when expanding the capacity of an OXC with the addition of input and output links. For example an OXC that supports two links fiber optic cables each having three paths will need to provide a switching fabric that supports the six possible combinations of connections between the paths carried by the two fiber optic cables. When this number is increased to four paths per fiber optic cable the number of possible connections increases to twenty four. As still more paths are added to each link and more links are supported the possible number of connections increases dramatically increasing the physical size of the affected OXC.

An OXC can be either transparent i.e. purely optical in which the signals are never converted to electrical signals or opaque i.e. the optical signals are converted into electrical signals and then converted back into optical signals . Transparent optical cross connects provide little in the way of manageability because the information carried by lightwave is never made accessible to the OXC s operator. In contrast opaque OXCs can be configured to permit access to the information being switched. However neither type of OXC maintains information regarding the topology of the network and in fact OXCs possess no intrinsic network intelligence. Moreover OXC technology is expensive making initial investment quite high as well as the cost of future expansion.

Alternatively a SONET network may be configured in a ring SHR topology by using add drop multiplexers ADMs . An ADM is a SONET multiplexer that allows DS1 signals to be added into or dropped from an STS N signal. ADMs have two bidirectional ports commonly referred to as an east and a west port. Using ADMs a SONET network in a SHR topology uses a collection of nodes equipped with ADMs in a physical closed loop such that each node is connected to two adjacent nodes with a duplex connection. Any loss of connection due to a single failure of a node or a connection between nodes is automatically restored. The traffic terminated at a failed node however is lost. Two types of SHRs are unidirectional USHR and bidirectional BSHR as defined by the traffic flow in normal conditions. Bidirectional rings have a capacity carrying advantage over unidirectional rings because of the ability to share protection capacity among the links between nodes as opposed to unidirectional rings which dedicate capacity all the way around the ring.

Provisioning in such architectures is centralized and can be performed in minutes. While restoration can also be performed quickly on the order of 50 ms as previously noted 100 spare bandwidth is required. Thus the user must install fiber optic cabling for two networks one for normal traffic and one to be used in the event of a failure. Moreover the cabling for each link should be physically located as far from its corresponding link in order to minimize the possibility that a cause of physical damage will damage both links and cause both directions of a ring to fail. These issues detrimentally affect cost manageability and scalability. With regard to expansion ADMs are stacked in an SHR in order to increase capacity. However stacked ADMs are blocking. In other words the switching function may not allow the transfer of data from a port on one stacked ring to a portion on another ring. Thus an architecture employing ADMs is best suited for small offices or other situations that do not require the relatively large amounts of bandwidth implying the need for stacked ADMs . As noted stacked ADMs are also difficult to manage and expensive due to the extra hardware required for 100 spare capacity.

Other combinations can also be employed. For example WDMs can be combined with OXCs either transparent or opaque in order to create a network having a mesh topology. Such an architecture supports the cross connection of wavelength routes by either manual connection or under centralized control. However such an architecture is also difficult to expand due to the need to add WDMs fiber optic cables and the increase in size of the OXC and cannot restore failed links quickly enough to avoid dropping or interrupting telecommunications connections.

Another option is the use of a digital cross connect system DCS . A DCS is used to terminate digital signals and cross connect them integrating multiple functionalities such as signal adding and dropping cross connection capabilities and multiplexing and demultiplexing of signals. DCS based networks enjoy an advantage over networks employing back to back WDMs because the use of DCS eliminates the need for additional back to back electrical multiplexing thus reducing the need for labor intensive jumpers. Operational cost savings are realized by a DCS through electronically controlling cross connections test access and loopbacks and maintenance. Two types of DCSs are wideband DCSs and broadband DCSs. Wideband DCS W DCS terminates full duplex OC Ns and DS3s has VT cross connection capability and provides DS1 interfaces. A broadband DCS B DCS terminates full duplex OC N signals and provides for example STS 1 and DS3 interfaces. The B DCS makes two way cross connection at the DS3 STS 1 and concatenated STS Nc levels. STS Nc may be used for example in broadband services such as high definition television HDTV where an STS 3c cross connection may be used to cross connect the signal as a single high capacity channel.

Various attempts have been made to use DCSs in a mesh configuration to create a fault tolerant network but none have been successful in reducing restoration times below a few seconds. Some of these configurations rely on a central database and a central controller usually an Operations System or OS to restore failures. Although these schemes often exhibit restoration times exceeding 10 minutes such restoration times are an improvement over manual restoration which requires hours or even days to effect restoration. However these results are not enough to meet the 50 200 ms restoration time required by existing telecommunication network equipment. Other implementations employ distributed architectures in which control is shared among multiple network nodes. This results in faster restoration times on the order of about 2 10 seconds but still does not address the need for restoration times below 200 ms.

The present invention allows a service provider to automatically allocate bandwidth between two of a number of nodes in a network in response to a request by an end user. Each of the nodes is capable of routing information from one carrier signal to another. The network supports the routing of information across the network using those signals to form a circuit. The connection is a virtual path that is provisioned on a physical path. It will be noted that the term virtual wavelength path is used herein to describe a virtual path provisioned using wavelengths of light. The carrier signals e.g. optical signals differ from one another in at least one physical characteristic e.g. wavelength . The carrier signals and so the circuit thus selected can be based on routing information gathered from a user generated by one or more of the nodes or assembled from other sources. The end user need only specify end points and required bandwidth to the service provider in order to determine if the circuit is possible given the current state of the network and to have the circuit provisioned if the requested bandwidth is available between the two nodes. Optionally the end user may also specify other metrics such as cost distance between the two nodes latency quality of service and similar factors.

According to another embodiment of the present invention a method is provided to allocate bandwidth from a first node to a second node in a optical network. The method begins by accepting a request from an end user who requests a virtual path between the first node and the second node. The first and second nodes are ones of a number of such nodes. Each one of the nodes is coupled to at least one other node by at least one of a number of optical links. The nodes and links form the optical network. The virtual path has a bandwidth requirement associated therewith. Next the service provider determines an amount of bandwidth available between the first and the second nodes. The service provider then allocates at least a portion of the amount of bandwidth available between the first and second nodes equal to the bandwidth requirement so long as the bandwidth requirement is not greater than the amount of bandwidth available between the first and second nodes.

According to yet another embodiment of the present invention a method of allocating bandwidth in an optical network is provided. First the service provider determines a bandwidth requirement of a requested virtual path between a first node and a second node. The first and second nodes are ones of a number of nodes. Each one of the nodes is coupled to at least one other node by at least one of a number of optical links. The nodes and links form the optical network. Next a physical path between the first and the second nodes is selected from a number of such physical paths. The service provider then determines whether the physical path has enough available bandwidth to meet the bandwidth requirement of the requested virtual path. The steps of selecting a physical path and determining the available bandwidth for the physical path are repeated until either an acceptable physical path is found or every one of the plurality of physical paths has been selected. If an acceptable physical path is found the acceptable physical path is allocated.

The foregoing is a summary and thus contains by necessity simplifications generalizations and omissions of detail consequently those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting. Other aspects inventive features and advantages of the present invention as defined solely by the claims will become apparent in the non limiting detailed description set forth below.

The use of the same reference symbols in different drawings indicates identical items unless otherwise indicated.

The following is intended to provide a detailed description of an example of the invention and should not be taken to be limiting of the invention itself. Rather any number of variations may fall within the scope of the invention which is defined in the claims following the description.

In addition the following detailed description has been divided into sections subsections and so on in order to highlight the various subsystems of the invention described herein however those skilled in the art will appreciate that such sections are merely for illustrative focus and that the invention herein disclosed typically draws its support from multiple sections. Consequently it is to be understood that the division of the detailed description into separate sections is merely done as an aid to understanding and is in no way intended to be limiting.

Among other benefits router solves three growth related problems often encountered in today s information networks and particularly in SONET networks 

Router is a multi rack fully redundant router that in one embodiment supports at least 256 1 1 I O ports and provides 1 plus 1 protection by using multiple copies e.g. two or more of group and main matrices operating in 1 1 mode. Failures within one copy of a given matrix do not require a complete switchover to the backup copy. Only the affected paths through the matrix are switched to the backup copy. This greatly improves switching speed and minimizes the impact of such redundancy on other connections. Preferably the group matrix is a 2 1 reduction stage that selects output signals from one of two line cards or I O modules and connects the selected output signals to the main matrix thus preventing non working antecedent from consuming any ports on the main matrix.

In one embodiment there are at least three types of processors in a router . The lowest level level 3 resides on the line card also referred to herein as the I O module and is responsible for all real time aspects of the processing of the physical protocol e.g. SONET . In a SONET implementation every level 3 processor is responsible for a single optical signal e.g. an OC 48 signal and via a protocol processor performs all required SONET SDH section and line termination functions. The fast response time required from the level 3 processor makes a firmware implementation preferable. The firmware which may be written in the C or C programming languages assembler or other programming language is preferably optimized for low latency and resource efficiency. Higher level processing is implemented on a separate module the shelf processor module which is shared by several line cards.

The second level of processors level 2 reside on a shelf and main matrix processor modules. The software on the shelf processor module is responsible for managing and controlling line cards. Only half the line cards supported are active at any one time in order to support 1 1 protection. A level 2 processor deals with tasks that require a reasonable response time for example on the order of milliseconds but have no direct impact on the data path. In other words missed events such as hardware interrupts do not result in bit errors. Some of the functions handled by the shelf processor include the periodic collection of maintenance data from the line cards receiving and processing periodic keep alive messages from those cards shelf startup and configuration proxy management and other related functions.

The third processor level level 1 resides on a system processor module and provides system wide management and control services. In one embodiment there are preferably two fully synchronous copies of the level 1 processor in the system both of which are simultaneously active and through a dedicated and redundant high speed link keep their run time and stored databases fully synchronized. One of the two processors is designated the master and is responsible for all level 1 processing. An update message is sent to the second processor whenever a change is made to the database and before that change is effected. A periodic keep alive mechanism allows either copy of the system controller to detect failures on the other copy.

Router provides yet another type of processor referred to herein as a route processor. Such a processor is dedicated to the path route discovery and restoration functions. The route processor is responsible for receiving failure indications from the line cards calculating a new route for failed connections and sending reconfiguration requests to all affected nodes including its own.

In one embodiment router is a multi rack communications system capable of terminating at least 8192 signals and cross connecting at least 4096 OC 48 signals. Such a router can be used for example as SONET SDH line terminating equipment LTE capable of terminating the Section and Line overheads of received OC 48 signals and cross connects those signals according to provisioned input output mappings. Some of the terminated signals can optionally be protected using any of the common protection schemes 1 1 1 1 and 1 N .

Overhead processing and generation is performed on the line card by a protocol processor. This protocol processor handles all aspects of the SONET protocol including framing insertion and extraction of embedded data channels error checking AIS detection pointer processing clock recovery multiplexing duplexing and similar duties.

NOTE The variable identifier N is used in several instances in and subsequent use of other variables such as m x k and others to more simply designate the final element e.g. group matrix N line card N N and so on of a series of related or similar elements e.g. group matrices N line cards N N and so on . The repeated use of such variable identifiers is not meant to imply a correlation between the sizes of such series of elements. The use of such variable identifiers does not require that each series of elements has the same number of elements as another series delimited by the same variable identifier. Rather in each instance of use the variable identified by N or m x k and others may hold the same or a different value than other instances of the same variable identifier. For example group matrix N may be the tenth group matrix in a series of group matrices whereas line card N N may be the forty eighth line card in a series of line cards.

Using signal paths as an example data enters the system at one of line cards N N . It is at this point in a SONET based system the Section and Line overheads are processed and stripped off by a protocol processor not shown . The extracted SONET SDH payload envelope is then synchronized with the system clock and sent to two different copies of a local matrix depicted as group matrices N and N in . In one embodiment group matrices N and N are used mainly as 2 1 reduction stages that select one of two optical signals and pass the selected optical signal to switching matrix . This allows the implementation of a variety of protection schemes including 1 N or 0 1 without having to use any additional ports on main matrix . All protect signals are terminated at group matrices N and N . In order to maximize bandwidth it is preferable that only active signals be passed through to switching matrix .

In one embodiment switching matrix is an errorless rearrangeably non blocking switching network. In one embodiment switching matrix is a 256 256 switching network that consists of three columns and 16 rows of 16 16 switching elements that allow any of their inputs to be connected to any of their outputs. Also preferably a single copy of the matrix is housed in a single rack that contains three shelves one for each column or stage of the matrix. Each shelf contains cards housing the 16 switching elements in each stage. The switching element itself may include for example a 16 16 crosspoint switch with optical transceivers and a microcontroller for controlling the crosspoint switch and providing operational feedback to the level 2 processor. Communications between the two processors may be carried for example over an Ethernet connection. The level 2 processor in turn communicates with the level 1 and route processors using for example a redundant Ethernet connection.

The switching elements in each matrix copy of the exemplary embodiment may be connected using fiber optic cables for example. While copper cabling may also be employed such an option may not offer the speed and number of connections provided by an optical arrangement. After passing through the stages of switching matrix an optical signal may be routed to an I O shelf that optionally splits it into two signals. One of the signals is sent to an active line card while the other when available is sent to a backup card.

Line cards N N receive optical signals from group matrices N and N which are in turn connected to two separate copies of the main matrix. Line cards N N monitor both signals for errors and after a user defined integration period switch to the backup signal if that signal exhibits better bit error rate BER performance than the prior active signal. This scheme referred to herein as 1 plus 1 allows line cards N N to select between the two copies of the group matrix without any level 1 or level 2 CPU intervention. This helps to ensure that such a switch can be made in 50 ms or less per Bellcore s recommendations in GR 253 GR 253 Common Generic Criteria Issue 2 Bellcore December 1995 included herein by reference in its entirety and for all purposes . The selected signal is then processed by the transmit section of the protocol processor which inserts all required transport overhead bytes into the outgoing stream.

Regarding the signals described herein both above and subsequently those skilled in the art will recognize that a signal may be directly transmitted from a first logic block to a second logic block or a signal may be modified e.g. amplified attenuated delayed latched buffered inverted filtered or otherwise converted etc. between the logic blocks. Although the signals of the embodiments described herein are characterized as transmitted from one block to the next other embodiments may include modified signals in place of such directly transmitted signals with the informational and or functional aspect of the signal being transmitted between blocks. To some extent a signal input at a second logic block may be conceptualized as a second signal derived from a first signal output from a first logic block due to physical limitations of the circuitry involved e.g. there will inevitably be some attenuation and delay . Therefore as used herein a second signal derived from a first signal includes the first signal or any modifications to the first signal whether due to circuit limitations or due to passage through other circuit elements which do not substantively change the informational and or final functional aspect of the first signal.

At the bottom of the hierarchy is what is referred to herein as a group matrix or a Group Ethernet Repeater in a system using Ethernet communications and depicted in as group matrices N and N . Each one of group matrices N and N also referred to herein as a hub a repeater or concentrator is a physical layer device and preferably supports a star network topology such as the IEEE 802.3 10BASE T networking standard. The redundant connections from line cards N N in each of groups N are connected to two repeaters that reside on two separate copies of the group matrix module. Preferably each one of line cards N N supports two network ports e.g. 10BASE T Ethernet ports . The two sets of four signals from each port pass through a relay that selects one of them for connection to the LAN for purposes of redundancy.

Shelf switches N and N are the next higher level of the control hierarchy in router and are located on the shelf processor module exemplified by line racks N . Each copy of shelf switches N and N interconnects six connections from the three groups in each shelf another connection from the shelf processor and one connection from system switch and . Shelf switches N and N can be implemented for example using an 8 port Ethernet configured to handle 10 Mbps Ethernet traffic and a single port dual rate switch e.g. 10 Mbps 100 Mbps Ethernet .

The next level of the hierarchy is the system switch in routers using Ethernet based inter processor communications this is referred to as the system Ethernet switch of which there are two copies in each router. These are shown as system switches and in . This fully redundant scheme prevents failures on one shelf switch from taking down the entire control bus. In one embodiment a system switch manages connections from the following sources 

It will be noted that main matrix includes matrix cards N and that more generally main matrices and are included matrix racks N 

System switches and are located in a management bay. As noted the fully redundant switches manage connections from various router elements such as I O and matrix bays level 1 processors and route processors. Each of level 1 processors and and route processors and is preferably connected to system switches and using 100 Mbps Ethernet connections in a configuration that creates an expandable efficient and fully redundant control bus. If more inter processor processor communication bandwidth is required then the connection is preferably a higher speed connection such as that provided by a gigabit Ethernet or fiber channel connection.

A group is made up of line cards occupying a number of slots on a shelf. A slot is also referred to herein as a magazine. In one implementation the group is 20 line cards that occupy five slots. Four of the slots hold for example 16 line cards at 4 per slot. The same slot can be used with a wide variety of I O modules and in various configurations. One example of this flexibility in a SONET configuration is the ability to house an OC 192 I O line card in the same space occupied by four OC 48 line cards. In fact the slots in each group are not required to be of the same type or structure. This architecture provides flexibility to allow any combination of line cards to be installed in each slot.

The fifth slot in the aforementioned embodiment can be configured to accept line cards containing an optical switching matrix and a hub e.g. an Ethernet hub . Preferably two group matrix cards are employed each containing a 2 1 optical reduction stage that selects working channels before the signals leave the shelf. In a 1 1 protection scheme the two inputs to the line cards are classified as active and protect channels. The working channel is one of the active and protect channels that is selected based on bit error rate or other criteria and so implements a redundancy scheme. This prevents the standby line cards from using any bandwidth on switching matrix .

The following describes one embodiment of a backplane and some of the interface signals on that backplane. The backplane in the I O bay shelf carries a variety of signals between line cards and other modules in the shelf. Each I O shelf module is configured to allow an automatic errorless switch from one power bus to the other. Backplane signals that are common to all modules in the I O shelf includes power ground and signal ground.

Shelf processor module backplane signals include reset signals clock signals hardware detect signals e.g. card detect copy present and the like slot ID signals and slot communication signals both low and high speed . I O module line card backplane signals include reset signals clock signals communication signals hardware detect signals and slot ID signals. Group matrix module backplane signals include reset clock signals communication signals both low and high speed detection and hardware detect signals and slot ID signals.

Line card receives optical signals from other network elements via a line side optical receiver and from the local router s system via a system side optical receiver . Each of these receivers implements an optical to electrical O E conversion function. Line card transmits optical signals to other network elements using a line side optical transmitter and to the group matrices using a system side optical transmitter . Each of these transmitters implements an electrical to optical E O conversion function. It will be noted that line side refers to the side of the line card coupled to other network elements and system side refers to the side of the line card coupled to the group matrices.

Line side optical receiver is coupled to a protocol processor which performs clock recovery multiplexing demultiplexing and SONET STE LTE processing in both directions. Similarly system side optical receiver is also coupled to protocol processor to allow protocol processor to receive optical signals. The processed electrical signals from protocol processor are coupled to the transmitters and . The clock recovery functions are combined with demultiplexers and multiplexers to support reception and transmission of the optical data respectively. The multiplexers serialize output data generated in protocol processor by performing parallel to serial conversion on the parallel data. In contrast de multiplexers are used in protocol processor to perform serial to parallel conversion on received data.

In order to add protection channels line side optical transmitter is also coupled to a 1 2 broadcast unit . To receive such optical signals optical receiver is also coupled to a 2 1 selector in order to select the working channel before the optical signals leave the shelf and thus prevent the standby channel also referred to herein as the protect channel from using any bandwidth on switching matrix .

Protocol processor is coupled to a bus . Protocol processor interfaces the line card to two copies of the matrix in a 1 1 physical protocol. In a SONET implementation protocol processor provides both STE LTE processing according to published industry standards. Also coupled to bus are a memory and a CPU . Memory should be fast enough for efficient operation of CPU .

CPU communicates with other of line cards N N over a control bus not shown using a transceiver that is coupled to CPU . Transceiver is coupled to a transformer which is coupled to a switch . Switch is coupled to the control bus. Switch implements a 1 1 protection scheme for transceiver and couples CPU to two independent ports on the backplane not shown . Each of the two ports connects to one copy of the hub of the group matrix. This allows the software on the line card to switch to the backup link when it detects failures on the active link.

Preferably CPU includes numerous integrated peripherals including embedded SCC channels e.g. M band communications and an Ethernet controller for example to support communications with other system modules . In one embodiment CPU provides an onboard communications processor module not shown that handles time critical aspects of the protocols supported.

The group matrix module includes two independent blocks a group matrix and a hub also referred to herein as a repeater .

One or more hubs are also provided to support communication between the group matrices and system switches in router . In an Ethernet communications environment the hub s functions are carried out primarily by repeater interface controllers RICs . Each RIC integrates the functions of a repeater clock and data recovery unit CDR Manchester encoder decoder and transceiver. Each RIC has a set of registers that convey status information and allow a number of configuration options to be specified by the user using for example a microcontroller.

The shelf processor module provides among other elements a shelf processor and switch that interconnect the LAN segments from the groups and the shelf processor to a port on the shelf switch Ethernet switch .

Shelf CPU is also connected to a timer which preferably contains the following three functional blocks 

Ethernet switch is coupled to a transceiver which via a select allows Ethernet switch to connect to two separate Ethernet segments. Select implements a 1 1 protection scheme that allows shelf processor to recover from failures on the active segment by simply switching to the other segment. Ethernet switch is also coupled to one or more group transceivers exemplified by group transceivers and . Group transceivers and connect ports on Ethernet switch to the groups.

One embodiment of a system switch or system Ethernet switch in routers that communicate using Ethernet capable of interconnecting at least 13 network segments in a switched configuration. In an Ethernet based system the system switch supports both 10 Mbps and 100 Mbps connections. The segments come from the shelf switching in the I O shelf and the matrix switches among others and the system switch allows these elements to communicate.

A switching matrix in router is based on a rearrangeable non blocking network. A switching matrix as described herein consists of switch nodes arranged in a staged array. For a 256 256 switching matrix for example switch matrix consists of 48 nodes arranged in an array of 16 rows by 3 columns with each column containing one stage of the switch matrix. All 48 nodes in the switch matrix are substantially similar and consist of a 16 16 crossbar device that allows any of its 16 inputs to be connected to any of its 16 outputs regardless of the current state of the crossbar.

The cross connect information i.e. input to output mapping is written into the crosspoint switch by a local microcontroller which receives it from the local shelf processor over a high speed connection. The three shelf processors in each rack receive such information from the node controller which resides in a different rack. This hierarchy can be extended indefinitely. The crosspoint switch receives a high speed serial data from the optical receivers that perform optical to electrical conversion on the received optical signals. Data from the crosspoint switch is re timed to synchronize the data with the system clock of router using a clock and data recovery CDR unit before being converted back into an optical signal that connects to the next stage of the matrix over fiber optic cables.

The block diagram of switch node in illustrates the main elements of a switch node using a SONET based implementation. The core of the switch node is crosspoint switch which is a 16 16 crossbar switch when implementing a 256 256 matrix. Crosspoint switch is preferably a 2.5 Gbps 16 16 differential crosspoint switch with full broadcast capability. Any of its input signals can be connected to any or all of its output signals. The device is configured through a low speed port that through a two step two stage process allows changes to be made to switch configuration without disturbing its operation.

Assuming 16 input signals indicated in as inputs crossbar switch is configured to receive optical input signals from optical receivers at switch input signals . Crossbar switch also provides switch outputs which serve as the source of optical output signals for switch node . Microcontroller is also responsible for detecting and reporting loss of signal LOS and out of lock OOL conditions from the optical receivers and CDRs respectively. Microcontroller communicates with the shelf processor via transceivers and over a bus that carries asynchronous data over a backplane not shown .

Incoming signals are routed to one of switch outputs by crosspoint switch under the control of microcontroller . Switch outputs are coupled to CDRs which in turn drive optical transmitters . Output signals from optical transmitters appear at outputs as optical signals.

Matrix shelf processor module provides local control and management for one of the main matrix shelves. The matrix shelf processor communicates with the level 1 and route processors over a low speed network connection and with the matrix node cards over a multi drop low speed bus.

All of the above modules are fully redundant and communicate with the rest of router over redundant control buses. The placement of individual modules within the rack is not addressed in this document since there are no architectural preferences or restrictions on such choices.

APB may also be connected to a dual channel serial communication controller SCC which is used to communicate with one or more remote Operations Systems OS using for example the X.25 protocol. For more OS links and higher link speeds the user can optionally install one or more WAN Interface Modules in the management bay. Such modules which preferably handle all real time aspects of the OS link including layer 2 of the OSI stack communicate with the level 1 processor.

In one embodiment router implements many functions in software to provide flexibility support for communications protocols and ease of implementation. The software architecture presented here forms a distributed management control and routing layer capable of spanning hundreds or thousands of nodes. The software architecture covers all protocol layers management and control applications and inter node communication protocols and APIs.

The software modules described herein may be received by the various hardware modules of router for example from one or more computer readable media. The computer readable media may be permanently removably or remotely coupled to the given hardware module. The computer readable media may non exclusively include for example any number of the following magnetic storage media including disk and tape storage media optical storage media such as compact disk media e.g. CD ROM CD R etc. and digital video disk storage media nonvolatile memory storage memory including semiconductor based memory units such as FLASH memory EEPROM EPROM ROM or application specific integrated circuits volatile storage media including registers buffers or caches main memory RAM etc. and data transmission media including computer network point to point telecommunication and carrier wave transmission media. In a UNIX based embodiment the software modules may be embodied in a file which may be a device a terminal a local or remote file a socket a network connection a signal or other expedient of communication or state change. Other new and various types of computer readable media may be used to store and or transmit the software modules discussed herein.

The software running the various processors of router normally includes three major components operating system inter processor and inter node communications and management and control applications. An important aspect of any software architecture is its underlying inter process communications IPC mechanism.

IPCs that provide for the isolation of tasks are preferable. Such IPCs use message passing as their preferred communication. Message passing allows for full but isolated interaction among tasks. To the rest of the system a task no matter how complex is reduced to a simple producer and consumer of messages. It provides a set of well defined services each accessed through one or more messages. Though sometimes visible to other tasks in one embodiment none of a given task s variables and structures should be accessible outside its context. Limiting task interactions to message passing and keeping runtime variables private to each task allows individual software components to evolve independently and in parallel.

In order to keep code generic i.e. system and processor independent the message based IPC should also provide a consistent application programming interface API that doesn t rely on any system specific features or attributes. The API should have the same syntax and behavior regardless of the underlying operating system processor or message passing mechanism used. With certain generating systems for example message queues are used to implement the IPC while on other kernels pipes might be more appropriate. Preferably then the API should provide the following services to the application code 

The last service name lookup and registration makes it possible for communicating entities to reference one another using names rather than task ID s which are system dependent.

A resource manager RM is the software module responsible for collecting information about available resources and monitoring their status during normal system operation. A resource is used generically in this document to refer to any manageable hardware element that performs one or more system functions. The RM builds its resource list from unsolicited information it receives from other modules in the system and from periodic keep alive messages it exchanges with those modules. The RM for example is the first system application notified of card failures insertions and removals.

In one embodiment of router there are two RM versions in the system. The first which runs on the level 1 processor is responsible for managing system resources and in some cases network wide resources. The other version which runs on level 2 processors is responsible for managing resources in a single shelf. This multi level hierarchy creates a flexible and expandable system where lower level resource managers are custom designed for the specific shelf controlled.

The RM maintains information about a given resource in a structure called the Resource Control Block RCB . The RCB consists of two main sections a generic section which is the same for all resources regardless of type and a resource specific section that varies according to resource type. All resource managers maintain a hierarchical list of resource control blocks that represents resources under their control. The list is referred to herein as the resource list and reflects the resources hierarchy and their interdependencies. This allows the RM to determine relatively quickly the effect a given resource s failure has on other members of the hierarchy.

The router preferably runs one or more versions of the Unix operating system on the level 1 processor and the level 2 processors in the I O and matrix shelves . Level processors preferably run a real time version of the Unix operating system OS . Other processors e.g. level 3 route group and matrix node processors preferably run a single task that does not require the services of an operating system or kernel. While Unix operating systems are described herein as being preferable any one of a number of operating systems may be used.

The system controller is responsible for overall system management and control. The system controller uses a variety of protocols to communicate with other nodes in the network including the operating system OS . Some of the protocols satisfy specific requirements e.g. in a SONET based system the transfer of OAM P message across the SONET SDH communications channels DCC while others implement features or functions that are not part of the physical protocol used. To facilitate these functions every router in a network is assigned an ID that uniquely identifies it within the network. The ID can also serve as a priority metric that determines the node s level within the hierarchy. However the network can be configured to allow the user to override this by manually assigning priorities to network nodes. The system controller supports a number of tasks that perform management control and routing functions including resource management OS interfacing various network protocol servers and operations control and intermediate system services.

The matrix shelf processor is responsible for the overall operation of a single main matrix shelf. It communicates with the system controller the route processor and the microcontroller on each of the switch nodes to provide local control and management for the shelf including matrix configuration diagnostics and error reporting. The software on the matrix shelf processor preferably runs under a real time Unix operating system. The RM on the matrix shelf processor is responsible for managing the hardware resources in its shelf. Like other resource managers in the system the level 2 manager on this module uses a combination of hardware and software to discover and maintain a list of available shelf resources. A protocol may be implemented to support such messaging.

In one embodiment fault isolation is implemented by a dedicated task that is responsible for locating failures within the shelf. In a SONET based implementation the software running on the shelf processor with help from the microcontroller on the switch node to determine s the quality of any of the input signals.

The line card terminates an input signal from one of the other nodes in the network. For example in a SONET based implementation a single SONET SDH OC 48 signal is terminated by a line card although other signal levels OC 192 OC 12 and so on may be supported. In one embodiment the software consists of two threads one that runs in the background and is responsible for non time critical tasks. The other thread which runs at the interrupt level is responsible for all real time aspects of the software including limited overhead processing alarm detection and forwarding and fault detection and recovery. The line card processor maintains a copy of its firmware and startup code onboard.

When used in a optical networking context a router such as router and its method of use can support the provisioning of circuits on a wavelength basis. This ability opens a new avenue in the provision of information delivery services by Internet backbone providers inter exchange carriers IXCs bandwidth brokers and similar entities. Varying amounts of bandwidth can be provisioned for varying lengths of time in order to better meet the needs of Internet service providers ISPs long distance carriers private line customers and the like. A router and so network according to the present invention thus permits virtual paths to be provisioned and deprovisioned as necessary allowing the amount of bandwidth and duration of the virtual wavelength path to be tailored to the needs of the end user. This commoditization of bandwidth moves the current sales methodology e.g. selling only dark fiber strands into a new realm. Instead of offering bandwidth only in denominations of unused fiber strands i.e. dark fiber service providers can now sell or lease bandwidth in increments of wavelengths. In a SONET network this enables the sale or lease of single OC 48 C 192 connections. Ultimately this leads to the ability to support a brokered spot market for bandwidth and allows the use of QoS distance source destination latency and other factors to price the requested service.

In terms of the participants in such transactions the growth path proceeds from the ability for carriers to exchange information at an OC 48 rate rather than the much slower DS 3 hand offs currently employed. Indeed such OC 48 services will be easily provided to ISPs and IXCs for routing of voice and data traffic. This will scale up to OC 192 services for both carrier carrier transactions and wholesale re sale and lease e.g. to ISPs . Ultimately OC 48 and then OC 192 services will be made available to retail users businesses and the like on a sale or lease basis.

By provisioning bandwidth in denominations of wavelengths either on demand or in advance for specified durations a service provider is given the flexibility to quickly adapt to fast changing demands placed on its transmission infrastructure by the requirements of services such as virtual private networks Internet telephony large numbers of voice channels increasing numbers of Internet users and the like. Virtual paths can be quickly provisioned to address peaks in demand and then terminated when the excess capacity is no longer necessary. This concept is referred to herein as the Wavelength Brokerage Service WBS concept

The WBS concept combines the optical networking techniques described herein to rapidly provision bandwidth in a communications network incorporating network elements according to the present invention. This enables the ability for a wavelength services provider to provide wavelengths on a spot market brokered basis. Pricing for these services can then be established on a demand quality of service and or time sensitive basis.

The WBS concept employs routers such as router and similar optical network elements to provide the rapid management and control of bandwidth in a communications network on a wavelength basis. These elements are connected together by optical cabling and wave division multiplexers WDMs dense WDMs DWDMs to create a manageable wavelength network. A network capable of providing WBS preferably includes four key elements 

If an acceptable physical path step cannot be provisioned at the time of the request step the service provider then attempts to determine if an acceptable physical path will be available in the future step . If an acceptable physical path will be available in the future and the user is willing to wait step the physical path is allocated at that later time step . Otherwise the connection cannot be provisioned step and the end user must determine if the stated requirements can be relaxed e.g. bandwidth reduced metrics reduced source destination changed or the like step . If so the process begins anew with the new requirements step . Otherwise the requested connection is not provisioned.

Because the WBS concept employs the present invention it provides several key functions for service providers and end users.

While particular embodiments of the present invention have been shown and described it will be obvious to those skilled in the art that based upon the teachings herein changes and modifications may be made without departing from this invention and its broader aspects and therefore the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of this invention. Furthermore it is to be understood that the invention is solely defined by the appended claims.

