---

title: High performance storage device access for non-linear editing systems
abstract: Disclosed are systems and methods for storage device access control initiated by a non-linear editor (NLE). In one embodiment, a storage device access controller can include: a storage device configured to store clips, such as audio, graphics, or video clips, arranged in frames; an NLE coupled to the storage device for requesting one or more of the clips; and a buffer engine coupled to the storage device and the NLE. The buffer engine can include: buffers for storing data from the storage device; a data index for indicating a location of data in a clip on the storage device; and a reader configured to control an access of the data using the data index in response to one or more parameters. Embodiments of the present invention can provide for improved data access performance from a disk where the data is requested in clip form from an NLE.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07769269&OS=07769269&RS=07769269
owner: Sony Electronics, Inc.
number: 07769269
owner_city: Parkridge
owner_country: US
publication_date: 20050913
---
This application claims the benefit of U.S. Provisional Application No. 60 624 940 filed Nov. 3 2004 which is incorporated herein by reference in its entirety.

Non linear editing NLE systems allow users to acquire video graphics and audio clips to manipulate them spatially and temporally and to assemble them into a composite multimedia stream and or file of data. This flexibility inherent in NLEs allows editors to create much of the content seen in theaters on television and on the Internet. Such editors can make complex edited sequences involving multiple layers with effects such as fast and reverse motion video. However such sequences can be especially demanding on the disk subsystem. Further the disk subsystem demand is compounded by the use of High Definition HD video and multiple NLEs used in a networked environment.

Referring now to a conventional picture in picture PiP timeline example as edited within a non linear editor NLE is shown and indicated by the general reference character . A timeline is a spatial and temporal arrangement of video audio and or graphics using an NLE. In the PiP effect view to the left of a spatial arrangement of two video layers V and V is shown. In the timeline view to the right of each video layer is shown in a temporal arrangement as having two video clips or files ordered sequentially. A typical NLE allows the user to apply both spatial as well as temporal e.g. motion effects to each clip individually in the timeline. In this particular example V is scaled to create the PiP effect. Also in this example a reverse motion effect is applied to Clip A and a freeze frame effect is applied to Clip D. Editing of this sort can continue with multiple layers of any duration including audio and graphics type clips.

While a timeline is being edited the NLE may allow the video composition to be visualized or played back. Accordingly the NLE typically must read video frames from the local disk array or storage area network SAN into a specialized hardware device s memory for further effects processing and or outputting to external devices such as a video monitor or tape deck.

Referring now to a conventional timeline and frame access example for the PiP example of is shown and indicated by the general reference character . In typical clip accessing from a disk each frame is read as requested consistent with the timeline as requested by the NLE. Clip A s reverse motion can result in frame accesses Read A Read A Read A and Read A . Also Clip B s forward motion can result in frame accesses Read B Read B Read B and Read B and Clip C s forward motion can result in frame accesses Read C Read C Read C and Read C . Clip D s freeze frame can result in one frame access Read D . Such excessive read patterns from a disk subsystem are not optimized.

It would be desirable to optimize the reads from a disk so that additional layers of video audio and graphics can be sent to the effects processing system for improved editing capabilities. Further more NLE stations in a networked system can function on a SAN when disk throughput is configured optimally thus increasing user productivity and decreasing overall system costs.

In one embodiment a storage device access controller can include a storage device configured to store clips such as audio graphics or video clips arranged in frames a non linear editor NLE coupled to the storage device for requesting one or more of the clips and a buffer engine coupled to the storage device and the NLE. The buffer engine can include buffers for storing data from the storage device a data index for indicating a location of data in a clip on the storage device and a reader configured to control an access of the data using the data index in response to one or more parameters. The storage device can include a disk for example.

In another embodiment a buffer engine can be configured to optimize data access from a storage device when one or more clips are requested by an NLE. The buffer engine can include buffers for storing data from the storage device a data index for indicating a location of data in a clip on the storage device and a reader configured to control the data access using the data index in response to one or more parameters.

In another embodiment a method of translating a storage access request for a clip in a storage device can include detecting a first request to retrieve the clip where the clip has a plurality of frames determining a location of frames in the clip on the storage device by accessing an index forming a second request to retrieve the clip by merging two or more of the frames and accessing the storage device according to the second request. The method may also include the step of determining an alignment of sectors for the frames.

Embodiments of the present invention can provide a system and method for improved data access performance from a disk where the data is requested in clip form from an NLE for example.

In the drawings well known storage device e.g. disk buffer non linear editor NLE and other system and or system component elements are omitted so as to more clearly illustrate embodiments of the invention. Like numbered elements shown in two or more drawings illustrate the same or substantially similar elements.

Referring now to a block diagram of an NLE system suitable for use in accordance with embodiments of the present invention is shown and indicated by the general reference character . For example most of the components of an NLE such as hardware devices and or software modules are shown in . Player can interface with Graphical User Interface GUI Viewers and Renderer . Player may be an NLE or a portion of an NLE for example. Developers can write code to MetaData Application Programming Interface API and timeline API . Hardware Abstraction Layer HAL can provide a uniform interface to control possibly different hardware and may interface to hardware API drivers and software emulation . Buffer engine may receive clips in the form of frames or data from disk .

Disk may be a single disk or an array of disks for example. Alternatively disk may be any storage device including networked storage devices such as a storage area network SAN . Further disk may be a fast array type of disk or any relatively slow access type of storage medium. According to embodiments of the present invention software may be adapted to optimize a read throughput from such a storage medium thereby largely minimizing or eliminating any performance effects due to having a relatively slow storage medium.

Referring now to a block diagram of an NLE system index information and parameter integration in accordance with embodiments of the present invention is shown and indicated by the general reference character . may represent a subset of the NLE system shown above in for example. GUI viewers external controllers can provide information such as a starting frame and a play speed to player as well as interface video graphics array VGA overlay information. A current frame position can be conveyed from player to GUI viewers external controllers . HAL can receive realtime override control from player and can also interface VGA overlay information. GUI knob control panel can provide override control to timeline metadata services and caching . Player can receive index information and parameters from timeline metadata services and caching . The index information can tell player where each requested frame is located on an associated disk. The parameters are tunable and can be provided to player to control or further optimize reads from the disk as will be discussed in more detail below.

Referring now to a block diagram of a buffer engine and an interface to an NLE and index store in accordance with an embodiment of the present invention is shown and indicated by the general reference character . Buffer engine can include reader and memory pool . Memory pool can be any type of random access memory RAM or other suitable storage medium. Memory pool can be broken up or configured into buffers such as buffers . . . buffer N. This buffer configuration e.g. buffer size and number of buffers is one of the tunable parameters that allow for optimization of reads e.g. optimized disk throughput from disk via path . In one implementation the number of buffers can be up to 32 and the buffer size can range from 584 KB to 16 MB.

NLE and index store may interface with buffer engine . NLE can provide requests to retrieve clips of data from storage device or disk for example. Index store can provide index information to buffer engine . This index information can include locations of frames on disk for example. In some embodiments index store may be included within buffer engine . Further data index or index information from index store may be any suitable form of location identification such as a pointer or a table of locations.

Disk queuing may be done using memory pool buffers . . . buffer N and reader . Buffer engine can queue frames of video audio and or graphics based on timeline data and playback position using the group of buffers in memory pool . Buffers . . . buffer N can control how and where blocks of data from disk can be queued for optimal performance. Memory pool can manage a list of read requests including the ability to back map data reads into memory based on the original file offset into the file and the size of the request. Index and tunable parameter information as shown in can be used to facilitate the disk read control. Generally as read requests e.g. from an NLE are queued up memory pool may act to sort the requests based on file and file offset in ascending order for example. Requests may be grouped together based on the tunable parameters to achieve optimal performance. Reader can then be used to initiate a read access from disk and may receive the data via path once a portion of memory pool assigned to a particular buffer e.g. . . . N is queued up full.

Buffers . . . buffer N can be used in a double buffering or other suitable scheme whereby while data is being displayed from one buffer another buffer can be receiving data from disk via path for example. As the number of buffers . . . buffer N is increased more data can be effectively cached going forward for forward play or reverse for reverse motion effect . In one embodiment a serial scheme can be employed whereby buffer can provide data for display while buffer receives data from disk via path for example. This can be reversed for reverse playback and in some applications old data read in to a buffer may be re used during a reverse motion effect situation.

Referring now to a timeline example for data access in accordance with embodiments of the present invention is shown and indicated by the general reference character . Video file A can include header padding . . . padding N N N and frames A A A A . . . frame A N A N A N A N. The padding may be simple padding metadata or audio data for interleaved media files for example. Video file B can include header padding . . . padding N N N and frames B B B B . . . frame B N B N B N B N. In the associated timelines not shown Clip A 4 frames can be followed by Clip B 4 frames . Accordingly the timeline may be queued for playback by reading in the 4 frames from each of Clip A and Clip B.

According to embodiments an optimized read of a clip can include a grouping of two or more frames into one disk access or read. As shown for contiguous reads a read of Clip A can place data frame A padding frame A padding frame A padding and frame A into hardware memory . Following this read of Clip A a read of Clip B can place data frame B N padding N frame B N padding N frame B N padding N and frame B N into hardware memory . Further while some extra or unused data e.g. padding may be read into buffers in addition to the requested frames of data as shown this effect may generally be offset by the increased disk throughput.

Referring now to a timeline example showing frames queued but not yet merged in accordance with embodiments of the present invention is indicated by the general reference character . This example shows a possible final list of queued frames for optimized disk reads for the example of . The frames may be queued in ascending order based on file offset and on a per file basis for example. During the queuing process frame requests may first be sector aligned. The sector aligning is also a tunable or configurable parameter according to embodiments and will be discussed further below.

Referring now to a block diagram example showing multiple video frame queuing in accordance with an embodiment of the present invention is indicated by the general reference character . The positions on the disk can include header padding frame padding frame padding frame padding frame etc. Any requests of non contiguous frames or data can be merged into one request based on a tunable parameter designating the merge distance or how far apart the frame locations can be for a merge to occur. This parameter can essentially control a tradeoff between seeking and making another read versus making one large and contiguous read at the expense of using additional buffer space e.g. some additional data read in by such a larger read may not be passed on to an associated NLE because the NLE did not request this additional data . Among the considerations for application of the merge distance parameter are the seek performance of the disk as well as the amount of buffer memory available. In the example of all four of frames are merged into one large read portion as opposed to making three or four smaller reads. Further while some extra or unused data may be read into buffers as part of the larger read portion this effect may generally be offset by the increased disk throughput.

Generally the sector aligning may be done to accommodate requirements of the storage medium or disk used. For example the disk subsystem may be divided into sectors which are effectively the smallest physical storage units on the disk. Accordingly for a 256B or 512B sector size sector alignment would require alignment to the 256B or 512B addressable boundary respectively. In practice the range of data to be accessed is shifted or extended forward or backward in order to reach an appropriate sector boundary.

Referring now to a timeline example diagram showing PiP queuing with motion effects on Clip A and Clip D in accordance with an embodiment of the present invention is indicated by the general reference character. . This example shows a queued list of frames prior to merging and follows the example shown above in . Once merged however larger and more optimal disk reads can increase disk throughput relative to the multiple frame accesses shown in . In Clip A having a reverse motion effect may still be sorted in ascending file offset even though Clip A may be queued by the buffer engine e.g. buffer engine of in reverse frame order. Accordingly Clip A s frames may be read from the disk in the same fashion as Clip C s frames which has no applied motion effect in this particular example. Also only one frame from Clip D is queued since it has an applied freeze frame effect in this particular example. Because the same frame is shown throughout for Clip D there is no need to repeatedly read from the disk the same frame for the duration of the clip. As discussed above the merge distance parameter can be used to set a data size limit on disk reads.

Once frames are queued and merged by buffer engine see the data can then be read into memory pool e.g. buffers . . . buffer N by reader . In general reader may be data type independent by substantially using file handle file offset and request size information for reads from the disk. As the request list is traversed disk I O calls may be made based on tunable parameters such as a factor configured for more uniform read sizes and a factor configured to control absorption of a smaller read portion into a larger read portion so as to avoid small residual piece reads.

Referring now to a diagram showing exemplary read size parameter adjustment options in accordance with embodiments of the present invention is indicated by the general reference character . An 8.1 MB request read portion is shown in the top of diagram . If the factor configured for more uniform read sizes e.g. MaxReadSize is set at 2 MB the read can be broken up as shown in the middle of diagram and four 2 MB reads can be made followed by a smaller 0.1 MB residual piece read for example. If the factor configured to control absorption of a smaller read portion into a larger read portion e.g. MinReadFactor is set at 256 KB the read can be arranged as shown in the bottom of diagram whereby the 0.1 MB portion is absorbed or combined with the nearest 2 MB data portion and three 2 MB reads can be made followed by one 2.1 MB read for example.

In effect MaxReadSize can control the largest disk I O request to be made. Accordingly if the total request size is larger than MaxReadSize the request can be broken into MaxReadSize blocks and disk I O requests can be made for that size. If the original request is not a multiple of MaxReadSize a residual amount of data may be left such as the 0.1 MB portion shown in the middle of diagram . To prevent having such relatively small blocks of residual data MinReadFactor can be used to regroup this residual data as shown in the bottom of diagram .

Accordingly reader may be able to break up requests that were previously merged in buffer engine . This can be beneficial to disk throughput because of the sizes of individual requests commonly encountered in NLE applications. For example a frame of video for a high density camera HDCAM application may be 584 KB or a frame of audio may be 3202 B for one channel of 48 KHz but it is more optimal to group such frame sizes into portions more suitable for disk access such as 512 KB 1 MB etc. As will be discussed in more detail below such post merge breaking can be beneficial to overall disk throughput.

Another tunable or user controllable parameter is the number of buffers e.g. buffers . . . buffer N of . Generally the size of memory pool is constrained by system costs and or available system or integrated circuit IC space for such memory. However the configuration of memory pool into buffers may typically be altered. According to embodiments at least two buffers may be allocated to allow for double buffering and in this case the largest available buffers can be formed. At the other extreme the smallest buffer size available may be one frame size since a frame is the smallest unit queued by buffer engine according to embodiments.

Several test implementations were performed in accordance with embodiments of the present invention. The tests included changing the number of buffers and the MaxReadSize parameter as discussed above. The tests were performed on a Sony XPRI NLE workstation with one fiber channel disk array using HDCAM video files.

Referring now to a buffer configuration parameter tuning plot for video playing with no motion effect i.e. normal playback for an implementation in accordance with embodiments of the present invention is shown and indicated by the general reference character . In this implementation the MaxReadSize was set larger than the buffer size to ensure that no requests were broken up in the reader module. In a steady increase in disk performance as the buffer size was increased was seen until four 8 MB buffers were used see point . Here about a 9 improvement was seen over the single frame reading case. Also these results were obtained during sustained playback of a video file so the time between disk requests of an 8 MB buffer is half that of a 16 MB buffer. An 8 MB buffer has half the capacity of a 16 MB buffer so half of the number of frames may be stored in an 8 MB buffer meaning the buffers have to load twice as often in order to play for the same duration.

Playing a video file in reverse generally requires reading from near the end of the file seeking back toward the beginning of the file to earlier frames and reading again. Referring now to a disk read and seek illustration for a video clip suitable for analysis of embodiments of the present invention is indicated by the general reference character . The additional seeking involved when reading single frames from a video file is shown. The first number in each box represents the frame number in the file and the second number represents a play out of order. Accordingly for the no motion effect case disk reads are for frames through with a play in order. For the reverse motion effect the disk reads are still for frames through but the play order is reversed and there is a need to seek back twice as far during the reverse motion effect. When buffers are small excessive seeking combined with small reads can cause performance to degrade greatly. Accordingly embodiments of the present invention allow for tunable parameters to also optimize for reverse motion video effects.

Referring now to a buffer configuration parameter tuning plot for video playing with a reverse motion effect for an implementation in accordance with embodiments of the present invention is shown and indicated by the general reference character . Also in this implementation the MaxReadSize was set larger than the buffer size to ensure that no requests were broken up in the reader module. The results seen in this test are more dramatic than those of the forward motion test shown in . In a peak performance point is found at also for the case of four 8 MB buffers.

Referring now to a read size parameter tuning plot using a configuration of 4 buffers of 8 MB each for an implementation in accordance with embodiments of the present invention is shown and indicated by the general reference character . In this implementation the optimal buffer configuration found in the previous tests was used while varying the MaxReadSize. A peak performance point labeled was found for 256 KB read sizes into an 8 MB buffer.

Referring now to a read size parameter tuning plot using a configuration of 4 buffers of 8 MB each for reverse motion video for an implementation in accordance with embodiments of the present invention is shown and indicated by the general reference character . Also in this implementation the optimal buffer configuration found in the previous tests was used while varying the MaxReadSize. A peak performance point labeled was found for 512 KB read sizes into an 8 MB buffer. A total throughput increase of over 13 was found.

Referring now to a flow diagram showing an exemplary method of controlling a disk access in accordance with embodiments of the present invention is indicated by the general reference character . The flow can begin and a request for a clip read from a disk can be made for example by an NLE. Next locations of frames in the clip on the disk can be determined by accessing an associated index . Next sectors may be aligned and the disk access may be queued in the buffer engine. Next parameters may be applied and frames may be merged . The disk can then be accessed in a fashion substantially optimized for disk throughput and the flow can complete .

While the specific implementation and examples discussed above shows specific optimal parameter values this will vary from one system arrangement to another. Thus embodiments of the present invention allow for tunable parameters so that each particular application can be optimized. SANs and other storage devices can relatively easily be optimized using a set of parameters specifically tuned for each device type. Further such a disk buffering system can be employed in other products and or environments based on the file handling and file offset based system approach described herein.

Accordingly embodiments of the present invention allow for optimization of a storage device read throughput particularly for an NLE requesting data from a disk subsystem. Further particular embodiments provide tunable parameters so that the user can optimize for a particular system product environment application or the like.

Although the invention has been described with respect to specific embodiments thereof these embodiments are merely illustrative and not restrictive of the invention. For example various other configurations are possible such as automatic parameter selection instead of user tuned parameters for example. In such an alternate automatic parameter selection embodiment the tool may utilize internal performance tracking features of the disk buffer system. The tool may then cycle through a series of tests while automatically adjusting the tunable parameters to arrive at the optimal set for a particular disk subsystem for example.

Aspects of the invention may be realized on different size scales and or configurations than those presented herein. Although exemplary memory pool and buffer sizes and configurations have primarily been presented other technologies such as macro nano or other designs sizes and or fabrication techniques may be used to advantage in different embodiments. Further while disk subsystems and buffering have been primarily presented herein any type of storage medium including networked storage devices could also be used in accordance with embodiments. Also while data index information is shown as stored in a separate index store this information may be included in the buffer engine itself. Further such index information can be any type of location identification such as pointers tables or any other suitable data location identification mechanism.

In the description herein numerous specific details are provided such as examples of components and or methods to provide a thorough understanding of embodiments of the present invention. One skilled in the relevant art will recognize however that an embodiment of the invention can be practiced without one or more of the specific details or with other apparatus systems assemblies methods components materials parts and or the like. In other instances well known structures materials or operations are not specifically shown or described in detail to avoid obscuring aspects of embodiments of the present invention.

Any suitable programming language can be used to implement the routines of embodiments of the present invention including C C Java assembly language etc. Different programming techniques can be employed such as procedural or object oriented. The routines can execute on a single processing device or multiple processors. Although the steps operations or computations may be presented in a specific order this order may be changed in different embodiments. In some embodiments multiple steps shown as sequential in this specification can be performed at substantially the same time. In addition the sequence of operations described herein can be interrupted suspended or otherwise controlled by another process such as an operating system kernel etc. The routines can operate in an operating system environment or as stand alone routines occupying all or a substantial part of the system processing.

A computer readable medium for purposes of embodiments of the present invention may be any medium that can contain and store the program for use by or in connection with the instruction execution system apparatus system or device. The computer readable medium can be by way of example only but not by limitation an electronic magnetic optical a semiconductor system apparatus system device or computer memory.

A processor or process includes any hardware and or software system mechanism or component that processes data signals or other information. A processor can include a system with a general purpose central processing unit multiple processing units dedicated circuitry for achieving functionality or other systems. Processing need not be limited to a geographic location or have temporal limitations. For example a processor can perform its functions in real time offline in a batch mode etc. Portions of processing can be performed at different times and at different locations by different or the same processing systems.

Reference throughout this specification to one embodiment an embodiment or a specific embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention and not necessarily in all embodiments. Thus respective appearances of the phrases in one embodiment in an embodiment or in a specific embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures or characteristics of any specific embodiment of the present invention may be combined in any suitable manner with one or more other embodiments. It is to be understood that other variations and modifications of the embodiments of the present invention described and illustrated herein are possible in light of the teachings herein and are to be considered as part of the spirit and scope of the present invention.

Embodiments of the invention may be implemented by using a programmed general purpose digital computer by using application specific integrated circuits ASICs programmable logic devices PLDs field programmable gate arrays FPGAs optical chemical biological quantum or nanoengineered systems components and mechanisms may be used. In general the functions of the present invention can be achieved by any means as is known in the art. Distributed networked systems and or components and circuits can be used. Communication or transfer of data may be wired wireless or by any other means.

It will also be appreciated that one or more of the elements depicted in the drawings figures can also be implemented in a more separated or integrated manner or even removed or rendered as inoperable in certain cases as is useful in accordance with a particular application. It is also within the spirit and scope of the present invention to implement a program or code that can be stored in a machine readable medium to permit a computer to perform any of the methods described above.

Additionally any signal arrows in the Figures should be considered only as exemplary and not limiting unless otherwise specifically noted. Furthermore the term or as used herein is generally intended to mean and or unless otherwise indicated. Combinations of components or steps will also be considered as being noted where terminology is foreseen as rendering the ability to separate or combine is unclear.

As used in the description herein and throughout the claims that follow a an and the includes plural references unless the context clearly dictates otherwise. Also as used in the description herein and throughout the claims that follow the meaning of in includes in and on unless the context clearly dictates otherwise.

The foregoing description of illustrated embodiments of the present invention including what is described in the Abstract is not intended to be exhaustive or to limit the invention to the precise forms disclosed herein. While specific embodiments of and examples for the invention are described herein for illustrative purposes only various equivalent modifications are possible within the spirit and scope of the present invention as those skilled in the relevant art will recognize and appreciate. As indicated these modifications may be made to the present invention in light of the foregoing description of illustrated embodiments of the present invention and are to be included within the spirit and scope of the present invention.

Thus while the present invention has been described herein with reference to particular embodiments thereof a latitude of modification various changes and substitutions are intended in the foregoing disclosures and it will be appreciated that in some instances some features of embodiments of the invention will be employed without a corresponding use of other features without departing from the scope and spirit of the invention as set forth. Therefore many modifications may be made to adapt a particular situation or material to the essential scope and spirit of the present invention. It is intended that the invention not be limited to the particular terms used in following claims and or to the particular embodiment disclosed as the best mode contemplated for carrying out this invention but that the invention will include any and all embodiments and equivalents falling within the scope of the appended claims.

