---

title: Shared memory interface in a programmable logic device using partial reconfiguration
abstract: Partial reconfiguration of a programmable logic device is used in combination with a shared memory block for communicating between two blocks of an electronic circuit design. In one embodiment, a shared memory is implemented on RAM resources of a field programmable gate array (FPGA), and a first design block implemented in resources of the FPGA is coupled to the shared memory. A second design block is also coupled to the shared memory. In response to a write request by the second design block, a process determines the RAM resources of the FPGA that correspond to the shared memory address in the write request. A configuration bitstream is generated to include configuration data for partial reconfiguration of the FPGA with the data from the write request at the appropriate RAM resources. The FPGA is partially reconfigured with the configuration bitstream via a configuration port of the FPGA.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07546572&OS=07546572&RS=07546572
owner: Xilinx, Inc.
number: 07546572
owner_city: San Jose
owner_country: US
publication_date: 20050920
---
The present invention generally relates to a shared memory interface implemented in a programmable logic device PLD .

During the process of developing a circuit design the behavior of the design is simulated based on a specification of the circuit design. Simulating the design helps to verify correct behavior prior to physical implementation of the circuit. Wasted manufacturing costs due to faulty design may thereby be avoided.

Numerous tools are available for preparing and simulating circuit designs including for example high level modeling systems HLMSs . Co simulation may also be used when the design may be more efficiently simulated by simulating different parts of the design on different simulation platforms co simulation platforms .

Example co simulation platforms include both software based and hardware based systems. In a software based system a portion of the design is emulated with software running on a workstation for example. In a hardware based co simulation system a portion of the design is emulated on a hardware platform that includes a programmable logic device PLD such as a field programmable gate array FPGA . Co simulation using a hardware platform may reduce the time required for a simulation run while also providing real time hardware verification and debug capabilities. The Modelsim simulator and the NC SIM simulator from Cadence are example software based systems and the Wildcard development platform from Annapolis Microsystems and the Benone development platform from Nallatech are example hardware based systems. The WildCard and Benone platforms are often used for algorithm exploration and design prototyping.

Most design tools recognize and support a hierarchical specification of the design which allows the design to be specified and viewed at different levels of abstraction. The term block is sometimes used to refer to a collection of parts of a design that perform a function. Blocks consume inputs and produce outputs as a function of internal state blocks are connected by arcs and arcs conduct data between blocks. At some level in this hierarchical framework simulating the design involves moving data from one block of the design to another block of the design.

An HLMS such as System Generator for DSP Sysgen from Xilinx Inc. of San Jose Calif. may permit a block of a circuit design to be translated into PLD configuration data that may be used to configure a hardware based co simulation platform. The HLMS may include a hardware co simulation block as a proxy for the hardware based co simulation platform. Like other blocks of the circuit design the hardware co simulation block consumes inputs and produces outputs. The hardware co simulation block transfers the inputs for the block from the HLMS to the hardware based co simulation platform and transfers the outputs of the block from the hardware based co simulation platform to the HLMS.

The overhead associated with the data transfer between the HLMS and the hardware based co simulation platform may limit the performance for the simulation. For example performance may be severely impacted in simulating a system requiring large amounts of data transfer such as real time signal processing applications including video and image processing.

The various embodiments of the invention provide a shared memory interface for blocks of an electronic circuit design by way of partial reconfiguration capabilities of a Programmable Logic Device PLD for example a field programmable gate array FPGA . In one embodiment a shared memory is implemented on RAM resources of a PLD and a first design block implemented in resources of the PLD is coupled to the shared memory. A second design block is also coupled to the shared memory. In response to a write request by the second design block a process determines the RAM resources of the PLD that correspond to the shared memory address in the write request. A configuration bitstream is generated to include configuration data for partial reconfiguration of the PLD with the data from the write request at the appropriate RAM resources. The PLD is partially reconfigured with the configuration bitstream via a configuration port of the PLD.

In other embodiments the partial reconfiguration capabilities of an FPGA are used in combination with a shared memory for simulating a circuit design.

It will be appreciated that various other embodiments are set forth in the Detailed Description and Claims which follow.

A shared memory block may be used to interface between a design block in an HLMS and a design block implemented on a hardware based co simulation platform. The shared memory block may span the software and hardware platforms may be hosted solely on the software platform e.g. a shared memory between two software processes or implemented only on the hardware platform e.g. a shared memory such as a FIFO between two portions of a circuit. In one specific implementation the shared memory block may be implemented on the hardware based co simulation platform as a dual port memory.

Dedicating the two ports of the dual port memory in this manner however limits the design block implemented on the FPGA to use of just one port of the dual port memory i.e. the convenience of having on chip dual port memory is sacrificed . Thus a shared memory block implemented as shown in is limited to a single port interface to the design block which may create unnecessary design complexity.

To provide dual port shared memory functionality the various embodiments of the invention use the partial reconfiguration and readback capabilities of a FPGA to support the interface between the shared memory block on the FPGA and the portion of the design not implemented in FPGA resources e.g. an HLMS block . The Virtex family of FPGAs from Xilinx provides such partial reconfiguration and readback capabilities for example. This leaves both ports of the dual port memory available for use by the design block implemented in the FPGA.

Some FPGAs may have more than one mechanism for providing the functions of the reconfiguration readback port . For example the reconfiguration and readback capabilities may be provided by way of a dedicated input output pin for serial configuration and readback multiple input output pins for parallel transfer of configuration data or boundary scan pins of the FPGA. Each approach requires a specification of a device relative address in order to access the appropriate data on the FPGA. Thus each of the design blocks and operates with shared memory block addresses and for design block to read from or write to the shared memory block the HLMS determines the FPGA relative address from the shared memory block address specified by the design block.

Devices such as the Virtex family of FPGAs from Xilinx support partial configuration and readback. This permits the HLMS to specify and write and read desired portions of the device such as a portion the device corresponding to an addressed part of a shared memory block. The HLMS may use a map of the high level abstraction of the shared memory block to physical resources of the FPGA occupied by the shared memory block. This map may be constructed in compiling the design for co simulation and include for example X and Y coordinates of a resource grid corresponding to resources of the FPGA. Data provided by various compilation tools may be used to construct the map. For example compilation tools from Xilinx may be directed to produce a file of data that maps FPGA primitive types names to the corresponding locations the resources occupy on the FPGA. The HLMS can then correlate the high level abstraction of the shared memory block to these primitives using a string based comparison of names i.e. the name of the high level shared memory block compared to names of FPGA primitives . During simulation the resource mapping table may be further translated into block RAM locations that would be incorporated into the configuration and readback sequences for writing to and reading from the shared memory block.

The HLMS implements the interface between simulated design block and the reconfiguration readback port in a manner that is FPGA dependent and that is suitable for the particular simulation. For writing data by the design block to the shared memory block the HLMS receives from the design block the data to be written and the shared memory address at which the data is to be written. The HLMS generates a partial configuration bitstream to be used to write the data to the FPGA. In one particular approach the partial configuration bitstream may be module based. For example distinct reconfigurable portions of the FPGA may be reconfigured while the rest of the device remains operational each distinct reconfigurable portion is a reconfigurable module. The modules may have device relative requirements for minimum height width and alignment. Along with the configuration data the HLMS generates the device relative address information needed to access the particular reconfiguration module. Known techniques may be used to implement the modular reconfiguration approach. Once the partial reconfiguration bitstream is generated the HLMS issues the commands needed to control the reconfiguration readback port such as for serial parallel or boundary scan input. It will be recognized that the requirements and limitations imposed by a particular device for partial reconfiguration and readback will dictate the approach implemented by the HLMS for writing to and reading from a shared memory block. For example in the Virtex family of devices partial reconfiguration and readback is accomplished through vertical frames and in the Virtex 4 family of devices a finer granularity of partial reconfiguration and readback is provided by way of cell based access.

For reading data from the shared memory block by the design block the HLMS receives from the design block a shared memory block address from which the data is to be read. The HLMS determines the FPGA relative address of the shared memory block and the input shared memory block address and generates the command sequence to read from the FPGA the data referenced by the shared memory block address. The particular command sequence depends on the chosen implementation of the reconfiguration readback port for example serial parallel or boundary scan. From the readback data returned from the reconfiguration readback port to the HLMS the HLMS returns to the design block that data referenced by the input shared memory block address.

In an alternative embodiment an internal reconfiguration readback port may be used to provide an interface to the shared memory block for a design block implemented on the FPGA. illustrates use of the internal reconfiguration readback port of a FPGA for transferring data between design blocks and implemented on the FPGA and the shared memory block. Design block is implemented on a processor embedded in the FPGA and design block is implemented with FPGA configurable logic resources. The internal reconfiguration readback port is accessible to circuits implemented in the configurable logic of the FPGA and to the embedded processor by way of configurable interconnect resources coupled to the port.

Some FPGAs for example the Virtex family of FPGAs have an internal configuration access port ICAP that provides configuration and readback access to configuration resources of the FPGA for logic that is internal to the FPGA. In the example embodiment the internal logic is the design block implemented by way of code that executes on embedded processor . The Virtex II Pro family of FPGAs is an example of FPGAs having embedded processors.

While not shown it will be recognized that processor also executes code that is dependent on the FPGA architecture for mapping an input shared memory block address to a location on the FPGA at which the data of the shared memory block is to be accessed code for generating the partial configuration bitstream and code for controlling configuration and readback modes of the internal reconfiguration readback port. Similarly design block may interface directly with the internal port via interface logic associated with or implemented as part of design block that controls configuration and readback modes of the internal port and that implements the mapping of shared memory block addresses to FPGA resource locations.

A second block is defined and coupled to the shared memory block via the HLMS step . The second design block access the shared memory block via the reconfiguration readback port as described above. and the accompanying description demonstrate an example embodiment for implementing a shared memory block on an FPGA. A tool such as an HLMS may be used to create the first and second design blocks along with the shared memory block and configure the FPGA accordingly.

An application specific testbench may then be used to simulate operation of the first and second design blocks step with the HLMS managing the simulation of design blocks.

Access to the shared memory block by the FPGA implemented design block is by way of the A and B address ports as shown in with an example implementation described in .

In response to a write request to the shared memory block from the second design block step a configuration bitstream is generated to update that part of the FPGA having the shared memory block step . The write request from the design block includes an address of the shared memory block along with the data to be written at that address. From the shared memory block address the correct configuration location on the FPGA is determined for the configuration bitstream. The device location may be determined from the map that indicates the FPGA resources and locations in which the shared memory block is implemented as established during compilation of the design. The address in the write request may be used as an offset from a base location on the FPGA assigned to the shared memory block. Commands are then issued to the reconfiguration readback port and the configuration bitstream is input to the FPGA step . The commands and configuration bitstream input to the reconfiguration readback port specify the partial reconfiguration function the device location at which reconfiguration is to occur and the data to be written to that location.

Reading data from the shared memory block by the second design block is also performed via the reconfiguration readback port. In response to a read request from the second design block step the location of the FPGA of the shared memory block address specified by the read request is determined and the FPGA specific commands are issued to the reconfiguration readback port for reading back the referenced data step . For reading from the shared memory block the manner in which the device location is determined for the requested address in the read request is similar to the manner in which the device location is determined for writing to the shared memory block. The second design block continues the simulation with further processing of the data from the shared memory block as returned via the reconfiguration readback port step .

The circuit design includes design blocks and a co simulation block having a proxy hardware co simulation block in the HLMS and having hardware realization in PLD on the hardware based co simulation platform . The HLMS simulates design blocks in software on a general purpose computer or a collection of networked computers and the co simulation block is simulated in hardware by realization on the hardware based co simulation platform .

Inputs and outputs for the blocks of the circuit design may be communicated during simulation by signals represented by lines . The hardware co simulation block acts as a proxy in HLMS for the hardware realization of the co simulation block. The inputs on lines for the co simulation block are received by the hardware co simulation block and sent to the hardware realization of the co simulation block via board interface layer . The outputs of the hardware realization of the co simulation block are sent via board interface layer to the hardware co simulation block which transmits the outputs on lines .

In addition to communication using signals on lines the design blocks and the hardware co simulation block may communicate during simulation using shared memory blocks such as lockable shared memory blocks . Shared memory blocks such as can be accessed by design blocks and hardware co simulation block via the application programming interface API for shared memory. Shared memory blocks may be locked for exclusive access by one of the design blocks or the hardware co simulation block .

Each lockable shared memory block may have a corresponding hardware memory in the hardware based co simulation platform . The data for a lockable shared memory may be duplicated in the corresponding hardware memory allowing the hardware realization of the co simulation block to access the same data from a hardware memory that a design block can access from the corresponding lockable shared memory block . Thus a lockable shared memory block provides a local copy for the HLMS of data in a memory block of the circuit design and a hardware memory provides a local copy for the hardware based co simulation platform of the data in the memory block.

Because there are two copies and of the data for a memory block data synchronization is required to maintain data coherency. To maintain data coherency the data from a lockable shared memory block may be transferred to the corresponding hardware memory before the hardware realization of the co simulation block begins accessing the hardware memory and subsequently the data from the hardware memory may be transferred back to the lockable shared memory block after the hardware realization of the co simulation block completes accessing the hardware memory . The data transfer in each direction may be a burst data transfer to efficiently utilize the communication link such as PCI or USB between the HLMS computer and the hardware based co simulation platform .

It will be appreciated that certain memory blocks of the circuit design may be accessed only from design blocks and thus do not need to be duplicated in hardware memories . In addition a hardware memory may be comprised of memory resources within PLD an external memory device or various combinations thereof.

During simulation design block accesses the lockable shared memory block via the shared memory API and the design block should lock the lockable shared memory block before access. The lock enforces mutually exclusive access to the lockable shared memory block for example the design block may not obtain the lock from the shared memory API if the lockable shared memory block is already locked by the hardware co simulation block . Conversely the hardware co simulation block may not obtain the lock from the shared memory API if the lockable shared memory block is already locked by the design block . If the lockable shared memory block is already locked a block or requesting the lock may not obtain the lock until the lock is released. Typically a block or releases the lock when the block has completed accessing the lockable shared memory .

Hardware co simulation block acts as a proxy in the HLMS for the hardware realization of the co simulation block. During simulation the hardware co simulation block receives inputs for example inputs A and B on lines and respectively from simulation blocks such as design block . The hardware co simulation block forwards the values of the inputs on lines and to locations zero and one of the memory map interface and locations zero and one are connected to the hardware realization of the co simulation block as corresponding inputs. During simulation the hardware realization of the co simulation block may generate output values for example the output on line sent to location two in memory map interface . The hardware co simulation block may read location two of the memory map interface and forward the value to the output C on line .

To access the data in the memory block the hardware realization of the co simulation block sends a request on line via access manager to location three in the memory map interface . In response to reading the request from location three in the memory map interface the hardware co simulation block locks the lockable shared memory block . The locking of the lockable shared memory block by the hardware co simulation block may be delayed if the lockable shared memory is already locked. After acquiring the lock to the lockable shared memory block the hardware co simulation block reads the data from the lockable shared memory block and forwards the data to the hardware memory in the memory map interface . The data read and or forwarded may be limited to a subset of the data in the lockable shared memory block that includes modified data as is later discussed in detail. After the data forwarding is complete the hardware co simulation block sends a grant to location four of memory map interface . The hardware realization of the co simulation block receives the grant on line via the access manager .

On receiving the grant on line the hardware realization of the co simulation block may process the data in the hardware memory . After completing the processing of the data in the hardware memory the hardware realization of the co simulation block sends a released request on line via access manager to location three in the memory map interface . In response to reading the released request from location three in the memory map interface the hardware co simulation block reads the data from the hardware memory in the memory map interface and forwards the data to the lockable shared memory block . The data read and or forwarded may be limited to a subset of the data in the lockable shared memory block that includes modified data as is later discussed in detail. After the data forwarding is complete the hardware co simulation block unlocks the lockable shared memory and sends a released grant to location four of memory map interface . The hardware realization of the co simulation block receives a released grant on line from the access manager as is later discussed in detail in connection with .

At step the hardware based co simulation platform is idle. At step the hardware realization of the co simulation block requests access to the data in a memory block by asserting a hardware lock request. The hardware realization of the co simulation block waits to receive a hardware access grant before accessing the data for the memory block in a hardware memory.

At step the hardware co simulation block in the HLMS actively polls for a software lock request. On receiving a software lock request resulting from the hardware lock request the HLMS proceeds to step . At step the hardware co simulation block locks the shared memory using a shared memory API. The lock may not be obtained immediately if the shared memory is already locked. On obtaining the lock for the shared memory the HLMS proceeds to step . It will be appreciated that the HLMS may be performing a portion of the simulation including accessing the shared memory in parallel with steps and and the HLMS may be performing a portion of the simulation that does not access the shared memory in parallel with steps and .

At step the hardware co simulation block performs data synchronization between the shared memory block and the hardware memory in the hardware based co simulation platform. After data synchronization the software memory and the hardware memory contain coherent data. Generally the data synchronization transfers to the hardware memory at least the data modified by the HLMS in the shared memory since the previous data synchronization. Typically the transfer uses a burst data transfer such as transferring values for multiple memory locations in each of one or more transactions. At step the hardware co simulation block sends a software grant to the hardware based co simulation platform.

At step the hardware realization of the co simulation block receives a hardware grant resulting from the software grant enabling the hardware realization of the co simulation block to process the data in the hardware memory at step . At step the hardware realization of the co simulation block releases the hardware lock request. Typically the hardware access grant received by the hardware realization of the co simulation block is immediately released.

At step the hardware co simulation block in the HLMS actively polls for a released software lock request. On receiving a released software lock request corresponding to the released hardware lock request the HLMS proceeds to step . At step the hardware co simulation block performs data synchronization between the shared memory and the hardware memory. After data synchronization the software memory and the hardware memory contain corresponding data values. Generally the data synchronization transfers to the shared memory at least the data modified by the hardware realization of the co simulation block in the hardware memory since the previous data synchronization. Typically the transfer uses a burst data transfer. At step the hardware co simulation block unlocks the shared memory using the shared memory API.

Initially the inputs on lines and are released with a deasserted value. The released value for the hardware access request on line causes registers and to be reset releasing the hardware access grant on line and the software access request on line . The assertion of a hardware access request on line combined with the continuing released value for the software access grant on line causes register to no longer be reset and to be enabled by clock enable on line to latch the asserted data input on line . Thus software access request on line is asserted the cycle after the assertion of the hardware access request on line .

Eventually the HLMS responds to the asserted software access request on line with a software access grant on line . The combination of the asserted software access request on line and the asserted software access grant on line causes register to be enabled by clock enable on line to latch the asserted data input on line . Thus hardware access grant on line is asserted the cycle after the assertion of the software access grant on line .

After completing an operation the hardware realization of the co simulation block deasserts the hardware access request on line immediately causing registers and to be reset releasing the hardware access grant on line and the software access request on line . The HLMS may have a delay interval before responding by deasserting the software access grant on line but until the HLMS deasserts software access grant on line register is prevented by clock enable on line from asserting another software access request on line which in turn causes the clock enable on line to prevent register from asserting another hardware access grant on line .

At step a subset of the blocks of a circuit design is simulated on a software platform typically in a HLMS on a general purpose computer. At step another subset of the blocks of a circuit design is simulated in hardware on a hardware based co simulation platform. At step a hardware representation and a software representation are maintained for the data in a memory block. The hardware representation is maintained in hardware memory on the hardware based co simulation platform and the software representation is maintained in memory on the software platform such as lockable shared memory.

At step mutually exclusive access to the data in the memory block is determined. Mutually exclusive access to the data may be provided by appropriate semaphore operations on the general purpose computer such as may be provided by lockable shared memory. Mutually exclusive access to the data of a memory block may be split between the subset of the blocks simulated in software and the subset of the blocks simulated in hardware. In one embodiment mutually exclusive access may be further split between the individual blocks of the subset of blocks simulated in software. While the blocks simulated in hardware are determined to have mutually exclusive access the hardware based co simulation platform may access the data for the memory block using the hardware representation. While a block simulated in software is determined to have mutually exclusive access the software platform may access the data for the memory block using the software representation.

At step prior to mutually exclusive access to the data for the memory block from the hardware based co simulation platform any of the data modified by the software platform is transferred from the software representation to the hardware representation. In addition prior to mutually exclusive access to the data for the memory block from the software platform and typically after the completion of a mutually exclusive access from the hardware based co simulation platform any of the data modified by the hardware based co simulation platform is transferred from the hardware representation to the software representation.

The transferring of the data for the memory block between the hardware and software representations may use a burst data transfer to accomplish efficient data transfer. In one embodiment the modified data may be transferred by unconditionally transferring all of the data for the memory block. In a second embodiment the modified data may be transferred by transferring all of the data for the memory block if any of the data for the memory block is modified. In a third embodiment the modified data may be transferred by transferring a contiguous range of locations for the memory block that includes all of the modified data. In a fourth embodiment the modified data may be transferred by transferring a modification history including a sequence of pairings of location address and update value.

In an example simulation the memory block may accessed by a producer which writes to the memory block but does not read from the memory block and a consumer which reads from the data block but does not write to the memory block. If the producer is a block simulated on the software platform and the consumer is a block simulated on hardware based co simulation platform step need only transfer data from the software representation to the hardware representation. Conversely if the producer is a block simulated on the hardware based co simulation platform and the consumer is a block simulated on software platform step need only transfer data from the hardware representation to the software representation.

In some FPGAs each programmable tile includes a programmable interconnect element INT having standardized connections to and from a corresponding interconnect element in each adjacent tile. Therefore the programmable interconnect elements taken together implement the programmable interconnect structure for the illustrated FPGA. The programmable interconnect element INT also includes the connections to and from the programmable logic element within the same tile as shown by the example .

For example a CLB can include a single programmable interconnect element INT and a configurable logic element CLE that can be programmed to implement user logic. A BRAM can include a BRAM logic element BRL in addition to one or more programmable interconnect elements. One or more of the BRL may be used to implement a shared memory block. The number of interconnect elements included in a tile may depend on the height of the tile. In the pictured embodiment a BRAM tile has the same height as four CLBs but other numbers e.g. five can also be used.

A DSP tile can include a DSP logic element DSPL in addition to an appropriate number of programmable interconnect elements. An IOB can include for example two instances of an input output logic element IOL in addition to one instance of the programmable interconnect element INT . As will be clear to those of skill in the art the actual I O pads connected for example to the I O logic element are manufactured using metal layered above the various illustrated logic blocks and are not confined to the area of the input output logic element .

In the pictured embodiment a columnar area near the center of the die shown shaded is used for configuration clock and other control logic. Horizontal areas extending from this column are used to distribute the clocks and configuration signals across the breadth of the FPGA.

Some FPGAs utilizing the example architecture include additional logic blocks that disrupt the regular columnar structure making up a large part of the FPGA. The additional logic blocks can be programmable blocks and or dedicated logic. For example the processor block PROC spans several columns of CLBs and BRAMs.

Note that FPGA is intended to illustrate only an exemplary FPGA architecture. The numbers of logic blocks in a column the relative widths of the columns the number and order of columns the types of logic blocks included in the columns the relative sizes of the logic blocks and the interconnect logic implementations are examples. For example more than one adjacent column of CLBs may be included wherever the CLBs appear to facilitate the efficient implementation of user logic. It will be appreciated that PLDs having different layouts of CLBs IOBs and interconnect circuitry and the functional equivalents thereof may also implement the various embodiments of the invention described herein.

The MGTs and IOBs may be configurable to support external communication using various communication standards including configurable drive strengths and configurable drive levels. CLBs may each include a look up table that may be configured to implement any logic function that has up to 4 bits of input data and 1 bit of output data. The programmable interconnect elements may be configurable to allow various interconnections between the MGTs IOBs CLBs and BRAMs . The BRAMs may be configurable to implement memory of various types such as dual or single port RAM or read only memory ROM of various sizes and data widths having either synchronous or asynchronous interfaces. In addition BRAMs may be configurable with a set of values for the initial contents of the BRAMs.

Various embodiments of the present invention are described in terms of specific components of a particular instance of a field programmable gate array FPGA . Those skilled in the art will appreciate however that the invention could be implemented in different FPGA architectures other types of programmable logic devices PLDs other than FPGAs integrated circuits that include programmable logic circuitry and or adapted to various application requirements based on both volatile and non volatile technologies.

The present invention is thought to be applicable to a variety of systems for co simulating circuit designs. Other aspects and embodiments of the present invention will be apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. It is intended that the specification and illustrated embodiments be considered as examples only with a true scope and spirit of the invention being indicated by the following claims.

