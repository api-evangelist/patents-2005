---

title: Hyperspectral scene projection/generation systems and methods
abstract: Embodiments of hyperspectral scene projection/generation systems and methods are disclosed. One method embodiment, among others, comprises dispersing a beam of light at one of a plurality of selectable wavelengths, the beam of light corresponding to a scene, and displaying a spectral image of the scene corresponding to the dispersed beam of light at one of the plurality of selectable wavelengths.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07733484&OS=07733484&RS=07733484
owner: The United States of America as represented by the Secretary of the Army
number: 07733484
owner_city: Washington
owner_country: US
publication_date: 20050926
---
The invention described herein may be manufactured used and licensed by or for the United States Government.

The present disclosure is generally related to scene projection generation systems and methods and more particularly is related to hyperspectral scene projection generation systems and methods.

Hyperspectral scene projection generation systems can be used for projection and generation of hyperspectral scenes which provide among other benefits insight into the ability to detect and identify minerals terrestrial vegetation and man made materials and backgrounds at various wavelengths. Actual detection of materials may be dependent on the spectral coverage spectral resolution and signal to noise ratio of the system in addition to the abundance of the material and the strength of absorption features for that material in the wavelength region of interest.

Current hyperspectral scene projection generation systems typically comprise traditional dispersive elements such as gratings and prisms that are rotated and or moved over a defined period of time in order to generate a hyperspectral scene. illustrate an exemplary hyperspectral scene projection generation system that comprises imaging elements or imager configured such that there is relative motion between a scene and the imager elements. The hyperspectral scene projection generation system comprises a light source that generates a scene e.g. a pixellated 2 spatial dimensional 2D triangle as shown comprising white light that includes a mixture of wavelengths through the use of well known systems and methods. The scene may comprise any two or more spatial dimensional collection of objects that is to be imaged. Such a light source may comprise a pixellated light source such as an exemplary light source described further in U.S. Pat. No. 6 485 150 herein incorporated by reference. The hyperspectral scene projection generation system further comprises a slit or thin aperture a grating or prism an imaging lens and a display system . The display system may be configured as a screen on which an imaged scene may be projected a camera and or a video monitor among other devices or systems on which an imaged scene may be captured and or displayed.

The light source provides beams of light corresponding to the generated scene that passes through the slit to the grating . All of the colors of the imaged scene as seen through the slit are diffracted from the grating as it is moved resulting in the formation of the image of the slit on the display system . The display system for example may comprise a camera or detector array coupled to a digital computer to digitize the image and store it and display it on a video monitor. Since there is relative motion between the scene and the imaging system e.g. the slit the grating the lens and the display system as a function of time for example t t this relative movement for example represented symbolically by the two headed arrow under the scene a progressively more complete image of the scene which includes all of the colors of the imaged scene is displayed on the display system as time progresses. Scene images and are generated at respective times t t t t t and t. Each scene image comprises columns each proportioned to the dimension of the slit of each respective color of the incident white length e.g. scene . For example in scene image at time t r represents the color red at a wavelength o represents the color orange at wavelength and so on until the color violet v at wavelength . In other words using a 2 D detector array for the display system one dimension recorded is the spatial dimension of the slit and the other dimension recorded is the wavelength or color due to dispersion. In recording these partial scene images at each time t t the position of pixels corresponding to the different colors can be recorded. That is as shown different colors are incident on different columns of pixels so the color information of the scene image has a column association.

Thus in one exemplary operation at time t a first partial image of the scene is formed on the camera stored on the computer the extent of the first partial image generated in proportion to the dimensions of the slit i.e. a one spatial dimension herein 1 D image . At time t a second partial image of the scene is generated corresponding to another slit dimension to the first image but covering a different portion of the scene due to the movement of the imager. Assuming the display system comprises a camera connected to a digital computer at a time corresponding to t the first partial scene stored in memory of the computer may be combined with the second partial scene during the image cube formation stage as explained below. This process of relative movement and partial scene image recording continues in ordered sequence from t t t and tcorresponding to image scenes and i.e. the wavelengths are in sequential order as a consequence of the diffraction from the grating until the complete scene image covering the entire spectrum is covered.

The left hand side of shows the series of partial scene images generated through the above described operation shown in . The right hand side of illustrates an exemplary process for generating a full image cube of 2 D scene images and each scene image at a respective color of the white light spectrum versus the partial scene images each spanning every color of the white light spectrum . The display system e.g. computer portion adds the pixel column values from each partial scene image to generate a full 2 D scene image at the respective color or wavelength. Thus the result of the computations within the display system is the generation and display of individual 2 D x or t and y spectral scene images generated at each wavelength as illustrated by the dimension axis . Desired wavelengths of the full color scene image are then selected to provide the hyperspectral scene projection generation functionality for individual wavelengths. However such conventional systems typically require moving parts large and time consuming computing requirements e.g. storing processing sorting etc. to retrieve a desired spectral scene image and or local control. Such systems are also inflexible due at least in part to requiring the collection of each scene image at each wavelength to generate a desired spectral scene image.

Embodiments of hyperspectral scene projection generation systems and methods are disclosed. One method embodiment among others comprises dispersing a beam of light at one of a plurality of selectable wavelengths the beam of light corresponding to a scene and displaying a spectral image of a scene corresponding to the dispersed beam of light at one of the plurality of selectable wavelengths.

One system embodiment among others comprises a tunable dispersive device configured to disperse a beam of light at one of a plurality of selectable wavelengths the beam of light corresponding to a scene and a display system configured to display a spectral image of a scene corresponding to the dispersed beam of light at one of the plurality of selectable wavelengths.

Other systems methods features and advantages of the present disclosure will be or become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems methods features and advantages be included within this description and be within the scope of the disclosure.

Disclosed herein are various embodiments of hyperspectral scene projection generation systems and methods herein referred to as a hyperspectral scene projection generation system or systems for brevity. Such hyperspectral scene projection generation systems generate a sequence of images having two or more spatial dimensions each at a single color to form an image cube. Thus at each time interval a spectral image of a scene is formed the spectral scene image comprising at least two spatial dimensions and a third dimension corresponding to wavelength e.g. single wavelength or band of wavelengths corresponding to the respective color of the image . In one implementation spectral scene images can be recorded on a computer as a function of time until an image cube comprising hyperspectral scene images a plurality of spectral scene images covering a defined range of colors is complete. Such a hyperspectral scene projection generation system can perform more efficiently and with greater speed and flexibility than conventional systems since full 2 dimensional spatial image scenes spectral scene images are collected for each wavelength eliminating or reducing computation time and resources and requiring no moving parts. Additionally in such a hyperspectral scene projection generation system wavelengths can be selected through local or remote control sequentially or randomly more than one wavelength can be used and a user is free to generate as few or as many spectral scene images as the application demands.

In one embodiment hyperspectral scene projection generation systems relate a tunable dispersive device operation to the generation and or projection of multi spatial dimension e.g. 2 spatial dimension or herein 2 D spectral scene images at distinct wavelengths forming an image cube comprising hyperspectral scene images. Certain hyperspectral scene images can be used to simulate how an object behaves in a particular color or spectral wavelength. In one embodiment a hyperspectral scene projection generation system comprises a computer controlled acousto optic tunable filter that spectrally filters white light produced and processed by a light source and optic system for display of the processed light on a display system.

The light source can generate a 2 D or more spatial dimension scene e.g. a triangle shown as one among many possible examples . In one embodiment the light source can comprise a two dimensional pixellated broadband light source which covers the electromagnetic spectrum from ultraviolet UV to infrared IR . In some embodiments a light source can be used where only a portion of the UV to IR range is covered or a different electromagnetic range is covered. Each pixel light source can be individually controlled to adjust how much light it emits. The light source can be a white light source with a 2 D screen having holes in it wherein the aperture of each hole can be individually controlled. Other configurations for the light source can be used including a 2 D resistor array of elements where each element can be heated under individual control to emit infrared light a micro mirror device with a 2 D structure where each mirror can be controlled separately or light emitting diodes. Regardless of the light source embodiment used each of the light sources may be operated with or without computer control.

The optic system may comprise one or more filters and lenses. The optic system receives the light from the light source and in one embodiment collimates the received light. The collimated beam of light is filtered and provided to the dispersive device . In some embodiments non collimated beams may be generated and processed.

The dispersive device is coupled to the tuning system through a transducer . The transducer may be for example a thin plate piezoelectric transducer. The tuning system provides an adjustable radio frequency RF signal to the transducer which converts the signal to sound waves. The sound waves cause dispersion of the collimated beam provided by the optic system resulting in the production of beams of light at distinct wavelengths. The tuning system may comprise a computer or other processing device control software and or an RF generator. Through application of an adjustable RF signal to the transducer coupled to the dispersive device the wavelength of the spectral image of the scene generated on the display system can be changed. In other words all the radio frequency change operations can be done seamlessly under computer control locally or from a remote location. In some embodiments manual adjustment can be used in addition to or in lieu of automatic control. Further in response to either manual input or in response to instructions from control software the tuning system can provide sequential changes or random changes or a combination of both to the frequency signal.

In one embodiment the dispersive device comprises a non collinear acousto optic tunable spectral filter. The dispersive device may also comprise an aperture among other elements. Other dispersive devices that are tunable and produce regions of high and low density e.g. compression and rarefaction to produce a grating e.g. phase grating effect based on the tuning signal can be used to obtain images of full 2 D spectral scenes including liquid crystal light filters Fabry Perot interferometers Michaelson interferometers or diffractive optical lenses among other devices.

The light output from the dispersive device at a distinct wavelength passes through the lens e.g. an iris lens and is imaged onto and or in the display system . The display system may comprise a projection screen video monitor computer and or a 2 D detector array e.g. as provided in a camera . For example the display system may comprise a charge coupled device CCD camera and a computer. The CCD camera may be coupled to a frame grabber to digitize the analog output of the camera and the digitized images can be stored on a computer. The operation of the dispersive device and or display system may be manually operated or automated or a combination of both forms of control.

It will be understood that the hyperspectral scene projection generation system illustrated in provides an overview of an exemplary embodiment of a hyperspectral scene projection generation system and in some embodiments may include fewer greater and or different components.

The optic system may comprise in one embodiment a spatial filter and lenses and . The lenses and collimate a light beam provided by the light source and filtered by the spatial filter . That is the light e.g. scene image from the light source is incident on the spatial filter which can comprise an aperture or iris. The spatial filter spatially filters the light beam. The spatially filtered beam passes through the lenses and e.g. configured as two plano convex or convex lenses providing a collimated beam of a size equal to an input aperture of the acousto optic tunable filter

The acousto optic tunable filter can be comprised of a specially cut birefringent crystal prism. The transducer can be bonded on one side of the crystal and an acoustic absorber can be bonded on the opposite facet. One of many different types of crystals may be used in the acousto optic tunable filter . Such different crystal types can cover various wavelengths included in for example the ultraviolet to infrared region. Such crystals may be fabricated in high purity single crystals of KDP ADP quartz MgF2 TeO2 LiNbO3 TAS Hg2Cl2 Hg2Br2 etc.

When a radio frequency signal is applied to the transducer from the tuning system it generates an ultrasonic wave that travels through the crystal and is absorbed at the other end by the acoustic absorber . The ultrasonic wave is represented in using lines . The traveling sound wave in the crystal creates regions of high and low density the regions acting like a grating and thus incident light is diffracted in an anisotropic diffraction process wherein white light can be filtered into different colors of diffracted light based on the applied radio frequency.

There are generally two types of acousto optic tunable filters collinear and noncollinear. In a noncollinear filter incident and diffracted light and acoustic beams do not travel in the same direction. In a collinear filter the beams travel in the same direction. The diffracted optical wavelength for collinear or non collinear filters is inversely proportional to the applied radio frequency. Thus the wavelength of the diffracted light can be changed by changing the applied radio frequency.

For a white light collimated incident beam that is incident normal to the input facet of the acousto optic tunable filter configured in this illustrated embodiment as a non collinear filter at least three beams and come out of the crystal. These include two diffracted beams and at defined angles with respect to the incident beam with orthogonal polarization at a defined wavelength corresponding to the applied radio frequency. The third beam is referred to as a zero order beam which contains all the light except the amount that was diffracted at the particular optical wavelengths.

Light output from the acousto optic tunable filter passes through an aperture external to the acousto optic tunable filter to pass only one of the diffracted beams and block the other two beams and . In some embodiments such an aperture may be integrated with the acousto optic tunable filter . The diffracted beam passes through the lens e.g. an iris lens and is imaged onto and or in the display system .

In some embodiments a collinear acousto optic tunable filter may be used. For a collinear acousto optic tunable filter a polarizer may be positioned before the collinear acousto optic tunable filter and an analyzer may be positioned after the collinear acousto optic tunable filter. A polarizer and an analyzer can be used to separate the incident light and a zero order beam from a diffracted beam.

The acousto optic tunable filter or like configured dispersive devices has several features including no moving parts the ability to generate a multi spatial dimension scene image at a defined wavelength i.e. a spectral image of a scene at one time without using any motion the ability to generate a spectral image of a scene by changing the wavelength sequentially or randomly also locally or remotely and the ability to generate a complex spectral content scene image by applying multiple radio frequencies to the transducer simultaneously. Another feature of the acousto optic tunable filter is the ability to generate many spectral frames in a brief period of time e.g. approximately 100 000 or more spectral frames per second . Further spectral scene images can be generated at distinct wavelengths of choice instead of generating hundreds of spectral images of a scene to fill an image cube.

A scene on the pixellated light source may show a variety of things for example represented as a 2 D triangle as in and is generated by pixellated light source . As described above in association with an incident light beam corresponding to the scene on light source is presented to the optic system where it is collimated and filtered to provide a light beam to the acousto optic tunable filter . The acousto optic tunable filter receives a control signal from the tuning system via the transducer to cause diffraction of the incident light beam. The diffracted beam at a defined wavelength provided by the acousto optic tunable filter passes through the aperture and lens . The lens focuses the resulting beam onto the display system .

Two dimensional spectral scene images and at distinct wavelengths are imaged onto the display system . At a first instance of time t corresponding to wavelength a red r triangle is the displayed 2 D x and y dimensioned spectral scene image because the frequency of the control signal provided to the acousto optic tunable filter from the tuning system via the transducer causes only the diffracted beam corresponding to the red wavelength to reach the display system . Similarly at a second instance in time t corresponding to wavelength an orange o triangle is the displayed 2 D spectral scene image because the frequency of the control signal provided to the acousto optic tunable filter from the tuning system via the transducer causes only the diffracted beam corresponding to the orange wavelength to reach the display system . Spectral scenes images yellow y triangle green g triangle blue b triangle and violet v triangle at respective instances of time t t t t etc. are similarly imaged using the same method. Thus each image has spatial dimensions of x and y at respective time or wavelength dimensions as represented by dimension axis .

The scene generation change can be performed rapidly. For example using the acousto optic tunable filter as an example dispersive device changes in scene generation can occur in a time equal to the time it takes for the ultrasonic beam to traverse through a crystal of the acousto optic tunable filter . The amount of time for the ultrasonic beam to traverse a crystal depends on the size of the crystal and the velocity of the sound wave in the defined direction. For example in a TAS crystal the acoustic velocity is 100 000 centimeters second and thus it takes approximately 10 microseconds for the acoustic wave to traverse a 1 centimeter length of the crystal. At this rate the acousto optic tunable filter can process approximately 100 000 spectral scene images per second. The spectral scene images can be generated either sequentially or randomly. The tuning system can also simultaneously apply multiple radio frequencies to the acousto optic tunable filter via transducer which results in the generation and projection of a compound spectral effect.

In view of the above description it will be appreciated that one embodiment of a hyperspectral scene projection generation method may comprise as illustrated in creating a scene of interest directing a beam corresponding to the scene of interest to a dispersive device tuning the dispersive device to cause diffraction of the beam at the desired spectral wavelength which provides the scene image corresponding to a desired spectral wavelength and displaying a multi spatial dimension scene image corresponding to the desired spectral wavelength .

Another embodiment of a hyperspectral scene projection generation method may comprise as illustrated in creating a scene of interest collimating a beam corresponding to the scene of interest directing the beam to an acousto optical filter applying an adjustable radio frequency signal corresponding to a desired spectral wavelength to the acousto optical filter via a transducer coupled to the acousto optical filter to cause diffraction of the beam at the desired spectral wavelength filtering out beams corresponding to undesired spectral wavelengths passing beams corresponding to the desired spectral wavelength through a lens and displaying a multi spatial dimension scene image corresponding to the desired spectral wavelength .

Another embodiment of a hyperspectral scene projection generation method may comprise as illustrated in dispersing a beam of light at one of a plurality of selectable wavelengths the beam of light comprising a scene and displaying a spectral image of a scene corresponding to the dispersed beam of light at one of the plurality of selectable wavelengths .

Any process descriptions or blocks in the flow diagrams as described in should be understood as representing steps modules segments or portions of code which include one or more executable instructions for implementing specific logical functions or steps in the process and alternate implementations are included within the scope of the preferred embodiments in which functions may be executed out of order from that shown or discussed including substantially concurrently or in reverse order depending on the functionality involved as would be understood by those reasonably skilled in the art.

It should be emphasized that the above described embodiments of the present disclosure particularly any preferred embodiments are merely possible examples of implementations merely set forth for a clear understanding of the principles of the disclosed systems and methods. Many variations and modifications may be made to the above described embodiment s without departing substantially from the principles of the systems and methods. All such modifications and variations are intended to be included herein within the scope of this disclosure.

