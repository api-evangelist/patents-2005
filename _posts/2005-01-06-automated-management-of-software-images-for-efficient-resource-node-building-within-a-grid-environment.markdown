---

title: Automated management of software images for efficient resource node building within a grid environment
abstract: A grid service detects a current software environment for a grid job within a grid environment, wherein the grid environment includes multiple grid resources. The grid service searches a catalog of multiple software images to determine whether an image for the current software environment matches any software images in the catalog. Each of the software images includes an index into at least one installation image. Storage of the software images is structured in the catalog for automated efficient access to each software image by multiple resource nodes within the grid environment. If the grid service does not locate a software image for the current software environment in the catalog, the grid service captures at least one installation image for the current software environment for storage in the catalog as an additional software image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07590623&OS=07590623&RS=07590623
owner: International Business Machines Corporation
number: 07590623
owner_city: Armonk
owner_country: US
publication_date: 20050106
---
The present invention relates in general to improved grid computing and in particular to efficient resource allocation within an on demand grid environment. Still more particularly the present invention relates to automated management of the storage and distribution of software images for efficient access by any grid resource for building execution environments within a grid environment.

Ever since the first connection was made between two computer systems new ways of transferring data resources and other information between two computer systems via a connection continue to develop. In typical network architectures when two computer systems are exchanging data via a connection one of the computer systems is considered a client sending requests and the other is considered a server processing the requests and returning results. In an effort to increase the speed at which requests are handled server systems continue to expand in size and speed. Further in an effort to handle peak periods when multiple requests are arriving every second server systems are often joined together as a group and requests are distributed among the grouped servers. Multiple methods of grouping servers have developed such as clustering multi system shared data sysplex environments and enterprise systems. With a cluster of servers one server is typically designated to manage distribution of incoming requests and outgoing responses. The other servers typically operate in parallel to handle the distributed requests from clients. Thus one of multiple servers in a cluster may service a client request without the client detecting that a cluster of servers is processing the request.

Typically servers or groups of servers operate on a particular network platform such as Unix or some variation of Unix and provide a hosting environment for running applications. Each network platform may provide functions ranging from database integration clustering services and security to workload management and problem determination. Each network platform typically offers different implementations semantic behaviors and application programming interfaces APIs .

Merely grouping servers together to expand processing power however is a limited method of improving efficiency of response times in a network. Thus increasingly within a company network rather than just grouping servers servers and groups of server systems are organized as distributed resources. There is an increased effort to collaborate share data share cycles and improve other modes of interaction among servers within a company network and outside the company network. Further there is an increased effort to outsource nonessential elements from one company network to that of a service provider network. Moreover there is a movement to coordinate resource sharing between resources that are not subject to the same management system but still address issues of security policy payment and membership. For example resources on an individual s desktop are not typically subject to the same management system as resources of a company server cluster. Even different administrative groups within a company network may implement distinct management systems.

The problems with decentralizing the resources available from servers and other computing systems operating on different network platforms located in different regions with different security protocols and each controlled by a different management system has led to the development of Grid technologies using open standards for operating a grid environment. Grid environments support the sharing and coordinated use of diverse resources in dynamic distributed virtual organizations. A virtual organization is created within a grid environment when a selection of resources from geographically distributed systems operated by different organizations with differing policies and management systems is organized to handle a job request. A grid vendor may develop a grid environment to which a buyer may submit grid jobs for example.

While the open standards defining grid technology facilitate sharing and coordination of diverse resources in dynamic distributed virtual organizations grid standards do not solve all of the problems associated with actually determining how to allocate and group resources into virtual organizations. Further since grid computing is a relatively new and emerging art many processes have yet to be considered for automation and as such require inefficient manual interaction.

One such process that has yet to be considered for automation is the installation of software resources onto available hardware resources when currently available grid resources do not provide the software environment required for an inbound grid job. In particular there is a need for a method system and program for dynamically managing software resource images to facilitate efficient installation of software resources when building a required software environment on demand within a grid environment.

In view of the foregoing the present invention provides for grid computing and efficient resource allocation within an on demand grid environment. The present invention relates to automated management of the storage and distribution of software images for efficient access by any grid resource for building execution environments within a grid environment.

In one embodiment a grid service detects a current software environment for a grid job within a grid environment wherein the grid environment includes multiple grid resources. The grid service searches a catalog of multiple software images to determine whether an image for the current software environment matches any software images in the catalog. Each of the software images includes an index into at least one installation image. Storage of the software images is structured in the catalog for automated efficient access to each software image by multiple resource nodes within the grid environment. If the grid service does not locate a software image for the current software environment in the catalog the grid service captures at least one installation image for the current software environment for storage in the catalog as an additional software image.

Grid service detects the current software environment for a grid job upon completion of the grid job. Further once grid service detects a current software environment grid service also determines whether it is probable that a future grid job will require the current software environment before deciding to capture and catalog the images for the current software environment.

A single software environment include multiple software installation images or an updated software installation image. Installation images include an operating system base version installation image an operating system version maintenance level installation image an application software installation image and an application software maintenance level installation image.

Each of the software images are indexed by a particular index name form among multiple available index names. When the grid service receives a grid job requirement identifying a particular index name the grid service searches the catalog to determine if a particular software image with the specified index name is currently stored in the catalog. If the grid service identifies the particular software image then an index into the software image for building at least one grid resource is exported to the resource node.

Further responsive to receiving a request to install software meeting a job requirement for an incoming grid job the grid service searches the catalog for at least one software image for installation of the software meeting the job requirement. Selection of software meeting the job requirement also includes searching for the least costly software resource based on collected workload and pricing data. Once the grid service locates the software images meeting the job requirement the grid service enables at least one resource node being built to access the required software installation image.

Referring now to the drawings and in particular to there is depicted one embodiment of a computer system which may be implemented in a grid environment and in which the present invention may be implemented. As will be further described the grid environment includes multiple computer systems managed to provide resources. Additionally as will be further described the present invention may be executed in a variety of computer systems including a variety of computing systems mobile systems and electronic devices operating under a number of different operating systems managed within a grid environment.

In one embodiment computer system includes a bus or other device for communicating information within computer system and at least one processing device such as processor coupled to bus for processing information. Bus may include low latency and higher latency paths connected by bridges and adapters and controlled within computer system by multiple bus controllers. When implemented as a server system computer system typically includes multiple processors designed to improve network servicing power.

Processor may be a general purpose processor such as IBM s PowerPC processor that during normal operation processes data under the control of operating system and application software accessible from a dynamic storage device such as random access memory RAM and a static storage device such as Read Only Memory ROM . The operating system may provide a graphical user interface GUI to the user. In one embodiment application software contains machine executable instructions that when executed on processor carry out the operations depicted in the flowcharts of and others operations described herein. Alternatively the steps of the present invention might be performed by specific hardware components that contain hardwired logic for performing the steps or by any combination of programmed computer components and custom hardware components.

The present invention may be provided as a computer program product included on a machine readable medium having stored thereon the machine executable instructions used to program computer system to perform a process according to the present invention. The term machine readable medium as used herein includes any medium that participates in providing instructions to processor or other components of computer system for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Common forms of non volatile media include for example a floppy disk a flexible disk a hard disk magnetic tape or any other magnetic medium a compact disc ROM CD ROM or any other optical medium punch cards or any other physical medium with patterns of holes a programmable ROM PROM an erasable PROM EPROM electrically EPROM EEPROM a flash memory any other memory chip or cartridge or any other medium from which computer system can read and which is suitable for storing instructions. In the present embodiment an example of a non volatile medium is mass storage device which as depicted is an internal component of computer system but will be understood to also be provided by an external device. Volatile media include dynamic memory such as RAM . Transmission media include coaxial cables copper wire or fiber optics including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio frequency or infrared data communications.

Moreover the present invention may be downloaded as a computer program product wherein the program instructions may be transferred from a remote virtual resource such as a virtual resource to requesting computer system by way of data signals embodied in a carrier wave or other propagation medium via a network link e.g. a modem or network connection to a communications interface coupled to bus . Virtual resource may include a virtual representation of the resources accessible from a single system or systems wherein multiple systems may each be considered discrete sets of resources operating on independent platforms but coordinated as a virtual resource by a grid manager. Communications interface provides a two way data communications coupling to network link that may be connected for example to a local area network LAN wide area network WAN or an Internet Service Provider ISP that provide access to network . In particular network link may provide wired and or wireless network communications to one or more networks such as network through which use of virtual resources such as virtual resource is accessible as provided within a grid environment . Grid environment may be part of multiple types of networks including a peer to peer network or may be part of a single computer system such as computer system .

As one example network may refer to the worldwide collection of networks and gateways that use a particular protocol such as Transmission Control Protocol TCP and Internet Protocol IP to communicate with one another. Network uses electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link and through communication interface which carry the digital data to and from computer system are exemplary forms of carrier waves transporting the information. It will be understood that alternate types of networks combinations of networks and infrastructures of networks may be implemented.

When implemented as a server system computer system typically includes multiple communication interfaces accessible via multiple peripheral component interconnect PCI bus bridges connected to an input output controller. In this manner computer system allows connections to multiple network computers.

Additionally although not depicted multiple peripheral components and internal external devices may be added to computer system connected to multiple controllers adapters and expansion slots coupled to one of the multiple levels of bus . For example a display device audio device keyboard or cursor control device may be added as a peripheral component.

Those of ordinary skill in the art will appreciate that the hardware depicted in may vary. Furthermore those of ordinary skill in the art will appreciate that the depicted example is not meant to imply architectural limitations with respect to the present invention.

With reference now to a block diagram illustrates one embodiment of the general types of components within a grid environment. In the present example the components of a grid environment include a client system interfacing with a grid management system which interfaces with server clusters servers workstations and desktops data storage systems and networks . For purposes of illustration the network locations and types of networks connecting the components within grid environment are not depicted. It will be understood however that the components within grid environment may reside atop a network infrastructure architecture that may be implemented with multiple types of networks overlapping one another. Network infrastructure may range from multiple large enterprise systems to a peer to peer system to a single computer system. Further it will be understood that the components within grid environment are merely representations of the types of components within a grid environment. A grid environment may simply be encompassed in a single computer system or may encompass multiple enterprises of systems.

It will be understood that grid environment may be provided by a grid vendor where a cost for use of resources within grid environment may be calculated based on the amount of time required for a grid job to execute or the actual amount of resources used for example. In addition it will be understood that grid environment may include grid resources supplied by a single grid vendor such as a particular business enterprise or multiple vendors where each vendor continues to monitor and manage the vendor s group of resources but grid management system is able to monitor unintended changes across all the resources regardless of which vendors provide which resources. Further it will be understood that although resource discovery mechanisms for discovering available grid resources are not depicted client system or grid management system may discover grid resources advertised from local and global directories available within and outside of grid environment .

The central goal of a grid environment such as grid environment is organization and delivery of resources from multiple discrete systems viewed as virtual resource . Client system server clusters servers workstations and desktops data storage systems networks and the systems creating grid management system may be heterogeneous and regionally distributed with independent management systems but enabled to exchange information resources and services through a grid infrastructure enabled by grid management system . Further server clusters servers workstations and desktops data storage systems and networks may be geographically distributed across countries and continents or locally accessible to one another.

In the example client system interfaces with grid management system . Client system may represent any computing system sending requests to grid management system . In particular client system may send virtual job requests or requests for a quote RFQs and jobs to grid management system . Further while in the present embodiment client system is depicted as accessing grid environment with a request in alternate embodiments client system may also operate within grid environment .

While the systems within virtual resource are depicted in parallel in reality the systems may be part of a hierarchy of systems where some systems within virtual resource may be local to client system while other systems require access to external networks. Additionally it is important to note that systems depicted within virtual resources may be physically encompassed within client system .

To implement grid environment grid management system facilitates grid services. Grid services may be designed according to multiple architectures including but not limited to the Open Grid Services Architecture OGSA . In particular grid management system refers to the management environment which creates a grid by linking computing systems into a heterogeneous network environment characterized by sharing of resources through grid services.

According to an advantage of the invention grid management system includes a dynamic build subsystem of grid services that enables grid nodes of grid resources to be built adapted or updated to provide an execution environment required for a particular grid job. In particular a grid node may include a grouping of hardware software network and other types of grid resources built together. In addition grid management system includes a grid catalog and storage subsystem of grid services that manages the storage and distribution of software images for efficient resource building as will be further described in detail.

Referring now to a block diagram illustrates one example of an architecture that may be implemented in a grid environment. As depicted an architecture includes multiple layers of functionality. As will be further described the present invention is a process which may be implemented in one or more layers of an architecture such as architecture which is implemented in a grid environment such as the grid environment described in . It is important to note that architecture is just one example of an architecture that may be implemented in a grid environment and in which the present invention may be implemented. Further it is important to note that multiple architectures may be implemented within a grid environment.

Within the layers of architecture first a physical and logical resources layer organizes the resources of the systems in the grid. Physical resources include but are not limited to servers storage media and networks. The logical resources virtualize and aggregate the physical layer into usable resources such as operating systems processing power memory I O processing file systems database managers directories memory managers and other resources.

Next a web services layer provides an interface between grid services and physical and logical resources . Web services layer implements service interfaces including but not limited to Web Services Description Language WSDL Simple Object Access Protocol SOAP and eXtensible mark up language XML executing atop an Internet Protocol IP or other network transport layer. Further the Open Grid Services Infrastructure OSGI standard 322 builds on top of current web services by extending web services to provide capabilities for dynamic and manageable Web services required to model the resources of the grid. In particular by implementing OGSI standard 322 with web services grid services designed using OGSA are interoperable. In alternate embodiments other infrastructures or additional infrastructures may be implemented a top web services layer .

Grid services layer includes multiple services the combination of which may implement grid management system . For example grid services layer may include grid services designed using OGSA such that a uniform standard is implemented in creating grid services. Alternatively grid services may be designed under multiple architectures. Grid services can be grouped into four main functions. It will be understood however that other functions may be performed by grid services.

First a resource management service manages the use of the physical and logical resources. Resources may include but are not limited to processing resources memory resources and storage resources. Management of these resources includes scheduling jobs distributing jobs and managing the retrieval of the results for jobs. Resource management service monitors resource loads and distributes jobs to less busy parts of the grid to balance resource loads and absorb unexpected peaks of activity. In particular a user may specify preferred performance levels so that resource management service distributes jobs to maintain the preferred performance levels within the grid.

Second information services manages the information transfer and communication between computing systems within the grid. Since multiple communication protocols may be implemented information services manages communications across multiple networks utilizing multiple types of communication protocols.

Third a data management service manages data transfer and storage within the grid. In particular data management service may move data to nodes within the grid where a job requiring the data will execute. A particular type of transfer protocol such as Grid File Transfer Protocol GridFTP may be implemented.

Finally a security service applies a security protocol for security at the connection layers of each of the systems operating within the grid. Security service may implement security protocols such as Open Secure Socket Layers SSL to provide secure transmissions. Further security service may provide a single sign on mechanism so that once a user is authenticated a proxy certificate is created and used when performing actions within the grid for the user.

Multiple services may work together to provide several key functions of a grid computing system. In a first example computational tasks are distributed within a grid. Data management service may divide up a computation task into separate grid services requests of packets of data that are then distributed by and managed by resource management service . The results are collected and consolidated by data management system . In a second example the storage resources across multiple computing systems in the grid are viewed as a single virtual data storage system managed by data management service and monitored by resource management service .

An applications layer includes applications that use one or more of the grid services available in grid services layer . Advantageously applications interface with the physical and logical resources via grid services layer and web services such that multiple heterogeneous systems can interact and interoperate.

With reference now to there is depicted one illustration of a logical representation of the grid management system within a grid environment in accordance with the method system and program of the present invention. As depicted grid management system is logically represented by multiple grid managers and that are groups of services that perform the functions that provide grid management system . Each of grid managers and may provide monitoring scheduling and management to resource nodes RS such as resource nodes and . According to an advantage of the invention each of grid managers and may include a dynamic build services that controls automated building of resource nodes required for an execution environment for a particular grid job.

In particular in the example grid environment includes GM that manages RS and RS and communicates with GM and GM . Iii addition in the example grid environment includes multiple groups of resource nodes described by grid A and grid B . In one embodiment Grid A and Grid B are physically disparate groups of resource nodes but accessible to one another within grid environment . For purposes of illustration where Grid A and Grid B are physically disparate groups of resource nodes each grid may be considered a local grid to a particular physical location the GM within each grid manages a set of local resources. Thus in particular GM within grid A manages resource nodes and which are physically local to one another and GM within grid B manages resource nodes and which are physically local to one another. In another embodiment Grid A and Grid B are logically disparate groups of resource nodes.

In one embodiment Grid A is managed by one grid vendor and Grid B is managed by another grid vendor. Grid A may function as a buyer by selling off grid jobs or accessing additional resources from Grid B . Further grid environment may include grid groupings managed by a single or multiple grid vendors and grid resources within grid environment may be temporary permanent or accessed on demand for example.

Referring now to there is depicted a block diagram of an automated closed loop grid management system for handling bid requests and grid jobs in accordance with the present invention. As depicted grid management system includes multiple subsystems of grid services. In particular grid management system may include a central grid manager not depicted that coordinates the communication between each of the grid services. Alternatively the grid services may directly communicate with each other within the communication system enabled by grid management system .

As depicted grid management system includes a grid bid request portal that receives virtual job requests or bid requests from client systems inside or outside of grid environment such as client system . In addition grid bid request portal may receive bid requests from other grid management systems or grid vendors. Grid bid request portal may function as a grid service and may facilitate multiple bid request entry points.

Grid bid request portal may store bid requests in job request and bid storage for use in tracking the bid request and bid provided for a potential job submission. In particular job request and bid storage may store a bid request and bid for a limited period of time depending on the size of the storage medium and the number of bid requests received on average over a particular time period.

A bid request may include multiple required characteristics of the potential grid job. For example the bid request may include characteristics that specify the pricing constraints for a grid job the time limits for the grid job eligibility of the grid job for capacity on demand resources eligibility of the grid job for distribution or sell off to other grid vendors limitations on resource usage job completion requirements software platform class requirements hardware platform class requirements transport mechanism requirements for the grid job the size of data accesses required for the grid job and the job performance requirements. It will be understood that additional grid job characteristics and requirements may be included in the bid request that inform grid management system about the potential grid job.

In addition grid bid request portal interfaces with a grid workload calculator that may function as a grid service. In particular a grid workload calculator may access a grid workload monitor that monitors the current workload on virtual resource or a selection of resource nodes within virtual resource . Grid workload calculator may compare the current workload with past workloads to predict future workloads at particular periods of time or on particular selections of resource nodes within virtual resource . In addition grid workload calculator may calculate an estimated workload factor on grid resources for the bid request based on the characteristics of the grid job described in the bid request. In one example a workload factor may indicate the estimated load on multiple resource subsystems based on the bid request and the current and estimated availability of the resource subsystems. For example the workload factor may indicate the number of CPU cycles that grid workload calculator estimates the potential job will required based on the bid request. In another example the workload factor may indicate the resources which must be included in a resource node allocated for the grid job. In another example the workload factor may include a number calculated to represent on a scale of impact on all or a selection of resources by the potential grid job. In yet another example U.S. patent application Ser. No. 10 940 452 herein incorporated by references describes how grid workload calculator calculates workload factors based on the combination of job characteristics.

Grid workload calculator may pass the workload factor to a grid pricing service . Grid pricing service then determines whether grid management system can handle the potential grid job and if so calculates a price for handling the grid job. In particular grid pricing service may access a grid discounter service grid pricing metrics module and grid sell off service to calculate a price for handling the grid job. In one example U.S. patent application Ser. No. 11 031 489 herein incorporated by reference describes how grid pricing service calculates pricing for a bid for a grid job.

Grid bid request portal compiles the workload calculations and pricing calculations into a bid response and controls storage of the bid response in job request and bid storage and distribution of the bid response to client system .

A grid entry portal receives grid jobs from client system or other grid management systems and grid environments. In one embodiment grid entry portal accesses the bid request and bid response for the grid job from job request and bid storage and distributes the bid request and bid with the grid job throughout the grid services of grid management system . Grid entry portal may distribute and load balance grid jobs across multiple physical servers providing grid management system . Further the grid service providing grid entry portal may be distributed across multiple physical servers and may function as a grid service.

A grid environment service coordinates access of resource nodes for an incoming grid job. In one example grid environment service calls a grid allocation service to control the actual allocation of resource nodes that grid environment service determines should be accessible for an incoming grid job. If the types of resource nodes designated by grid environment service are not available then grid allocation service may direct a grid dynamic build service to build the resource nodes required for the execution environment for the grid job.

Grid dynamic build service may first query whether there are resources available to build the resource nodes required for the execution environment. If the resources are not available then grid dynamic build service may pass the grid job to a grid sell off service for controlling the sale of the grid job to another grid environment or may activate on demand resources. If grid dynamic build service decides to build the resource nodes then grid dynamic build service may call a grid catalog and storage service to access the cataloged software image required for the resource node. In one example grid dynamic build service builds together the hardware software and network resources required for the grid node. In another example grid dynamic build service updates or adjusts the software currently loaded on a hardware resource to build a resource node required for a grid job execution environment.

Execution environment and execution environment are examples of groupings of resource nodes allocated for use by a particular grid job or group of grid jobs from among the resources logically referred to as virtual resource . It will be understood virtual resource may include any number of execution environments and that resources may overlap between execution environments. In addition it will be understood that the resource nodes allocated to execution environments and may be redistributed to alternate execution environments. Further it will be understood that the resource nodes allocated to execution environments and may include resource nodes that are built specifically for allocation in one of the execution environments.

Once resource nodes are allocated to an execution environment for the incoming grid job a grid job router routes the grid job to the designated resource nodes of the execution environment within virtual resource . In one example grid job router may interact with a grid service that tests and verifies the allocated resource nodes first to ensure that the resource nodes are able to handle the grid job. For example U.S. patent application Ser. No. 11 031 427 describes a grid modules that tests and verifies allocated grid resource nodes for compliance with required standards and errors.

A grid job monitor in conjunction with grid workload monitor monitors job completion. In particular grid workload monitor monitors the workload applied to resource nodes within virtual resource . Grid job monitor determines which portions of the monitored workload results of grid workload monitor to attribute to each grid job. Thus grid job monitor is able to monitor the progress of a particular job using the monitored workload and determine whether the grid job executing is meeting performance requirements and other characteristics described for the grid job. If a grid job executing is not meeting performance requirements or other characteristics described for the grid job grid job monitor may access other grid services such as grid sell off service or grid allocation service to request redirecting the grid job to other resources or adding additional resource nodes to handle the grid job. In addition grid job monitor may interact with an error detection module not depicted that detects whether the grid job is executing with any degradation or errors in the execution environment. If an error or degradation is detected grid job monitor may respond by redirecting the grid job to other resources or adding additional resource nodes to bolster the execution environment.

A grid job completion manager ensures proper completion of each grid job. In particular grid job completion manager detects from grid job monitor when the grid job is complete and receives the response or result but may also communicate with other modules to ensure that the grid job is complete. Further grid job completion manager may update a billing service not depicted with the workload usage characteristics of the grid job upon completion so that the billing service may generate a bill for client system for the service provided.

Additionally once the grid job is completed grid catalog and storage service may capture and store an image of the software environment within an execution environment in an image catalog. In particular grid catalog and storage service may update the stored environment image if the current software environment is already stored. If the software environment is not already stored by grid catalog and storage service then grid catalog and storage service may first decide whether to store the software environment image based on whether it is likely that the software environment will be needed again in the future. In one example grid catalog and storage service may determine the likelihood that the execution environment will be needed again in the future by viewing the bid request for the grid job that used the execution environment and historical data gathered about execution environments used within the grid environment. Then according to an advantage grid dynamic build service may call grid catalog and storage service to access the previously stored software installation images required for building resource nodes for the execution environment required by an incoming grid job.

Referring now to there is depicted a block diagram of a grid allocation service in accordance with the method system and program of the present invention. It will be understood that the components depicted as part of grid allocation service may be performed as grid services or processes performed by grid services. Further it will be understood that grid allocation service may include additional processes. As depicted grid allocation service includes a bid access controller . Bid access controller controls access to the bid or bid request that specifies the quality of service required for a grid job to determine the types of grid resources required for the execution environment for the grid job. In an alternate embodiment grid environment service passes the required execution environment information retrieved for the incoming grid job to grid allocation service .

Next a workload query controller controls access to the current workload across the grid resources in the grid environment. Execution environment identifier then accesses grid pricing service to determine the total hardware and software costs for use of the available grid resources for the grid job and to identify the lowest cost resources available. In particular execution environment identifier may calculate hardware and software costs for already built available resource nodes and for resource nodes that will need to be built. If resource nodes need to be built then execution environment identifier may call grid dynamic build service to actually build the resource nodes identified as the most cost effective.

In identifying the lowest cost resource nodes for an execution environment for an incoming grid job it is important to note that pricing from the time that a bid is offered for a grid job to the time that the grid job is submitted may vary however the bid will likely cap the amount that the customer can be charged regardless of the current cost for executing the grid job within the grid environment. Further in identifying the lowest cost resource nodes for an execution environment for an incoming grid job it is important to note that in addition to price execution environment identifier may consider other factors such as the scheduled or predicted workload for a selection of resource nodes to ensure that all performance requirements for an incoming grid job are met.

Next once execution environment identifier identifies the resource nodes for an execution environment for an incoming grid job an environment stager performs configuration modifications required to support grid job router in routing the grid job to the resource nodes.

In a first example environment stager may increase the capacity of a hardware resource by activating on demand resources within the hardware resource. In particular a hardware platform such as a server may include excess capacity built into the platform that is only brought on line and paid for when necessary. In one example a server may include eight active CPUs and eight capacity on demand CPUs where for an inbound grid job requiring eight dedicated CPUs environment stager may activate the eight capacity on demand CPUs for the duration of the grid job. It is important to note that when configuring capacity on demand resources environment stager may also call grid dynamic build service to build in the other resources necessary for the capacity on demand resources to function. For example when capacity on demand CPUs are brought on line environment stager may call grid dynamic build service to build the required base operating system and storage with the capacity on demand CPUs.

In another example environment stager may configure partitions within resource nodes to handle a particular grid job or series of grid jobs. In particular by partitioning resource nodes into a selection of dedicated resources additional security is provided to a grid job. In partitioning resource nodes environment stager may also call grid dynamic build service to add or update additional grid resources to a partition.

In yet another example environment stager may configure a workload manager for a server or selection of servers included in the execution environment for a grid job. In particular where partitioning is not implemented and a selection of servers execute multiple grid jobs concurrently the workload manager for the servers will limit each grid job to use of a particular percentage of the available resources. For example environment stager may configure the workload manager to cap a grid job to access to 60 of the two available CPUs.

Further environment stager may configure the storage locations for use by a grid job. In one example a storage server resource available within a grid environment may include a large pool of disk resources available for use by other grid resources. For example using IBM S Enterprise Storage Server ESS multiple servers can see all the available storage and any storage which is not currently in use by one service can be brought on line by another server. Thus environment stager may call available storage on line for the grid job and return the storage to the pool of disk resources when the grid job is complete.

Further environment stager may configure IP addresses and IP aliases for the servers included in the execution environment for a grid job. In one example environment stager may apply IP addresses known by the grid job or applications required for the grid job to a network adapter which is not currently in use and has been selected as a resource for the grid job execution environment. In another example if the network adapter selected as a resource for the grid job execution environment is shared with other grid jobs then environment stager would configure IP aliases on the shared network adapter.

Finally once environment stager completes the configuration of the execution environment job submitter will inform grid job router and other services within grid management system that the execution environment for the grid job is prepared and that the grid job can be routed to the execution environment. Alternatively if execution environment identifier decides to sell the grid job to another grid environment through grid sell off service then job submitter notifies the other services in grid management system of the sell off.

With reference now to there is depicted an illustrative table of the workload and pricing data collected by a grid allocation service attempting to locate the least costly available resource nodes in accordance with the method system and program of the present invention. As illustrated the workload results returned by workload query controller for the resource nodes that meet the type of resource nodes required for a particular grid job are depicted at reference numeral . In the example as illustrated at reference numeral multiple available pSeries and xSeries servers are identified pSeries and xSeries are registered trademarks of International Business Machines Corporation . The operating system type and version currently loaded on each server is designated in addition to the percentage of free CPU cycles amount of free memory amount of storage available and network resources available.

Next execution environment identifier accesses grid pricing service to determine the current total hardware resource cost including but not limited to cost for CPU usage memory storage and network resources for each hardware platform as required by the particular job as illustrated at reference numeral . It will be understood that although not depicted the cost for usage of each resource may be calculated according to as granular of unit as possible or may be part of an agreed to price for the client requesting the grid job.

Additionally execution environment identifier also accesses grid pricing service to determine the current total software resource cost including but not limited to cost for the operating system licensing fee cost for the database software as required by the particular grid job as illustrated at reference numeral . In the example the database software required for the grid job is DB2EE however it will be understood that other application software may be required for a grid job. Further it will be understood that in addition to operating system and application software other types of software may be required for a grid job.

Finally execution environment identifier calculates a total job cost per hardware platform. In the example as depicted at reference numeral execution environment identifier calculates the total job cost for performing a grid job both the pSeries platform and the xSeries platforms. In the example the total job cost for performing the grid job on the xSeries platform is less expensive than the total job cost for performing the grid job so execution environment identifier will select one of the available xSeries servers unless other grid job requirement criteria override the lowest cost selection.

It is important to note that when grid allocation service selects available hardware resources and calculates costs for operating system and application software required for the grid job execution environment grid allocation service may still call the dynamic build service to actually build the hardware platform with the required operating system and application software or update the software with maintenance level updates.

Referring now to there is depicted a block diagram of the components of a grid catalog and storage service in accordance with the present invention. As depicted grid catalog and storage service includes a particular selection storage systems services and processes however it will be understood that other storage systems services and processes may be implemented.

First grid catalog and storage service includes an image catalog . As will be further described with reference to image catalog includes multiple software environment installation images stored in an efficiently searchable manner and for efficient access to quickly install and update software on grid hardware platforms.

In one example the most frequently requested operating system and application software images may be initially manually loaded into image catalog . Next a software image storage controller provides automated dynamic control of the actual cataloging of software images from software environments for grid jobs in image catalog based on software image storage policies after the initial images are loaded.

With reference now to a table illustrates examples of image content rationale for storage and indexing references that may be used by grid catalog and storage service . In the illustrative example table depicts the content of a software image in the column depicted at reference numeral the image storage rationale in the column depicted at reference numeral and an index reference in the column depicted at reference numeral .

An entry describes an image for the AIX operating system version 5.3 with an index reference of A5.3 and multiple rationale for storage including the ability to use the software image to build new software images as future maintenance levels MLs are released and the ability to use the image as a fresh starting point if an existing maintenance release is suspected of causing problems in an execution environment. In another example an entry describes an image for the maintenance level 1 ML1 release for the AIX operating system version 5.3 with an index reference of AM5.3.1 and a rationale for storage including the ability to use the image to selectively apply maintenance patches or in whole to bring the operating system up to ML1. An entry describes an image for the AIX operating system version 5.3 updated to ML1 with an index reference of A5.3.1 and a rationale for storage including the ability to use the software image to rapidly build the required operating system and maintenance level environment using a single installation process. Additional entries that will be further described with reference to depict image descriptions for DB2 software including entry of DB2 version 9 indexed as DB9 entry of the DB2 version 9 second maintenance level indexed as DBM9.2 and entry of DB2 version 9 updated to ML2 indexed as DB9.2 . In addition a software image may include a combination of an operating system and application software such as entry of the AIX operating system version 5.3 with DB2 version 9 or entry of the AIX operating system version 5.3 updated to ML1 with DB2 version 9 updated to ML2.

With reference to images are cataloged indexed and stored in image catalog for efficient storage location and access. In the example for purposes of illustration a hierarchical file system tree includes entries for each image stored in relations to DB2 software. Each entry described by a software index number such as DB7 that is linked to the storage location for the specific images.

The first level of hierarchical file system tree as depicted at reference numeral contains the high level directory entry identifying that the tree is for DB2 software for the AIX operating system. The first level of subdirectories are illustrated at reference numeral including images for DB2 versions 7 8 and 9. Next a second level of subdirectories are illustrated at reference numeral including images for maintenance level for each version of the DB2 product. For example DB7 as depicted at reference numeral is linked via a software index number to the installation image for DB2 version 7 but DBM7.1 as depicted at reference numeral is linked via a software index number to the installation image for the maintenance level 2 update for DB2 version 7. It will be understood that additional levels of directories and subdirectories may be implemented within hierarchical file system tree and that additional hierarchical file system trees may be implemented for each general type of software accessed for a grid job software environment. Further it will be understood that other types of data storage structures may be implemented within image catalog .

In one embodiment the index numbers used to identify software images may be standardized for use across multiple grid systems. In this embodiment a bid request for a grid job may specify the index numbers required for the grid job and the grid manager may determine whether the requested software is available or would be available if the grid job were submitted.

Returning now to new software environments may be introduced into a grid environment in multiple ways. For example a client may supply a software image to a software environment as part of a grid job an existing operating system or operating system and application combination environment may be modified to meet a job specification for a particular grid job or a software environment may be assembled from multiple stored software image that is a combination of operating system application software and maintenance software.

In one embodiment either after the build is complete or after the completion of a grid job software image storage controller evaluates whether to store an image of the software environment in image database for future build requests based on software image storage policies . In one example software image storage controller may determine whether the grid job will potentially be repeated based on other grid job bids and based on information collected by the grid accounting and statistics service . In another example software image storage controller may query job request and bid storage system to determine whether there are outstanding bids on the same grid job as the recently completed grid job or whether the recently completed grid job is similar to grid jobs completed within a particular period of time. Further software image storage controller may determine to initially store all software environment images which are then periodically archived if not reused within a particular period of time. In particular image database may be distributed across high performance media that holds more recently stored and used images and across a lower cost media that holds archived images.

When software image storage controller decides to dynamically store a new software image in one embodiment a generic image would be created that is independent of any settings specific to a particular grid job. In one example to generate the generic image in an AIX environment the process may include 1 setting the root password to null 2 deleting all non root users 3 deleting custom configuration files 4 unconfiguring and deleting all controllers adapters and devices and 5 clear all error logs.

An export controller controls exporting images to any resource node. In particular export controller insures that all available images are accessible to all available nodes. The actual export mechanism used by export controller may vary based on the operating system being used. For example for AIX and DB2 export controller may implement the General Parallel File Systems GPFS as the file sharing mechanism. In one embodiment using GPFS the images in image catalog are stored as a shared file system and each grid node would be configured as a client running GPFS peer software which would allow any grid node to directly access all of the images contained within the shared file system. Alternatively image catalog may be implemented in a single or multiple Network Installation Management NIM servers. It is important to note that each export mechanism available within export controller may be controlled by an automated script or workflow which enables export of the software images to resource nodes and controls the completion of installations and the performance of configurations.

A usage activity updater controls updates to grid accounting and statistics service when a software image is captured and added to image catalog and when a software image is exported from image catalog . In particular grid accounting and statistics server maintains historical data of activity in grid environment based on data collected from multiple subsystems and services within grid environment . Software image storage controller may poll grid accounting and statistics service to determine whether or not any of the stored images have remained idle for more than a particular period of time.

In particular as previously described software image storage controller may remove or archive outdated or infrequently used images from image catalog . The actual process for removing images may depend upon the type of image the location of the image and whether the image directory and subdirectories need to be removed. In one example if software image storage controller determines that a particular version of DB2 is outdated then the directory and subdirectories for that DB2 version are deleted. In another example if NIM servers are implemented to install the DB2 version images then software image storage controller would remove all references to the DB2 version images from the NIM configuration. Further in another example if a DB2 version is not outdated but is infrequently used then software image storage controller may control archiving the image for the DB2 version to a low cost storage media using operating system archiving commands or using a backup and recovery management system such as Tivoli Storage Manager.

With reference now to there is depicted a high level logic flowchart of a process and program for controlling a grid allocation service in accordance with the method system and program of the present invention. As illustrated the process for controlling a grid allocation service starts at block and thereafter proceeds to block . Block depicts a determination whether the grid allocation service receives an inbound grid job. When the grid allocation service receives an inbound grid job the process passes to block depicts accessing the job requirements for the grid job including the bid request bid service level agreement and analysis of job requirements performed by other services within the grid management system. Next block illustrates accessing the current workload characteristics for potential resource nodes. Thereafter block depicts a determination whether the grid allocation service detects that the resource nodes required for the execution environment are available meaning the resource nodes are available for allocation and already built to the job requirements.

At block if the required resource nodes are available then the process passes to block . Block depicts accessing pricing for use of the hardware and software resources in the resource nodes. Next block illustrates selecting the lowest cost resource nodes. Thereafter block depicts performing the required configurations for the use of the selected resource nodes. Next block illustrates informing the job router that the execution environment is prepared for the grid job and the process ends.

Otherwise at block if the required resource nodes are not available then the process passes to block . Block depicts a determination whether the required environment capacity is available within the grid environment. If the required environment capacity is available within the grid environment then the process passes to block . Block depicts instructing the dynamic build service to create the required environment from the available capacity of resources and the process passes to block . Otherwise at block if the required environment capacity is not available then the process passes to block.

Block depicts a determination whether multi grid execution is possible. To determine whether multi grid execution is possible there must be access to use of resources from other grids and the job requirements for the grid job must allow multi grid execution. If multi grid execution is not possible then the process passes to block . If multi grid execution is possible then the process passes to block . Block depicts a determination whether there are available grid resources in other grid groupings or environments. If there are not available grid resources in other grid groupings or environments then the process passes to block .

Block depicts a determination whether sell off of the grid job to an external grid is permitted. If sell off of the grid job to an external grid is not permitted then the process passes to block . Block depicts queuing the job and updating the job router to indicate that no execution environment is available for the grid job and the process ends. Otherwise at block if sell off of the grid job to an external grid is permitted then the process passes to block . Block depicts querying the grid sell off broker service with the job requirements. Next block depicts a determination whether the grid sell off broker service advises a sell off. If the grid sell off broker service does not advise a sell off then the process passes to block which was previously described. If the grid sell off broker service does advise a sell off then the process passes to block . Block depicts selling the job and updating the job router about the sale and the process ends.

Returning to block if there are available grid resources in other grid groupings or environments then the process passes to block . Block depicts adding the required virtual resource nodes to the execution environment and the process passes to block . In addition although not depicted grid allocation service may call the grid dynamic build service to build the virtual resource nodes.

Referring now to there is depicted a high level logic flowchart of a process and program for controlling a grid dynamic build service in accordance with the method system and program of the present invention. As illustrated the process stars at block and thereafter proceeds to block . Block depicts a determination of whether the grid dynamic build service is invoked. If the grid dynamic build service is invoked then the process passes to block . Block depicts the grid dynamic build service evaluating whether to perform the dynamic build. In particular the grid dynamic build service may consult with the grid allocation service and other grid services to determine whether it is cost effective and performance effective to build the resource nodes. Next block depicts a determination whether the grid dynamic build service decides to build the resource nodes. If the grid dynamic build service decides not to build the resource nodes then the process ends and an error message may be returned to the grid allocation service. If the grid dynamic build service does decide to build the resource nodes then the process passes to block . Block depicts invoking the grid catalog and storage service to access the required software images to build the required resource nodes for the grid job and the process ends.

With reference now to there is depicted a high level logic flowchart of a process and program for controlling dynamic storage of software images in an efficient storage structure in accordance with the method system and program of the present invention. As illustrated the process starts at block and thereafter proceeds to block . Block depicts a determination whether a grid job completion is detected. When a grid job completes then the software image storage controller of the grid catalog and storage service determines whether the job has potential to be repeated as illustrated at block . As previously described the software image storage controller may access bid offers for future grid job submissions and statistics maintained about previous grid job submissions to determine if the current job is one that is likely to be repeated. If the job does not have potential to be a repeat job then the process ends. If the job has potential to be a repeat submission then the process passes to block . Block depicts a determination whether a catalog entry exists in the image catalog for the grid job software environment. If a catalog entry already exists then the process passes to block . Block depicts updating the statistics and accounting service with the image use and the process ends. Otherwise at block if the catalog entry does not exist for the grid job software environment then the process passes to block . Block depicts taking a snapshot of the software environment storing the resource node software images and creating a new catalog entry for the software image and the process ends. In one example a software environment snapshot contains the currently used software modules e.g. operating system application software databases and middleware current configurations and job execution environments and conditions for the execution of a current grid job.

Referring now to there is depicted a high level logic flowchart of a process and program for exporting software images in accordance with the method system and program of the present invention. As depicted the process starts at block and thereafter proceeds to block . Block depicts a determination whether the grid catalog and storage service is activated. If the grid catalog and storage service is activated then the process passes to block . Block illustrates searching the file system for the required software image where all software images are available for access by any resource node. Next block depicts exporting the located software images to the resources nodes being built and the process ends.

With reference now to there is depicted a high level logic flowchart of a process and program for archiving software images in accordance with the method system and program of the present invention. As illustrated the process starts at block and thereafter proceeds to block . Block depicts a determination whether an archiving period is triggered. Software image storage controller may trigger archiving periods at particular intervals in time or an archiving period may be triggered if the higher speed storage medium used for storing the software images is full for example. If an archiving period is triggered then the process passes to block . Block illustrates querying the grid statistics and accounting service for a unused software images log or other indication of software images that have not been used or have not been used recently. Next block depicts archiving or removing those software images that indicated as not recently used and the process ends.

While the invention has been particularly shown and described with reference to a preferred embodiment it will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention.

