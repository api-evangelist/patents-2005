---

title: Effecting action to address an issue associated with a category based on information that enables ranking of categories
abstract: A categorizer is trained for plural categories according to a machine-learning algorithm. The categorizer classifies cases in a set of cases into the plural categories. One or more quantification measures regarding cases in the data set are computed based on output from the categorizer, and information is provided to enable ranking of the categories based on the one or more quantification measures. Action is effected to address an issue associated with at least one of the categories based on the provided information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07593904&OS=07593904&RS=07593904
owner: Hewlett-Packard Development Company, L.P.
number: 07593904
owner_city: Houston
owner_country: US
publication_date: 20050630
---
In a typical customer support organization e.g. call center service desk electronic support center and so forth of a large organization e.g. a business organization an educational organization or a government organization tens to hundreds of thousands of calls may be received monthly from customers regarding various issues. Based on the calls received the customer support organization typically attempts to identify problems that may exist in products or services. In response to these problems the customer support organization may attempt to solve the problems such as by improving documentation and various search tools used by technicians at the customer support organization. Additionally the customer support organization can provide documentation on web portals to enable customers to solve problems on their own.

Conventionally procedures and mechanisms have not been provided to efficiently and accurately identify issues that are associated with the calls received by the customer support organization. Also procedures and mechanisms have also not been provided for efficiently and accurately quantifying received calls by a customer support organization broken down by different types of issues to enable the customer support organization to quickly determine which issues have higher priority and thus should first be addressed. Without the ability to efficiently and accurately identify and quantify issues a customer support organization may waste resources trying to address an issue that should have lower priority than other issues.

Most calls received by customer support organizations are documented based on summaries entered by the customer call agents that received the calls. Some customer support organizations ask call agents to label each call from a menu of choices also referred to as issue paths. Such labeling of calls performed by call agents is usually not accurate since call agents are typically under time pressure to resolve a call as quickly as possible. Moreover call agents may not be properly trained to classify a call to all the possible categories. In addition as new categories are added the training involved to re train call agents to recognize the new categories can involve substantial costs. If not trained properly call agents tend to bias classifying of calls to the top of a list toward a catch all other category or toward overly general categories such as a hardware or software category without specificity. Also if the list of categories is not complete then the classification performed by the call agents would be incomplete. Also the available categories in the list may not accurately describe a particular call.

Another technique of categorizing calls is based on using an expert off line to look at information pertaining to the calls or a sample of the calls. The expert would then attempt to label the calls into various issue categories. Using an expert or plural experts to label calls received by a customer support organization can be time consuming labor intensive and expensive. Moreover experts may be familiar with certain issues while not very familiar with other issues. As a result classification performed by such experts may be biased toward certain categories resulting in somewhat inaccurate categorizations.

Another approach is to survey customers in which customers are asked to fill out customer surveys or to answer questions. This process is relatively intrusive and many customers may not be willing to participate in the survey. Moreover the information collected from customers may be incomplete as the customers may not be properly motivated to enter all information or the customers may interpret different questions differently and thus provide differing answers based on the different interpretations.

As a result of unreliable or inefficient classification of calls using conventional techniques organizations have been unable to reliably or efficiently prioritize problems to better focus the resources of the organizations.

The one or more data sets are stored in a storage . The storage can be persistent storage such as magnetic or optical disk drives or non volatile semiconductor memory devices volatile memory such as dynamic random access memories or static random access memories or other types of storage devices. The storage is connected to one or plural central processing units CPUs in the analysis server . Alternatively the one or more data sets are stored on a database system separate from the analysis server .

The data collector is executable on the one or plural CPU s . Also as depicted in the analysis server includes an analysis tool that is also executable on the CPU s . The analysis tool performs analysis of the information contained in the data set s stored in the storage . The information in the data set s is collected as individual cases or incidents associated with calls received by call agents at call agent stations . A case or incident refers to a data item that represents a thing event or some other item. Each case or incident is associated with predefined information e.g. product description summary of problem time of event and so forth . The terms case and incident are used interchangeably herein.

The analysis tool in the analysis server is an interactive analysis tool that allows a user to interact with the analysis tool for the purpose of identifying categories relevant for the cases contained in the data set s . The analysis tool also enables the creation of training cases based on user input described further below for the purpose of training a categorizer or plural categorizers in the analysis tool . Note that the cases stored in the data set s include unlabeled cases cases that are not initially identified with any particular category or categories as well as labeled cases cases that have been labeled as belonging to a category or plural categories .

In the customer support context a case represents an instance of an interaction between a customer e.g. a user patron subscriber visitor member employee participant constituent supplier partner etc. and an organization e.g. company manufacturer store provider employer representative etc. that is indicative of satisfaction or dissatisfaction with something at least partially under control of the entity or another party the entity represents A category e.g. problem issue concern etc. represents an underlying reason for the interaction such as satisfaction or dissatisfaction that led to the case Such categories can reflect problems associated with a product or service e.g. defects in product design or manufacture hardware problems software problems hard disk problems battery problems and so forth difficulties in understanding how to correctly use a product or service difficulty obtaining a product or service difficulty obtaining information about a product or service concerns about the value of a product or service desires for features lacking in a product or service poor experience interacting with the entity and so forth. Other entity customer relationships e.g. employer employee government constituent will have similar sets of categories reflecting the types of concerns the customers have and the types of control the entities have. In other environments other types of categories are employed.

Although described in the context of a customer support environment that includes call agents receiving calls at call agent stations other embodiments of the invention are applicable to other types of systems for other types of organizations e.g. educational organizations government organizations business organizations financial organizations and so forth .

According to some embodiments the analysis tool is able to compute quantification measures with respect to various categories based on categorizations performed by a categorizer or plural categorizers . The analysis tool is also able to perform ranking of categories based on the computed quantification measures. Based on the ranking information provided by the analysis tool an action can be taken with respect to a category or multiple categories to address an issue or issues associated with the category or categories . For example the category can be associated with a particular problem of a customer support organization that has to be remedied. By using the ranking information provided by the analysis tool in accordance with some embodiments an organization or user can identify higher priority categories such as categories associated with the largest volume of customer calls the categories associated with the largest impact on revenue etc. for which the organization or user should expend resources to resolve.

In alternative embodiments a categorizer can be trained without using the search and confirm mechanism to develop training cases. For example the categorizer can be trained using a machine learning algorithm based on data associated with a set of training cases developed by another mechanism. A machine learning algorithm is an algorithm that takes as input a training set of cases labeled with correct categories. The output of the machine learning algorithm is a trained categorizer that is able to categorize or classify a case into one or more categories. Examples of machine learning algorithms include the following a support vector machine learning algorithm na ve Bayes network learning algorithm a Bayesian network learning algorithm a neural network learning algorithm and a decision tree learning algorithm.

In accordance with some embodiments concurrently with the search and confirm procedure for the purpose of developing categorizer training cases new categories such as for issues associated with a customer support organization can be discovered or existing categories modified. Examples of issues associated with a customer support organization include product problems e.g. problems with a computer display battery software wireless hardware and so forth . As new categories are added or existing categories modified training cases are further developed for these new or modified categories to further train the categorizer .

The trained categorizer is then used to categorize cases of the data set s into one or more categories. In alternative implementations multiple trained categorizers can be used to categorize cases of the data set s into one or more categories. As the categorizer categorizes cases quantification of the cases in each category is performed by a quantifier . Quantification refers to the computation of one or more of the following quantification measures 1 a quantity of cases in each category and 2 an aggregate e.g. sum average maximum minimum etc. of a data field associated with each of the cases in the respective category. For example the quantification measure can represent a sum of labor time and or parts costs involved in resolving cases in each category.

The quantification measures produced by the quantifier allow a ranking module in the analysis tool to provide information to identify higher priority categories based on one or more predefined criteria. Providing information to identify higher priority categories enables ranking of the categories so that an organization can properly and efficiently allocate resources to the more important issues. For example the ranking can enable a customer support organization to identify the top or most significant ten or other predetermined number customer support issues that should be given more attention. The information identifying the higher priority categories is provided for a predetermined frame of reference such as a predetermined time period product line geographic region and so forth. In addition to identifying the top issues a user is also given the ability to drill down to obtain more detailed information regarding any of the identified issues. This ability to drill down for more detail allows a user to quantify an issue identify sub issues obtain detailed data on cases associated with the issue and obtain example cases for the issue.

As noted above based on the ranking performed by the analysis tool a user or organization can identify a category or plural categories for which an action is taken to address the category such as to fix a problem or to address some other type of issue . Examples of actions that can be taken with respect to a category include one or more of allocating a sum of money or otherwise defining a budget allocating a physical resource e.g. equipment hiring a person assigning a task to a person writing a document such as a help document modifying an existing document identifying a document altering availability of a document such as to make the document more widely available such as posting the document on a web site altering an organization of a web site modifying a design of a product modifying a packaging of a product modifying a manufacturing process for a product creating a software program modifying a software program creating a patch for a software program contacting a customer vendor supplier employee or partner modifying a marketing campaign changing response time of service providers training service personnel discontinuing efforts that are no longer required changing the process of writing and delivery of software programs taking actions with reference to seasonal fluctuations provide reports to customers regarding how issues are being monitored and addressed and other actions.

As discussed above the analysis tool effectively provides an interactive package useable by a user to efficiently and accurately identify categories train a categorizer categorize cases produce quantification measure s for the categorized cases and provide information identifying higher priority categories. The analysis tool enables the category identification categorizer training case categorization quantification and higher priority identification processes to be performed generally in a concurrent manner for enhanced efficiency. Also the analysis tool simplifies the processes of identifying new categories for cases unlabeled cases and or labeled cases in the data set s developing training cases for training the categorizer training the categorizer categorizing cases quantifying the categorized cases and providing information identifying higher priority categories.

Although the various modules depicted in are part of one analysis tool it is contemplated that in other implementations the modules can be implemented in multiple tools that are deployable in the analysis server or even on other systems. Moreover in some cases the categorizer s quantifier and ranking module can be provided as an output of the analysis tool for use on other data sets or for use on other systems. Note that although the categorizer s quantifier and ranking module are depicted as separate modules the modules can be integrated into a single module in other implementations. Also note that some of the modules in the analysis tool can be omitted in other embodiments.

Optionally the identification of categories is performed by a user of the analysis tool as the user uses the search and confirm mechanism of the tool . The search and confirm mechanism includes the search engine and confirmation module . The search engine enables a user to submit a search and to display a list of cases matching the search criterion or criteria. With the confirmation module the user is able to confirm or disconfirm whether each of the displayed cases belongs to a category or plural categories .

The search engine is able to receive a query from a user through the user interface and to issue the query to identify cases from the data set s . The search engine displays information regarding identified cases from among the unlabeled cases that match the query. The displayed information regarding the identified cases is presented in the user interface . The user interface can be a graphical user interface according to an example implementation.

The information displayed in the user interface by the search engine in response to the query includes information regarding a subset of the unlabeled cases that match search criterion ia in the form of search terms in the query. A case is said to match a query if any information associated with the case satisfies some criterion such as search term in the query. A term specified by a query refers to any string substring regular expression glob expression non textual object e.g. audio object video object etc. or any other term. A glob expression is an expression containing an operator indicating presence of zero or more characters e.g. an arbitrary character e.g. a range of characters or a range of strings. A case matches a search term in the query if any information associated with the case satisfies the search term in any specified manner in other words equality between the case information and the search term is not required since the query can specify other forms of relationships between the case information and search term . Not all cases that match need to be used. The user interface displays a summary of each of the matching cases to provide a user with information regarding each case. The process of specifying a query and viewing results of matching cases is referred to as a scooping process. Following the scooping process a confirming process is performed in which a user is able to confirm whether or not each of the matching cases belongs to a particular category by selecting or deselecting displayed fields or other indicators .

User confirmation or disconfirmation is monitored by the confirmation module . Not all displayed cases need to be confirmed or disconfirmed. For cases that have been correctly matched to a category such cases are added to a positive training set of cases. On the other hand for cases that have been incorrectly matched the confirmation module adds such incorrectly matched cases to a negative training set of cases. The positive and negative training sets which are part of the training cases stored in the data set are accessed by the training module for training the categorizer .

The search engine and confirmation module thus cooperate to develop training cases from cases in the data set based on user confirmation and disconfirmation which training cases are used by the training module to train the categorizer . As noted above the search and confirm mechanism provided by the search engine and confirmation module can be omitted in alternative embodiments. In some alternative embodiments the training module can implement another machine learning algorithm for developing the categorizer based on an input set in which cases have been labeled as belonging to particular categories.

In some embodiments during the searching and confirming using the optional search and confirm mechanism a user can determine that additional categories should be added to a hierarchy of categories or existing categories in the hierarchy modified. Using a category editor in the analysis tool the user can move add modify or even delete categories represented by the hierarchy of categories stored in a storage . In the example hierarchy depicted in each box designated C represents a category. As depicted a category can have subcategories which also can have subcategories. As categories are added deleted or modified additional training cases can be developed for each category with the training module training the categorizer based on these additional training cases. Adding deleting or modifying categories or subcategories causes the positive and negative training sets of the training cases to be modified.

The category editor is responsive to user input at a user interface UI presented in a display monitor to add categories or subcategories delete categories or subcategories or modify categories or subcategories . In response to user input to add delete or modify categories or subcategories the category editor is able to modify the hierarchy of categories. In some embodiments the category editor may be omitted and the search and confirm procedure may take place with respect to a predefined set of categories.

Note that initially there may already be a developed set of categories before the search and confirm procedure is started which existing set of categories can be used as a starting or initial set of categories. In an alternative scenario such as with a new project no categories may exist. In this alternative scenario the user may create one or a few categories as the starting point or the one or few categories can be created by another technique described further below.

In one embodiment the categories in the hierarchy of categories are in a directed acyclic graph DAG rather than a tree. In other words any category in the hierarchy can have not only several children but also several parents. However a category cannot be simultaneously an ancestor and a descendant of another category. Subcategories associated with a particular category are considered the children of the particular category. In alternative implementations other structural relationships of categories can be employed.

A manager module in the analysis tool performs overall management operations such as managing the storing of data including training cases and hierarchy of categories in the storage and coordination among the various modules of the analysis tool .

As the positive and negative training sets are modified based on the user confirming and disconfirming acts and based on modification of the hierarchy of categories the modified positive and negative training sets are propagated through the hierarchy of categories to enable the training module to train the categorizer for the categories.

During development of the categorizer the quantifier is also created by a quantifier creator module in the analysis tool . The quantifier can be in any format such as an Extensible Markup Language XML format C code format or any other format. In the arrangement of the categorizer s is are part of the quantifier . However in other embodiments the quantifier and categorizer s are separate modules. In either case the quantifier cooperates with the categorizer s to perform automated quantification of the cases. Such cooperation may include making requests of or otherwise interacting with the categorizer s running on computer or on other computers or it may include using the result of prior executions of the categorizer s . In this manner manual quantification which can be time intensive inaccurate and expensive is replaced with quantification by the quantifier using categorizer s trained according to some embodiments of the invention.

The quantification performed by the quantifier includes computing for one or more of the categories in the hierarchy of categories a quantification measure that represents the number of cases in each category. Alternatively the quantifier is able to generate another quantification measure such as a sum or some other aggregate of a data field associated with the cases that belong to each category. As an example the quantification can represent a measure e.g. sum of one or more of the following the duration of calls cost of repair amount of time to resolve the calls amount of lost revenue an amount of money to resolve calls amount of lost revenue due to calls a degree of customer aggravation an amount of time spent by customers before initiating a call an amount of time spent by customers during the call an amount of time spent diagnosing cases an amount of money spent by customers an amount of money spent interacting with customers an amount of money spent diagnosing the cases and a number of customers who declined to initiate a call and so forth. Other examples of aggregation include an average or mean a standard deviation a 95 or other percentage level confidence interval a variance a minimum a maximum a median a mode a geometric mean a harmonic mean a percentile rank an ordinal statistic or other statistic of the values in the data field associated with the cases or a value computed based on fitting a model to the values in the data field associated with the cases. The data field of a case can contain a single value or a collection of values or the data field can be a value or collection of values computed from other values associated with the case. In some embodiments the aggregate may involve a plurality of data fields associated with each case. The quantification measures computed by the quantifier are stored as quantification measures in the storage .

Note that the quantification measures computed by the quantifier are estimated measures in light of the fact that the categorization performed by a categorizer is often not absolutely accurate. For example the accuracy of a trained categorizer can be impacted by the quality of training cases used to train the categorizer. As explained further below to compensate for inaccuracies of the categorizer calibration or adjustment of the quantifier is performed based on some indication of the ability of the categorizer to categorize cases in a data set.

The quantifier is able to display the quantification measures it computes either numerically textually or graphically. Also the quantifier is able to generate one or more reports that present these quantifications. The reports optionally also provide comparative quantifications such as providing a comparison of cases in different data sets or in different partitions of one data set.

Moreover in some embodiments the analysis tool can provide the quantifier along with one or plural associated categorizer s as an output. The output quantifier and categorizer s is useable on other data sets to perform categorization and quantification on the other data sets. By being able to re run the quantifier and categorizer s on other data sets no additional substantial manual labor is involved in applying the quantifier to the other data sets. For example using the output quantifier the quantification analysis can be easily repeated daily weekly monthly annually and so forth.

The analysis tool also includes the ranking module for providing information to identify higher priority categories based on quantification measure s provided by the quantifier . Providing information to identify higher priority categories includes providing information to identify some order of the categories or to rank the categories based on predetermined one or more criteria. The information identifying the higher priority categories are presented in report s .

Identifying priority of categories can be based on one or more of the following criteria as examples the number of calls in each category the amount of time involved in resolving calls in the category the amount of money spent by the organization to resolve calls in the category the amount of time money or aggravation of the customer customer dissatisfaction in resolving calls in the category the estimated amount of lost future revenue due to calls in the category and the estimated number of customers having the problem associated with the category who simply gave up rather than call lost customers . Note that the above criteria are provided for the purpose of example. In other embodiments other criteria can be used by the ranking module .

The ranking module also takes into account whether a sufficient number of cases e.g. calls at a customer support organization have been considered. The sufficient number can be a predefined fixed number or a number that accounts for a given fraction of calls or amount of money spent or some other factor. Consideration of a sufficient number of cases is an indication of how well trained the categorizer is. The more cases considered the better trained the categorizer and thus the more accurate the quantification measure s provided by the quantifier . Thus the ranking module may determine that a report should not be generated until the number of cases considered has exceeded a threshold that represents this sufficient number. 

The report produced by the ranking module can provide details regarding various categories in the hierarchy of categories. For example the report can show details regarding the high level categories e.g. general customer support issues such as issues associated with hardware or software . Alternatively the report can show details regarding intermediate categories or low level categories e.g. subcategories of hardware such as battery wireless interface keyboard etc. . The report generated can also allow a user to click user selectable fields to drill down into subcategories of general categories. The report can present the information in the form of a graph such as a pie chart bar chart stacked bar chart line chart scatter plot bar and whiskers plot or in any other format e.g. a table . The report can be a textual document including graphs a spreadsheet an interactive document e.g. a web page or some other type of document. With an interactive document such as a web page a user can focus on subcategories such as problems with a keyboard and ignore the other categories. Also the interactive document can allow a user to change the criteria used to rank the categories such that the ranking module is responsive to user input in the interactive document to re rank the categories and produce a modified output report .

The details of the report presented by the ranking module include the quantification measures provided by the quantifier . As noted above the quantification measures include a number of cases in each category and or an aggregate of some data field associated with the cases. In addition to providing a quantification of higher priority issues the report also enables a user to obtain sub issues in the form of subcategories detailed information regarding each issue and example cases for each issue.

Each quantification measure provided in the report can be the actual quantification measure produced by the quantifier or alternatively can be an adjusted extrapolated or normalized value produced by an adjustment module . Adjusted quantification measures include quantification measures extrapolated into the future which can be based on a simple trend of the quantification measures. Alternatively adjusted quantification measures include quantification measures normalized based on sales numbers and trends marketing promotions seasonal buying patterns product end of life information product introduction information and so forth. Adjusted quantification measures can also reflect estimated measures in a larger population from which the data set forms a sample. The ranking module can take into account the adjusted quantification measures from the adjustment module when producing the ranking of categories in a report . In some cases adjusted quantification measures allow the ranking module to determine that a category that may be a major issue currently may not be a major issue in the future based on a trend a product close to end of life and so forth. The ranking module is also able to compare categories in different time horizons based on the expected amount of time involved in addressing each category.

Another module in the analysis tool is an example case identifier which is able to identify example cases for each category. The ability to develop example cases by the example case identifier enables the user to better understand each category. For example by looking at relevant example cases for each category a user may be able to better understand a problem represented by the category. The example cases developed by the example case identifier can be incorporated into the report generated by the ranking module . Alternatively the report developed by the ranking module can include links to example cases. In yet another implementation the example cases are accessible through the user interface by use of an application programming interface API .

The example case identifier selects one or more example cases for each category based on the confidence level assigned by the categorizer to each example case. Thus the example case identifier presents example case s to a user if a confidence level exceeds a predefined threshold. Also if multiple cases are presented for each category then the multiple cases are selected such that they are dissimilar to each other to provide a better illustration of cases associated with the category. Also for each case presented by the example case identifier for a category the example case identifier can provide some indication of how many similar cases are present. The user can also be presented with a feature to enable access of the similar cases if desired.

In yet another implementation the cases of a particular category are partitioned by a clustering algorithm with the most competently predicted case for each cluster identified by the example case identifier for the category. Thus if multiple clusters are present in a particular category then an example case would be provided for each cluster.

The ranking module can also present details regarding a subset of cases in a category. For each category information pertaining to the subsets can be presented side by side so that a user can compare information regarding the multiple subsets for the category.

In the bar chart the hardware category and software category each has a icon that is user selectable to enable the user to drill further into the respective categories to determine additional information regarding subcategories. Although not depicted in many other types of information can be displayed for the listed categories. Also instead of the bar chart format the output can be in another format.

The GUI screen includes a first frame that displays the hierarchy of categories also referred to as classmap that is being built using the analysis tool of . In the example depicted in the four main categories include sync screen batt and sdcard. Note that any of these four categories can include subcategories. For example the screen category has subcategories. Examples of subcategories of the screen category include the cracked subcategory and the align subcategory. The subcategories can further include subcategories to any desired depth.

The GUI screen also includes a second frame with a training column to display the number of cases that have been identified by a user either directly or by inference as being positive cases for a given category. The Training column lists the number of cases for each of the sync screen batt and sdcard categories. For example in the Training column the sync category has 93 cases the screen category has 200 cases the batt category has 2 394 cases and the sdcard category has 47 cases.

Another column in the second frame is an Estimate column which displays the estimated number of cases identified by the quantifier as belonging to each of the categories and subcategories. A third Quantity column lists an estimated sum of some data field of the cases in each category such as time spent on cases that belong in the category or cost of handling the cases in the category. The values in the Quantity column are also provided by the quantifier . As other examples the Quantity column can indicate costs or percentages of volume of cases.

Another optional column in the second frame can indicate the perceived quality of the current categorizer with respect to each particular category. Examples of information pertaining to the measure of the quality of the categorizer that has been trained using training information developed according to some embodiments includes true positive rate the likelihood that an item in a category will be identified by the categorizer to be in the category false negative rate the likelihood that an item in a category will be identified by the categorizer to be not in the category true negative rate the likelihood that an item that is not in a category will be identified by the categorizer to be not in the category false positive rate the likelihood that an item that is not in a category will be identified by the categorizer to be in the category accuracy the likelihood that an item will be correctly identified to be or not to be in a category recall same as true positive rate precision the likelihood that an item identified to be in a category actually is in the category bi normal separation a measure of the separation between the true positive rate and the false positive rate information gain a measure of the decrease in entropy due to the categorizer lift a measure of an increase in e.g. response rate if only the cases the categorizer is most confident about are processed stability under cross validation measure of the likelihood that the categorizer has or has not overfit the training information by learning to recognize individual cases rather than learning generalities that apply to unseen data area under an ROC receiver operating characteristic curve area under a curve that is a plot of true positive rate versus false positive rate for different threshold values for a categorizer number of training cases percentage of target training size same as number of training cases except with the added notion that a user has indicated a desire to see a minimum number of cases for every category f measure a parameterized combination of precision and recall total cost an expected aggregate cost over analyzed cases considering separate individual costs for the true positives true negatives false positives and false negatives and average cost similar to total cost except averaged over the number of cases .

A search frame is also displayed in the GUI screen . The search frame includes a search area in which a user can enter a query for performing the scooping process. As part of the scooping process the user provided query is submitted to the search engine to retrieve a number of cases that will be displayed in a display frame . In the example shown in the query contains the search term charge which means find cases that contain a word in a case title or elsewhere that contains the word charge. 

The display frame displays a summary e.g. title of some or each of the cases identified by the search based on the query entered in the search frame . Note that each case is associated with several pieces of information with the title being one of the pieces for example. In other implementations other pieces of information associated with the cases can be displayed. In some embodiments the user may separately select which pieces of information are to be displayed to be used for matching queries and to be used for training the categorizer. In the example of the leftmost column of the display frame indicates the category in text form of each of the corresponding cases. In a second column of the display frame user selectable boxes are provided to allow a user to confirm whether or not the corresponding cases belong to the category displayed in this case the batt category. The user selectable boxes are clickable by a user to perform confirmation or disconfirmation. Also the categorizer can provide an initial guess as to whether or not the displayed cases belong to the category by displaying a check mark or leaving the user selectable box blank .

If the result cases do not fit in one page a scroll bar is provided to enable the user to scroll to the remaining cases. Alternatively a user may specify that the GUI screen displays a set of randomly selected cases that fit within the display frame such that the scroll bar would not have to be used.

In the third column of the display frame a summary of the case such as the case title is illustrated. For example the summary provided can have been previously entered by a customer support representative when answering customer calls. Even though the displayed summaries may contain mis spellings grammatical errors and abbreviations a user looking at each summary can quickly ascertain whether each respective case is associated with the category in question.

Note that each of the case titles displayed in the third column of the display frame contains the word charge. Based on the displayed case title a user can select or de select each user selectable box in the second column . In other implementations other types of summaries can be displayed in the third column to provide information that the user can use to select or de select boxes in the second column . Selection of a box indicates that the user has confirmed that the particular case belongs to the category. On the other hand when a user de selects a box in the second column that is an indication that the corresponding case does not belong to the category in question that is the user has disconfirmed that the case belongs to the category .

In a different embodiment instead of displaying just one category the display frame can display multiple categories with fields that are user selectable to confirm or disconfirm whether a case belongs to the categories. A confirmed case can be added to a positive training set while a disconfirmed case can be added to a negative training set. The positive and negative training sets are used to train the categorizer.

As a user labels cases as belonging or not belonging to particular categories based on input to the confirmation module training cases positive and or negative training cases are added. As the training cases are added the categorizer is trained concurrently. The training of the categorizer as positive training cases or negative training cases are added can be performed in the background according to some embodiments so that the training or retraining of the categorizer does not interfere with the search and confirm processes used for identifying training cases. The trained categorizer is installed atomically once the training is complete. If the user makes changes to the categories while the categorizer is training the training can be stopped and restarted with the modified categories. Note that the term training refers to either the first training of a categorizer or a retraining of the categorizer.

Also as categories are added modified and or deleted the categories displayed in the first frame are changed by the category editor . During the search confirm and training processes the Estimate and Quantity columns and in the second frame are also continually updated by the quantifier .

As shown in the data collector receives at information regarding customer support issues which information is received from one or plural call agent stations . In a different embodiment the data collector receives information regarding other issues in other contexts. The data collector stores at information regarding customer support issues in a data set or plural data sets .

Examples of the types of information that are received and stored include information such as the time and duration of call information about the product being called about replacement parts ordered compensation offered or repair people sent information automatically gathered from a computer of a customer uniform resource locators URL s or other resources visited and documents consulted in attempting to solve the problem linked information on the demographics of the customer e.g. location age gender technological sophistication loyalty generated revenue etc. call agent entered description of the state of mind of the customer description of interaction between call agents and customers call agent selection of a category or problem based on a call transcripts or recording of on line chat sessions or telephone conversations call agent written short summaries of a problem customer e mail messages records of pages visited on a web site such as on line documents viewed by customer or call agent outputs from a diagnostic program data stored in a database e.g. data relating to a prior support call information relating to a purchase and demographic information of a customer computer files received from a customer survey data data received by a monitoring device and others.

Next an optional search and confirm procedure may be performed for the purpose of developing training cases for categories associated with the unlabeled cases. The training cases is used to train one or plural categorizers .

The analysis tool reads an initial hierarchy of categories at . One way of creating the initial hierarchy categories is based on user input. In one scenario where training cases are to be developed for a new project a set of categories may not yet exist. In this scenario a user can create one or a few categories as the starting point. An expert may create the categories based on a preconceived notion of the relevant categories such as problems associated with a particular project. Alternatively the expert may create the one or few categories based on prior experience or common knowledge of the expert. For example it may be well known that a product has problems with battery life wireless connectivity and keys following off. In a second approach an expert may eyeball cases by scooping random samples and seeing which problems jump out at the expert. A user or expert can add delete or modify categories using the category editor .

Alternatively instead of relying on a human user or expert an automated module in the analysis tool can be used to examine the unlabeled cases and determine based on this examination one or plural possible categories. For example one technique that can be used by such a module is a cluster detecting technique based on a clustering algorithm to identify groupings of cases. These groupings of cases identified are reviewed by a user or expert to determine which categories are appropriate to add to an initial set of categories. Note that this initial set of categories provided at does not have to be highly accurate categories nor do these categories have to survive the process of developing the categories. The initial set of categories merely provides a starting point.

In a different scenario there may already be a set of extant categories that can be used as a starting point for further development of training cases.

After one or a few initial categories have been identified at for the purpose of searching and confirming the scooping process can begin. To start the scooping process a user enters a query relating to a category into the search area of the GUI screen . A query relates to a category if the query contains search term s for finding cases that belong to the category. Note that a query relating to one category can also relate to other categories as well in other words in some scenarios a query can contain search terms to find cases belonging to multiple categories. The query received at by the search engine can be in any of a number of formats including a Boolean expression a structured query language SQL query or some other type of query. The search engine can also have the capability of matching search terms specified by the query with related terms such as synonyms. The related terms that are to be matched to the search term specified in the query can be grouped into a collection of terms. A case containing a term that matches any of the collection of terms is considered to be a match by the search engine .

In response to the query the search engine identifies at the matching set of cases and displays at the identified set of cases in the user interface . As depicted in the example GUI screen of the displayed summary of the matching cases includes numbers dates and short strings with a single line per case in a table. Alternatively the identified cases may be displayed in two dimensional or three dimensional graphs or in other formats. Optionally a user can also access information in addition to the displayed information such as by clicking on a link. Additionally the displayed information includes the category or categories that a user or the categorizer has associated with the case either based on an earlier training set or based on a prediction by the categorizer .

As noted above the submission of the query identification of cases matching the query and the display of the cases is part of the scooping process. Typically the scooping process has been performed with a hypothesis in the form of cases that match this query should be training examples for category C. 

After the cases have been displayed by the search engine then the confirmation module can receive at user confirmation or disconfirmation. For example some of the cases may have been identified or inferred as being or not being in the category or categories in question. In the example of some of the user selectable boxes in column of the display frame can have been checked based on this previous identification or inference.

In an embodiment the categorizer can determine whether a matching case should be indicated as belonging to a category by computing a confidence indication. The confidence indication is compared to a predefined threshold and if the confidence indication is greater than the predefined threshold the categorizer identifies the matching case as belonging to the category.

The user next goes through the displayed cases and either confirms or disconfirms by respectively checking the box or leaving the box checked or un checking the box or leaving the box un checked in the column . Note that a case can belong to more than one category so that a scoop for one category may return cases that have already been labeled as belonging to another category. Note that check boxes constitute one example implementation for confirming or disconfirming that a case belongs to a category. There are numerous other techniques in other implementations including techniques to check plural boxes at the same time.

For those cases that have been indicated as belong to the category in question based on user selection of the box in column in the confirmation module modifies at the positive training set by adding such cases to the positive training set for the category. For those cases that have been incorrectly matched which are cases that the categorizer initially identified as belonging to the category but which the user has disconfirmed as belonging to the category the confirmation module modifies at the negative training set by adding such cases to the negative training set for the category. Optionally when the user disconfirms a case as belonging to a first category the user can confirm that the case belongs to another category although the user does not have to . The positive training set of cases and negative training set of cases are part of the training cases in . Note that there can be plural sets of positive cases and plural sets of negative cases for respective categories.

Steps are repeated to develop training cases for other categories or to more fully develop training cases for a current category.

In an alternative embodiment where the search and confirm procedure of is not used a machine learning algorithm can be used for producing a trained categorizer that is based on training cases developed by another technique.

In accordance with some embodiments as part of the process of confirming or disconfirming cases the user may realize that a new category should be created. In the example depicted in the user can do this using one of the menu items of the GUI screen such as the File Edit or Tools menu items or some other control element in the GUI screen . As shown in the category editor receives at an edit input through the GUI screen regarding a newly created category or subcategory a modified category or subcategory or a deleted category or subcategory . In response to user input adding a new category or subcategory modifying a category or subcategory or deleting a category or subcategory the category editor modifies at the hierarchy of categories . In the present discussion it is noted that adding deleting or modifying a category refers to adding deleting or modifying a category and or a subcategory. The user can also split a category into multiple categories or reparent a category indicate one category as being a parent of another category .

The modification of the hierarchy of categories can result in changes of the positive and negative training sets which changes are propagated at .

Since any added or modified category is based on a user s examination of the summaries of cases listed in response to the query the added or modified category is likely to be semantically meaningful the label for the category or subcategory is descriptive of the corresponding problem or other event or item . Also the set of categories created is not biased by any requirement that all cases have to be labeled or that all cases have to be assigned to a single category.

As discussed as the user performs confirm disconfirm and as categories or subcategories are added modified deleted changes occur in the positive and negative training sets which are propagated at through the hierarchy of categories as depicted in . The display of cases per category is updated at .

As the training cases are being updated by the scooping and confirming processes described above the categorizer is trained at in the background for categories whose positive or training sets have changed. Optionally the retraining at can be delayed by use of a timer involving optional steps and . The timer is set or updated at to expire after a predetermined amount of time. Any change to the training cases will cause the process to loop back to step which will cause the timer to again be set or updated at . After some period of stability a period during which no changes occur has been detected the timer expires at which allows the categorizer retraining at to be performed. Checking for stability at avoids the situation where many successive changes in the positive and training sets in a short period of time caused by user confirming disconfirming or category modification causes the retraining to restart many times. The retraining of the categorizer can occur generally concurrently with the scooping and confirming processes so that the user can continue to perform the scooping and confirming processes even while the categorizer is being trained subject to the training module optionally waiting for expiration of the timer to ensure some period of stability. An output provided by the scooping process confirming process and training process described above is a categorizer or plural categorizers.

The retrained categorizer is invoked to re categorize or relabel at the cases . Also the quality of categorization or labeling performed by the categorizer can be determined at and a measure of this quality can be displayed at . The quality measures of a categorizer are listed above. If the quality measures of the categorizations performed by the trained categorizer indicate that the categorizations are either incorrect or of insufficient confidence quality measure being less than a predefined threshold the categorizer can be retrained again.

As depicted in at some point which can be during or after the categorizer s has been trained and has been invoked to categorize cases in the one or more data sets the quantifier is created at . The quantifier is also calibrated at to take into account any inaccuracies present in the categorizer . As noted above a categorizer usually does not perform categorization of cases with perfect accuracy. An indication of quality of a categorizer that has been trained is provided by one or more of the quality measures listed above. In some embodiments the quantifier is calibrated based on the quality measures.

In one embodiment to calibrate the quantifier with respect to a category C the analysis tool determines the fraction TPR of the time that the categorizer is correct when presented with a case that should be categorized in a category C also referred to as the true positive rate and the fraction FPR of the time that the categorizer is wrong when presented with a case that should not be categorized in the category C also referred to as the false positive rate . Assuming that a data set includes a total of T cases of which N cases have been categorized in the category C then the calibration to be performed by the calibrated quantifier on the value N is as follows FPR TPR FPR where N is the calibrated N value.

Similar fractions representing true positive rates and false positive rates are also maintained for the other categories to enable calibration of the quantity values for other categories. This calibration technique for calibrating a quantifier categorizer is described in U.S. patent application entitled A Method of and System for Classification Count Adjustment filed by George H. Forman et al. on Mar. 14 2005. In other embodiments any other technique of calibrating a quantifier or adjusting its output quantification especially by observing the behavior of its underlying categorizer s may also be used.

In yet another calibration technique a score associated with each of a group of cases is obtained from the categorizer. A statistical distribution is computed based on the scores. The quantification measure is adjusted based on the statistical distribution.

The calibrated quantifier is used to update at quantification measure s for each of the categories. The calibrated quantifier produces calibrated quantification measure s . The categorizer s associated with the quantifier provides information regarding the categorized cases to the quantifier to enable the quantifier to produce the quantification measure s . Note that the quantification process can proceed concurrently with the search and confirm and the training processes discussed above. Thus the analysis tool may present running estimate s of the quantification measure s in each category. The running estimate is updated as the categorizer is further trained or as new cases arrive. The quantifier displays at the updated quantification measures such as estimated number of cases and quantity estimates columns and in the frame of .

Steps are created to continually update quantification measure s as more cases are received and the categorizer is retrained.

As shown in the ranking module receives at the quantification measure s generated by the quantifier . Identification of higher priority categories can be based on the received quantification measure s . For example a category having a larger number of cases can be ranked higher than a category having a lower number of cases. Alternatively a category associated with a higher aggregate number e.g. hours spent resolving calls estimated lost revenue etc. can be ranked higher than another category with a lower aggregate number.

Optionally for more accurate ranking the ranking module also receives at adjusted quantification measure s extrapolated or normalized quantification measure s from the adjustment module . Extrapolation can be based on a simple trend such as a trend detected over time. The extrapolated quantification measures represent quantification measure predicted for a future time period based on the detected trend. The adjusted quantification measure s can also include normalized quantification measure s based on factors such as sales numbers and trends marketing promotions seasonal buying patterns product end of life information product introduction information and so forth. For example a larger number of calls can result from a marketing promotion for a given time period. Thus such larger number of calls should be normalized to factor out the increase in the number of calls due to increased sales volumes due to the marketing promotion.

A benefit of using adjusted quantification measure s for identifying higher priority categories is that categories that may appear currently to be major issues may not be major issues in the future or after normalizing the measure s to account for various factors.

Based on the actual quantification measure s from the quantifier or the adjusted quantification measure s from the adjustment module the ranking module provides information to identify higher priority categories at . As an example the ranking module can provide information identifying the top ten or other number of categories that represent problems that should be addressed e.g. categories associated with highest quantification measures . Alternatively the information presented by the ranking module can be for categories associated with quantification measures that are greater than a predefined threshold. Alternatively the presented information is for categories associated with highest quantification measures that when aggregated exceeds a predefined threshold e.g. the quantification measures represent costs where aggregation of costs exceed a particular percentage such as 80 of the overall cost of all categories .

The ranking module generates at a report or multiple reports that lists the ranked categories. The report s can be in graphical textual or in any format as discussed above. The report s can also be interactive report s such as in web page format to enable a user to drill down to obtain various information relating to the issues identified in the report e.g. quantification measure s information regarding sub issues detailed information regarding the issues example cases and so forth.

The quantification measures provided in the report s are estimated measures that provide indications of magnitudes associated with various categories e.g. magnitude of problems etc. . Also the presented quantification measures in the report s can be predictions of what the quantification measures will be for the various categories in a future time period. The predicted quantification measures can be based on extrapolating observed quantification measures into the future which can be based on linear regression fitting as an example.

The content of a report can optionally be presented in a document containing information indicated by one or more of the following parameters a selection criterion for categories to display a desired depth to display in a hierarchy of problems an ordering criterion used to rank categories a category to focus on a set of information related to a category to display a selection of a presentation format and a selection of a data set to use as the first data set. The document can be interactive to provide a user with the ability to dynamically alter one or more of the parameters. The document can be communicated to another computer or device over a computer network.

The report s generated by the ranking module can also present information regarding a subset of cases within a category. For example a report may be focused on a particular product model a particular geographic region e.g. state country demographic information of customers incident dates purchase dates product introduction dates and product manufacture dates. This enables a user of the analysis tool to determine quantification measures and other information relating to the subset of cases. As an example the user may realize that a particular model or geographic or user sophistication level has a relatively greater number or fewer instances of a particular problem which information can point the way to a solution. The information can also be presented hierarchically. The user can also select the number of levels of the hierarchy to view.

Also a user may select that the report contains information for multiple subsets of cases. The information such as ranking information and quantification measures can be provided in the report for the multiple subsets to enable comparison by a user of the relative magnitudes of the plural subsets of cases.

The report s generated can also show information that changes over time. For example a graph for a current set of data can be overlaid or presented next to graphs produced for cases in earlier time periods. In fact the output quantifier produced by the analysis tool can be used to process earlier data in other data sets for more accurate comparison with current data.

Based on output provided by the ranking module such as in the form of the report s generated at an organization or user can take an action with respect to higher priority categories such as to take action to fix a problem or to address some other issue . As shown in the organization or user obtains at the ranking information from the report s provided by the analysis tool . The ranking information is associated with quantification measures that provide indications of magnitudes of the various categories. Optionally the quantification measures can be predicted quantification measures for a future time period.

For categories associated with quantification measures above some predefined threshold e.g. number of calls greater than a predefined number total amount of time to resolve the calls greater than a predefined time total amount of lost revenue greater than a predefined amount and so forth the organization or user obtains at computations of the following 1 the estimated cost related to labor costs associated with the amount of time involved in addressing the category parts cost etc. to address the issue associated with each of such categories and 2 the expected benefit of taking an action e.g. cost savings increased revenue etc. . The computations can be calculated manually or in an automated fashion using a module of the analysis tool or by some other software module.

Next the organization or user obtains at computations of the expected return on investment ROI for addressing each of the categories. To calculate the expected ROI expected cost information relating to an action taken with respect to a category is received. Cost information includes any or some combination of the following labor cost to implement a product fix material cost to implement the product fix labor cost related to time spent creating documentation and so forth. The expected ROI is computed based on a value e.g. monetary value such as cost savings increased revenue increased customer satisfaction or some other benefit that can be expected from addressing the issue associated with the category.

The expected improvement in customer satisfaction results from taking an action with respect to a particular category. For example customer satisfaction can be improved if call agents responding to customer complaints or inquiries can answer such complaints or inquiries more quickly. Other types of actions can also improve customer satisfaction such as adding equipment to improve access times or availability of servers e.g. web servers providing documentation to allow customers to more easily use a product and so forth.

Next the organization or user causes at the categories to be ordered in a list according to either expected ROI. The organization or user then takes action at based on the ordered list to address issues associated with one or more of the categories. The categories for which the organization or user takes action can be based on the overall budget available to the organization or user. The organization or user can choose to ignore categories that are too small to justify expending resources to address.

Examples of actions that can be taken with respect to a category include one or more of allocating a sum of money or otherwise defining a budget allocating a physical resource e.g. equipment hiring a person assigning a task to a person writing a document such as a help document modifying an existing document identifying a document altering availability of a document such as to make the document more widely available such as posting the document on a web site altering an organization of a web site modifying a design of a product modifying a packaging of a product modifying a manufacturing process for a product creating a software program modifying a software program creating a patch for a software program contacting a customer vendor supplier employee or partner modifying a marketing campaign changing response time of service providers training service personnel discontinuing efforts that are no longer required changing the process of writing and delivery of software programs taking actions with reference to seasonal fluctuations provide reports to customers regarding how issues are being monitored and addressed and other actions.

Taking an action with respect to a given category can be based on single factor or multi factor input variable analysis to determine a most effective issue resolution path. A single factor input variable analysis refers to an analysis that takes into account a single input variable e.g. defective hard disk drives . A multi factor input variable analysis refers to an analysis that takes into account multiple input variables e.g. defective hard disk drives and an inability to boot . In some cases several factors or categories can be related. In the above example customers with defective hard disk drives are usually unable to boot. Consequently by performing multi factor input variable analysis it can be determined that solving the hard disk drive problem will also solve the inability to boot problem. In this manner the expected ROI would be higher since multiple categories can be addressed by one action.

As shown in the example case identifier is optionally invoked to identify at example cases for the listed categories provided by the ranking module . The example case identifier selects at a case or cases that are most confidently predicted to be representative of a category based on one or more factors. The example case identifier can also identify at cases that are similar to the selected example case such that the similar cases are not also provided as examples to reduce redundancy . The similar cases can then be removed at from consideration in finding other example cases. The other example cases for a category are selected based on dissimilarity with previously selected example cases so that a user is presented with a number of dissimilar example cases for better understanding of a particular category. When a desired number of example cases have been identified the example case identifier repeats steps for another category.

As noted above the example case identifier can also alternatively use a clustering algorithm for finding example cases for different clusters of a category.

The quantifier and ranking module can be used off line on the analysis server separate from the analysis tool or on another computer for application to other data sets. For use off line the created quantifier as calibrated along with associated categorizer s and the ranking module are packaged into a separate software tool that can be invoked on the computer or another computer.

As the quantifier in the separate software tool is used with new data sets the estimated quantification measure s made by the quantifier on the new data sets along with categorizations provided by the categorizer s can be provided to an expert or other user. The expert or other user can then decide whether further calibration of the quantifier and or training of the categorizer s associated with the quantifier should be performed.

The categorizer s associated with the quantifier is also able to produce confidence indications that are output for the new data sets. As an example the categorizer s is able to report the number of cases for which the categorizer s has a low level of confidence. As the number of low confidence cases grow then the categorizer s is retrained since the hierarchy of categories may no longer be sufficient. The analysis tool can then again be used in an interactive fashion with a user to retrain the categorizer s and either create a new quantifier or modify the existing quantifier.

Instructions of the various software modules described above are loaded for execution on corresponding processors. The processors include microprocessors microcontrollers processor modules or subsystems including one or more microprocessors or microcontrollers or other control or computing devices. As used here a controller refers to hardware software or a combination thereof. A controller can refer to a single component or to plural components whether software or hardware .

Data and instructions of the software are stored in respective storage devices which are implemented as one or more machine readable storage media. The storage media include different forms of memory including semiconductor memory devices such as dynamic or static random access memories DRAMs or SRAMs erasable and programmable read only memories EPROMs electrically erasable and programmable read only memories EEPROMs and flash memories magnetic disks such as fixed floppy and removable disks other magnetic media including tape and optical media such as compact disks CDs or digital video disks DVDs .

In the foregoing description numerous details are set forth to provide an understanding of the present invention. However it will be understood by those skilled in the art that the present invention may be practiced without these details. While the invention has been disclosed with respect to a limited number of embodiments those skilled in the art will appreciate numerous modifications and variations therefrom. It is intended that the appended claims cover such modifications and variations as fall within the true spirit and scope of the invention.

