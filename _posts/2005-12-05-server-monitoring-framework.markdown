---

title: Server monitoring framework
abstract: A novel software framework monitors server statistics for a plurality of software modules and makes its collected statistics available to those modules. Unlike prior implementations, the framework provides shared server-monitoring code through which the plurality of software modules can monitor various types of servers, such as authentication servers, ICAP servers, origin servers, hierarchical proxy servers and so forth. Because the same server-monitoring code is accessed by each of the software modules, the overall amount of code that is written, compiled and executed may be reduced. Moreover, the shared server-monitoring code is not protocol-dependant and therefore may be coded outside of the kernel-level protocol engines. Preferably, the shared server-monitoring code is implemented as a user-level thread or process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07653722&OS=07653722&RS=07653722
owner: NetApp, Inc.
number: 07653722
owner_city: Sunnyvale
owner_country: US
publication_date: 20051205
---
The present invention generally relates to monitoring server statistics and more specifically to a novel framework through which multiple software modules can register servers to monitor and access statistical information associated with their registered servers.

In general a server may be configured to provide information to one or more clients according to a client server model of information delivery. In this model the server is a storage system that typically contains one or more mass storage devices such as magnetic hard disks in which information may be stored and retrieved as desired. The server is usually deployed over a computer network comprising a geographically distributed collection of interconnected communication links such as Ethernet optical or wireless links that allow the clients to remotely access the server s stored information. The clients may include network devices or computers that are directly or indirectly attached to the server e.g. via point to point links shared local area networks LAN wide area networks WAN or virtual private networks VPN implemented over a public network such as the Internet.

In some client server arrangements the server may be configured as a network cache that buffers previously accessed or frequently accessed client information. As such the server provides a set of clients with faster access to the buffered information than if they were to access the same information directly from the origin servers that normally serve the information. For instance the set of clients may be physically situated closer to the network cache than to the origin servers or the clients may be able to access the cache over a lower latency or higher bandwidth data path etc. The network cache s buffered information is typically in the form of files which are made accessible to the set of clients.

In practice the network cache can be configured to operate as a reverse proxy or forward proxy cache. A reverse proxy cache is a server that stores a selected set of information from one or more origin servers. For example a multimedia company may copy selected streaming audio or video content from its origin servers to a reverse proxy cache which is then used as an accelerator for providing the selected content to clients. In contrast a forward proxy cache is a server that buffers network data for a particular set of clients. Unlike the reverse proxy cache the forward proxy cache does not necessarily store selected data from specific origin servers and instead may store data from a variety of different origin servers i.e. based on the network traffic patterns of the cache s particular set of clients.

A reverse proxy or forward proxy cache may be coupled to one or more other servers in a computer network. In a conventional two level cache hierarchy clients communicate with child network caches which are coupled to one or more higher level parent caches which in turn are coupled to one or more origin servers. A subset of the parent caches files are stored in the child caches and a subset of the origin servers files are stored at the parent caches. The above noted hierarchy may be generalized to various levels wherein each cache in the hierarchy is coupled to one or more higher level proxy caches and or origin servers. Network caches in such a hierarchical arrangement typically communicate with one another by exchanging discrete packets of data formatted according to predefined file access protocols such as the HyperText Transfer Protocol HTTP Network File System NFS protocol Common Internet File System CIFS protocol File Transfer Protocol FTP etc.

A network cache also may be coupled to other types of servers besides origin servers and higher level proxy caches. For instance the cache may be coupled to an authentication server such as Remote Authentication Dial In User Service RADIUS server that implements a predetermined authentication procedure. RADIUS and its associated protocol are generally described in more detail in the Request For Comments RFC 2138 entitled by Rigney et al. published April 1997 which publication is available through the Internet Engineering Task Force IETF and is hereby incorporated by reference as though fully set forth herein.

Yet other types of servers also may be coupled to the network cache. For instance Lightweight Directory Access Protocol LDAP servers may provide directory services for the network cache such as storing public key certificates email addresses etc. whereas Internet Content Adaptation Protocol ICAP servers may provide object based content vectoring services such as virus scanning content filtering and the like. The LDAP protocol is generally described in more detail in RFC 2251 entitled 3 by Wahl et al. published December 1997 and the ICAP protocol is described more in detail in RFC 3507 entitled by Elson et al. published April 2003 and both of these publications are hereby incorporated by reference as though fully set forth herein.

Because the network cache can communicate with servers using many different types of network communication protocols the cache generally executes a separate protocol specific software module for each protocol type. As used herein a software module may be a user level or kernel level process or thread. For example each protocol specific software module may be implemented as a kernel level protocol engine that executes in the network cache. That is the cache may include a HTTP protocol engine that is configured to communicate with higher level proxy caches or origin servers using the HTTP protocol. Similarly the cache may include RADIUS LDAP and ICAP protocol engines that respectively communicate with remote RADIUS LDAP and ICAP servers.

Often the network cache may be coupled to more than one server configured to communicate using the same network communication protocol. Each protocol engine in the network cache typically includes a mechanism for selecting an optimal or best available server among multiple servers of the same protocol type. A protocol engine may select the optimal server based on various statistics associated with the servers such as their available bandwidths round trip times or response times and so forth. For example if the cache is coupled to multiple RADIUS servers the RADIUS protocol engine may be configured to select an optimal RADIUS server for authenticating clients e.g. based on which of the RADIUS servers has the shortest latency for response.

Each protocol engine typically includes server monitoring code for collecting and storing server statistics and selecting optimal servers of a given protocol type. For example server monitoring code in the HTTP protocol engine may be configured to collect and store the network cache s HTTP server statistics in a first table whereas server monitoring code in the ICAP protocol engine may collect and store the cache s ICAP server statistics in a second table. In this case the HTTP protocol engine consults the contents of the first table to select an optimal HTTP server and the ICAP protocol engine references the contents of the second table to select an optimal ICAP server. More generally in the conventional case every software module that is configured to monitor server statistics has to periodically query each of its monitored servers and then store its obtained server statistics in a local protocol specific statistics table i.e. allocated for and managed by the software module.

The above noted conventional approach to monitoring and selecting optimal protocol specific servers suffers various disadvantages. First each protocol engine contains a copy of substantially the same server monitoring code usually differing only in terms of which particular protocol is used to collect and store the server statistics. As a result a large amount of server monitoring code is usually replicated among the protocol engines in the network cache. Such code replication often causes the network cache to consume excessive processing and memory resources e.g. storing and executing multiple versions of essentially the same server monitoring code. For example the conventional approach may consume excessive memory resources since each protocol engine allocates and maintains a separate statistics table for storing its collected server statistics.

In addition since the protocol engines are typically implemented at the kernel level i.e. within the operating system of the network cache a problem with the server monitoring code in one protocol engine may affect operations of other kernel level processes in the operating system. For example a software bug in one protocol engine s server monitoring code could stall interrupt or otherwise crash the operating system and require the entire system to be rebooted or the operating system to be recompiled. Accordingly it is often difficult for an administrator of the network cache to manage and debug the multiple versions of server monitoring code executing in the kernel level protocol engines.

The present invention overcomes the disadvantages of the prior art by providing a software framework that monitors server statistics for a plurality of software modules and makes its collected statistics available to those modules. Unlike prior implementations in which each software module executes its own version of server monitoring code the novel framework provides shared server monitoring code through which the plurality of software modules can monitor various types of servers such as authentication servers ICAP servers origin servers hierarchical proxy servers and so forth. Because the same server monitoring code is accessed by each of the software modules the overall amount of code that is written compiled and executed may be reduced. Moreover the shared server monitoring code is not protocol dependant and therefore may be coded outside of the kernel level protocol engines. Preferably the shared server monitoring code is implemented as a user level thread or process.

In accordance with an illustrative embodiment the software framework includes a server monitoring thread a statistics table and an application programming interface API . Each entry in the statistics table is configured to store statistics and other information associated with a different server. The server monitoring thread collects server statistics and updates the contents of the statistics table. For example the thread may periodically measure a connection based round trip time RTT or a protocol specific RTT for a particular server. One or both of the server s measured RTT times may be input to a mathematical function that derives a weight metric representative of the relative availability of the server. Then the thread may store the weight metric and measured RTT times at appropriate locations in the server s corresponding table entry in the statistics table. The timing interval that the server monitoring thread uses to update the RTT times and weight metric may be predefined or user configured e.g. by a system administrator and may differ from server to server.

The API provides a software interface that enables the plurality of software modules to i add or remove servers from the statistics table and ii access statistics and other information stored in the table. In the latter case the API may provide selective filtering and searching services for accessing information in the statistics table. The API is responsive to a set of predetermined function calls which may be customized for different operating environments. For instance a software module may invoke an API function to add or register one or more servers in the statistics table. Each of the module s registered servers is allocated a separate entry in the statistics table and the contents of each entry is periodically updated by the server monitoring thread. Later the software module may invoke an API function to request which of the module s registered servers has the largest or smallest associated weight metric. Alternatively the software module may request that the API return only those registered servers having weight metrics above or below a predetermined threshold value or within a specified range of weight metric values.

Advantageously the server monitoring thread is not replicated for each software module as it is in previous implementations and therefore can provide more efficient resource utilization and simplified code management. Preferably the server monitoring thread is a user level thread that may be debugged or restarted without affecting the underlying operating system. The thread may be configured to collect various types of server statistics and other information for the software modules. Further the thread also may be configured to combine at least some of its collected statistics in accordance with one or more mathematical weighting functions e.g. predefined by a system administrator. Based on the outputs of the weighting functions a preferred subset of the thread s monitored servers can be identified.

The exemplary network is arranged as a two level cache hierarchy in which the network cache stores a subset of the files contained in the higher level proxy caches and respectively labeled proxy cache and proxy cache . The higher level proxy caches in turn store a subset of the files available in the origin server . Besides the proxy caches and the network cache may be coupled to one or more other servers including for example a RADIUS server and an ICAP server . Of course those skilled in the art will appreciate that the cache also may be coupled to e.g. LDAP servers origin servers other RADIUS or ICAP servers proxy servers etc. in addition to or in place of the servers explicitly depicted in the network .

The network cache communicates with the client and its neighboring servers using one or more network communication protocols. For instance the cache may exchange data with the client and higher level proxy caches using the HTTP protocol and may communicate with the RADIUS and ICAP servers using the RADIUS and ICAP protocols respectively. The network cache transmits and receives data as protocol data units PDU which are formatted according to specific network communication protocols. The cache typically transmits the PDUs over a reliable transport protocol such as the conventional Transmission Control Protocol TCP .

In practice the client may send a request to the network cache to access a particular file. The cache analyzes the received request to determine whether it contains a local copy of the client requested file. If so the cache returns its local copy of the requested file to the client. However if the client requested file is not already resident in the cache the cache may be configured to forward the client request to one of the higher level proxy caches or . If the higher level proxy cache determines that it contains a local copy of the client requested file then a response containing the requested file is returned to the network cache which then may store a local copy of the file before forwarding the file to the requesting client . However if a copy of the requested file is not resident in the higher level proxy cache the higher level proxy cache requests the file from the origin server . Thereafter the origin server retrieves the requested file from its data storage and the file is forwarded in a downstream direction from the origin server to the higher level cache to the network cache and eventually to the client . In this case both the network cache and the higher level proxy cache may store local copies of the client requested file.

When the network cache is coupled to multiple servers of the same protocol type the cache may have to select which of the servers to forward PDUs of that protocol type. For instance consider the exemplary cache which is coupled to two different HTTP based proxy caches and . Suppose that a client requested file is not locally available at the network cache and thus the cache needs to request the file from at least one of the higher level proxy caches or . The network cache may be configured to select an optimal one of the higher level caches e.g. based on one or more server statistics associated with the proxy caches and . After selecting an optimal higher level proxy cache the network cache may forward a HTTP request to the selected cache in order to retrieve the client s requested file.

In accordance with an illustrative embodiment of the invention the network cache employs a novel software framework that enables it to select an optimal server from a plurality of servers of the same protocol type. To that end the software framework monitors statistics corresponding to various servers coupled to the network cache and makes its collected statistics available to protocol engines executing in the cache. The protocol engines can select optimal servers associated with their respective protocols based on the statistics collected by the software framework. Advantageously unlike prior implementations where each protocol engine executes a separate set of server monitoring code for collecting server statistics the novel framework instead provides a single set of server monitoring code for each of the protocol engines. Consequently the overall amount of code that is written compiled and executed in the network cache may be reduced. Moreover the shared server monitoring code is not protocol dependant and therefore may be coded outside of the kernel level protocol engines. The shared server monitoring code is preferably implemented as a user level thread and is also preferably started at system bootup time. As such the user level server monitoring thread may be debugged or restarted without affecting the underlying operating system or other threads and processes.

The novel software framework may be used to monitor servers in various network configurations including but not limited to the topology illustratively depicted in the exemplary computer network . For example rather than collect server statistics for multiple ICAP RADIUS or hierarchical proxy servers the network cache instead may be configured as a reverse proxy cache that collects server statistics associated with a plurality of origin servers . In this scenario the reverse proxy cache collects server statistics associated with each of the origin servers that it accelerates. The cache can use its collected statistics to determine a preferred origin server from which it can retrieve client requested information.

The storage adapter interfaces with one or more mass storage devices . Each mass storage device may be embodied as any type of writable storage device such as a magnetic or optical disk drive a non volatile random access memory e.g. FLASH memory a magnetic or optical tape drive an erasable programmable read only memory EPROM or any other form of mass storage device. Preferably the storage devices are deployed as an array of storage disks . The disks may be arranged as a Redundant Array of Independent Disks RAID group so that some disks store striped data and at least one disk stores separate parity data for the group e.g. in accordance with a conventional RAID 4 configuration. However other configurations e.g. RAID 5 having distributed parity across stripes are also contemplated.

The storage adapter is configured to store and retrieve a set of data objects such as files from the disks . The storage adapter includes input output I O interface logic and circuitry that couples the disks to the adapter over an I O interconnect arrangement such as a conventional Fibre channel serial link topology. A client requested file may be retrieved by the storage adapter and if necessary processed by the N module and D module processors and or the storage adapter itself prior to being forwarded over the system bus to an appropriate network adapter . The file is formatted into a response that is transmitted from the network adapter to the requesting client .

The memory comprises storage locations that are addressable by the processors and adapters for storing program code and data. The memory preferably comprises a form of random access memory RAM that is generally cleared is by a power cycle or other reboot operation e.g. it is a volatile memory . The processors and adapters comprise processing elements logic and or circuitry configured to execute the software code and manipulate the data stored in the memory . It will be apparent to those skilled in the art that various types of memory means including computer readable media and electromagnetic signals may be used for storing program instructions pertaining to the inventive technique described herein.

The memory may be logically organized to include a kernel memory and a user memory . The kernel and user memories may be embodied as different memory regions in a shared memory or alternatively may be logically and or physically differentiated as known in the art. The kernel memory is configured to store kernel level threads processes and related data structures whereas the user memory is configured to store user level threads processes and related data structures. In accordance with the illustrative embodiments the kernel memory is configured to store among other things a storage operating system including a statistics table N module software D module software network caching software and an application programming interface API . Further to the illustrative embodiments the user memory is configured to store among other things a user level server monitoring thread .

The storage operating system portions of which are typically resident in the memory and executed by the N module and D module processors and functionally organizes the network cache by inter alia invoking storage operations in support of the storage services provided by the cache. The storage operating system includes a set of core services such as file system semantics disk I O operations memory management and the like. For example the storage operating system may include N module software that defines a set of software layers i.e. a network protocol stack for formatting and processing data packets sent and received at the network interfaces . Similarly the operating system may include D module software for performing file system semantics and RAID related operations.

Although the N module software is preferably executed by the N module processor and the D module software is preferably executed by the D module processor those skilled in the art will appreciate that other hardware configurations are possible. For instance the processors and may be configured to execute portions of both the N module and D module software or a single processor may be employed and so forth. The storage operating system is preferably implemented as the NetApp Data ONTAP operating system available from Network Appliance Inc. of Sunnyvale Calif. However it is expressly contemplated that other storage operating systems may be used in accordance with the inventive principles described herein.

The storage operating system includes network caching software that functionally invokes proxy caching operations for storing and retrieving files from the memory and storage disks . The caching software is further configured to cooperate with remote servers to retrieve those client requested files that are not stored locally in the cache . The network caching software may be embodied within a version of the NetCache software module developed by Network Appliance Inc. of Sunnyvale Calif. or in any other similar software module that is used to manage proxy caching operations. Although the network caching software is preferably directly incorporated into the storage operating system it alternatively may be implemented as a separate user process i.e. outside of the operating system kernel .

In accordance with the illustrative embodiment the network cache implements a novel software framework including inter alia the statistics table server monitoring thread and API . The statistics table is configured to store server statistics and other information associated with a set of servers coupled to the network cache . The statistics table may be stored at a predetermined location in the memory and its contents may be made available to both kernel level and user level threads and processes.

Advantageously the statistics table is preferably located in the kernel memory in order to facilitate faster access to the table by kernel level software modules such as the network caching software . Accordingly by storing the table in the kernel memory the kernel level software modules can quickly access the table without having to perform a context switch out of kernel memory space. Although this illustrative embodiment requires the user level server monitoring thread to perform a context switch whenever it accesses the statistics table it is expected that the server monitoring thread accesses the table less frequently than do the kernel level software modules which may access the table once per client request. Consequently an improvement in access latency can be achieved by eliminating context switching for the more common case of kernel level accesses to the statistics table .

The server monitoring thread collects server statistics and updates the contents of the statistics table . Preferably the thread is a user level thread that is executed by the N module processor . Further the server monitoring thread is preferably started at system bootup time. The server monitoring thread may implement a separate timer for each server that it monitors in order to determine when it is time to update that server s statistics. When a timer expires the server monitoring thread may invoke a helper thread that collects server statistics for the timer s associated server and then updates the statistics table based on the newly collected statistics. The timing intervals of the timers may be predefined or user configured e.g. by a system administrator and may differ from server to server.

The API provides a kernel level interface through which a plurality of software modules can i add or remove servers from the statistics table and ii access statistics and other information stored in the table. In the latter case the API may provide selective filtering and searching services for accessing information in the statistics table . The API is responsive to a set of predetermined function calls which may be customized for different operating environments. By way of example a software module may invoke an API function to add or register one or more servers in the statistics table. Each of the module s registered servers is allocated a separate entry in the statistics table and the contents of each entry is periodically updated by the server monitoring thread . Later the software module may invoke an API function to retrieve statistical information or other information associated with its registered servers. For instance the software module may request that the API search the statistics table to identify which of the module s registered servers is associated with statistical information satisfying certain search criteria e.g. from which the software module can select an optimal server.

The internetwork layer typically implements a version of the Internet Protocol IP which is primarily a connectionless protocol that provides internetwork routing fragmentation and assembly of data packets. The IP protocol generally relies on transport protocols for end to end reliability and other service characteristics. The transport layer implements the transport protocols such as the TCP protocol that provide connection oriented end to end reliability services to the upper layer protocols of the network protocol stack. The protocol engines implement various network communication protocols that process packet data received from the lower levels of the network protocol stack. The protocol engines may be implemented as software modules that are configured to process data packets formatted in accordance with for example the HTTP protocol LDAP protocol ICAP protocol RADIUS protocol and or other protocols not explicitly shown. After processing a particular request or response a protocol engine may send the processed request or response back to the lower layers of the protocol stack for transmission to an intended recipient.

The statistics table includes a plurality of table entries each corresponding to a different server to be monitored by the server monitoring thread . Each table entry is configured to store among other things a software module identifier a server identifier a protocol type a timing interval a TCP round trip time RTT a protocol specific RTT a weight function and a weight metric . Those skilled in the art will appreciate that other information besides the fields explicitly depicted also may be stored in the statistics table .

The software module identifier is a value that uniquely identifies which particular software module registered the server identified by the server identifier . The identifier alternatively may denote a particular user who registered the server through a software module. Software module identifier values may be statically assigned to various software modules and or users e.g. by a system administrator or may be dynamically assigned e.g. by the API through which the software modules and users register add servers to the table . The server identifier is a value such as an IP address that uniquely identifies a particular server coupled to the network cache . The protocol type is a value that indicates which network communication protocol should be used to monitor the server .

Referring again to suppose that the proxy cache is assigned an IP address 10.1.1.1 and the proxy cache is assigned an IP address 10.1.1.2. Further assume that the HTTP protocol engine is associated with a software module identifier value equal to 1 e.g. assigned by the API . Accordingly if the HTTP engine registers both of the HTTP based proxy caches and in the statistics table separate table entries and may be allocated for each of these proxy caches. The exemplary statistics table also may include entries corresponding to servers registered by other software modules or users. For instance the table entry indicates that an ICAP server assigned to an IP address equal to 10.5.6.7 was registered by the ICAP protocol engine having a software module identifier value equal to 2. 

The timing interval indicates how often the server monitoring thread updates the contents of the table entry . The value of the timing interval may be predefined or user configured e.g. by a system administrator. As shown the timing intervals stored in the exemplary table entries and indicate that server statistics associated with the proxy caches and are updated once every two seconds. In contrast the timing interval stored in the table entry indicates that server statistics associated with the ICAP server are updated once every second. The server monitoring thread preferably implements a separate timer for each table entry i.e. a separate timer for each registered server and the duration of a table entry s timer is preferably set equal to the entry s timing interval .

In the illustrative embodiment each table entry is configured to store a TCP RTT and a protocol specific RTT . More generally the table entries may be configured to store any type of server statistics. The TCP RTT indicates the responsiveness of a TCP connection between the network cache and the server . In operation when a table entry s associated timer expires the server monitoring thread sends a TCP synchronization SYN packet to the server identified by the table entry s server identifier . The server monitoring thread measures the TCP RTT as the amount of time elapsed e.g. in seconds from the time the TCP SYN packet was transmitted until a corresponding TCP acknowledgment ACK message is received at the network cache . Preferably if the measured TCP RTT is greater than a predetermined threshold value then the TCP session is determined to be inoperative and currently unavailable. In this situation the value of the TCP RTT may be left unchanged or set to a predefined value e.g. equal to zero.

Assuming the measured TCP RTT is less than or equal to the predetermined threshold value the server monitoring thread subsequently measures a protocol specific RTT for the server . The protocol specific RTT indicates the responsiveness of communicating with the server using the protocol identified by the protocol type . More specifically the server monitoring thread measures the protocol specific RTT as the amount of time that it takes for the server to respond to a protocol specific message. For example if the protocol type corresponds to the HTTP protocol the protocol specific RTT may be measured as the amount of time it takes for an HTTP server to respond to a conventional HTTP GET message.

In some cases the protocol type may correspond to a custom protocol i.e. that does not coincide with a standard network communication protocol. If the protocol type is custom then the table entry also may include an additional monitoring function field not shown that identifies a particular monitoring function that should be used for measuring the protocol specific RTT . The monitoring function field may store a memory address pointer to a block of monitoring function code e.g. stored in the memory that measures the protocol specific RTT in accordance with the custom protocol type.

The weight function identifies a predetermined mathematical function which may be used to calculate the weight metric . The weight function may be stored in the table entry as a memory address pointer to function code e.g. stored in the memory that implements the mathematical function. The weight metric is a value that represents a relative preference level or rank that characterizes the relative desirability of communicating with the server . Preferably the weight metric is a measure of the relative ease with which the network cache can communicate with the server . In the illustrative embodiment one or both of the measured RTT values and may be input to the weight function which then outputs the calculated weight metric .

Consider the weight function f x y x y where x equals the TCP RTT and y equals the protocol specific RTT . In this case the weight function f x y calculates a weight metric based on the sum of a server s TCP and protocol specific RTT measurements and . Next consider the weight function g x y y where y is the protocol specific RTT . Unlike the function f x y the weight function g x y calculates a weight metric based solely on the value of the server s protocol specific RTT. As shown in the exemplary table entries and the weight function f x y is used to calculate the weight metrics for the HTTP based proxy caches and the table entry indicates that the weight function g x y is used to calculate the weight metric of the ICAP server . Those skilled in the art will appreciate that the functions f x y and g x y are merely illustrative and any weight function may be employed to calculate the weight metrics in accordance with the present invention.

The API may receive a register monitor function call that requests the API to register add one or more servers in the statistics table . In response to receiving the register monitor function call the API allocates a separate table entry for each newly registered server. The register monitor function call may specify one or more arguments including for example a server identifier protocol type timing interval weight function and monitoring function if necessary. Other information not explicitly specified in the function call may be determined by the API . For example the API may allocate a software module identifier corresponding to which particular user or software module sent the register monitor function call to the API.

The network caching software protocol engines or other software module may send the API one or more function calls to retrieve statistical information or other information from the statistics table . For instance a software module may send a get weight function call to request that the API return the weight metric of a particular server. In response to receiving the get weight function call the API searches the statistics table to locate a table entry containing both the requesting software module s identifier and a server identifier corresponding to the server specified in the get weight function call. After locating this matching table entry the API returns the entry s weight metric to the requesting software module. The software module also may send the API a get best weight function call that requests the API to identity of which of the module s registered servers has the largest or smallest weight metric . Yet another API function call may request that the API return only those registered servers having weight metrics above or below a predetermined threshold value or within a specified range of weight metric values.

The server monitoring thread is preferably a user level thread i.e. not compiled into the operating system. The thread allocates a separate timer for each table entry in the statistics table . When a table entry timer expires the server monitoring thread creates a helper thread that queries the server identified by the table entry s server identifier and measures the table entry s TCP and protocol specific RTT values and . To effectuate these measurements the helper thread sends a TCP SYN packet and or a protocol specific message to the server and measures the latency RTT for response. The helper thread inputs its TCP and or protocol specific RTT measurements into the table entry s identified weight function which calculates an updated weight metric . The helper thread stores the calculated weight metric in the expired timer s associated table entry . After storing the weight metric the helper thread is preferably de allocated. Alternatively rather than de allocating the helper thread after it has finished updating the contents of the table entry the helper thread instead may be rendered inactive until the table entry timer expires again.

Because more than one timer may expire before the helper thread has finished measuring the TCP and protocol specific RTT values and updating the contents of the table entry multiple helper threads may be instantiated concurrently. For example as shown in a first helper thread may be in communication with a server A at substantially the same time as a second helper thread communicates with a different server B. A conventional lock manager not shown may be implemented by the server monitoring thread to manage lock contention among the helper threads as they concurrently update their respective table entries . In a preferred embodiment the storage operating system includes an API different from the novel API which is configured to issue read and write locks to multiple helper threads as they concurrently update the contents of different table entries in the statistics table .

At step the API creates a new table entry in the statistics table for each server identified in the received request. For each new table entry the API stores a software module identifier as well as the received server identifier protocol type timing interval weight function and monitoring function. The API may have to allocate the software module identifier for the requesting software module if one was not previously allocated. At step the API or server monitoring thread allocates a table entry timer for each new table entry . Thereafter at step the newly registered servers are monitored by the server monitoring thread. Specifically the thread periodically updates server statistics and other information stored in each table entry e.g. in response to the table entry s timer expiring. The sequence ends at step .

At step the helper thread sends a conventional TCP SYN packet to the server identified in the expired timer s associated table entry. Then the TCP RTT is is measured as the amount of time that it takes for the server to return a TCP ACK message in response to the TCP SYN packet. The helper thread stores the measured TCP RTT value in the expired timer s table entry at step . Next at step the server monitoring thread determines whether the measured TCP RTT value is greater than a predetermined threshold value. If so then at step the server is determined to be currently unavailable i.e. since it took an excessive amount of time to respond to the TCP SYN packet if it responded at all the sequence advances to step .

If at step the measured TCP RTT value is less than or equal to the predetermined threshold value then at step the helper thread measures a protocol specific RTT for the server . The protocol specific RTT is measured as the amount of time that it takes for the server to respond to a protocol specific message. At step the helper thread stores the protocol specific RTT value in the expired timer s associated table entry . Then at step the helper thread inputs the measured TCP and protocol specific RTT measurements into a weight function identified in the table entry. The weight function outputs a weight metric which the helper thread stores in the table entry. At step the helper thread is deallocated or otherwise rendered inactive. The expired table entry timer is reset at step and then the sequence returns to step .

The foregoing description has been directed to particular embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. For instance although the novel software framework is illustratively deployed in a network cache it is also expressly contemplated that the inventive framework may be implemented in other types of computer systems and network devices. Additionally the novel software framework may be configured to monitor server statistics corresponding to remote servers such as the exemplary servers as well as local servers e.g. executing within the network cache . In other words at least one of the plurality of software modules executing in the network cache may be configured to register a server for the server monitoring thread to monitor such that the registered server is also executing in the network cache.

In the illustrative embodiment the server monitoring thread is configured to periodically update server statistics for each server registered in the statistics table . It is further contemplated that in alternative embodiments the server monitoring thread may update at least some of the table entries on a non periodic basis. Furthermore although each table entry is illustratively associated with a separate table entry timer those skilled in the art will understand that a single table entry timer may be associated with multiple table entries . For instance suppose a single timer is associated with the table entries and . In this case when the timer expires a pair of helper threads may be concurrently instantiated for updating server statistics and other information stored in the table entries and . Although the statistics table is preferably organized in tabular form those skilled in the art will appreciate that the table may be implemented using various types of data structures including but not limited to conventional tree structures linked lists hash tables and so forth.

It is expressly contemplated that the weight functions stored in the statistics table may correspond to any type of predetermined mathematical function including both linear and non linear functions. More generally the weight functions may employ any technique that generates one or more weight metrics based on at least one measured server statistic. For example a weight function may be implemented as a lookup table that maps measured TCP and or protocol specific RTT values and to equivalent weight metrics . When a software module requests the API to search the statistics table for registered servers meeting predetermined search criteria the API may be configured to issue an error message if it cannot locate any servers satisfying the criteria.

The procedures threads processes and or modules described herein may be implemented in hardware software embodied as a computer readable medium having program instructions firmware or a combination thereof. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

