---

title: Programming multiple chips from a command buffer for stereo image generation
abstract: Multiple graphics devices are operable in parallel to render stereo images using efficient programming techniques. The same command stream is delivered to each graphics device, and device masks are used to control the execution of commands by different graphics devices. A viewing transform command corresponding to a left-eye transform is executed by one device while a viewing transform command corresponding to a right-eye transform is executed another device. Other rendering commands are executed by both devices to render the same image from somewhat different viewpoints.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07602395&OS=07602395&RS=07602395
owner: NVIDIA Corporation
number: 07602395
owner_city: Santa Clara
owner_country: US
publication_date: 20050422
---
The present disclosure is related to commonly assigned co pending U.S. patent application Ser. No. 10 639 893 filed Aug. 12 2003 entitled Programming Multiple Chips from a Command Buffer which disclosure is incorporated herein by reference for all purposes.

The present invention relates in general to the field of computer graphics and more particularly to computer generation of stereo images. Many computer graphic images are created by mathematically modeling an approximation of the interaction of light with a three dimensional scene from a given viewpoint. This process called rendering generates a two dimensional image of the scene from the given viewpoint and is analogous to taking a photograph of a real world scene. Stereo images can be created by rendering two somewhat different images of the same scene one image is viewed by a left eye while the other is viewed by a right eye thereby creating the illusion of a single three dimensional image.

As the demand for computer graphics and in particular for real time computer graphics has increased computer systems with graphics processing subsystems adapted to accelerate the rendering process have become widespread. In these computer systems the rendering process is divided between a computer s general purpose central processing unit CPU and the graphics processing subsystem. Typically the CPU performs high level operations such as determining the position motion and collision of objects in a given scene. From these high level operations the CPU generates a set of rendering commands and data defining the desired rendered image or images. For example rendering commands and data can define scene geometry lighting shading texturing motion and or camera parameters for a scene. The graphics processing subsystem creates one or more rendered images from the set of rendering commands and data.

To maximize rendering performance the graphics processing subsystem may include two or more graphics processing units GPUs operating in parallel. The graphics processing units can divide the rendering workload in a number of different ways. For example different portions of an image can be rendered in parallel by different GPUs. The portions are then combined to produce a complete rendered image. In another example parallel rendering scheme each GPU renders one image in a sequence of images. In still another example two GPUs can operate in parallel to render stereo images with one GPU rendering left eye images while the other GPU renders right eye images.

Programming multiple GPUs with a CPU is one difficulty arising from parallel rendering schemes. In parallel rendering schemes GPUs require a mixture of rendering commands common to all of the GPUs in the graphics processing subsystem and rendering commands specific to each GPU. However programming each GPU with different rendering commands and data often requires a large allocation of system resources for each GPU. This programming overhead makes parallel rendering schemes inefficient and in some cases even limits the total number of GPUs that can be used by the graphics processing subsystem.

Therefore it is desirable to have an efficient system and method for programming multiple graphics processing units with rendering commands while consuming a minimal amount of system resources. It is further desirable to be able to program multiple graphics processing units with both rendering commands common to all of the graphics processing units and rendering commands specific to one or more graphics processing units.

Embodiments of the present invention provide graphics devices operable in parallel to render stereo images and efficient techniques for programming such graphics devices for stereo image generation. The same command stream is advantageously delivered to each graphics device and device masks are used to control the execution of commands by different graphics devices. In particular the device masks are used such that a viewing transform command corresponding to a left eye transform is executed by one device or group of devices while a viewing transform command corresponding to a right eye transform is executed by another device or group of devices . Other rendering commands for the image are executed by both devices or groups of devices so that the same image is rendered from somewhat different viewpoints. The two images can then be delivered to a suitably configured stereo display device for viewing by a user.

According to one aspect of the present invention a method for generating a stereo image in a graphics subsystem comprising multiple graphics devices includes communicating a first device mask command and a first viewing transform command to each of the graphics devices with the first device mask command designating a first subset of the graphics devices to execute the first viewing transform command. A second device mask command and a second viewing transform command are also communicated to each of the graphics devices with the second device mask command designating a second subset of the graphics devices to execute the second viewing transform command. A third device mask command and a rendering command are also communicated to each of the graphics devices with the third device mask command designating both the first subset and the second subset of the graphics devices to execute the rendering command.

In some embodiments a unique identifier is associated with each of the graphics devices. The first device mask command can designate the first subset of the graphics devices according to the unique identifiers associated with the graphics devices. For example the first device mask command might include a set of bits each bit associated with one of the unique identifiers and adapted to designate the inclusion of one of the graphics devices in the first subset of the graphics devices.

Various graphics devices can be used in combination. For example at least one of the graphics devices can be a graphics processing unit and at least one of the graphics devices can be a coprocessor.

In some embodiments a program flow command is also communicated to each of the graphics devices. The program flow command is advantageously executed by each of the graphics devices regardless of the device mask commands.

A variety of communication techniques may be used. For example in some embodiments commands are communicated with each of the graphics devices via a single memory aperture. In other embodiments commands are communicated with each of the graphics devices via a bridge chip. In still other embodiments the commands are written into a command buffer adapted to be read asynchronously by each of the graphics devices.

According to another aspect of the present invention a graphics device is adapted to operate in parallel with at least one other graphics device. The graphics device includes a core unit adapted to execute commands and a front end unit adapted to receive a stream of commands and communicate commands from the stream to the core unit. The front end unit is further adapted to determine which commands to communicate to the core unit based on a device mask command included in the stream. The command stream includes a first device mask command associated with a first viewing transform command corresponding to a left eye view of a scene and a second device mask command associated with a second viewing transform command corresponding to a right eye view of the scene in response to the first and second device mask commands the front end unit communicates only one of the first and second viewing transform commands to the core unit. The graphics processing device might be for example a graphics processing unit or a coprocessor.

In some embodiments the front end unit is further adapted to execute commands associated with program flow regardless of the first and second device mask commands.

In some embodiments the command stream further includes a third device mask command associated with a rendering command in response to the third device mask command the front end unit communicates the rendering command to the core unit.

In some embodiments a unique identifier is associated with the graphics device and the third device mask command and only one of the first and second device mask commands each include a reference to the unique identifier. In some embodiments the device mask command includes a bit mask including a bit associated with the graphics device.

According to still another aspect of the present invention a computer program product includes a computer readable medium encoded with program code. The program code includes program code for communicating a first device mask command and a first viewing transform command to each of multiple graphics devices the first device mask command designates a first subset of the graphics devices to execute the first viewing transform command. The program code further includes program code for communicating a second device mask command and a second viewing transform command to each of the graphics devices the second device mask command designates a second subset of the graphics devices to execute the second viewing transform command. The program code further includes program code for communicating a third device mask command and a rendering command to each of the graphics devices the third device mask command designates both the first subset and the second subset of the graphics devices to execute the rendering command. In some embodiments the program code further includes program code for communicating a program flow command to each of the graphics devices the program flow command is executed by each of the graphics devices regardless of the device mask commands.

The following detailed description together with the accompanying drawings will provide a better understanding of the nature and advantages of the present invention.

A graphics subsystem is further connected with data bus and the components of the computer system . The graphics subsystem includes a graphics processing unit GPU and graphics memory. Graphics memory includes a display memory e.g. a frame buffer used for storing pixel data for each pixel of an output image. Pixel data can be provided to display memory directly from the CPU . Alternatively CPU provides the GPU with data and or commands defining the desired output images from which the GPU generates the pixel data of one or more output images. The data and or commands defining the desired output images is stored in additional memory . In an embodiment the GPU generates pixel data for output images from rendering commands and data defining the geometry lighting shading texturing motion and or camera parameters for a scene.

In another embodiment display memory and or additional memory are part of memory and is shared with the CPU . Alternatively display memory and or additional memory is one or more separate memories provided for the exclusive use of the graphics subsystem . The graphics subsystem periodically outputs pixel data for an image from display memory and displayed on display device . Display device is any device capable of displaying visual information in response to a signal from the computer system including CRT LCD plasma and OLED displays. Computer system can provide the display device with an analog or digital signal.

In a further embodiment graphics processing subsystem includes one or more additional GPUs similar to GPU . In an even further embodiment graphics processing subsystem includes a graphics coprocessor . Graphics processing coprocessor and additional GPUs are adapted to operate in parallel with GPU . Additional GPUs generate pixel data for output images from rendering commands similar to GPU . Additional GPUs can operate in conjunction with GPU to simultaneously generate pixel data for different portions of an output image or to simultaneously generate pixel data for different output images. In an embodiment graphics coprocessor performs rendering related tasks such as geometry transformation shader computations and backface culling operations for GPU and additional GPUs .

Additional GPUs can be located on the same circuit board as GPU and sharing a connection with GPU to data bus or can be located on additional circuit boards separately connected with data bus . Additional GPUs can have their own display and additional memory similar to display memory and additional memory or can share memories and with GPU . In an embodiment the graphics coprocessor is integrated with the computer system chipset not shown such as with the Northbridge chip used to control the data bus .

In general split frame parallel rendering schemes such as that illustrated by require GPUs to be programmed with a combination of common rendering commands which are executed by all of the GPUs of the system and specific rendering commands which are executed by a subset of the GPUs of the system. In the example of both GPUs are programmed with common rendering commands necessary to render all of the geometry and shading of the scene. The GPUs are then programmed with separate rendering commands to define clipping windows corresponding to image portions and .

Memory map graphically represents the range of available memory addresses in system . Memory map contains several apertures or ranges of memory addresses used to communicate with the GPUs and . Broadcast aperture enables the CPU to communicate with all of the GPUs in the system simultaneously. Commands and data written to the broadcast aperture are distributed to all of the GPUs and as well as any other GPUs in the system . In some systems a bridge chip is associated with the broadcast aperture and is adapted to copy data written to the broadcast aperture to each GPU in the system .

In addition to the broadcast aperture the memory map also includes a set of unicast apertures and . Unicast apertures and are adapted to distribute commands and data to GPUs and respectively. Commands and data written to a unicast aperture will only be distributed to the GPU associated with the unicast aperture. The unicast apertures enable the CPU to program GPUs and separately.

The use of broadcast and unicast apertures to program multiple GPUs introduces several limitations. First there is typically a separate unicast aperture for each GPU in a system. As each typical unicast aperture can be 256 megabytes in size systems with a large number of GPUs often need to reserves gigabytes of address space for the apertures. The large address space requirements can limit the performance of systems and in extreme cases limit the potential number of GPUs in a system particularly with 32 bit systems that are often limited to 4 gigabytes of total address space. Additionally some systems require that the GPUs operating in parallel be synchronized. To prevent de synchronization when the CPU writes commands and data to one unicast aperture the CPU must also write null commands and padding data to all of the other unicast apertures. This makes programming individual GPUs very inefficient.

Command buffer stores sets of commands such as rendering command and sets of rendering data such as rendering data . In one embodiment a rendering command is associated with rendering data. The rendering command defines the set of rendering processes to be performed by the GPU on an associated rendering data. In a further embodiment the rendering data is stored in the command buffer adjacent to the corresponding rendering command.

The CPU writes commands and data sets to the command buffer . The command buffer can include a number of commands and data sets. The CPU writes commands and data sets into the command buffer at the location determined by put pointer . Following each CPU write into the command buffer the CPU increments the put pointer to the next unused location in the command buffer . In an embodiment a driver software program executed by the CPU translates high level commands from a rendering application into commands and data sets which are then written into the command buffer . In a further embodiment the driver software program receives high level commands via an application programming interface for example DirectX or OpenGL .

The GPU reads commands and data sets from the command buffer at the location determined by get pointer . Following each GPU read from the command buffer the GPU increments the get pointer to the location of the next command or data set in the command buffer .

The CPU and GPU can access the command buffer independently. In an embodiment the CPU periodically adds new commands and data sets to the command buffer while the GPU continuously reads and processes commands and data sets previously stored by the CPU . Provided the CPU stays sufficiently far ahead of the GPU the GPU is able to render images without any idle time waiting for the CPU . In an embodiment the CPU writes commands and data sets for frames several frames ahead of the frame being rendered by the GPU .

In an embodiment the command buffer is limited in size. As an example a typical command buffer is five megabytes in size. When either the get pointer or put pointer reaches the end of the command buffer the pointer is reset to the location of the beginning of the command buffer . In this manner the command buffer wraps around enabling the CPU and GPU to access the command buffer in a continuous loop.

Command buffer includes common commands and data sets which are to be read and executed by all of the GPUs. To program a subset of the GPUs in the system separately the CPU writes a Set Device Mask SDM command to the command buffer . The SDM command designates a subset of GPUs to execute subsequent GPU specific rendering commands in the command buffer such as rendering commands . As discussed below any GPUs that are not designated by the SDM command will ignore the GPU specific rendering commands. However as discussed below the non designated GPUs will continue to read from the command buffer to maintain synchronization. A different subset of GPUs can be designated by a second SDM command to execute another group of GPU specific rendering commands. Following one or more groups of GPU specific rendering commands command buffer includes an SDM command designating all of the GPUs in the system. One or more groups of common rendering commands following SDM command will then be executed by all of the GPUs.

In an embodiment the SDM command includes a device mask designating the GPUs that will execute subsequent rendering commands. In this embodiment each GPU is assigned a unique identifier. In a further embodiment the identifier is assigned to each GPU and a graphics coprocessor if present by a software driver upon system initialization. Each identifier corresponds to a single bit in the device mask. If a bit in the device mask is asserted then the associated GPU is designated to execute subsequent rendering commands. Conversely a negated bit instructs a GPU to ignore subsequent rendering commands until its associated bit is reasserted.

For example SDM command includes a device mask with a value of 0 . . . 01. This device mask indicates that GPU should execute subsequent rendering commands while GPUs and will ignore rendering commands . It should be noted that the device mask included with the SDM commands can include any number of bits thereby enabling the separate programming of any number of GPUs. Further the device mask can have any combination of asserted or negated bits. This enables the CPU to program two or more GPUs simultaneously. For example a device mask of 100001111 would indicate that GPUs and are to execute subsequent rendering commands while GPUs and are to ignore subsequent rendering commands until their corresponding device mask bits are reasserted.

It will be appreciated that the SDM commands described herein are illustrative and that variations and modifications are possible. For example in one alternative embodiment instead of inserting a separate SDM command into the command buffer each rendering command can be accompanied by a set of device mask bits indicating whether a particular GPU should execute or ignore the rendering command.

Front end includes a command receive unit for receiving a command and data from the command buffer. Command can be classified as either an instruction or a rendering method and command receive unit includes logic for determining whether the received command is an instruction or a rendering method. Instructions are commands that determine the program flow executed by the GPU . Examples of instructions include a jump instruction which sets the get pointer to a new non consecutive location a no op instruction which does nothing and is used as a placeholder and call and return functions which are used to enter and exit subroutines of commands. The SDM command is also classified as an instruction. Rendering methods are commands that determine the pixel data output by the GPU. In embodiment the front end executes instructions and the GPU core executes rendering methods.

Upon receiving an instruction the command receive unit forwards the instruction to the instruction decoder . Rendering methods are similarly forwarded to method cache to be retrieved and executed by the GPU core subject to the SDM instruction. Upon receiving an SDM instruction instruction decoder compares the device mask with its own assigned identifier. If the associated bit of the device mask is negated the instruction decoder disables the link between command receive unit and method cache . This causes all subsequent rendering methods received by the GPU to be discarded and ignored.

During the time when GPU is ignoring rendering methods the front end continues to retrieve commands from the command buffer and to execute any commands that are instructions. For example instruction decoder can update the get pointer if indicated by a jump call or return instruction. In this manner the GPU state stays synchronized with the other GPUs even when the commands that are rendering methods are being ignored. Upon receiving a subsequent SDM instruction having the bit associated with GPU reasserted instruction decoder re enables the link between the command receive unit and the instruction cache . As a result subsequently received rendering methods are added to the cache and are processed by the GPU core .

Each viewing coordinate system is used to define a viewing transform a left eye transform and a right eye transform respectively that is applied during rendering to map the 3 D object onto a 2 D screen. Since the viewing coordinate systems are not identical the viewing transforms will be slightly different resulting in two slightly different 2 D images being rendered. The 2 D image generated using the left eye transform is delivered to the viewer s left eye while the 2 D image generated using the right eye transform is delivered to the viewer s right eye. If the left eye and right eye coordinate systems and are correctly placed and aligned relative to each other the viewer will perceive a realistic 3D image of the scene.

Flip command set includes one or more commands that are executed when rendering of the scene is complete. Various commands may be included in flip command set . Where the display buffers of the GPUs are double buffered e.g. where new pixel data is written to a back buffer while previously rendered pixels in a front buffer are read out to display device flip command set may include commands that reverse the identifications of the front and back buffers as is known in the art. Flip command set may also include a block transfer or blit command that instructs one of the GPUs to transfer its pixel data to the display memory of the other of GPUs for display the blit command may be preceded by an SDM command designating just one of the GPUs to perform the transfer. In still other embodiments flip command set may also include various synchronization instructions for GPUs so that new images for the left eye and right eye are delivered substantially simultaneously to stereo display device . Any timing offsets between the left eye and right eye are advantageously small enough to be imperceptible to a human viewer.

It will be appreciated that the command buffer described herein is illustrative and that variations and modifications are possible. For instance multiple GPUs can be used to generate the images for each eye. illustrates a system for rendering portions of each eye for a stereo image in parallel according to an embodiment of the invention. System includes GPUs and and stereo display device . In one embodiment GPUs and are located on separate circuit boards e.g. expansion cards for a computer system alternatively GPUs are located on one circuit board while GPUs are located on a different circuit board or all four GPUs might all be located on the same circuit board. In a further embodiment only one of GPUs is directly connected to the display device and the other GPUs deliver data to display device via the directly connected GPU. In yet a further embodiment system includes a coprocessor that may act as one of the GPUs. Alternative embodiments may have any number of GPUs arranged on any number of circuit boards and may or may not include a coprocessor.

Each of GPUs renders a different portion of an image for viewing by a right eye while each of GPUs renders a different portion of an image for viewing by a left eye. For instance if the image in is a right eye image GPU might render top portion while GPU renders bottom portion or vice versa. Similarly if image is a left eye image GPU might render top portion while GPU renders bottom portion .

Similarly command set includes an SDM command designating both right eye GPUs and and a VTR command defining a right eye viewing transform as described above. Command set includes an SDM command designating GPU only and a command C setting the clip region for GPU to the portion of the right eye image to be rendered by GPU . Command set includes an SDM command designating GPU only and a command C setting the clip region for GPU to the portion of the right eye image to be rendered by GPU .

Command set includes an SDM command with a device mask of 1111 that enables simultaneous programming of all of the GPUs. Common rendering commands SCENE commands following this SDM command are executed by all of the GPUs. A flip command or command set similar to flip command set described above follows the last common rendering command. In some embodiments the flip command set may include one or more blit commands instructing any GPUs that are not directly connected to display device to transfer their data to another GPU to be read out. For example in an embodiment where only GPU is directly connected to display device blit commands may be used to copy the portions rendered by GPUs and to the display memory of GPU . Because each image portion should be copied to a different location in the display memory of GPU the flip command set may include SDM commands to selectively program GPUs and with different copy commands. GPU outputs the assembled image to display device . In another embodiment GPUs and might both be connected to stereo display device and the flip command set may include SDM commands to selectively program GPU to copy its data to GPU and GPU to copy its data to GPU . It will be appreciated that this embodiment can be extended to use any number of GPUs the total processing power is advantageously divided as equally as practicable between left eye images and right eye images.

In still another embodiment referring to GPUs and are operated in an alternate frame rendering mode to render right eye images while GPUs and are operated in alternate frame rendering mode to render left eye images. In alternate frame rendering mode different GPUs render different images in a sequence of images to be viewed by the same eye. For example GPU might render a first right eye image while GPU renders a first left eye image GPU a second right eye image and GPU a second left eye image.

The invention provides a very efficient way to program multiple GPUs and an optional graphics coprocessor for generating stereo images without consuming an exorbitant amount of system resources. In a typical embodiment only a single memory aperture is needed to program any number of devices and all commands that are common to both eyes of a stereo image can be written only once.

Although the invention has been discussed with respect to specific examples and embodiments thereof these are merely illustrative and not restrictive of the invention. For instance the SDM commands are not required to be separate commands in the command stream in some embodiments a device mask may be appended to some or all of the commands e.g. using additional bits and a device mask appended to a command may affect only that command or all commands until a new device mask is presented. Further while the invention is discussed with reference to various parallel rendering schemes the invention can be used in any application where different hardware devices are used to render the left eye and right eye portions of a stereo image. Thus the scope of the invention is to be determined solely by the claims.

