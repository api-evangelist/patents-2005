---

title: Rendering images containing video
abstract: A video node for use in rendering one or more video frames of a video stream. The video node is represented by a compositing tree (). The compositing tree () comprises at least one image primitive node () representing one or more video frames () of the video stream. At least one of the video frames () represented by the image primitive node () is composited with at least one further graphical primitive represented by at least one further primitive node () of the compositing tree (). The video frame () is composited with the further graphical primitive according to a compositing operation represented by an operation node of the compositing tree () in order to generate a composite image () represented by at least one composite node () of the compositing tree ().
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07403209&OS=07403209&RS=07403209
owner: Canon Kabushiki Kaisha
number: 07403209
owner_city: Tokyo
owner_country: JP
publication_date: 20050317
---
This application claims the right of priority under 35 U.S.C. 119 based on Australian Patent Application No. 2004901571 filed 24 Mar. 2004 which is incorporated by reference herein in its entirety as if fully set forth herein.

The present invention relates generally to image processing and in particular to rendering video images comprising a plurality of frames. The present invention also relates to a method and apparatus for rendering video images and to a computer program product including a computer readable medium having recorded thereon a computer program for rendering video images.

Many existing graphics rendering systems provide images text and line work as primitives . The term primitive refers to a base graphical element used in the creation of a complex graphical image. In order to display video images on such graphics rendering systems software applications executing on the systems need to constantly update the contents of image primitives. These software applications also have to process audio data associated with the image primitives. The need to update image primitives constantly makes it difficult for software applications to process multiple video streams or to composite multiple video images and still images.

In order to improve the processing of multiple video streams some existing graphics rendering systems provide video images as a series of image primitives. However these rendering systems are typically limited in their ability to composite video with other video or still graphical primitives or to create special effects. Such rendering systems typically also require special hardware.

Thus a need clearly exists for an improved method and apparatus for rendering an image and in particular for rendering video images.

It is an object of the present invention to substantially overcome or at least ameliorate one or more disadvantages of existing arrangements.

According to one aspect of the present invention there is provided a video node for use in rendering one or more video frames of a video stream said video node being represented by a compositing tree said compositing tree comprising at least one image primitive node representing one or more video frames of said video stream at least one of said video frames represented by said image primitive node being composited with at least one further graphical primitive represented by at least one further primitive node of said compositing tree said at least one video frame being composited with said further graphical primitive according to a compositing operation represented by an operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree.

According to another aspect of the present invention there is provided a method of rendering an image said image being formed by compositing one or more graphical primitives according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive of said image or an operation for combining said graphical primitives said method comprising the steps of 

compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

compositing the composite image represented by said at least one composite node with one or more other composite images represented by other composite nodes of said compositing tree according to a further operation represented by a further operation node of said compositing tree in order to render said image wherein one or more attributes of said video frames are changeable by changing an attribute of said further operation node.

According to still another aspect of the present invention there is provided a method of creating a video node representing one or more video frames of a video sequence said video node being created according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive or an operation for combining said graphical primitives said method comprising the steps of 

representing said one or more video frames of said video sequence by at least one of said primitive nodes 

compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

compositing the composite image represented by said at least one composite node with one or more other ones of said graphical primitives represented by other ones of said primitive nodes of said compositing tree according to a further operation represented by said video node in order to create said video node representing said one or more video frames wherein one or more attributes of said video frames are changeable by changing an attribute of said video node.

According to still another aspect of the present invention there is provided an apparatus for rendering an image said image being formed by compositing one or more graphical primitives according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive of said image or an operation for combining said graphical primitives said apparatus comprising 

representation means for representing one or more video frames of a video sequence by at least one of said primitive nodes 

compositing means for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

further compositing means for compositing the composite image represented by said at least one composite node with one or more other composite images represented by other composite nodes of said compositing tree according to a further operation represented by a further operation node of said compositing tree in order to render said image wherein one or more attributes of said video frames are changeable by changing an attribute of said further operation node.

According to still another aspect of the present invention there is provided an apparatus for creating a video node representing one or more video frames of a video sequence said video node being created according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive or an operation for combining said graphical primitives said apparatus comprising 

representation means for representing said one or more video frames of said video sequence by at least one of said primitive nodes 

compositing means for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

further compositing means for compositing the composite image represented by said at least one composite node with one or more other ones of said graphical primitives represented by other ones of said primitive nodes of said compositing tree according to a further operation represented by said video node in order to create said video node representing said one or more video frames wherein one or more attributes of said video frames are changeable by changing an attribute of said video node.

According to still another aspect of the present invention there is provided a computer program product including a computer readable medium comprising recorded thereon a computer program for rendering an image said image being formed by compositing one or more graphical primitives according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive of said image or an operation for combining said graphical primitives said computer program comprising 

code for representing one or more video frames of a video sequence by at least one of said primitive nodes 

code for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

code for compositing the composite image represented by said at least one composite node with one or more other composite images represented by other composite nodes of said compositing tree according to a further operation represented by a further operation node of said compositing tree in order to render said image wherein one or more attributes of said video frames are changeable by changing an attribute of said further operation node.

According to still another aspect of the present invention there is provided a computer program product including a computer readable medium comprising recorded thereon a computer program for creating a video node representing one or more video frames of a video sequence said video node being created according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive or an operation for combining said graphical primitives said computer program comprising 

code for representing said one or more video frames of said video sequence by at least one of said primitive nodes 

code for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

code for compositing the composite image represented by said at least one composite node with one or more other ones of said graphical primitives represented by other ones of said primitive nodes of said compositing tree according to a further operation represented by said video node in order to create said video node representing said one or more video frames wherein one or more attributes of said video frames are changeable by changing an attribute of said video node.

According to still another aspect of the present invention there is provided a computer program for rendering an image said image being formed by compositing one or more graphical primitives according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive of said image or an operation for combining said graphical primitives said computer program comprising 

code for representing one or more video frames of a video sequence by at least one of said primitive nodes 

code for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

code for compositing the composite image represented by said at least one composite node with one or more other composite images represented by other composite nodes of said compositing tree according to a further operation represented by a further operation node of said compositing tree in order to render said image wherein one or more attributes of said video frames are changeable by changing an attribute of said further operation node.

According to still another aspect of the present invention there is provided a computer program for creating a video node representing one or more video frames of a video sequence said video node being created according to a compositing tree said compositing tree comprising a plurality of nodes each representing a graphical primitive or an operation for combining said graphical primitives said computer program comprising 

code for representing said one or more video frames of said video sequence by at least one of said primitive nodes 

code for compositing at least one of said video frames represented by said at least one primitive node with at least one further graphical primitive represented by at least one further primitive node of said compositing tree according to a first operation represented by a first operation node of said compositing tree in order to generate a composite image represented by at least one composite node of said compositing tree and

code for compositing the composite image represented by said at least one composite node with one or more other ones of said graphical primitives represented by other ones of said primitive nodes of said compositing tree according to a further operation represented by said video node in order to create said video node representing said one or more video frames wherein one or more attributes of said video frames are changeable by changing an attribute of said video node.

Where reference is made in any one or more of the accompanying drawings to steps and or features which have the same reference numerals those steps and or features have for the purposes of this description the same function s or operation s unless the contrary intention appears.

It is to be noted that the discussions contained in the Background section and that above relating to prior art arrangements relate to discussions of documents or devices which form public knowledge through their respective publication and or use. Such should not be interpreted as a representation by the present inventor s or patent applicant that such documents or devices in any way form part of the common general knowledge in the art.

A general purpose computer system upon which arrangements described below may be practiced is shown in . In particular the methods of may be implemented as software such as an application program executing within the computer system . In particular the steps of the described methods may be effected by instructions in the software that are carried out by the computer system . The instructions may be formed as one or more code modules each for performing one or more particular tasks. The software may also be divided into two separate parts in which a first part performs the described methods and a second part manages a user interface between the first part and the user. The software may be stored in a computer readable medium including the storage devices described below for example. The software may be loaded into the computer from the computer readable medium and then executed by the computer. A computer readable medium having such software or computer program recorded on it is a computer program product. The use of the computer program product in the computer preferably effects an advantageous apparatus for implementing the described method.

The computer system is formed by a computer module input devices such as a keyboard and mouse output devices including a printer a display device and loudspeakers . A Modulator Demodulator Modem transceiver device is used by the computer module for communicating to and from a communications network for example connectable via a telephone line or other functional medium. The modem may be used to obtain access to the Internet and other network systems such as a Local Area Network LAN or a Wide Area Network WAN and may be incorporated into the computer module in some implementations.

The computer module typically includes at least one processor unit and a memory unit for example formed from semiconductor random access memory RAM and read only memory ROM . The module also includes a number of input output I O interfaces including an audio video interface that couples to the video display and loudspeakers an I O interface for the keyboard and mouse and optionally a joystick not illustrated and an interface for the modem and printer . In some implementations the modem may be incorporated within the computer module for example within the interface . A storage device is provided and typically includes a hard disk drive and a floppy disk drive . A magnetic tape drive not illustrated may also be used. A CD ROM drive is typically provided as a non volatile source of data. The components to of the computer module typically communicate via an interconnected bus and in a manner which results in a conventional mode of operation of the computer system known to those in the relevant art. Examples of computers on which the described arrangements can be practised include IBM PC s and compatibles Sun Sparcstations or alike computer systems evolved therefrom.

Typically the software implementing the described methods is resident on the hard disk drive and is read and controlled in its execution by the processor . Intermediate storage of the program and any data fetched from the network may be accomplished using the semiconductor memory possibly in concert with the hard disk drive . In some instances the software may be supplied as an application program supplied to the user encoded on a CD ROM or floppy disk and read via the corresponding drive or or alternatively may be read by the user from the network via the modem device . Still further the software may also be loaded into the computer system from other computer readable media. The term computer readable medium as used herein refers to any storage or transmission medium that participates in providing instructions and or data to the computer system for execution and or processing. Examples of storage media include floppy disks magnetic tape CD ROM a hard disk drive a ROM or integrated circuit a magneto optical disk or a computer readable card such as a PCMCIA card and the like whether or not such devices are internal or external of the computer module . Examples of transmission media include radio or infra red transmission channels as well as a network connection to another computer or networked device and the Internet or Intranets including e mail transmissions and information recorded on Websites and the like.

The described methods may alternatively be implemented in dedicated hardware such as one or more integrated circuits performing the functions or sub functions of the described methods. Such dedicated hardware may include graphic processors digital signal processors or one or more microprocessors and associated memories.

Many existing graphics rendering systems use what is known as an immediate mode application programming interface API between an application program and a rendering system. For each video frame to be rendered for example a complete corresponding set of rendering commands are sent to the API by the application program. In contrast a retained mode API provides a complete compositing tree on a per frame basis. For such a retained mode API an application program provides an initial compositing tree. The initial compositing tree is then modified for each video frame in a video stream in order to effect a change in an image being displayed.

Modifications which may be made to a compositing tree include geometrically transforming part of the compositing tree or the entire compositing tree. The structure of a compositing tree may also be modified by unlinking and linking subtrees or nodes. Attributes eg colour or opacity of individual nodes of a compositing tree may also be changed modified.

In retained mode rendering systems graphical primitives may be used to build a compositing tree. Primitives form the leaf nodes of such a compositing tree. Six graphics primitives may be defined below as follows 

Compositing is the process of combining several graphical primitives to represent a final image. Graphical primitives may be combined using operators to represent more complex graphical images. The result of combining graphical primitives may likewise be combined using the same set of operators to form a compositing tree representing any desired image.

A sequence of images may be generated by repeatedly rendering or updating a compositing tree representing the image sequence. In a compositing tree graphical primitives are represented by the leaf nodes of the compositing tree and compositing operations are represented by the internal nodes of the compositing tree. The leaf nodes will be referred to below as primitive nodes and the internal nodes will be referred to as composite nodes. 

Primitive nodes and composite nodes may have different attributes associated with the nodes. These attributes may include transform matrices colour opacity and quality. Such attributes may be stored in memory and referenced by a corresponding node. A transform matrix determines the final position that a graphical primitive represented by a corresponding node will appear on a rendering target e.g. the display screen . The attributes such as opacity and colour apply to primitive nodes. Two new primitive types namely a video primitive and an audio primitive are described below for use in a retained mode rendering system.

As described above the software program implementing the described methods may be effected by instructions being executed by the processor . The instructions may be formed as one or more code modules each for performing one or more particular tasks. In one implementation the software may have three core code modules and as shown in . A rendering code module may be used to perform updating of a compositing tree representing an image to be displayed on the display for example. A media management code module may be used to perform media related functions. An encoder decoder code module may be used to provide encoding and decoding support to the media management code module .

In order to describe the code modules and in more detail an example of a compositing tree representing an image to be displayed on the display will now be described with reference to . The compositing tree comprises three primitive nodes and and two composite nodes and . The primitive node is a video primitive node or a video node . The video node represents a video primitive. In the present example the video primitive is a video movie as seen in . Frames of the video movie may be stored in a video file stored in memory which is referenced by the video node . Alternatively the video movie may be live streamed digital video e.g. input via the communications network . The primitive node represents a path primitive. In the present example the path primitive represented by the node is a circle shape path as seen in . A representation of the circle shaped path may be stored in a memory buffer configured within memory and referenced by the node . The primitive node is a video node. In the present example the video node represents a video movie as seen in . Frames of the video movie may be stored in a video file stored in memory or live streamed digital video may be used. The composite node represents the result of an in operation. The result of the in operation is the video movie clipped within the circle shape as shown in and may be stored in an intermediate buffer configured within memory . The composite node represents a final composite result as shown in and again may be stored in an intermediate buffer configured within memory . The final composite result will be explained in further detail below.

The method begins at the first step where the processor creates the video node representing the video movie . In this present example the video movie is used as an input video source to the video node and the frames of the video movie may be configured within a video file stored in memory which is referenced by the video node . At the next step the primitive node is created to represent the circle shape path . Then at step the video node is created to represent the video movie and the video movie is used as an input video source to the video node . Again frames of the video movie may be stored in a video file configured within memory and referenced by the video node .

The method continues at the next step where the video movie is clipped within the circle shape by compositing each of the frames of the video movie in the circle shape . That is the video node is composited with the primitive node using the in operation. The result of the in operation i.e. the clipped movie is represented by the composite node . Frames of the clipped movie may be stored in a video file configured within memory which is referenced by the composite node . Alternatively the frames of the clipped movie may be rendered to an intermediate buffer configured within memory . At the next step the clipped movie is placed on top of the video movie by compositing the frames of the clipped movie over frames of the video movie . Again the result of the over operation may be stored in a video file configured within memory which is referenced by the composite node or rendered to an intermediate buffer configured within memory . Then at step the video node and video node are set to a playing mode. The video nodes and may be set to play for example by executing the video files containing the frames of the video movies and respectively or the video file containing the result of the over operation. The setting of video nodes and to play may be triggered by altering the state of a variable associated with each of the nodes and for example. Similarly the playback rate of the video frames of the movies and the volume of audio associated with the video frames and the opacity of the video frames may be changed by altering the state of a variable associated with each of the video nodes and for example. In the following steps and the compositing tree gets updated regularly. A transform matrix of the composite node is changed before each update. The final output as seen in is the video movie playing at the same screen position at all times while the video movie plays inside the circle shape and moves around due to the transform matrix associated with the node changing as the compositing tree is updated. The updating of the compositing tree will be explained in more detail below with reference to .

The rendering code module executes in a retained mode rendering manner and thereby supports a compositing tree structure and compositing operations. In particular the rendering code module supports the operations plus and at least one of in or out . Alternatively the operations over or rover may be used instead of plus . Note rover is the same as over with the operands reversed. Using the operations plus and in or plus and out the media management code module may preform opacity operations on graphical primitives and in particular video images in an efficient manner.

An example of a video node representing a video primitive is shown in . A further example of a video node representing a video primitive which is equivalent to the node is shown in . A still further example of a video node representing a video primitive is shown in . An example of an audio node representing an audio primitive is shown in . A further example of an audio node representing an audio primitive is shown in . The video nodes and the audio nodes are collectively referred to as media nodes and will be described in more detail below. As will be described below the creation deletion seeking playing stopping and media attribute modification of the media nodes is executed by the media management code module . As described above the attributes of the media nodes may be changed by altering variables associated with the nodes for example.

A conventional rendering system operating in a retained mode provides a set of graphical primitives and a set of operations. Such a rendering system supports the use of each primitive with different operations such as path over text or image in path and is required to process all of the possible combinations of primitives and operations. If a new primitive type is introduced the rendering system has to process a whole new set of primitive operation combinations. For example if P represents the number of primitives O the number of operations and the rendering system complexity without a new primitive is P P O then the rendering system complexity with one new primitive is P 1 P 1 O. This is a large increase in the complexity of the rendering system.

Rather than using a new primitive type a composite node e.g. the composite node may be used to form a new primitive at an application level. As will be described in more detail below two image nodes e.g. the image node as seen in each comprising a memory buffer for storing pixel data representing an image associated with the nodes may be composited with a plane fill node e.g. to create a composite node . Some primitive type attributes such as opacity and position may be stored in memory as variables which are associated with such a composite node to generate a final composite node . The final composite node has all of the characteristics of a primitive node and is referred to herein as a video node.

The pixel format widely used for rendering images is RGBA or BGRA. In accordance with such a pixel format each pixel has a colour component comprising red green and blue levels RGB and an opacity component known as the alpha channel A . In a conventional retained mode rendering system in order to change the opacity of an image the opacity of each pixel of the image has to be changed. However such a method is inefficient. In a rendering system executing in a retained mode such as the rendering code module when an object A is composited in another object B the opacity of the resultant composite object is determined by multiplying the opacities of each pixel in object B with those of object A. If a plane fill primitive of uniform opacity is used as object B and the object A is composited in object B the opacity of the resultant composite object is equivalent to changing the opacity of the object A. Such a method is a much more efficient method of changing the opacity of the object A.

The video node of is generated by compositing two video frames represented by the nodes and using a plus operation. Each of the nodes and represents the result of an image node e.g. composited with a plane fill node e.g. as shown in . The result of the composition of the respective image node and plane fill node associated with each of the nodes and may be stored in one of two memory buffers configured within memory with each of the memory buffers being referenced by one of the nodes and respectively. The compositing operator of the nodes and may be in operator or an out operator and a path node may be used to construct the video node instead of a plane fill node as shown in . Further as seen in a video node may be generated by compositing two video frames represented by the nodes and using an over operation. In this instance each of the nodes and represents the result of an image node e.g. composited with a path node e.g. as shown in .

Each of the image nodes and represents a frame of an input video stream at a certain time associated with the respective node. The source of the input video stream may be a digital video file stored in memory or a live video stream sourced via the communications network for example. Each of the frames associated with each of the nodes and are stored in one of two further memory buffers configured within memory with each of the memory buffers being referenced by each of the nodes and respectively. The opacity of a displayed frame and hence the opacity of the video node may be altered by changing the opacity of the plane fill nodes and or path nodes and . Generally only one of the video frames represented by the nodes and will be active i.e. currently being displayed on the display for example at any time. The active video frame will be the frame that represents the correct time in the input video stream. However when interpolation between two consecutive video frames is required the video frames represented by the nodes and will be active and each of memory buffers associated with the nodes and will contain one of the two consecutive frames to be interpolated.

The opacity of each plane fill e.g. or path node e.g. may be linearly interpolated based on a required frame position between the two consecutive video frames to be interpolated. For example as shown in if the frame position of a required frame to be interpolated i.e. as represented by the arrow marked N 0.5 is half way between two real consecutive video frames and stored in memory buffers associated with video nodes the opacities of the frames and will both be set to 50 . As seen in if the frame position of a required frame to be interpolated i.e. as represented by the arrow marked N 0.25 is at 0.25 times the interval between two consecutive frames and then the opacity of the first frame will be set to 75 and the opacity of the second frame to 25 . After compositing the two frames i.e. frames and or frames and with the plus operation a final video frame at 100 opacity is produced.

As described above video attributes such as frame rate length frame size corresponding to one or more video frames represented by a video node e.g. the video node may be stored in memory which is referenced by the video node. Accordingly a new primitive type may be added to the compositing tree without increasing the complexity of a corresponding rendering system such as the rendering code module . A method of creating a video node will be described below with reference to .

An audio node as described herein is a single composition of a plane fill node as shown in . A further example of an audio node is a single composition of a path node as shown in . The audio nodes and reference information regarding an audio sample such as sampling rate bit rate length and quality. Such information may be stored in memory and may be referenced by a respective node . The audio nodes and may also each have a memory buffer associated with the nodes and . These memory buffers may be used to store audio samples associated with each of the nodes and .

The media management code module maintains two lists a video node list comprising a plurality of video nodes e.g. the video node and an audio node list comprising a plurality of audio nodes e.g. the audio node as shown in . As shown in the video node is linked with the audio node as represented by an arrow. Video and audio nodes of a compositing tree such as the compositing tree are added to a respective one of the lists or when the nodes are created. Such video and audio nodes are removed from a respective one of the lists or when the nodes are deleted. The link between a video node and an associated audio node e.g. the link between the video node and the audio node is maintained to ensure that any operation such as setting a current frame position is applied to both the video node and associated audio node.

When a video node switches between play mode and stop mode the media management code module changes the mode of an associated audio node linked with the particular video node if any. If a video node is deleted the media management code module also deletes the associated audio node.

A method of rendering images will now be described with reference to . The method is preferably implemented as software resident within the hard disk drive and being controlled in its execution by the processor . The method may be executed by the rendering code module . The method begins at step where the processor generates a compositing tree e.g. the compositing tree . The generated compositing tree may comprise video nodes e.g. and non video nodes e.g. path nodes . An image represented by the generated compositing tree may be stored in a memory buffer configured within memory and being referenced by a root node of the compositing tree. The image may also be rendered on the display screen for example. At the next step attributes e.g. opacity position of the generated compositing tree are initialised and one or more video nodes are set to play by setting variables associated with the video nodes. Therefore a series of video images represented by the video nodes of the generated compositing tree may be rendered on the display screen . Then at the next step the processor updates the generated compositing tree. A method of updating the compositing tree as executed at step will be described below with reference to . The method updates the generated compositing tree including media primitives i.e. video and audio primitives of the compositing tree. The method continues at the next step where the compositing tree is modified. For example the structure of the generated compositing tree or attributes of the compositing tree may be modified in order to change the image represented by the compositing tree and therefore the rendered image associated with the root node of the compositing tree. At the next step if the modification of the generated compositing tree is completed then the method concludes. Otherwise the method returns to step .

A method of updating the compositing tree as executed at step will now be described with reference to . The method is preferably implemented as software resident within the hard disk drive and being controlled in its execution by the processor . As described above the method updates a compositing tree including media primitives i.e. video and audio primitives of the compositing tree. The method begins at step where the processor updates any media nodes i.e. video and audio nodes of the generated compositing tree. A method of updating media nodes as executed at step will be described below with reference to . As will be explained in further detail below the method is executed by the media management code module .

Following step the method continues at step where the compositing tree generated at step is updated by the rendering code module . The method concludes after step .

The method of updating media nodes i.e. video and audio nodes as executed at step will now be described with reference to . The method may be implemented as software resident on the hard disk drive and being controlled in its execution by the processor .

The method begins at step where if the processor determines that the rendering code module is executing in a time base mode then the method proceeds to step . Otherwise the rendering code module is running in a frame base mode and the method proceeds to step . At step the processor sets an update time to the current time of a system clock not shown of the computer module .

At step the update time is set to the time of a next frame since the rendering code module is running in a frame based mode to generate a current update time. At step the update time is set by adding the interval between a current frame and a next frame i.e. the frame interval to the previous update time to form the current update time. The current update time is used during the updating of the media nodes of the compositing tree and is applied to every media node regardless of actual time taken to perform the update of a particular node. At the next step the video nodes of the compositing tree are updated. A method of updating video nodes will be described below with reference to . Then at the next step the audio nodes of the compositing tree are updated and the method concludes. A method of updating audio nodes will be described below with reference to .

The method of updating video nodes will now be described below with reference to . The method may be implemented as software resident on the hard disk drive and being controlled in its execution by the processor . During the updating of video nodes the media management code module processes a video node list e.g. the video node list configured within memory . The video node list comprises all of the video nodes in the compositing tree.

The method begins at the first step where the processor accesses the video node list stored in memory for the compositing tree and selects a first video node i.e. a current node that is present in the compositing tree. At the next step if the processor determines that the current node is in play mode then the method proceeds to step where a new frame position for the video node is determined based on the current update time and a first update time. Otherwise if the current video node is stopped i.e. not in play mode then the method proceeds directly to step . A method of determining a new frame position for a video node will be described below with reference to . At step irrespective of whether the video node is playing or stopped a video frame associated with the current video node is updated. That is the memory buffer associated with the current video node is updated by rendering a further frame into the memory buffer. The video frame is decompressed at step if necessary. A method of updating a video frame as executed at step will be described below with reference to . In accordance with the method the processor updates frames associated with specified video nodes of the compositing tree. The method continues at the next step where if the processor determines that there are more video nodes of the video node list to be updated then the method returns to step . Otherwise the method concludes.

One method of determining whether a particular video node is present in a given compositing tree as at step of the method is to traverse the entire compositing tree from the root of the compositing tree down to the leaf nodes. However such a method is inefficient. Typically the proportion of video nodes in a compositing tree is small compared to the total number of nodes in the compositing tree. Therefore rather than potentially searching through an entire compositing tree the media management code module may retrieve the root of each video node by traversing up through ancestors of the video node. The root of the particular video node may then be compared against the root of a particular compositing tree. If the compared nodes are in fact the same node the particular video node is present in the particular compositing tree.

After all video nodes of the compositing tree have been processed in accordance with the method the audio nodes of the compositing tree are processed in accordance with the method . Again all of the audio nodes of the compositing tree are contained in an audio node list configured within memory . The method of updating audio nodes may be implemented as software being resident in the hard disk drive and being controlled in its execution by the processor . The method may be implemented as one or more code modules of the media management code module . The media management code module updates the current position of each audio node that is in play mode and may decompress an audio node if necessary.

The encoder decoder code module maintains a set of codecs that may be used to encode or decode various video and audio formats. The codecs are loaded into memory buffers configured within memory on request of the encoder decoder code module and are retained in these memory buffers for later use. The codecs are placed into a decoder list or encoder list configured in memory as appropriate. The decoder or encoder lists are ordered such that a last codec to be loaded into a particular list will be the first codec to be used during processing i.e. last in first out . Such a last in first out ordering allows the encoder decoder code module to override priority of previously loaded codecs.

When a codec is required for loading and playing video and or audio for example the encoder decoder code module attempts to open a requested video and or audio file corresponding to the video and or audio to be played using the first codec in the decoder list i.e. the last codec to be loaded into the decoder list . If successful the first codec in the decoder list may be associated with a media node i.e. video node or audio node that is created for the video and or audio to be played. The media node uses the same codec until the node is deleted even if a new codec is loaded after the media node was created. If the codec failed to open the corresponding video and or audio file the encoder decoder code module tries a next codec in the decoder list and so on until the decoder list is exhausted. In the event that no codec is able to open the corresponding video and or audio file the encoder decoder code module reports the failure to load the video and or audio to be played.

When a codec is required for outputting video images e.g. to a video file on hard disk the encoder decoder code module attempts to initialise the requested video to be output using a first codec in the encoder list i.e. the last codec to be loaded . If successful the first codec in the encoder list may be used for the video to be output. If the first codec in the encoder list cannot be used the encoder decoder code module tries a next encoder codec in the encoder list until all codecs in the encoder list have been tried. In the event that no codec in the encoder list can be used for the video to be output the encoder decoder code module reports the failure.

The method of creating a video node will now be described with reference to . The video node is created from a given video file representing an input video frames. The video file may be stored in memory . The method may be implemented as software resident in the hard disk drive and being controlled in its execution by the processor . The method may be implemented as one or more code modules of the media management code module .

The method begins at the first step where the processor selects a first codec in the decoder list. At the next step the processor attempts to open the video file using the selected codec. At the next step if the video file was successfully decoded then the method proceeds to step . Otherwise the method proceeds to step . At step if the processor determines that there are more codecs in the decoder list then the method returns to step . Otherwise the method proceeds to step where the processor generates a message indicating that the video node creation has failed and the method concludes.

The method continues at step where after successful opening of the video file the processor creates two image nodes e.g. and and two plane fill nodes e.g. and . The processor then composites each image node with one of the plane fill nodes using an in operation. The processor then composites the two composite nodes with a plus operation. No image data is yet assigned to each image node created at step . That is memory buffers configured within memory and being referenced by the respective image nodes do not have any images stored within them. However image data will be assigned to the image nodes and stored in these memory buffers when the compositing tree comprising the image nodes is updated at update time as will be described below with reference to . The composite node resulting from the compositing of the two image nodes with each of the respective plane fill nodes now resembles the video node as shown in . The details of the video file used to create the video node at step are stored in memory and are referenced by the created video node. These details include video length frame rate video size codec used compression type etc.

The method continues at the next step where the video node created at step is added to a video node list and the method concludes. The video node list is configured within memory . Also at step the video node is initialised. In initialising the video node the video node is set to the frame rate of the video file used to create the video node the start point of the video node is set to the beginning i.e. the start time of the play range the video node is set to stop mode and the opacity of the video node is set to opaque. The video node created at step may be returned to an application that requested the creation of the video node for example.

A method of creating a video node using different codecs will now be described with reference to . In the method the different codecs are used to open the same video file. The method may be implemented as software resident on the hard disk drive and being controlled in its execution by the processor . The method will be described by way of an example in which two codecs i.e. codecs A and B are used to process input media M e.g. a video file . In the example codec A has better colour restoration than codec B but codec B has better image detail restoration than codec A.

The method begins at step where codec A is loaded into a decoding list configured within memory . At the next step a video node V representing the input media M is created using codec A. One or more frames of the input media M are stored in a memory buffer configured within memory and being referenced by the video node V. The video node is created at step in accordance with the method . Then at step codec B is loaded into the decoding list configured within memory . Since the codecs are used in last in first out order codec B now has a higher priority than codec A. At step a video node V representing the same media M is created using the codec B instead of the codec A to open the input media M The video node is created at step in accordance with the method . Again one or more frames of the input media M may be stored in a memory buffer configured within memory and being referenced by the video node V. Then at the next step different transform matrices are applied to video node V and video node V so that the video frames associated with each of the nodes i.e. the video frames stored in the two memory buffers associated with a respective one of the video nodes V and V will appear at different positions on a rendering target such as the display screen .

The method continues at the next step where the video nodes are composited with a background image using the rendering code module . The video nodes V and V are then set to the play mode by altering an attribute associated with the video nodes V and V. If the compositing tree comprising the video nodes V and V is then regularly updated at the next step two versions of the same video input will play on the display screen at different positions. However the output of video node V will have better colour quality than the output of video node V and the output of video node V will have better image quality than the output of video node V due to the differing codecs used for each.

The method of updating audio nodes will now be described with reference to . As described above all of the audio nodes of the compositing tree being processed i.e. the compositing tree created at step are contained in an audio node list configured within memory . The method begins at step where the processor selects a first audio node i.e. a current audio node of the audio node list that is present in the compositing tree. At the next step if the processor determines that the current audio node is in play mode then the method proceeds to step . Otherwise if the current audio node is in stop mode then the method proceeds to step . Again the current audio node may be configured in one of either play mode or stop mode by altering an attribute associated with the audio node. Next the processor determines a new sample number for the current audio node based on the current update time determined at step or step . The new time position is determined in a similar manner to the method of determining a new frame position for the video node which will be described below. The time difference between the current update time and the start time of the audio node is determined at step . Then a new sample number is determined at step by multiplying the determined time difference by the audio sample rate and the playback rate. The method continues at the next step where the processor updates a sample buffer configured within memory and being associated with the current audio node. The sample buffer is updated with an audio sample that represents the new audio sample number determined at step . At step if there are any more audio nodes in the audio list to be processed then the method returns to step . Otherwise the method concludes.

The method of determining a new frame position for a video node as executed at step of the method will be described below with reference to . The method may be implemented as software resident on the hard disk drive and being controlled in its execution by the processor . The method begins at step where the processor determines a time difference representing the time between a current frame update time of the video node and the time of a first frame update i.e. the start time . At the next step the processor determines a frame number for the current video node based on time difference determined at step as follows New frame number current time start time video frame rate playback rate where video frame rate refers to the original frame rate in frames per second of the video stream being input to the memory buffer associated with the current video node and the playback rate indicates the speed ratio relative to the original frame rate. For example if the playback rate is equal to two then video stream is playing at twice the original frame rate.

At the next step the frame number determined at step is stored in memory as the new frame position. Then at the next step if the processor determines that the new frame position has reached or surpassed the end of a predetermined play range then the method proceeds to step . Otherwise the method concludes. At step the processor determines whether or not the video stream associated with the current video node should loop i.e. be replayed . If the video stream associated with the current video node is looping then the method proceeds to step . Otherwise if the video stream associated with the video node is not looping or a prescribed number of loops have been played then the method proceeds to step . At step the frame position of the video stream of the current video node is reset to the beginning i.e. the start time of the play range and the video stream will continue playing as per usual from the start time. At step the frame position of the video stream associated with the current video node is set to the end of the play range. The processor may also generate a notification to indicate that playback has finished.

The method of updating a video frame as executed at step will now be described with reference to . The method is preferably implemented as software resident in the hard disk drive and being controlled in its execution by the processor . The method updates a video frame stored in a memory buffer configured within memory and being referenced by a current video node. The method begins at step where if the processor determines that the media management code module is executing in a normal frame mode then the method proceeds to step . Otherwise the media management module is in accurate frame mode and the method proceeds to step . At step the processor updates the video frame in the frame buffer associated with the current video node in normal mode. A method of updating a video frame associated with a video node in normal mode will be explained below with reference to . At step the processor updates the video frame in the frame buffer associated with the current video node in accurate mode. A method of updating the video frame in accurate mode will be described below with reference to . Following either of steps or the method concludes.

The method of updating a video frame associated with a video node in normal mode will now be described with reference to . The method is preferably implemented as software resident in the hard disk drive and being controlled in its execution by the processor . The method begins at step where if the processor determines that the opacity of the current video node has changed since the video node was last updated then the method proceeds to step . Otherwise the method proceeds to step . The processor determines the opacity of the current video node at step based on an attribute associated with the current video node. At step the new opacity is applied to both plane fill nodes e.g. the plane fill nodes and associated with the current video node. At the next step a required frame number for the current update of the video node is determined from a previously stored required frame position. The required frame number determined at step corresponds to the frame position saved at step of the method . Since the required frame position may not necessarily be an integer whole number the required frame number determined at step is set to the closest frame at or before the required frame position as shown below 

At the next step if the processor determines that the frame corresponding to the required frame number is stored in either one of the two image buffers associated with the image nodes e.g. and of the current video node to be updated then the method proceeds to step . Otherwise the method proceeds to step .

At step one of the image buffers associated with the image nodes of the current video node is updated with the frame corresponding to the required frame number. The image node image buffer containing a frame that is furthest from the required frame corresponding to the required frame number is updated at step in case a next update uses the image node image buffer comprising a frame that is closer to the required frame. The method continues at the next step where the processor notifies the rendering code module that the frame to be rendered has changed so that the rendering code module will update the rendered frame. The method concludes at the next step where an activity property of the current video node is used to enable a frame stored in one image node s image buffer associated with the current video node and to disable the frame stored in the other image node s image buffer in order to choose the appropriate image node containing the required frame.

The method of updating a video frame in accurate mode as executed at step will now be described below with reference to . The method may be implemented as software resident in the hard disk drive and being controlled in its execution by the processor . In accurate frame mode two frames closest to the required frame number are used with differing opacities to produce a final frame for rendering on the display screen for example. The method begins at step where the processor determines two frame numbers F F required for updating the video frame as follows F required frame position F required frame position 

At the next step if F is equal to F then the method proceeds to step . Otherwise the method proceeds to step where two opacities O and O that will be applied to the frames F and F are determined as follows 

where the opacity value represents the opacity of the current video node in both cases. The opacity of the current video node is determined by an attribute associated with the video node as at step of the method . The opacities O and O determined at step are only applicable for a video node using a plus operator as in . When an over operator is used as in the video node of the opacity O applied to the frame F will be equal to the opacity represented by the attribute associated with the video node i.e. O opacity .

At the next step the existing contents of the image node image buffers associated with the current video node are analysed to determine if the image node image buffers already contain frames matching the frames represented by F and F. If the image node image buffers already contain frames matching the frames F and F then no changes are required to be made to the image node image buffers at step . If one of the image node image buffers does not contain a frame matching either one of the frames F and F then the image node image buffer not containing the frame is updated the appropriate missing frame F or F at the next step . Then at the next step if both of the image node image buffers associated with the image buffers of the current video node do not contain frames matching either one of the frames F and F then both of image node image buffers are updated so that one of the image node image buffers is updated to contain the frame F and the other image node image buffer is updated to contain the frame F.

The method concludes at the next step where the opacities O and O detemined at step are applied to the plane fill nodes composited with the image nodes associated with the image buffers comprising the frames F and F. The opacity O is applied to the plane fill node composited with the image node associated with the image buffer comprising the frame F. Further the opacity O is applied to the plane fill node composited with the image node associated with the image buffer comprising the frame F.

As described above if F is equal to F then the method proceeds to step . At step the existing contents of the image node image buffers associated with the current video node are analysed and if either one of the image node image buffers already contain a frame matching the required frame number then the method proceeds directly to step . Otherwise the method proceeds to step . At step the frame that is closer to the frame matching the required frame number is retained in the corresponding image node image buffer and the other frame is replaced by the frame matching the required frame number. The method concludes at the next step where the opacity of the video node i.e. the opacity attribute associated with the video node is applied to the plane fill node composited with the image node associated with the image node buffer containing either the frame matching the required frame number or the updated frame containing the frame F. The method concludes at step Where an activity property of the current video node is used to enable the frame stored in the node s image buffer containing the required frame and disable the frame stored in the other image buffer.

A method of creating a video file will now be described with reference to . The method may be implemented as software resident in the hard disk drive and being controlled in its execution by the processor . The method begins at the first step where a compositing tree e.g. the tree comprising video and or non video nodes e.g. audio nodes is created. At the next step the processor identifies a region of the image represented by the compositing tree. The identified region is used in creating the video file. The area of the region identified therefore determines the size of each frame in the created video file. The method continues at the next step where the media nodes i.e. video and or audio nodes and or non media nodes i.e. text path nodes of the compositing tree created at step are updated to reflect any changes e.g. any further video frames added to a frame buffer of a video node or a transform of a path node . The media nodes are updated at step according to the method . At the next step the region of the image identified at step is rendered to a memory buffer configured within memory . Then at the next step the encoder decoder code module is executed by the processor to encode the data in the memory buffer to a single video frame in a particular format. The format may be specified by an application program for example. At the next step the encoded video frame is appended to the end of the video file created at step . The method continues at the next step where the compositing tree is modified to reflect any changes to the encoded video frame so that a following output video frame differs from the encoded video frame i.e. the previous frame . At the next step if the processor determines that there are further video frames to be added to the video file then the method returns to step . Otherwise the method concludes and the video file created at step is closed.

The aforementioned preferred method s comprise a particular control flow. There are many other variants of the preferred method s which use different control flows without departing the spirit or scope of the invention. Furthermore one or more of the steps of the preferred method s may be performed in parallel rather sequentially.

The foregoing describes only some embodiments of the present invention and modifications and or changes can be made thereto without departing from the scope and spirit of the invention the embodiments being illustrative and not restrictive.

