---

title: Apparatus, system, and method for offloading pattern matching scanning
abstract: Diagnostic software often requires pattern matching scanning to be performed to detect problems such as computer viruses or unwanted intruders. A computing system offloads pattern matching scanning from a central processing unit to a graphics processing unit.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07818806&OS=07818806&RS=07818806
owner: NVIDIA Corporation
number: 07818806
owner_city: Santa Clara
owner_country: US
publication_date: 20051108
---
The present invention is generally directed towards performing pattern matching scanning of data in a computer system to detect problems such as computer viruses or intrusive attacks. More particularly the present invention is directed towards offloading pattern matching scanning from a central processing unit.

Computer systems typically include diagnostic software that scans data files or received data packets to detect pattern matches indicative of problems such as computer viruses or intrusive attacks. For example computer anti virus software typically scans files for patterns indicative of computer viruses. Depending upon the implementation diagnostic software may also scan data packets received from a network. For example some types of computer intrusion software detects patterns in data packets indicative that a source of incoming data or requests is untrustworthy. As one example intrusion detection software may look for patterns in password prompts and other information indicative of an intruder.

Conventional pattern matching software performs sequential pattern matching in which a data source is compared to different patterns in a sequence i.e. first pattern 1 is checked against the data source then pattern 2 then pattern 3 and so on until all of the different patterns are checked. A problem with pattern matching software is that it places a substantial burden on the resources of a central processing unit CPU . This is due in part to the large number of patterns that must be compared in typical applications. For example anti virus software typically must guard against numerous different types of viruses that each require different pattern matches to be performed. As a result many computer systems run significantly slower when anti virus software is running in the background. Moreover a complete anti virus scan often takes longer than desired in many computer systems. For example in some personal computer systems it can take several hours to perform a complete anti virus scan of all files stored on a disk.

The demands for diagnostic pattern matching scans continues to increase. For example anti virus software companies regularly increase the dictionary of patterns that must be scanned in order to address new viruses or other problems such as spyware. Additionally diagnostic software is increasingly being applied to address new issues such as implementing increasingly sophisticated intrusion detection algorithms. It can therefore be expected that pattern matching scanning will impose an ever increasing burden on computing resources.

Therefore in light of the problems described above the apparatus system and method of the present invention was developed.

Diagnostic software may require pattern matching scans to be performed to detect problems in a computing system. An apparatus system and method is disclosed for offloading pattern matching scans from a central processing unit to a graphics processing unit.

One embodiment of an apparatus for use in a computing system having a central processing unit CPU and diagnostic software requiring pattern matching scanning comprises a graphics processing unit GPU for processing graphics data the GPU configured to have a mode of operation in which the GPU performs pattern matching scanning operations on the behalf of the computing system whereby pattern matching scanning is offloaded from the CPU to the GPU.

One embodiment of a computing system comprises a central processing unit having a memory and associated diagnostic software requiring pattern scanning matching and a graphics processing unit communicatively coupled to the central processing unit for performing graphics processing the graphics processor adapted to have a mode of operation in which the graphics processing unit performs pattern matching scanning for the diagnostic software in which data is compared to a string database.

One embodiment of a method of performing a diagnostic operation in a computing system having a central processing unit and a graphics processing unit comprises offloading pattern matching scanning to a graphics processing unit and receiving reports from the graphics processing unit indicative of instances of pattern matching of input data blocks to a string database.

A central processing unit is provided for executing software applications. As an illustrative example in a personal computer CPU may be the CPU that executes software applications running on the personal computer. A bridge module may be included to couple data between different devices in computing system . Bridge module may for example implement the function of a North bridge. A main memory is provided to store data and may for example be coupled either directly to CPU or via bridge module or other intermediate element.

Graphics processing unit GPU performs graphics processing operations on the behalf of CPU . In one embodiment a frame buffer memory is provided for GPU to store graphics data. In one embodiment GPU and frame buffer are disposed on a graphics card . However it will also be understood in the following discussion that other implementations of GPU are contemplated. For example GPU may be implemented as an integrated GPU residing inside a chipset with the frame buffer located in system memory.

CPU has diagnostic software that it executes which requires pattern matching scans. The pattern matching scans may for example include scans to detect strings of characters indicative of a problem. In many typical diagnostic applications a dictionary will include many different strings of characters for which a pattern matching scan must be performed to complete a particular diagnostic function. Illustrative examples of diagnostic software requiring pattern matching scans include computer virus detection software often known as anti virus software and intrusion detection software. The diagnostic software may require a pattern matching scan to be performed on a scheduled basis. Alternatively diagnostics software may diagnose problems as computing system receives a stream of data from a network such as performing virus scans as a computer user downloads data from the Internet.

CPU also executes a graphics driver for interacting with GPU . CPU may also execute other software applications such as graphics applications not shown text applications media applications and email applications. It will be understood that software modules for each application reside on a memory associated with CPU and may be provided to end users pre loaded on computing system downloadable from the Internet or as software modules having computer readable program code stored on a computer readable medium.

One aspect of the present invention is that at least some pattern matching scanning calculations are offloaded from CPU to GPU . GPUs have evolved to support demanding graphics applications such as three dimensional games and simulations. Consequently GPU will typically have substantial processing power for performing calculations upon graphics data within the graphics domain. Moreover in a multi purpose computing system GPU is typically fully utilized only for the fraction of the time that an end user operates a demanding graphics application. Thus GPU is a potential resource for performing pattern matching scanning. Consequently in accordance with the present invention diagnostic software has a mode of operation in which it offloads pattern matching scanning calculations to GPU .

Pattern matching scanning may be performed on data blocks of a pre selected size. An exemplary size is 64K corresponding to a conventional network data window size. An individual data block may reside in any memory of computing system accessible by GPU directly or through a direct memory access such as main memory or frame buffer . The source of data for a data block may be stored data such as data accessed from a disk not shown via a disk interface .

In one embodiment the source of data for a data block comes from data packets received by a network interface . For the case of data packets received from a data network payload data for a number of data packets may be aggregated into a data block for efficient analysis. Attributes of the header information may also be collected for analysis. In one embodiment a data block formed from incoming data packets may be intercepted for pattern matching in GPU before it is processed by CPU . For example bridge module may be configured in response to an offload command to route data packets to GPU for pattern matching analysis.

In one embodiment an application programming interface API call is made from diagnostic software to driver to initiate an offloading of the pattern matching scanning to GPU . That is software hooks in diagnostic software utilize an API call to driver to request that pattern matching scanning be offloaded to GPU . In turn driver then generates any necessary commands and data pointers to instruct bridge module and GPU to provide access to data blocks to GPU for pattern matching scanning. In the case of a computing system performing two or more different types of pattern matching scanning driver may also provide instructions to GPU to define the type of pattern matching scanning to be performed.

The results of the pattern matching scanning performed by GPU are reported back to diagnostic software in CPU . This may be implemented with different levels of specificity depending upon bandwidth and processing constraints. For example the report may be a flag or other bit indicating a match occurred. Alternatively an exact string may be reported or a list of all strings and offsets. While GPU may perform all of the pattern matching scanning more generally GPU may perform selected portions of the pattern matching scanning. For example GPU may perform a first pass of pattern matching scanning to identify data blocks having potential problems. In one implementation the report that is sent back to diagnostic software is used by diagnostic software to select data blocks for additional analysis in a second pass of analysis. The second pass of analysis may for example be performed either on GPU or on CPU .

GPU may be adapted to receive data in specified data formats. Reformatting of input data may occur in CPU . Alternatively in one embodiment bridge module includes a data reformater to convert input data blocks into a format compatible with GPU . In another embodiment a processing block of GPU is used to perform at least some of the data reformatting

GPU utilizes a string database to perform pattern matching scans for a particular diagnostic function. In one embodiment an initialization process is implemented by diagnostic software to load the string database into a memory accessible to GPU such as frame buffer or a portion of main memory .

The string database is a dictionary of strings of characters that input data is compared against to identify matches indicative of problems with a data block . Pattern matching scanning requires testing input data for the occurrence of a sequence of characters having a specified order. As such one way of performing a pattern matching scan in GPU is to utilize a state table in which the state is incremented each time that a successive character of an input data string matches a pattern. That is the state advances with each successive matching character until a terminal state is reached indicating a pattern match was identified. There may also be an exit state indicating that no pattern match was found. In one embodiment string database includes finite state machine FSM dictionary tables which are designed to execute a FSM implementation of a pattern matching algorithm when GPU executes a pre selected processing operation. The FSM dictionary tables may be compiled and loaded by diagnostic software into a memory accessible by GPU .

String pattern matching scanning is performed utilizing at least one processing block of GPU such as a pixel shader vertex processor or video processor. GPUs typically include pipeline stages designed to perform certain types of graphics operations in parallel over a substantial number of parallel processors. For example many GPUs have hundreds or even thousands of processors in selected pipeline stages such as a shader stage or a vertex processor stage. It is therefore desirable to perform pattern matching scanning in a way that is compatible with the types of graphics operations that a GPU is designed to process in parallel. This permits GPU to be used to perform pattern matching using parallel processors improving the speed with which pattern matching scanning can be performed. As a result GPU can be utilized to perform pattern matching scanning with the processing work of the pattern matching scanning distributed over many different internal processors resulting in potential speed improvements compared with performing pattern matching scanning in a conventional CPU .

An exemplary graphics operation to execute a FSM implementation of a pattern matching scanning algorithm is a dependent texture fetch. Dependent texture operations are well known graphics operations described in graphics standards such as the OpenGL 2.0 Specification the contents of which are hereby incorporated by reference. Pixel texture and dependent texture are commonly used to describe graphics operations in which color fragments are used to generate texture coordinates. The color fragments are replaced with corresponding entries from a texture. These operations are essentially equivalent to an arbitrary function evaluation using a lookup table. Thus one way to implement a FSM for pattern matching scanning in a GPU is to implement string database as textures selected to execute a FSM for performing pattern matching when a dependent texture operation is performed. In particular string database may be implemented as FSM dictionary tables stored as a texture such that in response to a dependent texture operation an input character string is compared to entries in the FSM dictionary table . In this case the function evaluation performed by the table lookup to FSM dictionary table is selected to implement a FSM designed to perform a pattern matching scan.

Table I illustrates in more detail a portion of an exemplary FSM dictionary table. An input data block is represented as an input data structure corresponding to a first texture such as a linear texture in which each character e.g. each ASCII byte value is assigned to one pixel. The FSM dictionary table corresponds to a second texture which is a two dimensional texture. An x dimension of a second texture corresponds to the ASCII byte value of an input character e.g. a b c or d defining a pattern match and the y dimension corresponds to the current state of the state machine. In a dependent texture operation the value accessed at a point x y would be the next state of the state machine. Thus as a dependent texture fetch operation is performed Table I is traversed in a raster fashion. Thus for example in the first state second row if characters ab are encountered the state moves to state 2.

Table II illustrates another example of an FSM dictionary table. The table structure is arranged as a jump table. The address into the table is formed from state byte where state is a per thread register that is retained and byte is the next byte of input. The contents of the texture are used to update state. As one example consider a state table of 7 256 entries which searches for the strings foo and sam . The initial state is set to 2. States 0 and 1 are sticky. Upon exit if state 0 there was no match. If state 1 there was a match.

Referring back to and Tables I and II in one embodiment shader program starts in an initial state and reads sequential values from a starting point within texture . Shader program then uses these values to make a dependent texture fetch to the FSM dictionary table to find the next state. This continues until the state of the FSM dictionary table indicates that the next state is a terminal state. In one embodiment the output data structure is a one dimensional texture surface in which the byte value of each pixel position represents whether a string was detected beginning at a corresponding character position e.g. byte position in an implementation in which a character corresponds to a byte in texture . For example in one embodiment the output of the shader program is a bitmap wide by N long where N is the number of bytes in the payload e.g. in an embodiment where a character corresponds to a byte the bitmap corresponds to a length of N characters . If the FSM arrives at a terminal case indicating that a match was found a pixel is written to indicate that a match was found. In one embodiment the pixel is written in a location indicative of a corresponding byte location in the input data character string where a pattern match begins e.g. the pixel is written red in the location of the bitmap corresponding to a string pattern match starting at that byte location . If no match is found the pixel is written with a different format e.g. the pixel is written white . Thus upon completion of shader program the pixels are written such that instances of pattern matches can be detected by detecting pixels with the specified shading characteristics e.g. red pixels in this example .

In one embodiment pointers to data structures are passed on to a shader program to perform the pattern matching scanning. One of the pointers is to the data to be scanned. The input data is formatted as a one dimensional or two dimensional texture with each pixel being a single character of the input data. The other pointer is to a state table corresponding to an output texture. Depending upon the implementation other information may also be passed on the shader program to implement the desired pattern matching scans and output data in a desired format.

One aspect of the present invention is that it can exploit the parallelism of a GPU having one or more stages with parallel processing units. illustrates an exemplary GPU having a pipelined architecture which includes a vertex processor stage geometry processor stage shader stage raster operations ROP and video processor . As illustrated in an individual stage such as shader stage may in turn have a multi threaded parallel processor architecture in which stage has a number of different processors that are assigned work from a thread pool. This permits a program executed on stage having parallel processors to generate execution threads which are processed in parallel.

GPU is preferably optimized for a particular implementation to efficiently read FSM dictionary tables of string database read input data blocks record matches report results and reformat data. One optimization is to encode a FSM dictionary table for a data string so that a single read of the FSM dictionary table returns not only the next FSM state but a compressed list of one or more of next most likely states along with corresponding input values. The number of data reads can be reduced by selecting an efficient input texture format based upon the different types of data stored in a pixel. For example in an R G B alpha format an input texture can be optimized by repeating values of a character string in a staggered manner in the red green blue and alpha fields of a pixel such that the data string abcdefg is encoded in a pixel as abcd bcde cdef and defg. In this example a single read permits the input value and the next three values to be obtained from a single read. In one embodiment the shader program discards pixels where no strings were detected to reduce the amount of data that must be recorded. In this embodiment the number of strings matches with the input data can then be obtained by counting the number of pixels written to the output structure. One optimization for handling larger input data blocks is to format large data blocks as two dimensional textures. Two dimensional textures complicate comparisons at the edges of textures. However these issues can be addressed by padding the two dimensional structures with repeated sections of input data or by adding a wrapping mode in the graphics hardware. Another optimization is to offload reformatting of input data to hardware such that the CPU does not have to reformat input data into a texture format.

In one implementation of parallel pattern matching scanning a shader program is run for every byte offset in the input data to perform pattern matching scanning in a parallel fashion. For example for a 2 kB input string the shader program may be run 2048 times in parallel with the value of the coordinates ranging from 0 0 to 0 2047 . In one embodiment if a string is found at a position coordinate x then the corresponding pixel in the output texture is set to red and the occlusion counter will increment. Below is exemplary pseudocode describing operations performed by a shader program for checking for strings 

As previously described a benefit of the present invention is that scanning is offloaded to GPU . In many computing systems GPUs are bundled with a CPU. As a result in many applications an end user gets the benefit of a reduced burden on their CPU and potentially faster scanning without increasing the hardware cost of computing system . Additionally a GPU is also capable of performing pattern scanning processing using parallel processing potentially increasing the rate at which pattern matching scanning is performed in a computing system.

An embodiment of the present invention relates to a computer storage product with a computer readable medium having computer code thereon for performing various computer implemented operations. The media and computer code may be those specially designed and constructed for the purposes of the present invention or they may be of the kind well known and available to those having skill in the computer software arts. Examples of computer readable media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs and holographic devices magneto optical media such as optical disks and hardware devices that are specially configured to store and execute program code such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer code include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment of the invention may be implemented using Java C or other object oriented programming language and development tools. Another embodiment of the invention may be implemented in hardwired circuitry in place of or in combination with machine executable software instructions.

The foregoing description for purposes of explanation used specific nomenclature to provide a thorough understanding of the invention. However it will be apparent to one skilled in the art that specific details are not required in order to practice the invention. Thus the foregoing descriptions of specific embodiments of the invention are presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the invention to the precise forms disclosed obviously many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications they thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated. It is intended that the following claims and their equivalents define the scope of the invention.

