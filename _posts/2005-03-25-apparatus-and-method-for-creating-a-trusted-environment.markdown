---

title: Apparatus and method for creating a trusted environment
abstract: A computer apparatus for creating a trusted environment comprising a trusted device arranged to acquire a first integrity metric to allow determination as to whether the computer apparatus is operating in a trusted manner; a processor arranged to allow execution of a first trust routine and associated first operating environment, and means for restricting the first operating environment access to resources available to the trust routine, wherein the trust routine being arranged to acquire the first integrity metric and a second integrity metric to allow determination as to whether the first operating environment is operating in a trusted manner.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07467370&OS=07467370&RS=07467370
owner: Hewlett-Packard Development Company, L.P.
number: 07467370
owner_city: Houston
owner_country: US
publication_date: 20050325
---
Computer platforms used for commercial applications typically operate in an environment where their behaviour is vulnerable to modification by local or remote entities.

Additionally with the continuing increase in computer power it has become increasingly common for computer platforms to support multiple users where each user can have their own operating environment installed on the computer platform. Various virtualization technologies have been developed to support this approach typically allowing each user to have their own virtual machine running on the computer platform.

Where a number of separate operating systems are running simultaneously on a computer platform the operating systems are not necessarily isolated or protected from one another. The volume of source code for the software components involved is typically so large in modern operating systems that it is virtually impossible to ensure the correctness of the source code and whether the behaviour of the source code will behave as expected.

Accordingly this potential insecurity of the platform is a limitation on its use by parties who might otherwise be willing to use the platform.

Increasing the level of trust in platforms therefore enables greater user confidence that the platform and operating system environment behave in a known manner.

In accordance with the present invention there is provided a computer apparatus for creating a trusted environment comprising a trusted device arranged to acquire a first integrity metric to allow determination as to whether the computer apparatus is operating in a trusted manner a processor arranged to allow execution of a first trust routine and associated first operating environment and means for restricting access of the first operating environment to resources available to the trust routine wherein the trust routine is arranged to acquire the first integrity metric and a second integrity metric to allow determination as to whether the first operating environment is operating in a trusted manner.

Two sets of embodiments of the invention will now be described with some common features particularly in relation to basic platform architecture trusted devices and collection of integrity metrics between the two. The first set of embodiments describes a first approach to virtualization employing privilege levels of a processor to achieve isolation. The second set of embodiments describes another approach to virtualization and also indicates a form of virtual trusted device for a virtual operating environment developed to be highly consistent with Trusted Computing Group TCG specifications for trusted platforms and trusted devices.

The embodiments generally provide the incorporation into a computing platform of a physical trusted device and a software trust routine i.e. a virtual trusted device . The function of the physical trusted device is to bind the identity of the platform to reliably measured data that provides an integrity metric of the platform while the virtual trusted device binds the identity of an associated software operating environment e.g. an operating system to reliably measured data that provides an integrity metric of the operating environment. The identities and the integrity metrics may be compared with expected values provided by a trusted party TP that is prepared to vouch for the trustworthiness of the platform. Optionally the expected values provided by the trusted third party are securely stored in the respective physical trusted device and the virtual trusted device. If there is a match the implication is that at least part of the platform and operating system is operating correctly depending on the scope of the integrity metric.

A user verifies the correct operation of the platform and operating environment before exchanging other data with the platform. A user does this by requesting the identities and integrity metrics of the physical trusted device and the virtual trusted device. Optionally the trusted devices will refuse to provide evidence of identity if it itself was unable to verify correct operation of the platform. The user receives the proof of identity and the identity metric and compares them against the values provided by the trusted third party. If the measured data reported by the trusted devices are the same as that provided by the trusted third party the user can trust the platform.

Additionally where the computer platform is arranged to support a plurality of separate operating environments each operating environment having their own respective virtual trusted device the users of the respective operating environments can trust that their operating environment is isolated from any other operating environment running on the computer platform.

Once a user has established trusted operation of the platform and operating environment he exchanges other data with the platform. For a local user the exchange might be by interacting with some software application running within the operating environment on the platform. For a remote user the exchange might involve a secure transaction. In either case the data exchanged is typically signed by one of the trusted devices. The user can then have greater confidence that data is being exchanged with a platform whose behaviour can be trusted.

The trusted devices use cryptographic processes but do not necessarily provide an external interface to those cryptographic processes.

In first embodiments to ensure there is a minimum risk that the virtual trusted device is susceptible to software attack by rogue software running on the computer platform the virtual trusted device is arranged to be executed in a processor privilege level that restricts access to other software applications being executed on the computer platform as described below . Additionally secrets associated with the virtual trusted device are stored such that the secrets are inaccessible to software applications being executed in a processor privilege level that is lower than that in which the virtual trusted device is executed. Also a most desirable implementation would be to make the physical trusted device tamperproof to protect secrets by making them inaccessible to other platform functions and provide an environment that is substantially immune to unauthorised modification. Since tamper proofing is impossible the best approximation is a trusted device that is tamper resistant or tamper detecting. The trusted device therefore preferably consists of one physical component that is tamper resistant.

Techniques relevant to tamper resistance are well known to those skilled in the art of security. These techniques include methods for resisting tampering such as appropriate encapsulation of the trusted device methods for detecting tampering such as detection of out of specification voltages X rays or loss of physical integrity in the trusted device casing and methods for eliminating data when tampering is detected.

A trusted platform is illustrated in the diagram in . The platform includes the standard features of a keyboard mouse and visual display unit VDU which provide the physical user interface of the platform. In the platform there are a plurality of modules these are other functional elements of the trusted platform of essentially any kind appropriate to that platform the functional significance of such elements is not relevant to the present invention and will not be discussed further herein .

As illustrated in the motherboard of the trusted computing platform includes among other standard components a main processor with internal memory main memory a trusted device a data bus and respective control lines and lines BIOS memory containing the BIOS program for the platform and an Input Output IO device which controls interaction between the components of the motherboard the keyboard the mouse and the VDU . The main memory is typically random access memory RAM .

In the first embodiment the processor has four execution privilege levels PL PL PL PL. Examples of such processors are the Hewlett Packard s PA RISC processor or Intel s IA 64 processor however other processor configurations having a plurality of privilege levels can also be used.

Running in the processor of this first embodiment is a secure platform architecture SPA as shown in .

The SPA includes BIOS program or firmware that runs on the processor at execution privilege level PL the most privileged level of processor . SPA includes a four layer software ring that runs on top of BIOS firmware in processor .

The innermost software ring running on top of BIOS firmware is referred to as the secure platform kernel SPK and is the only software ring that runs as a privileged task. SPK runs at PL and forms the foundation layer of SPA and is the only ring layer that accesses privileged system registers and executes privileged instructions.

A secure platform global services module SPGS runs on top of the SPK as an unprivileged task. SPGS runs at execution privilege level PL the second most privileged level of processor . SPK and SPKGS are collectively referred to as secure platform SP .

At least one operating system image runs on top of SPGS as an unprivileged task. Operating system image runs at execution privilege level PL the third most privileged level of processor . End user applications run on top of operating system image s as unprivileged tasks. End user applications run at execution privilege level PL the fourth privileged level i.e. the least privileged level of processor .

SPK is preferably a small kernel of trusted provably correct code that performs security critical services where the small size contributes to the SPK s security and correctness. Examples of security critical services include memory and process management trap and interrupt handling and cryptographic services where some of these security services may be performed via a virtual trust device as described below. SPGS is constructed with trusted code but utilizes hardware security capabilities of the processors such as IA 64 processors to minimize the impact of a failure. SPGS runs as an unprivileged task and employs SPK to perform privileged operations.

Additionally the SPK includes code to allow execution of one or more virtual trusted devices within the SPK . The virtual trusted device s are associated with an operating environment executed in PL and PL and allow a user to establish whether the associated operating environment can be trusted as described below. It is not essential however for the virtual trust device code to be incorporated within the SPK code the code can be housed elsewhere for example in the trusted device .

To ensure that the virtual trusted device can be trusted it is desirable for the manufacture of the SPK code to be validated by a trusted third party. On validation a validation credential signed with the trusted third parties private key is associated with the SPK code.

SPGS typically includes all the services that do not have to be included in SPK . One reason that secure platform is split into SPK and SPGS is to permit SPK to be small stable and verifiable.

Interfaces between BIOS firmware and processor hardware include a privileged application binary interface ABI and a non privileged ABI. The interfaces between SPK and BIOS firmware include a privileged ABI a non privileged ABI and processor abstraction layer PAL system abstraction layer SAL extensible firmware interface EFI interfaces. The interfaces between SPGS and SPK include a secure platform interface SPI and a non privileged ABI. The interfaces between operating system image s and SPGS include a SPI a global services interface GSI and a non privileged ABI. The interfaces between end user applications and operating system image s include an application program interface API and a non privileged ABI.

SPGS can partition operating system image layer into multiple independent protection domains which operate at PL. A protection domain is herein referred to as a software partition and associated collection of system resources such as memory I O processors and the like created by SPGS for the purpose of loading and executing a single operating system image . Each of the multiple independent protection domains are capable of booting and executing an operating system image or any other program capable of operation using only SPK and SPGS services such as a specialized application control program.

The multiple independent protection domains running at PL are protected from each other through the memory protection capabilities of the four privilege level processor hardware such as the memory protection capabilities of the IA 64 processor. Therefore a failure in one of the independent protection domains typically has no effect on the other independent protection domains even if the failure is an operating system crash. The independent protection domains provide the capability to manage system utilization on a fine grain basis while maintaining security. Operating system images are ported to secure platform of SPA similar to how operating systems are ported to a new hardware platform industrial standard archicture ISA in the classical architecture for operating systems.

End user applications run at the least privileged level PL as unprivileged tasks under the control of an operating system image in a secure platform protection domain. Typically from the end user application perspective the end user application operates under the control of an operating system image as the end user application would run under the control of an operating system in the classical architecture for operating systems.

In order for the computer platform and operating environment s to be trusted a chain of trust from the system hardware through the boot process to final running code is established. In addition all software code is preferably authenticated before being executed and a properly authenticated piece of code is preferably unchangeable except by a similarly trusted component to maintain the chain of trust. The software authentication should be more than a simple check sum or other forgeable scheme. Thus SPA preferably employs strong authentication using cryptographic methods such as public key encryption such that software can be undetectably corrupt only if a private key is known.

The chain of trust extends back to the trusted device . As described below after system reset the processor is initially controlled by the trusted device which then after performing a secure boot process hands control over to the BIOS firmware . During the secure boot process the trusted device acquires an integrity metric of the computer platform as described below.

Specifically the trusted device used for embodiments of the invention comprises as shown in a controller programmed to control the overall operation of the trusted device and interact with the other functions on the trusted device and with the other devices on the motherboard a measurement function for acquiring the integrity metric from the platform a cryptographic function for signing encrypting or decrypting specified data an authentication function and interface circuitry having appropriate ports for connecting the trusted device respectively to the data bus control lines and address lines of the motherboard . Each of the blocks in the trusted device has access typically via the controller to appropriate volatile memory areas and or non volatile memory areas of the trusted device . Additionally the trusted device is designed in a known manner to be tamper resistant.

For reasons of performance the trusted device may be implemented as an application specific integrated circuit ASIC . However for flexibility the trusted device is preferably an appropriately programmed micro controller. Both ASICs and micro controllers are well known in the art of microelectronics and will not be considered herein in any further detail.

One item of data stored in the non volatile memory of the trusted device is a certificate . The certificate contains at least a public key of the trusted device and optionally an authenticated value of the platform integrity metric measured by a trusted party TP . The certificate is signed by the TP using the TP s private key prior to it being stored in the trusted device . In later communications sessions a user of the platform can verify the integrity of the platform and operating environment by comparing the acquired integrity metric i.e. measured integrity metric with an authentic integrity metric as described below. Knowledge of the TP s generally available public key enables simple verification of the certificate . The non volatile memory also contains an identity ID label . The ID label is a conventional ID label for example a serial number that is unique within some context. The ID label is generally used for indexing and labelling of data relevant to the trusted device but is insufficient in itself to prove the identity of the platform under trusted conditions.

The trusted third party that is requested to supply the authentic integrity metric will inspect the type of the platform to decide whether to vouch for it or not. This will be a matter of policy. If all is well the TP measures the value of integrity metric of the platform. Then the TP generates a certificate for the platform. The certificate is generated by the TP by appending the trusted device s public key and optionally its ID label to the measured integrity metric and signing the string with the TP s private key.

The trusted device can subsequently prove its identity by using its private key to process some input data received from the user and produce output data such that the input output pair is statistically impossible to produce without knowledge of the private key. Hence knowledge of the private key forms the basis of identity in this case. Clearly it would be feasible to use symmetric encryption to form the basis of identity. However the disadvantage of using symmetric encryption is that the user would need to share his secret with the trusted device. Further as a result of the need to share the secret with the user while symmetric encryption would in principle be sufficient to prove identity to the user it would insufficient to prove identity to a third party who could not be entirely sure the verification originated from the trusted device or the user.

The trusted device is initialised by writing the certificate into the appropriate non volatile memory locations of the trusted device . This is done preferably by secure communication with the trusted device after it is installed in the motherboard . The method of writing the certificate to the trusted device is analogous to the method used to initialise smart cards by writing private keys thereto. The secure communication is supported by a master key known only to the TP that is written to the trusted device or smart card during manufacture and used to enable the writing of data to the trusted device writing of data to the trusted device without knowledge of the master key is not possible.

At some later point during operation of the platform for example when it is switched on or reset the trusted device measures and stores the integrity metric of the platform.

The trusted device is equipped with at least one method of reliably measuring or acquiring the integrity metric of the computing platform with which it is associated to enable comparison with the authentic integrity metric supplied by the trusted third party. In this first embodiment the integrity metric is acquired by the measurement function by generating a digest of the BIOS instructions in the BIOS memory and the SPK code. The measured integrity metric is signed using the trusted device private key to provide confidence that the integrity metric has been acquired by the trusted device . Such an acquired integrity metric if verified as described above gives a potential user of the platform a high level of confidence that the platform has not been subverted at a hardware or BIOS program level.

The measurement function has access to non volatile memory for storing a hash program and a private key of the trusted device and volatile memory for storing acquired integrity metric in the form of a digest . In appropriate embodiments the volatile memory may also be used to store the public keys and associated ID labels of one or more authentic smart cards not shown that can be used to gain access to the platform .

In one preferred implementation as well as the digest the integrity metric includes a Boolean value which is stored in volatile memory by the measurement function for reasons described below.

A process for acquiring an integrity metric for the computer platform as used in first embodiments of the invention will now be described with reference to .

In step at switch on the measurement function monitors the activity of the main processor on the data control and address lines to determine whether the trusted device is the first memory accessed. Processor is directed to the trusted device which acts as a memory. In step if the trusted device is the first memory accessed in step the measurement function writes to volatile memory a Boolean value which indicates that the trusted device was the first memory accessed. Otherwise in step the measurement function writes a Boolean value which indicates that the trusted device was not the first memory accessed.

In the event the trusted device is not the first accessed there is of course a chance that the trusted device will not be accessed at all. This would be the case for example if the main processor were manipulated to run the BIOS program first. Under these circumstances the platform would operate but would be unable to verify its integrity on demand since the integrity metric would not be available. Further if the trusted device were accessed after the BIOS program had been accessed the Boolean value would clearly indicate lack of integrity of the platform.

However if a user is prepared to trust the BIOS the computer platform can be arranged to use the BIOS instructions as the first instructions accessed.

In step when or if accessed as a memory by the main processor the main processor reads the stored native hash instructions from the measurement function in step . The hash instructions are passed for processing by the main processor over the data bus . In step main processor executes the hash instructions and uses them in step to compute a digest of the BIOS memory by reading the contents of the BIOS memory and processing those contents according to the hash program. In step the main processor writes the computed digest to the appropriate non volatile memory location in the trusted device . In a similar manner the measurement function initiates the calculation of a digest for the SPK that is correspondingly stored in an appropriate non volatile memory location in the trusted device . The measurement function in step then calls the BIOS firmware in the BIOS memory and execution continues as described below.

Clearly there are a number of different ways in which the integrity metric of the platform may be calculated depending upon the scope of the trust required. The measurement of the BIOS program s integrity provides a fundamental check on the integrity of a platform s underlying processing environment. The integrity metric should be of such a form that it will enable reasoning about the validity of the boot process the value of the integrity metric can be used to verify whether the platform booted using the correct BIOS. Optionally individual functional blocks within the BIOS could have their own digest values with an ensemble BIOS digest being a digest of these individual digests. This enables a policy to state which parts of BIOS operation are critical for an intended purpose and which are irrelevant in which case the individual digests must be stored in such a manner that validity of operation under the policy can be established .

Other integrity checks could involve establishing that various other devices components or apparatus attached to the platform are present and in correct working order. In one example the BIOS programs associated with a SCSI controller could be verified to ensure communications with peripheral equipment could be trusted. In another example the integrity of other devices for example memory devices or co processors on the platform could be verified by enacting fixed challenge response interactions to ensure consistent results. Where the trusted device is a separable component some such form of interaction is desirable to provide an appropriate logical binding between the trusted device and the platform. Also although in the present embodiment the trusted device utilises the data bus as its main means of communication with other parts of the platform it would be feasible although not so convenient to provide alternative communications paths such as hard wired paths or optical paths. Further although in the present embodiment the trusted device instructs the main processor to calculate the integrity metric in other embodiments the trusted device itself is arranged to measure one or more integrity metrics.

Preferably the BIOS boot process includes mechanisms to verify the integrity of the boot process itself. Such mechanisms are already known from for example Intel s draft Wired for Management baseline specification v 2.0 BOOT Integrity Service and involve calculating digests of software or firmware before loading that software or firmware. Such a computed digest is compared with a value stored in a certificate provided by a trusted entity whose public key is known to the BIOS. The software firmware is then loaded only if the computed value matches the expected value from the certificate and the certificate has been proven valid by use of the trusted entity s public key. Otherwise an appropriate exception handling routine is invoked.

Optionally after receiving the computed BIOS digest the trusted device may inspect the proper value of the BIOS digest in the certificate and not pass control to the BIOS if the computed digest does not match the proper value. Additionally or alternatively the trusted device may inspect the Boolean value and not pass control back to the BIOS if the trusted device was not the first memory accessed. In either of these cases an appropriate exception handling routine may be invoked.

Further details of the operation of first embodiments of the invention will now be described with reference to .

Optionally as shown in to provide control and support to the computer platform a system management counsel SMC is coupled to computer platform via connection . In one embodiment SMC includes separate independent processors not shown such as standard non networked personal computers PCs . Connection can include serial interfaces e.g. RS 232 and USB and or private LAN connections. SMC is primarily employed to authenticate SPK during computer platform initialization. In addition computer platform is configured via SMC . In one embodiment SMC performs remote debugging for SPK and SPGS .

In one embodiment GUI interfaces for system control and management are only implemented on SMCs . This embodiment permits development and testing of system management interfaces and human factors in parallel with development of the rest of computer platform without having to wait for the entire computer platform to be brought up.

More than one SMC can be coupled to computer platform via serial interface and or LAN connection . In one embodiment SMC functions are integrated into SPGS in a computer platform having a single processor such as a workstation.

Additionally the trust device could be located in the SMC and act as the trusted device remotely to the computer platform .

Once the trusted device has initiated a trusted boot up sequence as described above it is still necessary to ensure the chain of trust is maintained through to the initialisation of the operating domains. Therefore in addition to utilising the trusted device to provide information as to whether the computer platform can be trusted it is necessary to determine that a users operating environment can be trusted.

Accordingly once the trusted device has passed control to the BIOS firmware the SPA is arranged to provide a trusted operating environment as described below.

Initially on passing control to the BIOS firmware the BIOS firmware inter alia boots up and authenticates the EFI.

An EFI file system stores a secure platform SP loader a system configuration database SCD a SPK image and a SPGS image .

The EFI loads SP loader from EFI file system into memory . The EFI authenticates this image using the processor manufacturer s public key. This authentication requires that SP loader be digitally signed with the processor manufacturer s private key.

The EFI then transfers control to SP loader stored in memory . SP loader is an EFI based secondary loader which is secure platform specific. SP loader is responsible for loading SP images into memory .

In one embodiment it is possible for execution to be transferred to an EFI shell prompt to enable initial system installation and other administrative details which breaks the SP chain of trust. In this case the EFI recognizes that trust was lost and does not precede with loading SP loader. Instead computer platform resets so that all processors will again start fetching instructions from trusted device .

SP loader running from memory loads the SCD from EFI file system into memory . SP loader then authenticates SCD employing a public key contained in the SP loader image. SP loader employs SCD to determine which SPK and SPGS images to load from EFI file system into memory. SP loader employs the above public key for authenticating the SPK and SPGS images. SP loader creates a virtual mapping for an entry area of SPK with read and execute only permissions. SP loader then switches to virtual mode and branches to the SPK entry point.

In the boot sequence for bringing up SPK SPK running from memory on processor initialises privilege state e.g. interruption vector table NT control registers and some interrupt configuration and creates any other additional memory mappings required for SPK such as writeable areas for SPK data. SPK then creates any required memory mappings and any additional set up required to run SPGS .

A secure platform SP mirrored file system stores two redundant control block images. SPK reads the two redundant control block images from SP mirrored file system into SPK in memory as redundant control block images. The two redundant control block images contain control information initialized at the very first computer platform . The redundant control block images are employed to test whether computer platform has already been initialized.

In one embodiment the redundant control block images each contain at least three distinct control areas. First control area contains an image that also is signed by the processor manufacturer s public key which was written when computer platform booted for the first time. First control area is employed to store a root system key RSK in second control area. Second control area contains the RSK encrypted under itself. Second control area is employed to validate that a correct RSK has been supplied on subsequent boots. Encrypting the RSK under itself permits validation of the RSK by comparing the results with the value already stored in second control area. Third control area contains a top level directory of platform control information including keys pseudo random number generator PRNG state and last entropy pool snapshot all encrypted and integrity checked by the RSK.

SPK typically has minimal or no I O capability. In one embodiment the SP loader performs I O accesses prior to transfer of control to SPK . In another embodiment SPGS is brought up to an I O ready state prior to the I O operation to read from the disk and returns control to SPK . In another embodiment SPGS loads memory and then a call is made to SPK which performs the above operation.

SPK determines whether the control areas of the two redundant control block images agree and the digital signature checks. If the control areas disagree the control areas of the redundant control block image whose integrity checks as valid are used and the control areas of the other redundant control block whose integrity checks as invalid are restored to match the used control areas of the valid redundant control block image. If the control areas of both redundant control block images are damaged logs are used to recover similar to many database systems and to restore the control areas of both redundant control block images. Once the RSK is obtained the boot process continues.

The initial SPGS domain initializes and performs discovery of I O to include access to SMC . The initial SPGS domain loads an encrypted SCD from the SP mirrored file system. The initial SPGS domain requests SPK to decrypt the encrypted SCD. The decrypted SCD specifies the number of SPGS domains to create and which system resources belong to which SPGS domain. The initial SPGS domain then creates each additional SPGS domain specifying the corresponding subset of system resources to include in the processor in which the SPGS domain is run on.

Each SPGS domain similarly reads the decrypted SCD and creates the specified domains. Each SPGS created domain includes the following. System resources are allocated to each SPGS domain on a per domain basis. A domain initial image DII is loaded from EFI file system into memory as DII. DII is typically an operating system specific loader for initiating the loading of an operating system for a specific domain in PL. If SCD indicates that the given SPGS domain is a secure domain the self contained public key of SP loader is employed to authenticate DII. Thus DIIs which are to run in secure SPGS domains are preferably digitally signed with the SP loader s private key. One use of a non secure SPGS domain is to allow development and debugging of DIIs.

On creation of each of the specified domains an associated virtual trusted device is created in the SPK .

As the virtual trusted devices are executed in the SPK which runs at the PL level the only level that executes privileged instructions the virtual trusted devices can effectively be isolated from software executed in the other processor privilege levels. Accordingly as the SPK is trusted code a user can be confident that the virtual trusted devices are shielded from non trusted software.

Each virtual trusted device comprises as shown in a central routine for controlling the overall operation of the virtual trusted device a measurement function for acquiring an integrity metric for an associated operating environment and obtaining the integrity metric acquired by the trusted device and makes measurements on software that is to be executed in the associated operating environment a cryptographic function for signing encrypting or decrypting specified data. Additionally each virtual trusted device is able to verify the integrity metric acquired by the trusted device using the trusted third parties public key. The virtual trusted devices have access to memory associated with the PL level. Additionally each virtual trusted device is arranged to be isolated from any other virtual trusted device that is associated with a separate operating environment.

On creation of an associated operating environment in PL the associated virtual trusted device in PL is issued with a certificate that is associated with the user of the operating environment.

Each virtual trusted devices certificate is stored in local memory in the PL level. The certificate contains a public key of the respective virtual trusted device and optionally an authenticated value of an integrity metric for measured by a trusted third party to allow verification of the integrity metric acquired by the trusted device . The certificate is signed by the trusted third party using the trusted third parties private key prior to the certificate being stored in the virtual trusted device thereby confirming that the trusted third party vouches for the virtual trusted device . In this embodiment possible trusted third parties could be either the physical trusted device or the SMC .

As described below a user on accessing a virtual trusted device associated with the respective operating environment can obtain the computer platform integrity metric acquired and signed by the trusted device with the trusted device s private key and the integrity metric measured and signed by the virtual trusted device and the virtual trusted device s private key for the respective operating environment. Accordingly the user is able to obtain all the integrity metric information required to allow verification that the respective operating environment can be trusted from the virtual trusted device without the user needing to access the trusted device directly.

As virtual trusted devices are created and destroyed on the creation and destruction of operating environments it is necessary to ensure that their transitory existence does not compromise the trustworthiness of either the computer platform or associated operating environments. As such to ensure that trust can be maintained it is essential that secrets associated with the virtual trusted device s do not exist in more than one active trusted device at any given time. This requires that strict and reliable methods in the computer platform ensure that on the creation and destruction of a virtual trusted device only one copy of relevant secrets e.g. for example private keys are maintained.

As such destruction of a virtual trusted device requires the permanent safe secret destruction of the virtual trusted devices secrets. If a virtual trusted device is to be stored for re use at a later date it secrets must be safely and secretly preserved for future use.

The secrets belonging to the virtual trusted device could be stored in the physical trusted device or SMC using the protected storage facilities of a trusted platform module for example. Virtual trusted device secrets can be safely stored using the trusted computer platform association TPCA maintenance process.

For operating environments that need to continue to exist despite the computer platform having to be power down and back up again it is possible to reassemble the stored associated virtual trusted device . This allows the same virtual trusted device to be maintained for the same operating environment despite the temporary closing down of the operating environment.

However the method required to reassemble a virtual trusted device depends on the method used to dismantle the initial virtual trusted device .

If a virtual trusted device has been saved using the TCPA maintenance process as described in section 7.3 of the TCPA specification a new virtual trusted device and trusted platform i.e. operating environment must be created e.g. new endorsement key credentials can be provided via the virtual trusted devices certificate . The TCPA maintenance process is used to transfer the appropriate secrets of the virtual trusted device to the new virtual trusted device in the new operating environment. This is a two step process requiring first that the owner user of the new operating environment check that the new virtual trusted device and operating environment have at least the same level of security as the original virtual trusted device and operating environment such that the existing credentials do not overstate the security properties of the new virtual trusted device and associated operating environment.

If the previous virtual trusted device has been saved in full a blank virtual trusted device and associated operating environment are created in PL and PL respectively and the original secrets stored from the original virtual trusted device are loaded into the new virtual trusted device. As above the new operating environment must be checked that the new virtual trusted device and operating environment have at least the same level of security as the original virtual trusted device and associated operating environment such that the existing credentials do not overstate the security properties of the new virtual trusted device and operating environment. If a SMC holds the secrets some separate security service is required to confidentially communicate the secrets from the SMC to the computer platform . This will require a key distribution service as is well known to a person skilled in the art.

This allow multiple operating environments to be created where each operating environment has its own associated virtual trusted device such that each virtual trusted device derives the integrity metric for the computer platform from the trusted device and additionally measures an integrity metric for the associated operating environment. This allows a computer platform to have multiple users each with their own respective operating environment where each operating environment is isolated from each other and each operating environment can provide an integrity metric for both itself and the computer platform . This allows a user of an operating environment to determine whether his respective operating environment can be trusted without requiring any information as to whether any other operating environment is running on the computer platform .

Additionally as each domain is isolated and the virtual trusted devices are executed in a privileged processor level PL rouge software executed in one domain can not attack software executed in another domain.

The respective virtual trusted device receives the challenge and creates an appropriate response. This may be a digest of the measured integrity metric of the computer platform integrity metric received from the trusted device and signed with the trusted device s private key and the measured integrity metric for the respective operating environment signed with the respective virtual trusted device s private key and the nonce and optionally its ID label. The respective trusted device return the signed integrity metric accompanied by the respective virtual trusted devices certificate and the trusted device s certificate to the user.

The user receives the challenge response and verifies the certificate using the well known public key of the TP s . The user then extracts the virtual trusted device s public key and the trusted device s public key from the certificate and uses them to decrypt the signed integrity metrics from the challenge response. Then the user verifies the nonce inside the challenge response. Next the user compares the computed integrity metrics which it extracts from the challenge response with the proper platform integrity metrics which in this embodiment are extracted from the certificates. If any of the foregoing verification steps fails the whole process ends with no further communications taking place.

Assuming all is well the user and the trusted platform use other protocols to set up secure communications for other data where the data from the platform is preferably signed by the trusted device without any knowledge of the other two operating environments installed on the computer platform .

A second set of embodiments will now be described with reference to . These second embodiments have many features in common with the first embodiments differences are indicated positively some common features are indicated positively and the skilled person will appreciate how other features of the first embodiments may be applied in the second embodiments.

The second set of embodiments use a different form of virtualization technology. Alternative virtualization technologies will now be described. As the skilled person will appreciate although only specific examples are provided the principles of the present invention may be applied across the full range of virtualization technologies.

The basic requirement for virtualization is that any machine instruction that is either privileged or sensitive including input and output can be intercepted by a control layer the virtualization layer . Instructions might be ones that would allow direct access to the real hardware or reveal sensitive state about other software running on it.

This virtualization layer can be achieved in different ways. Some processors as has been described for the first embodiments are naturally virtualizable meaning that all privileged or sensitive instructions on that processor generally a CPU can be intercepted. Some CPUs for example those according to the Intel IA 32 architecture are not naturally virtualizable.

Most forms of CPU and 10 input output device virtualization make use of the hardware protection facilities such as privilege levels provided by the real CPU that is being virtualized. On naturally virtualizable platforms that usually just means relying on the CPU protection mechanisms to make sure that the underlying virtualization layer always remains in control of the real hardware. This is all as has been described for the first embodiments above.

On CPUs which are not naturally a more software based approach needs to be taken. It may also be desirable to take such an approach on naturally virtualizable CPUs for performance reasons. This approach involves rewriting the operating systems running on top of the control layer so that they do not contain any privileged or sensitive instructions that would not naturally cause a transition to the control layer. Para virtualization is the term used to describe such source code rewrites of the operating systems. The Xen virtual machine monitor relies on this approach. VMWare uses dynamic binary modification of the running operating systems as its means of remaining in control of the real hardware platform.

In a composite approach both Intel Vanderpool and AMD Pacifica have developed hardware features in CPUs to support the running of virtual machine monitors. With this support any instruction regardless of privilege level can be made to trigger a transition to the control layer. With this approach it is no longer necessary to rely on running operating systems at different privilege levels to those on which they would normally run.

A general depiction of a platform using virtualization is provided in . Hardware supports a virtual machine monitor VMM this is the virtualization layer which controls virtualization. On top of this are separate virtual machines with their own operating systems and applications .

Second embodiments of the invention will be described with reference to this depiction. The trusted device is at the hardware level and the isolation of a trusted module and any other virtual component is achieved by the virtualization layer . The result is shown in the hardware layer contains a trusted device and trust routines sit over the virtualization layer along with the associated operating environments. The second embodiments described below do not rely on the virtualization technology used.

For these second embodiments the computer system of the motherboard of and the trusted device of are all used essentially as described above modified to be independent of the virtualization technology further discussion on elements and use of a trusted device in accordance with TCG practice are however discussed below. Processor in may therefore be any processor suitable for use with a virtualization technology rather than specifically one with multiple privilege levels as specifically described above and as described in . Integrity metrics are obtained in the general manner indicated in FIG. the measurement process for such metrics is not reliant on the form virtualization technology as described although relevant aspects of the virtualization technology may be measured by integrity metrics as is described below . The measurement of integrity metrics in accordance with TCG practice is described more fully in for example Trusted Computing Platforms TCPA Technology in Context edited by Siani Pearson 2003 Prentice Hall PTR integrity metrics as described in Pearson may be used in second embodiments of the invention.

The description of above describes the trusted device and similarly trusted routines each as a single entity. The approach taken in TCG specifications is to consider rather than a single trusted device multiple entities. The measurement engine which makes the first measurement within the trusted platform is termed the Root of Trust for Measurement RTM this in addition to the TPM serves as a root of trust generally achieved by a trusted source of such software vouching for it. A Core Root of Trust for Measurement CRTM comprises executable instructions that when controlling the main processing engine on the platform cause the platform to perform the functions of an RTM. The Trusted Platform Module TPM is an engine that that stores and reports measurements loaded into it by the RTM and subsequent measurement agents. The Trusted Building Block TBB comprises the CRTM and the connections between the CRTM the TPM and the platform including the platform s main processing engine . The Trusted Platform Module is for the physical platform comprised in a physical device. Second embodiments of the present invention describe how trust routines providing these elements in a virtualized form with respect to the relationships between a trust routine and the operating environment to which it relates can be related to the trusted elements of the physical platform itself.

It should be appreciated that the trusted device and trust routines can have normal TCG Attestation Identities. An Attestation Identity as described in Pearson is a statistically unique difficult to forge or counterfeit identity which is verifiable to either a local or a remote entity. It comprises a digital certificate as a public part which contains a label and a public key all signed by a trusted entity and a private key retained as a secret in the TPM. Such an identity provides sufficient evidence that a trusted platform contains the capabilities and data that must be trustworthy if reports about the software environment in that platform are to be trusted. For the physically embodied TPM such identities there may be any number are generated by the TPM and attested by a trusted entity termed a Privacy CA. The Privacy CA attests to the Attestation Identity by creating a certificate termed an AIK Certificate as described this binds the identity key to the identity label and generic information about the platform. The Privacy CA is persuaded to provide such attestation by being provided with sufficient information to establish that the trusted platform containing the TPM is a genuine trusted platform. In TCG specifications this is provided by a Trusted Platform Module Entity vouching that a TPM is genuine by installing an endorsement key pair in the TPM and embedding the public key of the pair in an endorsement credential and by a platform manufacturer using a Platform Entity to provide an analogous Platform Certificate to prove that the platform is a genuine trusted platform. In embodiments there may also be required a Conformance Credential provided by the manufacturer to show that the design of TPM and the design of the platform meet TCG specifications. For the purpose of discussion of these second embodiments it will be assumed that the trusted device has a conventional TCG Attestation Identity discussion which follows relates to mechanisms which enable trust routines to obtain Attestation Identities of this type.

The steps involved in enabling a virtual trusted platform to acquire an Attestation Identity are shown in .

As indicated above the trusted device may use 1110 conventional TCG procedures and protocols to obtain an Attestation Identity. The AIK certificate could be a conventional TCG AIK certificate. In alternative embodiments however the AIK Certificate may be a modified TCG AIK certificate whose security properties field comprises a description of the platform including its virtualisation processes that create the trust routines and operating environments. These extra fields could be part of the security properties field in the platform s Platform Credential supplied to the entity creating the AIK Certificate.

In order for a virtual TPM to obtain an Attestation Identity the server s physical TPM must have previously used an Attestation Identity of the physical of the server to sign a virtual Endorsement Credential 1120 . This is consistent with but goes beyond the first embodiments which require that the trusted device uses one of its private asymmetric keys to vouch for a public key belonging to a trust routine.

In such second embodiments when a platform instantiates a trust routine the trust routine comprises the virtual equivalent of a TCG TPM containing a TCG Endorsement Key. Since the platform fully controls the trust routine the platform is fully capable of obtaining that Endorsement Key from the trust routine. The platform is a credible entity to construct and sign a certificate attesting that that EK belongs to a properly constructed virtual TPM created by the platform this certificate functioning as an Endorsement Credential.

The certificate is thus a conventional TCG Endorsement Credential signed by a TCG Attestation Identity belonging to the trusted device. This is possible provided the AIK credential belonging to the trusted device has fields comprising a description of the platform s security properties including its virtualisation processes and at least part of its trust routines.

In alternative embodiments the certificate is a modified TCG Endorsement Credential with extra fields comprising 1 metrics obtained by the trusted device describing the platform including its virtualisation processes 2 metrics obtained by the trusted device describing at least part of the trust routine. The certificate is as before signed by a TCG Attestation Identity belonging to the trusted device.

In order for a virtual TPM to obtain an Attestation Identity the server s physical TPM must have previously used an Attestation Identity of the physical of the server to sign a virtual Platform Credential 1130 . When a platform instantiates a trust routine the trust routine comprises the virtual equivalent of a TCG TBB and TPM. The trust routine and its associated operating environment contain a TCG TPM TBB RTM and CRTM securely bound to a virtual normal platform this certificate functioning as a Platform Credential.

The platform is a credible entity to construct and sign a certificate attesting that there exists a properly constructed virtual TCG trusted platform containing a particular TPM.

The certificate is a conventional TCG Platform Credential signed by a TCG Attestation Identity belonging to the trusted device. This possible provided the AIK credential belonging to the trusted device has fields comprising a description of the platform s security properties including its virtualisation processes and at least part of its trust routines.

In alternative embodiments this certificate is a modified TCG Platform Credential whose extra fields comprise 1 metrics obtained by the trusted device describing the platform including its virtualisation processes that create the trust routines and operating environments 2 metrics obtained by the trusted device describing at least part of the trust routine. The certificate is as before signed by a TCG Attestation Identity belonging to the trusted device.

The virtual TPM of the trust routine is now equipped with the necessary credentials to obtain an Attestation Identity Certificate 1140 . This is consistent with but goes beyond the first embodiments which indicate that a trusted party may use one of its private asymmetric keys to vouch for a public key belonging to a trust routine.

When a trust routine creates an Attestation Identity it may wish to acquire a TCG Attestation Identity Certificate for that identity. The trust routine follows conventional TCG procedures and protocols and supplies the Endorsement Credential and Platform Credential created by the platform.

It should be appreciated that a CA distinguished by TCG as a Privacy CA can follow normal TCG procedures and protocols to create an Attestation Identity certificate for a trust routine. The certificate however should be a modified AIK certificate whose extra fields comprise an indication of the TCG Attestation Identity belonging to the trusted device.

Alternative embodiments are possible as the platform is itself a credible entity to construct and sign an Attestation Identity certificate for the trust routine without following TCG procedures and protocols. This is because the platform fully controls the trust routine. Such a certificate is a modified TCG Attestation identity certificate whose extra fields comprise 1 metrics obtained by the trusted device describing the platform including its virtualisation processes that create the trust routines and operating environments 2 metrics obtained by the trusted device describing at least part of the trust routine. The certificate is signed by a TCG Attestation Identity belonging to the trusted device.

When in possession of an Attestation Identity certificate the trust routine can act as a conventional TCG TPM. In particular when a trust routine supplies integrity metrics about an operating environment the trust routine simply follows conventional TCG procedures and protocols and signs the metrics using an Attestation Identity key.

In second embodiments of the invention interactions between entities from third parties to entities associated with the platform to users may thus be essentially consistent with TCG procedures and protocols.

