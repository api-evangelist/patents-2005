---

title: System and method for rendering a binary volume in a graphics processing unit
abstract: A system and method for rendering a binary volume in a GPU are provided. The method for rendering a binary volume comprises: storing eight bits of the binary volume along an x-axis in a byte of memory to form a compact representation of the binary volume; generating a two-dimensional decoding table of the compact representation of the binary volume; extracting a byte including a bit of interest from the compact representation of the binary volume; determining a bit coordinate for the bit of interest and extracting a decoded value of the bit of interest from the two-dimensional decoding table; obtaining a gray value of the decoded value of the bit of interest and classifying the gray value; and multiplying the decoded value of the bit of interest by the gray value to form a resultant value.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07961958&OS=07961958&RS=07961958
owner: Siemens Medical Solutions USA, Inc.
number: 07961958
owner_city: Malvern
owner_country: US
publication_date: 20050926
---
This application claims the benefit of U.S. Provisional Application No. 60 645 085 filed Jan. 19 2005 the disclosure of which is herein incorporated by reference.

The present invention relates to image processing and more particularly to a system and method for rendering a binary volume in a graphics processing unit.

A graphics processing unit GPU is typically identified as the microprocessor of a graphics card for a personal computer or game console. Modern GPUs are very efficient at manipulating and displaying computer graphics and their highly parallel structure makes them more effective than central processing units CPUs for a range of complex algorithms. For example modern GPUs have all but taken over operations once performed by CPUs such as texture mapping and rendering of polygons and geometric calculations such as the mapping of vertexes into different coordinate systems.

As computer workstations with GPUs supporting the interactive rendering of complex three dimensional 3D polygon scenes consisting of directly lit and shaded triangles became widely available techniques for texture based rendering of grayscale volumetric datasets were developed. Building upon these techniques volume rendering methods using binary masks began to appear. These methods however encountered difficulties in attempting to distinguish between different types of material based solely on grayscale values that were measured during the acquisition of volumetric data. To remedy this binary segmentation masks were employed to mark wanted and unwanted parts of the volumetric data.

When a binary volume is in its native form as a binary segmentation mask flags for eight neighboring voxels along an x axis are stored in a single byte. Such binary volumes cannot be easily stored and rendered using GPUs. This occurs since neither boolean operations for fragment processing nor texture formats for binary data are utilzed by modern GPUs. Because of this binary volumes are often expanded by assigning a byte value to each bit of the original volume. The volumes are then stored in GPU memory. This however results in increasing the storage requirements of a GPU memory by a factor of for example 8 16 or 32 which is neither desirable nor practical especially when dealing with large volumes.

One technique for reducing the memory requirements of a GPU involves burning a binary segmentation mask into a gray volume by setting data corresponding to the binary segmentation mask to a specified value. This technique however leads to a loss of information in the gray volume since burned in data values are not distinguishable from original data values of the gray volume. In addition this technique can lead to undesirable artifacts in rendered images when using for example post interpolative transfer functions. As such there is a need for a technique of reducing the amount of memory used by a GPU when rendering a binary volume.

The present invention overcomes the foregoing and other problems encountered in the known teachings by providing a system and method for rendering a binary volume in a GPU.

In one embodiment of the present invention a method for rendering a binary volume comprises storing eight bits of the binary volume along an x axis in a byte of memory to form a compact representation of the binary volume generating a two dimensional decoding table of the compact representation of the binary volume extracting a byte including a bit of interest from the compact representation of the binary volume determining a bit coordinate for the bit of interest and extracting a decoded value of the bit of interest from the two dimensional decoding table obtaining a gray value of the decoded value of the bit of interest and classifying the gray value and multiplying the decoded value of the bit of interest by the gray value to form a resultant value.

The method further comprises receiving gray volume data and deriving the binary volume from the gray volume data. The gray volume data is acquired by using one of a magnetic resonance MR computed tomography CT positron emission tomography PET a two dimensional 2D or three dimensional 3D fluoroscopic a 2D 3D or four dimensional 4D ultrasound x ray imaging or digital scanning technique.

The method further comprises masking voxels of the gray volume data using the resultant value. Generating a two dimensional decoding table of the compact representation of the binary volume comprises generating a table having 8 j column X 256 i row entries setting values inside the table to 255 if a j th bit in an i byte is 1 and to 0 otherwise and storing the table in a two dimensional texture in the memory.

Determining a bit coordinate for the bit of interest comprises multiplying a texture coordinate of a voxel of gray volume data associated with the bit of interest by a number of voxels along the x axis of the byte divided by eight wherein a fractional part of the multiplication result is the bit coordinate. The decoded value of the bit of interest from the two dimensional decoding table is extracted by using the bit coordinate and a byte corresponding to the bit coordinate as lookup values in the two dimensional decoding table. The method further comprises blending the resultant value into a frame buffer. Classifying the gray value comprises looking up a red green blue alpha RGBA value in a one dimensional lookup table for assigning color and opacity values to the gray value.

In another embodiment of the present invention a system for rendering a binary volume comprises a memory device for storing a program a processor in communication with the memory device the processor operative with the program to store eight bits of the binary volume along an x axis in a byte of a graphics processing unit GPU memory to form a compact representation of the binary volume generate a two dimensional decoding table of the compact representation of the binary volume extract a byte including a bit of interest from the compact representation of the binary volume determine a bit coordinate for the bit of interest and extract a decoded value of the bit of interest from the two dimensional decoding table obtain a gray value of the decoded value of the bit of interest and classify the gray value and multiply the decoded value of the bit of interest by the gray value to form a resultant value.

The processor is further operative with the program code to receive gray volume data and derive the binary volume from the gray volume data. The gray volume data is acquired using one of an MR CT PET a 2D or 3D fluoroscopic a 2D 3D or 4D ultrasound x ray imaging or digital scanning device. The processor is further operative with the program code to mask voxels of the gray volume data using the resultant value.

When generating a two dimensional decoding table of the compact representation of the binary volume the processor is further operative with the program code to generate a table having 8 j column X 256 i row entries set values inside the table to 255 if a j th bit in an i byte is 1 and to 0 otherwise and store the table in a two dimensional texture in the memory.

When determining a bit coordinate for the bit of interest the processor is further operative with the program code to multiply a texture coordinate of a voxel of gray volume data associated with the bit of interest by a number of voxels along the x axis of the byte divided by eight wherein a fractional part of the multiplication result is the bit coordinate. The processor is further operative with the program code to blend the resultant value into a GPU frame buffer.

In yet another embodiment of the present invention a method for rendering a binary volume in a GPU comprises preprocessing the binary volume by storing eight bits of the binary volume along an x axis in a byte of memory of the GPU to form a compact representation of the binary volume and generating a decoding table of the compact representation of the binary volume and rendering the binary volume by extracting a byte including a bit of interest from the compact representation of the binary volume determining a bit coordinate for the bit of interest and using the bit coordinate and byte as lookup values in the decoding table to mask out voxels from the binary volume.

The pre processing technique is one of a volume segmentation or volume editing. The rendering is one of a direct volume rendering a maximum intensity projection MIP minimum intensity projection MinIP multi planar reformatting MPR or digitally reconstructed radiograph DRR . A binary segmentation mask is applied during rendering to mask out voxels from a gray volume used to derive the binary volume.

The foregoing features are of representative embodiments and are presented to assist in understanding the invention. It should be understood that they are not intended to be considered limitations on the invention as defined by the claims or limitations on equivalents to the claims. Therefore this summary of features should not be considered dispositive in determining equivalents. Additional features of the invention will become apparent in the following description from the drawings and from the claims.

As shown in the system includes inter alia an acquisition device a personal computer PC and an operator s console connected over for example an Ethernet network . The acquisition device may be a magnetic resonance imaging MRI device a computed tomography CT imaging device a helical CT device a positron emission tomography PET device a two dimensional 2D or three dimensional 3D fluoroscopic imaging device a 2D 3D or four dimensional 4D ultrasound imaging device or an x ray device.

The acquisition device may also be a hybrid imaging device capable of CT MR PET or other imaging techniques. The acquisition device may further be a flatbed scanner that takes in an optical image and digitizes it into an electronic image represented as binary data to create a computerized version of a photo or illustration.

The PC which may be a portable or laptop computer or a personal digital assistant PDA includes a CPU a memory and a graphics card which are connected to an input device and an output device . The CPU includes a volume rendering module that includes one or more methods for rendering a binary volume in a GPU. It is to be understood however that the volume rendering module could be included in the graphics card .

The memory includes a random access memory RAM and a read only memory ROM . The memory can also include a database disk drive tape drive or a combination thereof. The RAM functions as a data memory that stores data used during execution of a program in the CPU and is used as a work area. The ROM functions as a program memory for storing a program executed in the CPU . The input device is constituted by a keyboard or mouse and the output device is constituted by a liquid crystal display LCD cathode ray tube CRT display or printer.

The graphics card which is used to take binary data from the CPU and turn it into an image includes inter alia a GPU and a memory . The GPU determines what to do with each pixel to be displayed on for example the output device or a display of the operator s console . In operation the GPU makes a 3D image by first creating a wire frame out of straight lines rasterizing the image and adding lighting texture and color to the 3D image. The memory which may be a RAM holds information regarding each pixel and temporarily stores completed images. Although not shown the graphics card also includes a connection to a motherboard which also holds the CPU for receiving data and power and a connection to the output device for outputting the picture.

It is to be understood that the memory could be included in the GPU or that the GPU could include its own memory for performing certain storage tasks according to an exemplary embodiment of the present invention.

The operation of the system is typically controlled from the operator s console which includes a controller such as a keyboard and the display such as a CRT display. The operator s console communicates with the PC and the acquisition device so that 2D image data collected by the acquisition device can be rendered into 3D data by the PC and viewed on the display . It is to be understood that the PC can operate and display information provided by the acquisition device absent the operator s console using for example the input device and output device to execute certain tasks performed by the controller and display .

The operator s console further includes any suitable image rendering system tool application that can process digital image data of an acquired image dataset or portion thereof to generate and display 2D and or 3D images on the display . More specifically the image rendering system may be an application that provides 2D 3D renderings and visualizations of medical image data and which executes on a general purpose or specific computer workstation. Moreover the image rendering system may enable a user to navigate through a 3D image or a plurality of 2D image slices. The PC may also include an image rendering system tool application for processing digital image data of an acquired image dataset to generate and display 2D and or 3D images.

The volume rendering module may also be used by the PC to receive and process digital medical image data which as noted above may be in the form of raw image data 2D reconstructed data e.g. axial slices or 3D reconstructed data such as volumetric image data or multiplanar reformats or any combination of such formats. The data processing results can be output from the PC via the network to an image rendering system in the operator s console for generating 2D and or 3D renderings of image data in accordance with the data processing results such as segmentation of organs or anatomical structures color or intensity variations and so forth.

As shown in gray volume data is received by the CPU during a preprocessing stage . This is accomplished by acquiring image data of for example a pulmonary vessel tree. The image data may be acquired by using the acquisition device in this example a CT scanner which is operated at the operator s console to scan a patient s chest or lungs thereby generating a series of 2D image slices associated with the lungs. The 2D image slices of the lungs are then combined and the gray volume data of the pulmonary vessel tree is stored in the RAM of the CPU .

It is to be understood that the image data can be from any body organ of interest such as the heart or colon and can be acquired using a variety of medical imaging modalities such as those employed by the acquisition device discussed above. It should also be understood that the image data could be non medical image data such as a vehicle or a tree and can be acquired for example by taking a digital or conventional photograph and then using a digital scanner to create a digital representation thereof.

Once the gray volume data has been received by the CPU binary volume data is derived therefrom using for example a volume editing or segmentation algorithm . The derived binary volume data is then sent to the graphics card . At this point the binary volume data is stored in the memory of the graphics card for access by the GPU . This is accomplished by storing every eight bits of the binary volume data along an x axis in a separate byte of the memory to form a compact representation of the binary volume data. If for example only four bits of the binary volume data remain to be stored when all the other bits of the binary volume data have been stored the four bits are stored along the x axis of another byte and the other four bits of the byte are padded with a 0 or 1.

After the binary volume data has been stored a 2D decoding table of the compact binary volume data is generated . This is done by first generating a table having 256 entries in one dimension one for each possible combination of bits in a byte and eight entries in another dimension one entry for each bit position in the byte . Values are set inside the table to 255 for entries that have a value of 1 in a byte associated with a bit address and values are set inside the table to 0 for entries that have a value of 0 in a byte associated with the bit address. In other words assuming the table has eight j columns and 256 i rows values are set to 255 if aj th bit in a byte i is 1 otherwise the values are set to 0. After the table has been generated it is stored in the memory as a 2D texture.

As illustrated by the pseudo code a 2D decoding table shown for example in is generated by first allocating a byte array looping through all fields of the array and setting the bytes therein to 255 if a set bit in a corresponding byte indicates that a value of 1 should be entered. If the set bit indicates that a value of 0 should be entered the bytes corresponding thereto are set to 0. After this is completed a texture reflecting input binary volume data is generated the table is uploaded to the GPU and texture parameters are set.

Now that the table has been generated a volume rendering may take place. It is to be understood that the rendering can be any one of a direct volume rendering a maximum intensity projection MIP minimum intensity projection MinIP multi planar reformatting MPR or digitally reconstructed radiograph DRR . To perform the volume rendering a byte including a bit of interest is first extracted from the compact binary volume data . This is done by fetching the byte from the memory while executing for example a fragment program.

Once the byte including the bit of interest is extracted a bit coordinate indicating the location of the bit of interest is computed e.g. bitCoord . This is done by multiplying the original texture coordinate associated with a voxel of the gray volume data e.g. texCoord on the x axis by a factor that is computed by taking the fractional part of the number of voxels along the x axis from where the bit of interest was extracted and dividing it by eight. Thus a bit coordinate is derived by scaling the texture coordinate for the x axis by a constant factor e.g. numVoxelsX 8 .

It is to be understood that the above described computation can be represented mathematically by bitCoord frac texCoord numVoxels 8 . In addition the REPEAT parameter from the above pseudo code is used to make sure that only the fractional part of the texture coordinate is taken into account during step .

Referring still to step since texture space coordinates are usually in a range from 0 to 1 scaled texture coordinates may be used to identify the direction in which bits are packed into bytes. Thus as a texture coordinate is given in the range from 0 to Size 8 where Size refers to the number of voxels that the volumetric data set consists of in that direction the fractional part of the scaled texture coordinate is what is used as a lookup value in the decoding table in the bit direction. In other words by scaling original texture coordinates in the direction in which the bits are packed into bytes a bit coordinate may be derived as discussed above.

After computing the bit coordinate for the bit of interest a decoded value of the bit of interest is extracted from the decoding table . This is accomplished by using the bit coordinate and its corresponding byte as lookup values in the decoding table. Then a sample of the gray volume data is obtained and classified . The sample is obtained by fetching an interpolated data value from the gray volume data using the original e.g. unscaled texture coordinates. The classification is achieved for example by looking up a red green blue alpha RGBA value using the sample from a one dimensional 1D lookup table containing a transfer function that may be user specified. The transfer function is used to assign color e.g. RGB and opacity e.g. A values to the sample.

It is to be understood that the sample is a data value associated with the current position in the volume being rendered. In other words the sample is an interpolated data value taken from the gray volume during rendering. After the sample of the gray volume data has been obtained and classified it is multiplied by the decoded value of the bit of interest to form a resultant value .

At this point the resultant value may be blended into a frame buffer of the GPU . For example if the decoded value of the bit of interest is 1 the resultant value would indicate that the classification result is to be maintained and thus the decoded value is to be blended into the frame buffer. If however the decoded value were 0 the decoded value would not be blended into the frame buffer. In other words when the decoded value is 0 the masked voxel associated therewith does not contribute to the final image. Further if the resultant value is an RGBA value of for example 0000 nothing is blended into the frame buffer. Using this approach parts of the original gray volume data that refer to 0 entries of the binary volume data are masked. In the alternative the decoded value can be used with another rendering approach or classification such as an if then else branch in a fragment program.

After the resultant value has been blended or not by using a kill fragment command or an alpha test into the frame buffer it is determined if the rendering is to continue . If the rendering is to continue the process returns to step and repeats. If however it has been determined that the rendering is to stop when for example all samples from the original gray volume data have been processed and an image is generated the process ends. It is to be understood that the binary volume could be rendered directly or combined with a gray volume so that voxels can be masked out or assigned different color and opacity values. Further the rendering can be any conventional rendering method used for rendering gray volume data.

The following example of pseudo code demonstrates a rendering of a binary volume with bits along an x axis packed into bytes 

In the above pseudo code it is to be understood that a bit coordinate derived from a scaled texture coordinate is passed in as IN.TexCoord1.x while standard texture coordinates in the range from 0 to 1 are passed in as IN.TexCoord0. As shown a sample from the binary volume is taken. Then by using the binary volume sample as a y coordinate and the bit coordinate as an x coordinate as lookup values in the decoding table the correct bit from the given byte is decoded. By repeating the decoding table in the bit direction initiated by the above mentioned REPEAT parameter the scaled texture coordinate accesses the correct position in the decoding table for coordinates outside the range from 0 to 1 thus only the fractional portion is taken into account.

The following pseudo code demonstrates how to render a volumetric dataset with a classification by applying a binary segmentation mask to remove parts of the volume where bits in the segmentation mask are not set 

In the above pseudo code a bit coordinate derived from a scaled texture coordinate is passed in as IN.TexCoord1.x while standard texture coordinates in the range from 0 to 1 are passed in as IN.TexCoord0. As shown a sample from the volume is fetched and a sample from a segmentation mask is then acquired. By returning an RGBA color from a classification that has been multiplied with the result from the decoding table parts of the volume where the segmentation mask contains 0 bits are masked out. In other words the colors and alpha values are set to 0.

In accordance with an exemplary embodiment of the present invention a compact representation of a binary volume is rendered. This enables binary volumes to be rendered directly from their native representation thereby reducing the amount of GPU memory needed for rendering large volume datasets. In addition a binary segmentation mask can be applied to original volume data during rendering of a compact representation of the mask. Thus the binary segmentation mask can be separated from the original volume data. Accordingly artifacts that result from burning the segmentation mask into the original volume data can be prevented.

It is to be understood that because some of the constituent system components and method steps depicted in the accompanying figures may be implemented in software the actual connections between the system components or the process steps may differ depending on the manner in which the present invention is programmed. Given the teachings of the present invention provided herein one of ordinary skill in the art will be able to contemplate these and similar implementations or configurations of the present invention. For example although steps have been shown in sequence step could take place before steps or it could take place after step or .

It is to be further understood that the present invention may be implemented in various forms of hardware software firmware special purpose processors or a combination thereof. In one embodiment the present invention may be implemented in software as an application program tangibly embodied on a program storage device e.g. magnetic floppy disk RAM CD ROM DVD ROM and flash memory . The application program may be uploaded to and executed by a machine comprising any suitable architecture.

It should also be understood that the above description is only representative of illustrative embodiments. For the convenience of the reader the above description has focused on a representative sample of possible embodiments a sample that is illustrative of the principles of the invention. The description has not attempted to exhaustively enumerate all possible variations. That alternative embodiments may not have been presented for a specific portion of the invention or that further undescribed alternatives may be available for a portion is not to be considered a disclaimer of those alternate embodiments. Other applications and embodiments can be straightforwardly implemented without departing from the spirit and scope of the present invention.

It is therefore intended that the invention not be limited to the specifically described embodiments because numerous permutations and combinations of the above and implementations involving non inventive substitutions for the above can be created but the invention is to be defined in accordance with the claims that follow. It can be appreciated that many of those undescribed embodiments are within the literal scope of the following claims and that others are equivalent.

