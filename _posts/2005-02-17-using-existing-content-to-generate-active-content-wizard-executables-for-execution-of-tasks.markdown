---

title: Using existing content to generate active content wizard executables for execution of tasks
abstract: A computer implemented method of converting existing content files into an active content wizard executable file is provided, along with systems and tools for doing the same. In the method, an existing content file is converted into a corresponding file in an active content wizard schema. A database of user interface elements corresponding to user interface elements found in one or more windows of an application program to which the existing content file corresponds is accessed in order to retrieve information relating to user interface elements referenced in the corresponding file in the active content wizard schema. Then, an active content wizard file is created from the corresponding file in the active content wizard schema and the retrieved information relating to user interface elements.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07587668&OS=07587668&RS=07587668
owner: Microft Corporation
number: 07587668
owner_city: Redmond
owner_country: US
publication_date: 20050217
---
Reference is hereby made to the following co pending and commonly assigned patent applications U.S. application Ser. No. 10 337 745 filed Jan. 7 2003 entitled ACTIVE CONTENT WIZARD EXECUTION OF TASKS AND STRUCTURED CONTENT which was published on Jul. 8 2004 as Publication No. US 2004 0130572 A1 U.S. application Ser. No. 10 887 058 filed Jul. 8 2004 entitled AUTOMATIC TEXT GENERATION which was published on Feb. 10 2005 as Publication No. US 2005 0033713 A1 U.S. application Ser. No. 10 940 479 filed Sep. 14 2004 entitled ACTIVE CONTENT WIZARD TESTING U.S. application Ser. No. 10 887 543 filed Jul. 8 2004 entitled IMPORTATION OF AUTOMATICALLY GENERATED CONTENT which was published on Dec. 16 2004 as Publication No. US 2004 0255270 A1 U.S. application Ser. No. 10 887 414 filed Jul. 8 2004 entitled AUTOMATIC IMAGE CAPTURE FOR GENERATING CONTENT which was published on Dec. 9 2004 as Publication No. US 2004 0250214 A1 U.S. application Ser. No. 11 059 737 filed Feb. 17 2005 entitled DISCOVERABILITY OF TASKS USING ACTIVE CONTENT WIZARDS AND HELP FILES THE WHAT CAN I DO NOW FEATURE all of which are hereby incorporated by reference in their entirety.

The present invention relates to generating content such as help content. More specifically the present invention relates to methods of using existing content such as help files to generate Active Content Wizard ACW executable files.

The Graphical User Interface GUI is a widely used interface mechanism. GUI s are very good for positioning tasks e.g. resizing a rectangle visual modifier tasks e.g. making something an indescribable shade of blue or selection tasks e.g. this is the one of a hundred pictures I want rotated . The GUI is also good for speedy access to quick single step features. An application s GUI is a useful toolbox that is organized from a functional perspective e.g. organized into menus toolbars etc rather than a task oriented perspective e.g. organized by higher level tasks that users want to do such as make my computer secure against hackers .

However GUIs present many problems to the user as well. Using the toolbox analogy a user has difficulty finding the tools in the box or figuring out how to use the tools to complete a task composed of multiple steps. An interface described by single words tiny buttons and tabs forced into an opaque hierarchy does not lend itself to the way people think about their tasks. The GUI requires the user to decompose the tasks in order to determine what elements are necessary to accomplish the task. This requirement leads to complexity. Aside from complexity it takes time to assemble GUI elements i.e. menu clicks dialog clicks etc . This can be inefficient and time consuming even for expert users.

One existing mechanism for addressing GUI problems is a written help procedure. Help procedures often take the form of Help documents PSS Product support services KB Knowledge base articles and newsgroup posts which fill the gap between customer needs and GUI problems. They are analogous to the manual that comes with the toolbox and have many benefits. These benefits include by way of example 

However Help documents PSS KB articles and newsgroups have their own set of problems. These problems include by way of example 

5 For a user it is simply difficult to read step by step text and then visually search the UI for the element being described and take the action described with respect to that element.

Another existing mechanism for addressing GUI problems is a Wizard. Wizards were created to address the weaknesses of GUI and written help procedures. There are now thousands of wizards and these wizards can be found in almost every software product that is manufactured. This is because wizards solve a real need currently not addressed by existing text based help and assistance. They allow users to access functionality in a task oriented way and can assemble the GUI or tools automatically. Wizards allow a program manager and developer a means for addressing customer tasks. They are like the expert in the box stepping the user through the necessary steps for task success. Some wizards help customers setup a system e.g. Setup Wizards some wizards include content with features and help customers create content e.g. Newsletter Wizards or PowerPoint s AutoContent Wizard and some wizards help customers diagnose and solve problems e.g. Troubleshooters .

However wizards too have their own set problems. Some of these problems include there are many more tasks that people try to accomplish than there are wizards for accomplishing them. Wizards and IUI Inductive User Interfaces do not teach customers how to use underlying GUI and often when the Wizard is completed users are unsure of where to go next. The cost of authoring of wizards is still high and requires personnel with technical expertise e.g. software developers to author the Wizard.

Further all of these types of content suffer from yet another problem. The steps that must be taken to perform any given task may change based on the configuration of the computer on which the task is to be performed. For instance changing the background display or wallpaper on a computer may require the user to perform different steps depending on the operating system of the user s computer. In fact the steps required may even be different if the version number of the operating system is different. Similarly the steps may be different depending on the network configuration of the computer e.g. depending on whether the computer is on a network domain or on a workgroup . This requires the user to author fairly complicated branching logic in the written content.

Thus authoring all of these types of content that describe procedures to be taken by a user is often error prone. It is quite easy to miss steps to describe steps incorrectly or to lose track of what step is currently being described in a long sequence of UI manipulations. However this written procedural help content is extremely common. Such help content often ships with products on line help content is provided for product support teams and procedures inside companies are often documented in this way for specific business processes. Thus this type of information is difficult to author and often contains errors.

In addition end users must typically follow the steps that have been authored. It can be difficult to read step by step text and then search the UI for the particular control element being described and then to take the proper action with respect to that control element. It has been found that many users find this such a burden that they simply scan the first one or two steps of the text and then try their best to determine which UI elements need to be actuated next barely referring back to the written text steps. It has also been found that the eye can find and recognize pictures much more easily than it can read a word mentally convert the word into a picture and then find the corresponding UI control element. Yet in the past this is exactly what was done as an author must painstakingly take screenshots of each step crop the images and paste them into a document in the right place in order to have any type of visual depiction of an action to be taken.

Active Content Wizards ACW s address these issues by allowing authors to generate specific steps and descriptions thereof with relative ease. Authors simply interact with a user interface while a recording component records the author s actions. This allows ACW s to be easily created for a vast array of situations. ACW s generally include code in one form or another to interact with the user interface to essentially play a help topic for a user directly to the user interface. Thus while an ACW is interacting with the user interface the ACW will also provide a description to the user regarding the interaction. During playback the ACW may allow the user to interact with the user interface to enter specific information such as a filename etc.

As noted GUI applications today often ship with a number of procedural Help topics that let the user know how to perform a task using the GUI. Given the vast array of tasks that a user may need help with there are large numbers of procedural Help files or documents PSS KB articles and the like which have been written to aid users of software programs. Many of these would be very good candidates for ACW s. However it would not be economical to re write those topics as ACW s especially if there are thousands of them like in Windows or Office.

The present invention provides solutions to one or more of the above described problems and or provides other advantages over the prior art.

A computer implemented method of converting existing content files into an active content wizard executable file is provided along with systems and tools for doing the same. In the method an existing content file is converted into an existing content file in an active content wizard schema. A database of user interface elements corresponding to user interface elements found in one or more windows of an application program to which the existing content file corresponds is accessed in order to retrieve information relating to user interface elements referenced in the existing content file in the active content wizard schema. Then an active content wizard file is created from the existing content file in the active content wizard schema and the retrieved information relating to user interface elements.

Other features and benefits that characterize embodiments of the present invention will be apparent upon reading the following detailed description and review of the associated drawings.

The present invention includes methods of and a set of tools for converting existing procedural help topics KB articles and similar content documents into Active Content Wizard ACW scripts. Prior to describing the present invention in greater detail one exemplary environment in which the invention can be used will be discussed.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media. Computer storage media includes both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer .

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard a microphone and a pointing device such as a mouse trackball or touch pad. Other input devices not shown may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a hand held device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

An example of ACW formats generation methods and execution methods can be found in the previously referenced United States Patent Application entitled Active Content Wizard Execution of Tasks and Structured Content which was published on Jul. 8 2004 as Publication No. US 2004 0130572 A1. For purposes of better understanding ACW s and ACW authoring a description of an ACW authoring system is provided with reference to .

User Interface is in one embodiment a conventional graphical user interface with controls that allow a user to take actions to perform a task. The user interface is illustratively displayed on display device shown in . This type of graphical user interface GUI is a widely used interface mechanism.

Recording component is in one embodiment an application program that allows the author or another user to perform a task on the user interface and records the tasks by capturing images of each step in the task. As is described in more detail below while the author is performing the steps associated with the task on the user interface the recording component records information about what controls and windows the author interacts with on the user interface . This information is optionally provided to the text generator to automatically generate the text in a document such as a help document. Manual generation of the text by the user can also be employed.

The recording component interacts with the user interface through the hook and the user interface UI automation component . These components can be separate from the recording component or in some embodiments these components can be integral with the recording component .

The hook component is in one embodiment a module or component within an operating system that is used by the computer. When a hook is set for mouse clicks for example information indicative of the mouse click such as a message is forwarded to the hook component where it is consumed and after its associated control identifying information and images have been recorded by the recording component it is played back for other components in the computer that have registered to receive mouse clicks. Therefore generally the hook component acts as a buffer between the operating system and the target application. The hook component can be configured to look for substantially any input action such as the type of signal received e.g. single click double click right or left click keyboard action touch sensitive screen input etc. Once the information representing the action and screen shot image indicative of the action is recorded by the recording component the information representing the mouse click or whatever action recorded is then played back by the hook component to the application. One reason for this is that the user may take a second action before the first action is recorded. The second action may well cause the state of the user interface to change and thus result in improper recording of the first action. For example if the action being recorded is clicking a menu item the click will make the menu item disappear. Therefore the image is captured before the mouse click is passed to the application. By consuming the first mouse message and playing it back once recording is complete this ensures that the first action will be recorded properly.

It should also be noted that the functions performed by the hook component i.e. listening for mouse clicks and playing them back are illustratively performed on separate threads. This ensures that all user interface actions e.g. mouse clicks keyboard actions etc. will be properly recorded and played back without missing any. Further the record and playback mechanism of hook component can override any timeout features that are implicit within the operating system. This can be necessary if the timeout period of the operating system is too short to allow for proper recording of the action and capturing of the image indicative of the action. For instance capturing an image may take 300 400 ms or so and even up to a second if the entire desktop is being captured. Thus overriding the timeout and operating on multiple threads are helpful.

User interface automation component is illustratively a computer program configured to interpret the atomic steps for the overall task performed by the author or user through the user interface . In one embodiment user interface automation component is a GUI automation module implemented using Microsoft User Interface Automation by Microsoft Corporation of Redmond Wash. This module provides a programmatic way to access information about the visible user interface and to programmatically interact with the visible user interface. However depending on the system setup the user interface automation component can be implemented using any application that is able to programmatically navigate a graphical user interface and to detect and optionally programmatically navigate the GUI to perform and execute commands on the user interface.

User interface automation component thus detects each of the steps associated with the desired task performed on the user interface by author or another user in task order. For instance when the task requires the user to click a button on the GUI to display a new menu or window user interface automation component determines which control is located at the position of the mouse cursor on user interface and its size and its parent window. The recording component uses information from hook component e.g. the type name and state of the control to record the name and properties of the control that was used to perform the step. This information is provided from the user interface automation component and hook component to the recording component such that the recording component can record the control identifying information and image of the button or the control that was used by the author to perform the step. Obtaining the image is described in greater detail below with respect to .

Text generation component is a program or module configured to generate natural language text that describes the actions executed or performed during the recording process. The text generation component uses the recorded images and other information recorded by the recording component to search database and to choose a correct template or entry from the text database that corresponds to the recorded step.

Text database is illustratively a database or other information storage system that is searchable by the text generator . Text database contains information related to the controls that are available on the user interface . This information can include for example the name of the control the type of control the action performed on the control and a textual description of the action as a natural language sentence.

In some embodiments the textual description for the entry is provided in multiple languages. When the textual description is provided in multiple languages a language identifier is provided with each entry that allows the correct language to be selected.

However depending on the needs of the system other information can be provided in the text database . In one embodiment some entries in the text database have information related to two or more actions exemplified by multiple controls that are performed in sequence. Where multiple actions on multiple controls are represented by a single entry in the text database the text for the entry contains natural language descriptions of the action performed on both controls as a single sentence. By combining the description of the two commands as a single sentence the readability of the final text document is improved.

In one embodiment the text database is written in Extensible Markup Language XML . The data for each entry can be stored as a series of subentries where each subentry of the entry refers to an individual piece of information that is needed to identify the task. However other formats can be used for storing the data.

In one embodiment the text generation component looks at two or more of the recorded actions when searching for entries in the text database . This can be done in order to provide a more fluid text document. For instance good procedural documentation often combines more than one step into a single sentence as an enhancement to readability. If the text generation component identifies two or more that match the recorded information in the text database the text generation component can use any known method to determine which entry in the database to choose such as by disambiguating the entries based on scoring each entry and selecting the entry that has the highest score.

According to one embodiment based on the type of the control actuated on the user interface and the performed action the text generation component searches the text database for an entry that matches the executed control type and action. Once a match is identified in the text database the text generation component obtains the associated natural language description of the action from the text database and places it as a sentence instruction in the generated text document . In an alternative embodiment the text generation component can also generate an executable version of the text document based on the information provided by the UI automation module .

When choosing a textual description from the text database the text generation component can also look to the state of the control. This is important when the control is a checkbox or an expandable or collapsible tree. In this case merely clicking on the box may not be appropriate to describe the action as the action on the control is the same regardless of the desired result. Therefore in these cases the new state of the control will influence the selected text. For example if the control is a check box and it is to be deselected the text matched would be based on the new state of the control plus the control s name.

Text editor is an editor configured to correct change or add information or text to the automatically generated text . Depending on the resultant text generated by text generator and the actions performed by the author it may be necessary to edit the text to further enhance its understandability. Therefore text editor receives the generated text and allows the author to edit the generated text.

Text editing may be required for example because of a grammatical necessity or because one of the recorded steps required a user action and the system did not request the description of the user action at the time it was recorded. In such a case when a user input is required while performing the task to be recorded according to one embodiment the text generator only provides a space in the text for the author to provide an instruction description of what the user should do at this step.

For example assume that the task being performed by the user and recorded by the recording component is to change the background paneling on the computers screen. This requires the user to choose a pattern for the background. Therefore the text that is returned by the text database for a recorded user action to change the background can be Please select insert description of action where the author will have to edit the text to read Please select the desired background from the list. Also during the editing stage the author can provide a description of the overall task if this was not provided prior to recording the task. Once the text has been edited the final text is output from the authoring tool and is stored in an appropriate storage mode that allows for the final text to be retrieved by a user when desired.

Referring again to once author has started recording component the system simply waits for a user to take an action on user interface . It will be noted that shows that the user is author but the user could be a different user as well.

Once the user has taken an action on user interface such as by manipulating a control element on the user interface hook component receives a message or other signal indicative of the user action. As discussed above with respect to hook component hook component consumes the message and places it on a queue for recording. The user taking an action on UI is indicated by block in .

Recording component then receives control identifying information from UI automation component . This is indicated by block in . In one illustrative embodiment UI automation component provides recording component with a number of items of information that allow recording component to record the control identifier on the display screen which represents or corresponds to the action taken by the user at user interface . In one illustrative embodiment these items of information are the position of the control element on the display screen that the user has actuated or otherwise manipulated the bounding rectangle or size of that control element and the parent window that contains the control element. In exemplary embodiments the image of the control is not used in playback. It is only recorded to make it understandable by authors.

Recording component then obtains actual image information indicative of the screen shots associated with the user interface and corresponding to or reflecting the action taken by the user. This is indicated by block in .

In order to perform this step recording component can do a number of things in order to enhance the operation of the system. For instance recording component may determine that it would be helpful to record actual image information or the actual screen shot of more than just the control element manipulated by the user. This may be true for example if there is more than one similar control element currently on the display being manipulated by the user. Assume for instance that the user has clicked an OK button on the user interface. However there may be more than one OK button on the display screen at that time. Therefore in order to disambiguate among the various OK buttons recording component may obtain the actual screen shot information for not only the particular OK button manipulated by the user but for a desired number of pixels around that OK button . This provides an image with greater context than simply an image of the control itself.

Similarly recording component may also record the screen shot image of the entire parent window that contains the control element. Of course this contains a great deal of extra context which can be used to specifically identify the control element that the user has manipulated.

In order to determine whether additional context needs to be recorded by recording component recording component can make this determination using any of a wide variety of different techniques. For instance recording component can deploy heuristics that will identify an amount of context for recording. The heuristics may be based on the size and shape of the control element manipulated the particular function of the control element manipulated the type of control element e.g. checkbox textbox treeview the position of the control element on the screen for instance if the control element is in the upper left hand corner recording component may take more pixels on the lower and right hand sides of the control element or the heuristic can simply reflect a fixed number of pixels which are to be taken around the control element regardless of where it is located and what functions are performed by the control element.

Recording component can obtain the actual screen shot image information using any known technique. For example in most operating systems there are published application programming interfaces APIs that allow an application or other computing component to obtain a bitmap screen shot of any section of the screen as currently being displayed. Therefore in one illustrative embodiment recording component simply makes an API call to obtain the information once it knows the coordinates of the screenshot image information it desires and the amount of context information and optionally the parent window of the control element.

Having obtained the control identifying information recording component records it for later use. Depending on how it will be used recording component may compress or resize the image using standard image manipulation APIs. This reduces the memory required and the size of the final document. This is indicated by block in . Of course it will also be noted at this point that recording component can record other information provided by UI automation component . For instance UI automation component illustratively provides recording component with the control name the control type the action performed on the control the type of manipulation performed such as mouse click mouse wheel rotation keyboard keystrokes touch pad input etc. . This information can all be recorded by recording component .

In accordance with one example embodiment text generation component in conjunction with text database automatically generates text associated with the images and control identifying information captured and associated with the action taken by the user on user interface . In the embodiment in which these items are used recording component sends the information captured such as click type control type control name etc. to text generation component . This is indicated by optional block in . The automatically generated text illustratively provides a written procedure which corresponds to step by step instructions for each user manipulation of user interface in order to perform an overall task that requires multiple manipulations of user interface .

In order to generate this text text generation component can use any suitable method. In one illustrative method text generation component searches text data store for entries that correspond to the information received from recording component . For instance text data store may illustratively be an XML database containing a plurality of entries that include the type of control or other item manipulated by the user on user interface the type of action and a text corresponding to that action. Of course other data storage methods can be used to implement data store and data store can contain additional or different information as well.

For example assume that the information received from the recording component indicates that the user has clicked on or otherwise invoked an OK button . Then text generation component searches text data store for an entry that matches this type of action. Once a match is found text generation component retrieves the text from that entry in text data store that describes that type of action. The text may for instance simply say click OK .

In any case text generation component illustratively and optionally automatically generates text describing the user action taken on user interface and recorded by recording component . This is indicated by block in .

The generated text is indicated by block in . In one illustrative embodiment the images recorded by recording component are automatically embedded in the generated text or are at least associated with the generated text such that they can be recalled and displayed in conjunction with one another later in the process.

Next the image data recorded by recording component and the optional automatically generated text is provided to editor component . The images recorded by recording component and automatically generated text are illustratively displayed on a display screen at editor such that author can generate text corresponding to those images. Displaying of the images and optionally the text generated by generation component is indicated by block in .

Once displayed the author can then enter text or modify text as desired in order to obtain a full description of the step performed by the user at user interface . Modifying or generating text corresponding to the images using text editor is indicated by block in . The final text with embedded images is then saved as is indicated by the optional block in . However it is not necessary in all embodiments that images be embedded in text. For example the authoring system can simply be used to display the captured images to an author where the author is generating a written description of the steps taken and for which images are captured.

As discussed previously given the thousands of pre existing help files or documents PSS KB articles and other help content which are available it is labor intensive to use the above described methods to author corresponding ACW s for each of them individually. The methods systems and tools of the present invention provide mechanisms for converting these thousands of pre existing help content files or documents into ACW s. In some cases the conversion can result in an ACW that completely and accurately reflects the steps or instructions of the corresponding original help content file. In other cases the conversion results in an ACW that is substantially complete and accurate which with the use of the previously described authoring tools can be edited to complete the process. For example if the present invention provides 80 accuracy in the conversion process the resulting ACW can be edited to achieve complete accuracy in far less time than might be required to author the same ACW from scratch.

Referring now to shown is a method which creates ACW S from existing content files. illustrates a system which can be used to implement the method or which can other wise be used to perform some or all of the ACW creating process. First as shown at block of the method includes the step of converting existing content files in into an ACW Schema format in . This can be done with a conversion component which performs the conversion in one or more steps using maps style sheets and or other techniques.

In some embodiments Active Content Wizards are stored in an XML format such as the XML format which is a part of the Microsoft Assistance markup language MAML . Other XML formats can also be used for the ACW schema. Since many help files and other similar content are created using HTML or XML formats this step can include converting the existing content files from an HTML schema to an ACW XML schema or from a non ACW XML schema to an ACW XML schema. Even if the legacy help content files are in other formats it is usually very easy to convert them to an HTML format first as part of a multi step conversion process.

If the existing content format is XML then the conversion step s can use an XSLT style sheet or a map or program can be defined to transform the content. The style sheet depends on the XML schema used by the source application.

If the existing format is HTML it is harder to write a transform as HTML is a style based format and does not provide schematic information that is required in the MAML format. However a number of heuristics can be used to aid in the transformation. Though these heuristics are dependent of the format of the content they tend to work reasonably well in the case of Microsoft Windows Microsoft Office HTML help they work to 85 90 accuracy as the Help content tends to be very well structured. For most applications the Help content is written using a rigid style guideline. For example in both Windows and Office Help a numbered list correlates to a procedural Help topic. An example of some of the heuristics that can be used in the transformation process for Windows and Office Help include 

An example of a multi step conversion of an HTML content file to an ACW XML schema or format is provided as follows 

Referring back for the moment to shown at block is the step of recording UIs of application s in order to create a UI elements file or database. To implement this step a window recorder tool shown in is used. Window recorder functions similarly to task recorder shown in except that it uses the same methods and functionality to record every element of a Window of UI . The user of window recorder can open every relevant dialog box window in a particular application and run the window recorder on that window. The window recorder allows the user to select a part of the window or the whole one. As will be illustrated in greater detail below the window recorder tool stores information about all the elements found on the window in a file or database . In addition to the properties needed for playback the window recorder tool also captures the image of each element.

In one example embodiment illustrated in window recorder includes a Start Stop button used to start or stop the recording process. The recording process is started for example by defining a window on the UI to record. A Zap button is also included which when clicked upon begins the process of recording UI elements and their properties in the window established by the user. This is illustrated in greater detail below. To stop the recording process Start Stop button is again clicked. To clear the contents of the window recorder memory Clear button is included. To save the information recorded from a window Save button is clicked.

Referring now to the screen shots of use of the windows recorder tool to record entire windows is shown. In a control panel UI is shown along with recorder tool . Once the Start Stop button is clicked as the user moves the pointer using an input device such as a mouse a rectangle is drawn on the screen as shown in . The rectangle corresponds to a window in which the cursor is positioned. In the illustrated example the window corresponds to the listed UI element and other contents of the Control Panel.

Once window is defined the user clicks on Zap key or presses one or more defined hot keys such as and recorder records every element in that particular window . In recording every element of the window recorder also extracts the properties of interest of every element of that window along with the image or graphic for that element.

Referring next to shown is a recorded or zapped window which is displayed showing the user the text of every element recorded from window . The contents of window can be saved using button . This process takes little time and is repeated for each relevant window of an application storing all of the controls in a file or database .

Referring back to shown at block in is a final step of creating ACW scripts from the converted files step and from the UI elements file or database created in step . This adds the properties that are required by the runtime engine to playback the script. Using the converted scripts and all the relevant UI elements from file or database from the application recorded using the window recorder tool a third tool combines this information to create the ACW script . This is illustrated as ACW script generator in . This tool opens each converted script serially. Then for each actionRef element in the converted scripts i.e. the action text menu element pair it looks for a corresponding match in the file database . In cases where there is more than one match the tool shows the user the images of the corresponding matches and lets the author specify the correct one. The converted ACW scripts can then be tested to confirm the conversion and edited by the author as needed.

Although the present invention has been described with reference to particular embodiments workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention.

