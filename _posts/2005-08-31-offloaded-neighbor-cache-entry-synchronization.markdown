---

title: Offloaded neighbor cache entry synchronization
abstract: A method for the synchronization of network neighbor reachability between a host networking stack and a peripheral device, which offloads one or more network protocols is provided. The network neighbor reachability represents the reachability of another computer on the network. This invention enables conventional neighbor reachability to be extended to seamlessly support some network connections to a specific remote host to be offloaded to a peripheral device, while other network connections are not.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07886083&OS=07886083&RS=07886083
owner: Microsoft Corporation
number: 07886083
owner_city: Redmond
owner_country: US
publication_date: 20050831
---
The present invention relates generally to protocol offloading and more particularly to synchronization of offloaded protocol state.

An invention described in commonly assigned United States Patent Publication 2003 0204634 provides a method to offload a communication protocol stack such as a transmission control protocol TCP based protocol stack. Data that would normally be sent through a host NDIS network driver interface specification path that has multiple software layers to a network interface is offloaded to a path that includes a switch layer and an offload target. The offload target is conventionally a peripheral device that includes a second processor that processes the offloaded network stack connection in hardware software or a combination of both. Tight synchronization with the host network stack and processing unit is required. A request to offload the stack is sent through the NDIS path to the offload target. The request includes a list of resource requirements so that the offload target has the information needed to allocate resources. Each layer in the NDIS path adds its resource requirements to the list. If the offload target accepts the request the offload target allocates resources and sends an offload handle to each of the software layers so that the software layers can communicate with the offload target.

Once the offload target s acceptance of the offload is communicated to the software layer the state for each software layer is sent to the offload target. Alternatively the state may be sent with the offload request with only changes to the state later sent to the offload target. Each state has state variables and each state variable may be classified as a constant variable a cached variable or a delegated variable. The constant variables do not change during the time the protocol stack is offloaded. Cached variables are managed by the CPU and updated in the offload target if they change. Delegated variables are handled by the offload target.

However because the protocol stack is offloaded to the offload target for only specific connections the host protocol stack and the offload target may communicate with neighbor peers without the other knowing about it. This means that the host protocol stack might improperly invalidate a neighbor cache entry because there had been no forward progress in the host protocol stack. It might be the case that there has been forward progress on the offloaded connection making the invalidation of the neighbor cache entry improper.

This section presents a simplified summary of some embodiments of the invention. This summary is not an extensive overview of the invention. It is not intended to identify key critical elements of the invention or to delineate the scope of the invention. Its sole purpose is to present some embodiments of the invention in a simplified form as a prelude to the more detailed description that is presented later.

In view of the foregoing the present invention provides for synchronization of network neighbor cache entry state such as reachability between a host networking stack and a peripheral device which offloads one or more network protocols. Network neighbor reachability represents the reachability of another computer on the network. This invention enables conventional neighbor reachability to be extended to seamlessly support offloading of some network connections to a peripheral device while other network connections are maintained by the host. The method may include determining a host reachability delta that is the time difference between a current host time and a time that neighbor reachability was last confirmed by the host. When the HRD exceeds a threshold the host stack may query the offload target for a device reachability delta that is the time difference between a current offload target time and a time that neighbor reachability was last confirmed by the offload target. The method may determine the state of the neighbor state object based on the DRD received from the offload target. With this method the neighbor reachability state of a neighbor on the network may be distributively maintained by the host networking stack and the offload target.

Turning to the drawings wherein like reference numerals refer to like elements the present invention is illustrated as being implemented in a suitable computing environment. The following description is based on embodiments of the invention and should not be taken as limiting the invention with regard to alternative embodiments that are not explicitly described herein.

An example of a networked environment in which the invention may be used will now be described with reference to . The example network includes several computers communicating with one another over a network represented by a cloud. Network may include many well known components such as routers gateways hubs etc. and allows the computers to communicate via wired and or wireless media. When interacting with one another over the network one or more of the computers may act as clients network servers quarantine servers peers or other types of computers with respect to other computers. Accordingly the various embodiments of the invention may be practiced on clients network servers quarantine servers peers other types of computers or combinations thereof even though specific examples contained herein do not refer to all of these types of computers.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics mobile phones network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer which may act as a client network server quarantine server peer or other types of computers within the context of the invention. Components of the computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture bus Micro Channel Architecture bus Enhanced ISA bus Video Electronics Standards Associate local bus and Peripheral Component Interconnect bus.

The computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computer and include both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may include computer storage media and communication media. Computer storage media include both volatile and nonvolatile removable and non removable media implemented in any method or technology for the storage of information such as computer readable instructions data structures program modules or other data. Computer storage media include but are not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer . Communication media typically embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is typically stored in ROM . RAM typically contains data and program modules that are immediately accessible to or presently being operated on by the processing unit . By way of example and not limitation illustrates an operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary computing environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as the interface and the magnetic disk drive and the optical disk drive are typically connected to the system bus by a removable memory interface such as the interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example the hard disk drive is illustrated as storing an operating system application programs other program modules and program data . Note that these components can either be the same as or different from the operating system application programs other program modules and program data . The operating system application programs other program modules and program data are given different numbers to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard and a pointing device commonly referred to as a mouse trackball or touch pad. Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus. A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor the computer may also include other peripheral output devices such as speakers and a printer which may be connected through an output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the personal computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks such as wireless networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the personal computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device . By way of example and not limitation illustrates the remote application programs as residing on the memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

In the description that follows the present invention is described with reference to acts and symbolic representations of operations that are performed by one or more computing devices unless indicated otherwise. As such it will be understood that such acts and operations which are at times referred to as being computer executed include the manipulation by the processing unit of the computing device of electrical signals representing data in a structured form. This manipulation transforms the data or maintains them at locations in the memory system of the computing device which reconfigures or otherwise alters the operation of the device in a manner well understood by those skilled in the art. The data structures where data are maintained are physical locations of the memory that have particular properties defined by the format of the data. However while the invention is being described in the foregoing context it is not meant to be limiting as those of skill in the art will appreciate that various of the acts and operations described hereinafter may also be implemented in hardware.

In an embodiment of the invention a mechanism is provided for synchronizing the neighbor cache entry states of a host stack and an offloaded target such as a network interface card NIC with associated device drivers. The network interface may include the NIC and associated device drivers. Helpful context and details with respect to neighbor cache entries NCEs as described in Narten et al. Neighbor Discovery for IP Version 6 IPv6 Request for Comments RFC 2461 promulgated by the Internet Engineering Task Force IETF in December 1998 are described below.

Communication to or through a neighbor may fail for numerous reasons at any time including hardware failure hot swap of an interface card etc. If the destination has failed no recovery is possible and communication fails. On the other hand if it is the communications path that has failed recovery may be possible. Thus a node actively tracks the reachability state for the neighbors to which it is sending packets. By way of example and not limitation the description of the invention uses examples of how states are maintained using IPv6. Those of ordinary skill in the art will understand that the examples may be mapped to examples using IPv4. For example the Neighbor Solicitation message roughly maps to the ARP Request message and the Neighbor Advertisement message roughly maps to the ARP Reply message.

A neighbor is considered reachable if the node has recently received a confirmation that packets sent recently to the neighbor were received by its IP layer. Positive confirmation can be gathered in two ways hints from upper layer protocols that indicate a connection is making forward progress or receipt of a Neighbor Advertisement message that is a response to a Neighbor Solicitation message. A connection makes forward progress if the packets received from a remote peer can only be arriving if recent packets sent to that peer are actually reaching it. In a transmission control protocol TCP for example receipt of an acknowledgement which advances the left hand side of the TCP window indicates that previously sent data reached the peer. Likewise the arrival of new non duplicate data indicates that earlier acknowledgements are being delivered to the remote peer. If packets are reaching the peer they must also be reaching the sender s next hop neighbor thus forward progress is a confirmation that the next hop neighbor is reachable.

In some cases e.g. user datagram protocol or UDP based protocols and routers forwarding packets to hosts such reachability information may not be readily available from upper layer protocols. When no hints are available and a node is sending packets to a neighbor the node actively probes the neighbor using unicast as opposed to broadcast Neighbor Solicitation messages to verify that the forward path is still working.

INCOMPLETE Address resolution is being performed on the entry. Specifically a Neighbor Solicitation has been sent to the solicited node multicast address of the target but the corresponding Neighbor Advertisement has not yet been received.

REACHABLE Positive confirmation was received within the last ReachableTime that the forward path to the neighbor was functioning properly. While REACHABLE no special action takes place as packets are sent.

STALE More than ReachableTime have elapsed since the last positive confirmation was received that the forward path was functioning properly. While stale no action takes place until a packet is sent. The STALE state is entered upon receiving an unsolicited Neighbor Discovery message that updates the cached link layer address. Receipt of such a message does not confirm reachability and entering the STALE state insures reachability is verified quickly if the entry is actually being used. However reachability is not actually verified until the entry is actually used.

DELAY More than ReachableTime have elapsed since the last positive confirmation was received that the forward path was functioning properly and a packet was sent within the last DELAY FIRST PROBE TIME seconds. If no reachability confirmation is received within DELAY FIRST PROBE TIME seconds of entering the DELAY state send a Neighbor Solicitation and change the state to PROBE. The DELAY state is an optimization that gives upper layer protocols additional time to provide reachability confirmation in those cases where ReachableTime have passed since the last confirmation due to lack of recent traffic. Without this optimization the opening of a TCP connection after a traffic lull would initiate probes even though the subsequent three way handshake would provide a reachability confirmation almost immediately.

PROBE A reachability confirmation is actively sought by retransmitting Neighbor Solicitations every RetransTimer until a reachability confirmation is received.

Neighbor Unreachability Detection operates in parallel with the sending of packets to a neighbor. While reasserting a neighbor s reachability a node continues sending packets to that neighbor using the cached link layer address. If no traffic is sent to a neighbor no probes are sent. When a node needs to perform address resolution on a neighboring address for the first time after a time out it creates an entry in the INCOMPLETE state and initiates address resolution. If address resolution fails the entry should be deleted so that subsequent traffic to that neighbor invokes the next hop determination procedure again. Invoking next hop determination at this point insures that alternate default routers are tried.

When a reachability confirmation is received either through upper layer advice or a solicited Neighbor Advertisement an entry s state changes to REACHABLE. When a ReachableTime period has passed since receipt of the last reachability confirmation for a neighbor the Neighbor Cache entry s state changes from REACHABLE to STALE. The first time a node sends a packet to a neighbor whose entry is STALE the sender changes the state to DELAY and a sets a timer to expire in DELAY FIRST PROBE TIME seconds. If the entry is still in the DELAY state when the timer expires the entry s state changes to PROBE. If reachability confirmation is received the entry s state changes to REACHABLE.

Upon entering the PROBE state a node sends a unicast Neighbor Solicitation message to the neighbor using the cached link layer address. While in the PROBE state a node retransmits Neighbor Solicitation messages after every RetransTimer period until reachability confirmation is obtained. Probes are retransmitted even if no additional packets are sent to the neighbor. If no response is received after waiting the RetransTimer period after sending the MAX UNICAST SOLICIT solicitations retransmissions cease and the entry should be deleted. Subsequent traffic to that neighbor will recreate the entry and performs address resolution again.

A Neighbor Cache entry enters the STALE state when created as a result of receiving packets other than solicited Neighbor Advertisements i.e. Router Solicitations Router Advertisements Redirects and Neighbor Solicitations . These packets contain the link layer address of either the sender or in the case of Redirect the redirection target. However receipt of these link layer addresses does not confirm reachability of the forward direction path to that node. Placing a newly created Neighbor Cache entry for which the link layer address is known in the STALE state provides assurance that path failures are detected quickly. In addition should a cached link layer address be modified due to receiving one of the above messages the state should also be set to STALE to provide prompt verification that the path to the new link layer address is working.

When for example a TCP connection is offloaded the state maintenance of the Neighbor Cache entry is distributed between the host stack and the offload target. Salient details of TCP chimney offload an example of a suitable offload technique are described below with reference to .

Switch is used to offload the processing unit from performing network stack operations for the intermediate software layer s . While the switch is shown separately it should be noted that the switch may be integrated into the top intermediate layer of the network stack . Data is sent to the offload target via chimney for the offload target to perform network stack operations. In this hierarchy the intermediate software layers do not have to exclusively reside in the host or the offload target and it allows any of the intermediate layers to either be completely offloaded to remain in the host or a combination of both e.g. offload one or more specific connections . Additionally chimneys may be layered on top of chimneys e.g. an IPSEC chimney may be layered on top of a TCP chimney . A connection may be any combination of reliable and unreliable data transfer and unicast or multicast data transfer. If an intermediate layer remains in the host the host updates cached variables as described below in the offload target . For example a transport control block TCB state entry for a connection can be offloaded for the transport layer with a route cache entry RCE for the network layer offloaded to the offload target . The switch continues to send traffic for a different TCB through the network stack that shares the same RCE while the switch sends traffic through the chimney for the offloaded TCB.

The switch initiates the offload by sending the intermediate layer s an offload request. The offload request includes resource information that helps the offload target decide whether it can successfully offload the connection. Each intermediate layer either refuses the offload request or adds resource information to the offload request and sends the offload request to the adjacent software layer in the network stack . When the offload target receives the offload request it calculates whether it has resources available to offload the connection. The offload target refuses the offload request if the offload is not possible. Otherwise the offload target accepts the offload request and allocates resources for the connection. The offload target completes the offload request by sending a completion message having a linked list of parameters to the intermediate software layer s . The linked list of parameters provides information to the intermediate software layer s and switch to allow the intermediate software layer s and switch to communicate with the offload target. Each intermediate software layer removes information for its layer from the linked list of parameters.

When an intermediate layer receives the completion message for offloading the intermediate layer passes its state to the offload target . Each state may have three types of variables CONST CACHED and DELEGATED. A state may have all three types of variables or a subset of the three types of variables. CONST variables are constants that do not change during the life of the offloaded connection. They are not read back to the layers when the connection is uploaded. The host processing unit maintains ownership of CACHED variables and ensures that any changes to a CACHED variable in the host processing unit are updated in the offload target . Control messages that change the CACHED state are handled by the network stack . As a result the host will write but does not need to read back the CACHED variables when the connection is uploaded. The host processing unit transfers ownership of DELEGATED variables to the offload target . The DELEGATED variables are written once when the offload occurs and are read back when the offload is terminated. By only transferring back the DELEGATED variables the overhead of transferring the connection back to the host is minimized. State that must be shared e.g. controlled between the network stack and the offload target that for various performance reasons is being offloaded i.e. delegated is cleanly divided between the network stack and chimney e.g. IP address in TCP offloads such that both the network stack and offload target each owns an exclusive portion of the state. The host processing unit queries the offload target for DELEGATED variables when needed e.g. for statistics . The host processing unit may also query CONST or CACHED variables for diagnostics. Dividing the state into three categories enables the network stack to coexist cleanly with the chimney . It should be noted that the state may be included in the offload request. This can be done if either the state does not contain delegated state variables or contains delegated state variables that will not change between the initial offload request and the completion of the offload request.

Multiple connections may be off loaded by an intermediate software layer to the offload target . A reference counter is maintained by the intermediate software layer of the number of upper layer state objects i.e. state objects of layers above the intermediate software layer which reference the intermediate software layer s state object for offload. A state object as used herein is a collection of state variables for a particular layer that are categorized as CONST CACHED or DELEGATED as used herein. If an intermediate layer s offloaded state object has no references to it by a layer above it the intermediate layer may send a message to the offload target to upload the state object for the intermediate layer and send delegated state variables to the intermediate layer . The offload target packages the delegated state variables and passes them to the intermediate layer and then deletes the state object for the intermediate layer . The intermediate layer sends a completion message to the switch .

Turning now to details of the invention will be described by way of example and not limitation in an embodiment where the offload target is NIC the switch is a transport layer interface TLI switch and the network stack comprises a transport layer a network layer and a framing layer . Network layer is also known as a path layer and the framing layer is also known as a neighbor layer.

Networked messages are sent by the application through network stack to the NIC during operation. Data sent from the application travels through the TLI switch which controls whether the data goes down the host based network stack or the chimney . Note that the TLI switch may be incorporated into the transport layer . The software layers in the network stack receive data from the application package it in a packet form and send it to the offload target hardware via NDIS minidriver . Other tasks the network stack may perform as a data packet passes through the stack includes data encryption reliable data transmission and calculation of a message digest e.g. checksum or CRC for the data packet . Many of these tasks are performed by the processing unit and are processor intensive.

The TLI switch is used to offload the processing unit from performing stack operations by sending data for connections to the NIC via chimney and chimney driver . Those skilled in the art will recognize that the upper edge of NDIS minidriver and chimney driver may be the NDIS application programming interface API in a Microsoft Windows operating system.

Communications between computers has become a basic service underlying many applications. As a result performance has become significant and mechanisms such as communication protocol stack offloading provide performance enhancement. However the performance enhancement may be lost for example if synchronization between the host and offload target is inefficient. Accordingly some conventional object state synchronization systems and methods are suboptimal. Example steps for object state synchronization in accordance with an embodiment of the invention are described below with reference to and .

At step a request to send a communication packet e.g. a TCP IP packet may be received for example by the chimney driver of the sending host. In this example some or all of the protocol stack has been offloaded to an offload target such as the communication hardware . As a result communications object state associated with CACHED variables may diverge and synchronization is necessary. In this example in contrast with inefficient brute resynchronization or timer driven resynchronization synchronization is event driven and lazy that is unnecessary synchronization is deferred.

Although each embodiment of the invention is not so limited for clarity this example synchronizes a neighbor state object NSO associated with a neighbor cache entry NCE as well as one or more communication connections. Since the protocol stack has been offloaded in an embodiment of the invention versions of the neighbor state object are maintained by the host and the offload target. These versions are called the host neighbor state object HNSO and the device neighbor state object DNSO respectively. At step a lookup operation may be performed to determine and or obtain reference to the host neighbor state object associated with the communication connection over which the communication packet is to be sent.

Each version of the neighbor state object may maintain one or more of a host reachability time HRT a device reachability time DRT a host reachability delta HRD and a device reachability delta DRD . The host reachability time may correspond to a time at which the host last received information confirming that a destination associated with the communication connection was reachable. For example the host reachability time may be a timestamp corresponding to a TCP acknowledgement ACK packet received from the destination. The host reachability delta may be the difference between the host reachability time and a current time. The host reachability delta may be computed dynamically or updated at need. Similarly the device reachability time may correspond to a time at which the offload target last received information confirming that the destination was reachable and device reachability delta may be the different between the device reachability time and the current time.

At step the host reachability time may be retrieved from the host neighbor state object. At step the host reachability delta may be determined as a function of the host reachability time retrieved at step . For example the host reachability delta may be determined by subtracting the host reachability time from the current time at the host. In some embodiments of the invention a linear or nonlinear scaling function may in addition be applied to the host reachability time and or the host reachability delta for example to compensate for differences between the clocks of the host and the offload target.

At step the host reachability delta determined at step may be compared to a reachability stale threshold. For example the reachability stale threshold may be a system wide constant and have value 10 seconds. If the host reachability delta is greater than the reachability stale threshold the procedure may progress to step to check with the offload target device with respect to information received from the neighbor. Otherwise the procedure may progress to step to perform any neighbor cache entry state updates and send the communication packet without further delay.

Although step may determine that the host reachability delta is greater than the reachability stale threshold it may be that the offload target has received verification of reachability from the neighbor and that it is the host neighbor state object that is stale. To check for this case at step the offload target device may be queried for the device reachability delta maintained by the device neighbor state object. At step the device reachability delta may be received from the offload target device.

At step the host reachability time maintained by the host neighbor state object may be updated as a function of the device reachability delta received at step . For example the host reachability time may be set to the most recent of a the current host reachability time and b the current time less the device reachability delta. In symbols HRT max HRT current time DRD . Following step in an embodiment of the invention the host reachability time maintained by the host neighbor state object has been updated to include the most current information available from both the host and the offload target.

At step the host reachability delta may be re determined in a manner corresponding to that of step . At step the re determined host reachability delta may be compared to the reachability stale threshold. If the re determined host reachability delta is greater than the reachability stale threshold the procedure may progress to step to update the neighbor cache entry state with a threshold exceeded event. Otherwise the offload target did have more recent evidence of destination reachability and the procedure may progress to step to update the neighbor cache entry state with a beneath threshold event.

At step the neighbor cache entry state may be updated with a threshold exceeded event for example in accordance with RFC 2461. Depending on the current neighbor cache entry state the neighbor cache entry state may or may not change in response to the threshold exceeded event. For example if the current neighbor cache entry state is REACHABLE then the neighbor cache entry state may change to STALE in response to the threshold exceeded event however if the current neighbor cache entry state is PROBE then the neighbor cache entry state may not change in response to a particular threshold exceeded event.

Similarly at step the neighbor cache entry state may be update with a beneath threshold event for example in accordance with RFC 2461. Again depending the current neighbor cache entry state the neighbor cache entry state may or may not change in response to the beneath threshold event. For example if the current neighbor cache entry state is STALE DELAY or PROBE then the neighbor cache entry state may change to REACHABLE in response to the beneath threshold event however if the current neighbor cache entry state is REACHABLE then the neighbor cache entry state may not change in response to the beneath threshold event.

At step the communication packet may be send to the destination utilizing the host neighbor state object as updated by the above steps.

The steps depicted by include step querying the offload target device in order to update the host neighbor state object. The steps depicted by are complementary in that they include a query of the host in order to update the device neighbor state object. Significantly the steps depicted by do not include an update of a neighbor cache entry state maintained by the offload target device. This corresponds in accordance with an embodiment of the invention to an ability of the offload target device to be free of a duty to maintain a neighbor cache entry state machine.

At step a request to send a communication packet e.g. a TCP IP packet may be received by the offload target device communication subsystem. For example the request may be generated by the offload target device as part of the communication protocol. As described above with reference to in this example some or all of the protocol stack has been offloaded to the offload target and as a result communications object state associated with CACHED variables such as host reachability time and device reachability time at the host and the offload target device may be out of synchronization with each other. First several steps are performed to determine if a synchronization check is desirable.

At step a lookup operation may be performed to determined and or obtain reference to the device neighbor state object associated with the communication connection over which the communication packet is to be sent. At step the device reachability time may be retrieved from the device neighbor state object. At step the device reachability delta may be determined as a function of the device reachability time retrieved at step . For example the device reachability delta may be determined by subtracting the device reachability time from the current time at the offload target device. In some embodiments of the invention a linear or nonlinear scaling function may in addition be applied to the device reachability time and or the device reachability delta for example to compensate for differences between the clocks of the offload target device and the host.

At step the device reachability delta determined at step may be compared with the reachability stale threshold. For example the reachability stale threshold may be the system wide constant described above with reference to and may be provided by the host to the offload target device at device initialization time. If the device reachability delta is greater than the reachability stale threshold synchronization with the host may be required and in an embodiment of the invention the procedure progresses to step . Otherwise the procedure may progress to step to send the communication packet without further delay.

At step the host may be queried for the host reachability delta maintained by the host neighbor state object. At step the requested host reachability delta may be received from the host. The response of the host to the query at step and the value of the host reachability delta returned at step in accordance with an embodiment of the invention is described below in more detail with reference to .

At step the device reachability time maintained by the device neighbor state object may be updated as a function of the host reachability delta received at step . For example the device reachability time may be set to the most recent of a the current device reachability time and b the current time less the host reachability delta. In symbols DRT max DRT current time HRD . Similarly at step the host reachability time maintained by the device neighbor state object may be updated as a function of the host reachability delta received at step . Following steps and in an embodiment of the invention the device reachability time and the host reachability time maintained by the device neighbor state object has been updated to include the most current information available from both the host and the offload target.

At step the communication packet may be send to the destination utilizing the device neighbor state object as updated by the above steps.

Although the steps depicted in do not explicitly include an update of a neighbor cache entry state step may trigger such an update at the host. depicts example steps for responding to a query for host reachability delta in accordance with an embodiment of the invention. At step the request for the host reachability delta maintain by the host neighbor state object may be received from the offload target device.

The incoming request for the host reachability delta may include a copy of the device reachability delta maintained by the device neighbor state object. At step the host reachability time maintained by the host neighbor state object may be updated for example in a manner corresponding to that described above with reference to step . At step the host reachability delta may be determined as a function of the updated host reachability time for example in a manner corresponding to that described above with reference to step .

At step the host reachability delta determined at step may be compared with the reachability stale threshold. If the host reachability data is greater than the reachability stale threshold the procedure may progress to step to adjust the neighbor cache entry state. Otherwise the procedure may progress to step . At step the neighbor cache entry state may be updated with a threshold exceed event for example as described above with respect to step .

At step the neighbor cache entry state may be determined for example a stored value of the neighbor cache entry state associated with the communication connection may be retrieved. If the neighbor cache entry state is REACHABLE the procedure may progress to step . Otherwise the procedure may progress to step .

At step the host reachability delta determined at step may be returned to the offload target device in response to the request. In an embodiment of the invention the way that the host reachability time is updated at step ensures that the host reachability delta returned at step includes the most current information available from both the host and the offload target. At step the most current information indicates that the neighbor cache entry has fallen out of the REACHABLE state and may require invalidation. To check an invalidate timer is set at . depicts example steps for servicing the invalidate trigger in accordance with an embodiment of the invention. At step a nonstandard host reachability delta value e.g. zero may be returned to the offload target device to prevent new host reachability delta requests for a time period of at least the reachability stale threshold e.g. 10 seconds .

At step the invalidate timer set at step triggers in accordance with an embodiment of the invention. In order to ensure that the host neighbor state object is updated with the most current information available from both the host and the offload target at step the offload target device may be queried for the device reachability delta maintained by the device neighbor state object. At step the device reachability delta may be received from the offload target device. At step the host reachability time maintained by the host neighbor state object may be updated as a function of the device reachability delta received at step for example as described above with reference to step .

At step. the host reachability delta may be determined as a function of the updated host reachability time in a manner corresponding to that described above with reference to step . At step the host reachability delta determined at step may be compared to the reachability stale threshold. If the host reachability delta is greater than the reachability stale threshold the procedure may progress to step to update the neighbor cache entry state in accordance with a threshold exceeded event for example as described above with reference to step . Otherwise the procedure may progress to step to update the neighbor cache entry state in accordance with a beneath threshold event for example as described above with reference to step .

At step it may be determined whether the neighbor cache entry state is PROBE. If the neighbor cache entry state is PROBE the procedure may progress to step to attempt to contact the neighbor. Otherwise the procedure may progress to step to reset the invalidate timer. At step the invalidate timer may be reset so that the steps depicted in can recur after a delay eventually progressing to step and or step .

At step a Neighbor Solicitation message may be unicast to the unreachable neighbor for example in accordance with RFC 2461. At step a check may be made for a response to the Neighbor Solicitation message. If a response to the Neighbor Solicitation message is detected then the procedure may progress to step to update the neighbor cache entry state in accordance with a beneath threshold event since in an embodiment of the invention the response corresponds to recent evidence of neighbor reachability that is a low host and or device reachability delta. Otherwise the procedure may progress to step .

At step it may be determined if a maximum number of Neighbor Solicitation probes e.g. 10 have been unicast to the unresponsive neighbor. If the maximum number of probes has been sent then the procedure may progress to steps and to invalidate the corresponding neighbor cache entries at the host and at the offload target device respectively. Otherwise the procedure may progress to step to reset the invalidate timer so that for example there is a delay before the next Neighbor Solicitation message is sent at step . In an embodiment of the invention the offload target device may operate independent of Neighbor Solicitation probing except its involvement in steps and .

Example data structures and functions in accordance with an embodiment of the invention are now described in greater detail below.

An offload target may call the NdisMOffloadEventIndicate function to indicate various events to the host stack 

where NdisMiniportHandle specifies the handle that the offload target obtained in a previous call to NdisMRegisterMiniport and OffloadBlockList specifies a pointer to an NDIS MINIPORT OFFLOAD BLOCK LIST structure. This structure identifies the offloaded state object on which the indication is being made. Note that there is only one NDIS MINIPORT OFFLOAD BLOCK LIST structure. There is not a linked list of such structures. The offload target supplies a valid OffloadBlockList pointer when making a NeighborReachabilityQuery indication. In this case the offload target supplies a NEIGHBOR OFFLOAD STATE CONST structure a NEIGHBOR OFFLOAD STATE CACHED structure and a NEIGHBOR OFFLOAD STATE DELEGATED structure in that order immediately following the NDIS MINIPORT OFFLOAD BLOCK LIST structure referenced by the OffloadBlockList pointer.

An offload target may initialize the following members of an NDIS MINIPORT OFFLOAD BLOCK LIST structure that it passes to the NdisMOffloadEventIndicate function all members of the NDIS OBJECT HEADER structure including Type Revision and Size. The offload target may initialize Type to NeighborOffloadState. The NextBlock pointer may be initialized to a non NULL value if there is a next block otherwise it may be set to NULL. The DependentBlockList pointer may be set to NULL. The Status member may be set to NDIS STATUS SUCCESS.

The offload target is not required to initialize any other members of the NDIS MINIPORT OFFLOAD BLOCK LIST structure. For all indications other than the NeighborReachabilityQuery indication the offload target may supply an OffloadBlockList pointer that is NULL.

IndicationCode may specifies the event being indicated as one of the following INDICATE OFFLOAD EVENT values 

The host stack may use the NeighborReachabilityQuery indication to detect neighbor unreachability for IPv4 and IPv6. Note that the IPv6 neighbor unreachability algorithm can be much more robust than the traditional IPv4 ARP algorithm for detecting neighbor unreachability. Thus the host stack may use the neighbor unreachability algorithm for both IPv4 and IPv6 to determine whether a specific neighbor state object NSO should be invalidated. In the case of IPv6 the host stack uses neighbor solicitation messages to perform address resolution see RFC 2461 . In the case of IPv4 the host stack uses ARP messages see D. Plummer An Ethernet Address Resolution Protocol RFC 826 Network Working Group November 1982 for details .

When the host stack offloads a neighbor state object it may supply values for the following two neighbor state variables 

The offload target may then use these variables to calculate the following timestamps after the neighbor state object has been offloaded 

Advantageously in an embodiment of the invention only the DRT timestamp need be updated on a per packet basis.

The host stack specifies the HRD and DRD values in units of ticks. The host stack may specify a number of ticks per second in a TicksPerSecond member of the NDIS TASK TCP CONNECTION OFFLOAD structure when the host stack sets OID TCP TASK OFFLOAD. Determining HRT and DRT at the offload target may include scaling one or more of HRT DRT HRD and DRD based on the specified number of ticks per second.

For example HRD DRD HRT and DRT may be unsigned variables of unsigned integer ULONG length. Because of this the above calculations may cause HRT and DRT to wrap. As a result the offload target typically uses normal unsigned arithmetic e.g. modular arithmetic when making this calculation. In an embodiment of the invention at the time that the neighbor state object is offloaded HRD and DRD are equal. Thus HRT and DRT are also equal. As the offload target or host stack sends for example IP datagrams on the connection that uses the neighbor state object the values of HRT and DRT may diverge.

Forward progress is made for example on a TCP connection when TCP segments that are received from the remote peer indicate that the remote peer is receiving segments from the offload target or the local host stack see RFC 2461 . Examples of such TCP segments are 

In an embodiment of the invention whenever an offload target receives confirmation of forward progress on a connection it finds the neighbor state object used by the connection and sets the neighbor state object s DeviceReachabilityTime DRT to the device s current time DCT . This effectively resets the DeviceReachabilityDelta DRD value to zero.

In an embodiment of the invention before the host stack sends an IP datagram on an offloaded connection it checks its own neighbor cache entry NCE for the connection. If the reachability state of the NCE is DELAY the host stack may call the MiniportQueryOffload function of the offload target to query the DeviceReachabilityDelta DRD variable for the connection. The host uses the queried DRD value to determine whether its NCE should transition to the PROBE reachability state.

Before an offload target sends an IP datagram on an offloaded connection it may perform the following test determine if DCT DRT NCEStaleTicks and DCT HRT NCEStaleTicks . Note that the host stack may supply the NCEStaleTicks value when setting OID TCP TASK OFFLOAD.

If the result of this test is true the offload target may do the following set DRD to DCT DRT and call the NdisMOffloadEventIndicate function with an IndicationCode of NeighborReachabilityQuery. The offload target may also pass an OffloadBlockList pointer to the NdisMOffloadEventIndicate function. This pointer may reference a single NDIS MINIPORT OFFLOAD BLOCK LIST structure that is immediately followed by 

In the call to NdisMOffloadEventIndicate the offload target may supply the current value of the DRD variable and the HRD variable for the neighbor state object. In response to a NeighborReachabilityQuery indication the host stack may synchronously return a value for the neighbor s HRD variable. The offload target uses the HRD value to update HRT HRT DCT HRD . The offload target may perform this same calculation after the neighbor state object is offloaded.

In an embodiment of the invention the value of HostReachabilityDelta HRD depends on whether the host stack s neighbor cache entry NCE for the neighbor is stale. If the host stack s NCE is stale the host stack may return a value of zero for HRD. This causes the offload target s HostReachabilityTime HRT to be equal to DCT which prevents the offload target from making another NeighborReachabilityQuery indication for at least NCEStaleTicks. The NeighborReachabilityQuery indication prompts the host stack to start a timer. When that timer expires the host stack may query the offload target s DeviceReachabilityDelta DRD value for the NCE.

If the offload target has received confirmation of forward progress on the connection since it made the NeighborReachabilityQuery indication it will have updated the DeviceReachabilityTime DRT value. This will cause the queried value of DRD to be less than the value of DRD that was supplied by the offload target in the NeighborReachabilityQuery indication. The host stack may use the queried value of DRD to update its copy of the HostReachabilityDelta HRD value.

If the offload target has not received confirmation of forward progress on the connection since it made the NeighborReachabilityQuery indication the value of the queried NRD variable may be greater than the value of NRD that is supplied by the offload target in the NeighborReachabilityQuery indication. In this case the host stack may send unicast Neighbor Solicitation probes to verify reachability of the neighbor. In an embodiment of the invention if the host stack does not receive a Neighbor Advertisement message in response to the probes it invalidates its copy of the NCE and also invalidates the offload target s copy of the NCE by causing NDIS to call the offload target s MiniportInvalidateOffload function.

If the NCE for the host stack is in the REACHABLE state the host stack may return a non zero value for HRD which the offload target may use to update its value for HostReachabiltyTime e.g. HRT DCT HRD and DeviceReachabilityTime e.g. DRT DCT DRD .

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

The use of the terms a and an and the and similar referents in the context of describing the invention especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate the invention and does not pose a limitation on the scope of the invention unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention.

The foregoing description of various embodiments of the invention has been presented for purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise embodiments disclosed. Numerous modifications or variations are possible in light of the above teachings. The embodiments discussed were chosen and described to provide the best illustration of the principles of the invention and its practical application to thereby enable one of ordinary skill in the art to utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated. All such modifications and variations are within the scope of the invention as determined by the appended claims when interpreted in accordance with the breadth to which they are fairly legally and equitably entitled.

