---

title: System and method for multiplexing channels over multiple connections in a storage system cluster
abstract: A system and method multiplexes channels over multiple connections between one or more nodes. Each node includes a cluster fabric interface module adapted to implement a novel network protocol that enables intra-cluster communication among the nodes. The network protocol is a multi-layered protocol that integrates a session infrastructure and an application operation set into a session layer. The network protocol is illustratively a request/response protocol wherein a node (requester) receiving a data access request from a client redirects that request to another node (responder) that services the request and, upon completion, returns a response.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07443872&OS=07443872&RS=07443872
owner: Network Appliance, Inc.
number: 07443872
owner_city: Sunnyvale
owner_country: US
publication_date: 20050429
---
The present invention is directed to network protocols and in particular to a session layer of a network protocol adapted to multiplex channels over multiple connections in a storage system cluster.

A storage system typically comprises one or more storage devices into which information may be entered and from which information may be obtained as desired. The storage system includes a storage operating system that functionally organizes the system by inter alia invoking storage operations in support of a storage service implemented by the system. The storage system may be implemented in accordance with a variety of storage architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The storage devices are typically disk drives organized as a disk array wherein the term disk commonly describes a self contained rotating magnetic media storage device. The term disk in this context is synonymous with hard disk drive HDD or direct access storage device DASD .

The storage system may be further configured to operate according to a client server model of information delivery to thereby allow many clients to access data containers such as files and logical units stored on the system. In this model the client may comprise an application such as a database application executing on a computer that connects to the storage system over a computer network such as a point to point link shared local area network LAN wide area network WAN or virtual private network VPN implemented over a public network such as the Internet. Each client may request the services of the storage system by issuing file based and block based protocol messages in the form of packets to the system over the network.

A plurality of storage systems may be interconnected to provide a storage system cluster configured to service many clients. Each storage system or node may be configured to service one or more volumes wherein each volume stores one or more data containers. Communication among the nodes involves the exchange of information between two or more entities interconnected by communication links. These entities are typically software programs executing on the nodes. The nodes communicate by exchanging discrete packets or messages of information according to predefined protocols. In this context a protocol consists of a set of rules defining how the nodes interact with each other.

Each node generally provides its services through the execution of software modules such as processes. A process is a software program that is defined by a memory address space. For example an operating system of the node may be implemented as a single process with a large memory address space wherein pieces of code within the process provide operating system services such as process management. Yet the node s services may also be implemented as separately scheduled processes in distinct protected address spaces. These separate processes each with its own process address space execute on the node to manage resources internal to the node and in the case of a database or network protocol to interact with a variety of network elements.

Services that are part of the same process address space communicate by accessing the same memory space. That is information exchanged between services implemented in the same process address space is not transferred but rather may be accessed in a common memory. However communication among services that are implemented as separate processes is typically effected by the exchange of messages. For example information exchanged between different addresses spaces of processes is transferred as one or messages between different memory spaces of the processes. A known message passing mechanism provided by an operating system to transfer information between process address spaces is the Inter Process Communication IPC mechanism.

Resources internal to the node may include communication resources that enable a process on one node to communicate over the communication links or network with another process on a different node. The communication resources include the allocation of memory and data structures such as messages as well as a network protocol stack. The network protocol stack in turn comprises layers of software such as a session layer a transport layer and a network layer. The Internet protocol IP is a network layer protocol that provides network addressing between nodes whereas the transport layer provides a port service that identifies each process executing on the nodes and creates a connection between those processes that indicate a willingness to communicate. Examples of conventional transport layer protocols include the reliable connection RC protocol and the Transmission Control Protocol TCP .

Broadly stated the connection provided by the transport layer such as that provided by TCP is a reliable securable logical circuit between pairs of processes. A TCP process executing on each node establishes the TCP connection in accordance with a conventional 3 way handshake arrangement involving the exchange of TCP message or segment data structures. The resulting TCP connection is identified by port numbers and IP addresses of the nodes. The TCP transport service provides reliable delivery of a message using a TCP transport header. The TCP protocol and establishment of a TCP connection are described in 3 particularly at pgs. 521 542 which is hereby incorporated by reference as though fully set forth herein.

Flow control is a protocol function that controls the flow of data between network protocol stack layers in communicating nodes. At the transport layer for example flow control restricts the flow of data e.g. bytes over a connection between the nodes. The transport layer may employ a fixed sliding window mechanism that specifies the number of bytes that can be exchanged over the network communication link before acknowledgement is required. Typically the mechanism includes a fixed sized window or buffer that stores the data bytes and that is advanced by the acknowledgements.

The session layer manages the establishment or binding of an association between two communicating processes in the nodes. In this context the association is a session comprising a series of interactions between the two communicating processes for a period of time e.g. during the span of a connection. Upon establishment of the connection the processes take turn exchanging commands and data over the session typically through the use of request and response messages. Flow control in the session layer concerns the number of outstanding request messages requests that is allowed over the session at a time. Laggard response messages responses or long running requests may force the institution of session layer flow control to limit the flow of requests between the processes thereby adversely impacting the session. It is desirable to allow a session to continue to perform at high throughput even in the event of a long running request or a lost request or response.

The present invention overcomes the disadvantages of the prior art by providing a system and method for multiplexing channels over multiple connections between two nodes. Each node is generally organized as a network element and a disk element. Each element includes a cluster fabric interface module adapted to implement a novel network protocol that enables intra cluster communication among the elements. The network protocol is a multi layered protocol that integrates a session infrastructure and an application operation set into a session layer. The network protocol is illustratively a request response protocol wherein an element requester receiving a data access request from a client redirects that request to another element responder that services the request and upon completion returns a response.

The session layer manages the establishment and termination of sessions between bi directional requesters responders and is illustratively built upon a connection layer that defines a set of functionality or services provided by a connection oriented protocol. All network protocol communication occurs via connections which provide a network transport for the sessions between the requesters responders. Moreover each session provides a context for bi directional flow of requests and bi directional flow of corresponding responses to those requests through the cluster. At least one connection is required for each session wherein the connection is used for both requests and responses. Although more than one connection can be bound to a session only connections that are bound to the session can be used to carry the requests and responses for that session.

According to the invention each session comprises a plurality of channels disposed over the connections that unlike a session are not bound to the connections. A channel is a construct that enables multiple requests to be sent asynchronously over one or more connections. Each channel is illustratively embodied as a request window having a plurality of entries for staging requests sent over the connection i.e. for tracking and or recording outstanding requests. Within a session the session layer selects any request window with an available slot to send a request thereby obviating the possibility of one long running or lost request blocking the progress of the session. Each request window has a predetermined initial sequence window size and the maximum number of outstanding requests in a session is the sum of the window sizes of all the channels in the session.

Moreover each channel has an assigned priority level. Although this arrangement imposes a binding between channels and connections of a particular priority level the requests for any number of channels at that priority level can be sent over any set of connections used to service that priority level. Notably there is no present assignment of channels to connections e.g. requests within a channel may be sent over different connections of identical priority primarily because the session layer performs its own matching of request to response messages within various sessions. This aspect of the invention enables the session layer to multiplex i.e. send requests from channels request windows of a session over any connection that is available at the proper priority level.

Advantageously the inventive network protocol employs multiple request channels within a session to allow high levels of concurrency i.e. to allow a large number of requests to be outstanding while enabling the requester to specify an order to request processing if desired within each channel. Multiple channels are multiplexed over the connections to thereby insulate a session from lost throughput due to laggard responses or long running requests i.e. multiple channels allow the requester to continue to make progress even if one channel stalls because of a long running request or a lost request or response. Channels can also be used to guarantee exactly once request execution semantics across any failure mode.

The clients may be general purpose computers configured to interact with the node in accordance with a client server model of information delivery. That is each client may request the services of the node and the node may return the results of the services requested by the client by exchanging packets over the network . The client may issue packets including file based access protocols such as the Common Internet File System CIFS protocol or Network File System NFS protocol over the Transmission Control Protocol Internet Protocol TCP IP when accessing information in the form of files and directories. Alternatively the client may issue packets including block based access protocols such as the Small Computer Systems Interface SCSI protocol encapsulated over TCP iSCSI and SCSI encapsulated over Fibre Channel FCP when accessing information in the form of blocks.

Each node is illustratively embodied as a dual processor storage system executing a storage operating system that preferably implements a high level module such as a file system to logically organize the information as a hierarchical structure of named directories files and special types of files called virtual disks hereinafter generally blocks on the disks. However it will be apparent to those of ordinary skill in the art that the node may alternatively comprise a single or multi processor system. In alternate embodiments a node may comprise any type of computer including e.g. a desktop PC an application server etc. As such the term node should be taken to include any type of computer suitable for use with the present invention. Illustratively one processor executes the functions of the N blade on the node while the other processor executes the functions of the D blade .

The memory illustratively comprises storage locations that are addressable by the processors and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system portions of which is typically resident in memory and executed by the processing elements functionally organizes the node by inter alia invoking storage operations in support of the storage service implemented by the node. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The network adapter comprises a plurality of ports adapted to couple the node to one or more clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network. The network adapter thus may comprise the mechanical electrical and signaling circuitry needed to connect the node to the network. Illustratively the computer network may be embodied as an Ethernet network or a Fibre Channel FC network. Each client may communicate with the node over network by exchanging discrete frames or packets of data according to pre defined protocols such as TCP IP.

The storage adapter cooperates with the storage operating system executing on the node to access information requested by the clients. The information may be stored on any type of attached array of writable storage device media such as video tape optical DVD magnetic tape bubble memory electronic random access memory micro electro mechanical and any other similar media adapted to store information including data and parity information. However as illustratively described herein the information is preferably stored on the disks of array . The storage adapter comprises a plurality of ports having input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC link topology.

Storage of information on each array is preferably implemented as one or more storage volumes that comprise a collection of physical storage disks cooperating to define an overall logical arrangement of volume block number vbn space on the volume s . Each logical volume is generally although not necessarily associated with its own file system. The disks within a logical volume file system are typically organized as one or more groups wherein each group may be operated as a Redundant Array of Independent or Inexpensive Disks RAID . Most RAID implementations such as a RAID 4 level implementation enhance the reliability integrity of data storage through the redundant writing of data stripes across a given number of physical disks in the RAID group and the appropriate storing of parity information with respect to the striped data. An illustrative example of a RAID implementation is a RAID 4 level implementation although it should be understood that other types and levels of RAID implementations may be used in accordance with the inventive principles described herein.

To facilitate access to the disks the storage operating system implements a write anywhere file system that cooperates with one or more virtualization modules to virtualize the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directories and files on the disks. Each on disk file may be implemented as set of disk blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module s allow the file system to further logically organize information as a hierarchical structure of blocks on the disks that are exported as named logical unit numbers luns .

In the illustrative embodiment the storage operating system is preferably the NetApp Data ONTAP operating system available from Network Appliance Inc. Sunnyvale Calif. that implements a Write Anywhere File Layout WAFL file system. However it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such where the term WAFL is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

In addition the storage operating system includes a series of software layers organized to form a storage server that provides data paths for accessing information stored on the disks of the node . To that end the storage server includes a file system module in cooperating relation with a volume striping module VSM a RAID system module and a disk driver system module . The RAID system manages the storage and retrieval of information to and from the volumes disks in accordance with I O operations while the disk driver system implements a disk access protocol such as e.g. the SCSI protocol. The VSM illustratively implements a striped volume set SVS and cooperates with the file system to enable storage server to service a volume of the SVS. In particular the VSM implements a Locate function to compute the location of data container content in the SVS volume to thereby ensure consistency of such content served by the cluster.

The file system implements a virtualization system of the storage operating system through the interaction with one or more virtualization modules illustratively embodied as e.g. a virtual disk vdisk module not shown and a SCSI target module . The vdisk module enables access by administrative interfaces such as a user interface of a management framework not shown in response to a user system administrator issuing commands to the node . The SCSI target module is generally disposed between the FC and iSCSI drivers and the file system to provide a translation layer of the virtualization system between the block lun space and the file system space where luns are represented as blocks.

The file system is illustratively a message based system that provides logical volume management capabilities for use in access to the information stored on the storage devices such as disks. That is in addition to providing file system semantics the file system provides functions normally associated with a volume manager. These functions include i aggregation of the disks ii aggregation of storage bandwidth of the disks and iii reliability guarantees such as mirroring and or parity RAID . The file system illustratively implements the WAFL file system hereinafter generally the write anywhere file system having an on disk format representation that is block based using e.g. 4 kilobyte kB blocks and using index nodes inodes to identify files and file attributes such as creation time access permissions size and block location . The file system uses files to store meta data describing the layout of its file system these meta data files include among others an inode file. A file handle i.e. an identifier that includes an inode number is used to retrieve an inode from disk.

Broadly stated all inodes of the write anywhere file system are organized into the inode file. A file system fs info block specifies the layout of information in the file system and includes an inode of a file that includes all other inodes of the file system. Each logical volume file system has an fsinfo block that is preferably stored at a fixed location within e.g. a RAID group. The inode of the inode file may directly reference point to data blocks of the inode file or may reference indirect blocks of the inode file that in turn reference data blocks of the inode file. Within each data block of the inode file are embedded inodes each of which may reference indirect blocks that in turn reference data blocks of a file.

Operationally a request from the client is forwarded as a packet over the computer network and onto the node where it is received at the network adapter . A network driver of layer or layer processes the packet and if appropriate passes it on to a network protocol and file access layer for additional processing prior to forwarding to the write anywhere file system . Here the file system generates operations to load retrieve the requested data from disk if it is not resident in core i.e. in memory . If the information is not in memory the file system indexes into the inode file using the inode number to access an appropriate entry and retrieve a logical vbn. The file system then passes a message structure including the logical vbn to the RAID system the logical vbn is mapped to a disk identifier and disk block number disk dbn and sent to an appropriate driver e.g. SCSI of the disk driver system . The disk driver accesses the dbn from the specified disk and loads the requested data block s in memory for processing by the node. Upon completion of the request the node and operating system returns a reply to the client over the network .

It should be noted that the software path through the storage operating system layers described above needed to perform data storage access for the client request received at the node may alternatively be implemented in hardware. That is in an alternate embodiment of the invention a storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array FPGA or an application specific integrated circuit ASIC . This type of hardware implementation increases the performance of the storage service provided by node in response to a request issued by client . Moreover in another alternate embodiment of the invention the processing elements of adapters may be configured to offload some or all of the packet processing and storage access operations respectively from processor to thereby increase the performance of the storage service provided by the node. It is expressly contemplated that the various processes architectures and procedures described herein can be implemented in hardware firmware or software.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer to perform a storage function that manages data access and may in the case of a node implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel an application program operating over a general purpose operating system such as UNIX or Windows NT or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the invention described herein may apply to any type of special purpose e.g. file server filer or storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write any where file system the teachings of the present invention may be utilized with any suitable file system including a write in place file system.

In the illustrative embodiment the storage server is embodied as D blade of the storage operating system to service one or more volumes of array . In addition the multi protocol engine is embodied as N blade to i perform protocol termination with respect to a client issuing incoming data access request packets over the network as well as ii redirect those data access requests to any storage server of the cluster . Moreover the N blade and D blade cooperate to provide a highly scalable distributed storage system architecture of the cluster . To that end each blade includes a cluster fabric CF interface module adapted to implement a novel network protocol that enables intra cluster communication among the blades as described herein.

The protocol layers e.g. the NFS CIFS layers and the iSCSI FC layers of the N blade function as protocol servers that translate file based and block based data access requests from clients into network protocol messages used for communication with the D blade . That is the N blade servers convert the incoming data access requests into primitive operations commands that are embedded within messages by the CF interface module for transmission to the D blades of the cluster . Notably the CF interface modules cooperate to provide a single file system image across all D blades in the cluster . Thus any network port of an N blade that receives a client request can access any data container within the single file system image located on any D blade of the cluster.

Further to the illustrative embodiment the N blade and D blade are implemented as separately scheduled processes of storage operating system however in an alternate embodiment the blades may be implemented as pieces of code within a single operating system. Communication between an N blade and D blade is thus illustratively effected through the use of message passing between the blades although in the case of remote communication between an N blade and D blade of different nodes such message passing occurs over the cluster switching fabric . A known message passing mechanism provided by the storage operating system to transfer information between blades processes within a single node is the Inter Process Communication IPC mechanism.

The network protocol illustratively described herein is the Spin network protocol SpinNP that comprises a collection of methods functions constituting a SpinNP application programming interface API . SpinNP is a proprietary protocol of Network Appliance of Sunnyvale Calif. The term SpinNP is used herein without derogation of any trademark rights of Network Appliance Inc. The SpinNP API in this context is a set of software calls and routines that are made available exported by a process and that can be referenced by other processes. As described herein all SpinNP protocol communication in the cluster occurs via connections. Communication is illustratively effected by the D blade exposing the SpinNP API to which an N blade or another D blade issues calls. To that end the CF interface module is organized as a CF encoder and CF decoder. The CF encoder of e.g. CF interface on N blade encapsulates a SpinNP message as i a local procedure call LPC when communicating a command to a D blade residing on the same node or ii a remote procedure call RPC when communicating the command to a D blade residing on a remote node of the cluster . In either case the CF decoder of CF interface on D blade de encapsulates the SpinNP message and processes the command.

According to the invention the SpinNP network protocol is a multi layered protocol that integrates a session infrastructure and an application operation set into a session layer that obviates encapsulation and buffering overhead typically associated with protocol layering. The session layer manages the establishment and termination of sessions between blades in the cluster and is illustratively built upon a connection layer that defines a set of functionality or services provided by a connection oriented protocol. The connection oriented protocol may include a framing protocol layer over a network transport such as RC and or TCP or a memory based IPC protocol. These connections are formed via the network transport or via the local memory to memory or adapter to memory transport and provide a packet message transport service with flow control. It should be noted that other connection oriented protocols perhaps over other transports can be used as long as those transports provide the same minimum guaranteed functionality e.g. reliable message delivery.

The SpinNP network protocol is illustratively a request response protocol wherein a blade requester receiving a data access request from a client redirects that request to another blade responder that services the request and upon completion returns a response. The network protocol is illustratively implemented by the CF interface modules and as such a SpinNP session provides a context for bi directional flow of request messages requests and the flow of corresponding response messages responses to those requests. Each request consists of one SpinNP message and generates one response unless the connection is lost or the session terminates abnormally. is a schematic block diagram illustrating the organization of the CF interface modules adapted to implement the SpinNP protocol in accordance with the present invention. Each module comprises a SpinNP session layer and a connection layer

The SpinNP session layer allows implementation of different operation protocols hereinafter referred to generally as operation interfaces . Examples of such interfaces include a session interface that defines a set of protocol operations that is used to provide the session infrastructure and a file operations interface that defines file access operations that are generally translated requests coming from external clients. Other interfaces implemented by the session layer include those used by data management system management or other application subsets of cluster functionality as needed. Notably the session infrastructure operations exist in the network protocol at the same level of encapsulation as the application operations to enable an efficient and highly functional implementation. All interfaces share common features of the session layer including credentials authentication verification sessions recovery and response caches. Each operation provided by an interface is illustratively defined by an interface number coupled with a procedure number.

As noted the SpinNP network protocol relies on connections for reliable message delivery. As such a session is disposed over one or more connections and is illustratively established between a pair of blades or other participants. For example a session can be established between D blades between an N blade and a D blade and between N blades if there proves to be a need for N blade to N blade SpinNP calls . The session can also be used to inter connect other entities or agents including user space processes and services to blades or to each other. Each pair of blades typically requires only one session to communicate however multiple sessions can be opened simultaneously between the same pair of blades. Each session requires bi directional request flow over the same connection. The session also provides an infrastructure that makes messages secure and supports recovery without requiring an additional protocol layer between the network transport layer RC or TCP and the application layer e.g. file access operations . Each session is independently negotiated and initiated to thereby enable a high level of message concurrency and asynchrony.

The connections are established by the connection layers and provide the network transport for the sessions between the blades. At least three connections are typically utilized for each session wherein each connection is used for both requests and responses at a given or higher priority. Typically a request or response is sent over a connection having the same priority. However in alternate embodiments a request response may be sent over a connection having a lower priority than the request response. Although more than one connection can be bound to a session only connections that are bound to the session can be used to carry the requests and responses for that session. The connections are bi directional allowing message flow in each direction. For example requests flow in both directions on each session thereby allowing forward operational and reverse callback flows to be sent through the same session. Responses for both directions of request flow are also carried in the session. Connections that are bound to sessions cannot be shared by multiple sessions however multiple channels may be multiplexed onto a single connection. That is operational and callback channels between an N blade D blade pair can be multiplexed onto a single connection. Channels can also multiplex operations for different clients and different users.

Each session is illustratively identified by a globally unique identifier id formed of the universal unique ids UUIDs of its two participant blades with the session initiator s UUID listed first. The globally unique id is combined with a 64 bit uniquifier that is unique for all concurrent sessions between the pair of blades regardless of which blade is the initiator as well as for any dormant recoverable session for which any state is still stored on either of the two blades. The uniquifier may be generated using the current time indicating the time of constructing a session initiation operation i.e. CREATE SESSION conveyed within an appropriate request. The resulting session id uniquifier is then confirmed to be unique by the receiver blade. Note that the id uniquifier should be unique unless both blades are trying to create a session to each other simultaneously. If so each blade can counter propose a different session id possibly by simply adding a small random number to the original proposed session id uniquifier.

In the illustrative embodiment each connection has an assigned priority level and each session is bound to at least three connections each of which is independently flow controlled and has a different priority level. Illustratively the connections include a high priority level connection a medium priority level connection and a low priority connection level . The priority level indicates the minimum priority of message that the connection will accept. To that end each request has one of the three priority levels high medium and low. Every response is sent with the same priority as its request. It should be noted that a response message does not need to utilize the same connection as did the corresponding request message. Low priority is used for the vast majority of requests and as such each session may include multiple low priority connections . Medium priority is used for some callback requests. Callback requests are requests that flow in the reverse of the typical direction e.g. from server to client. The medium priority callback requests are those requests that are issued to inform the client that it must take some action that will allow the server to free some resources or unblock a different client. Finally high priority is reserved for requests that the client issues to fulfill the demands of a callback. SpinNP session operations can be performed at any priority.

The present invention is directed to a system and method for multiplexing channels over multiple connections in a cluster of storage systems or nodes. To that end each session comprises a plurality of channels disposed over the connections that unlike a session are not bound to the connections. is a schematic block diagram illustrating channels of a session in accordance with the present invention. According to the invention a channel is a light weight construct that enables multiple requests to be sent asynchronously over a connection . Each channel is illustratively embodied as a request buffer request window comprising a plurality of slots for staging requests sent over the connection i.e. for storing outstanding requests. Within a session the session layer selects any request window with an available slot to send a request thereby obviating the possibility of one long running or lost request or response blocking the progress performance of the session. Each request window has a pre determined initial sequence window size and the total number of outstanding requests in a session is the sum of the window sizes of all the channels in the session.

Moreover each channel has an assigned priority level e.g. high priority channel medium priority channel and low priority channel . Although this arrangement imposes a binding between channels and connections of a particular priority level the requests for any number of channels at that priority level can be sent over any set of connections used to service that priority level. That is any request from a channel that is staged in a request window can be sent over any connection as long as the priority levels of the request and channel are the same. The connection must have either the same priority or a lower priority than the request and channel. Although a request is associated with a channel of the session layer this notion disappears at the connection layer and connections .

Notably there is no mapping between channels and connections e.g. requests within a channel may be distributed among sent over different connections of the same priority primarily because the session layer performs its own matching of request to response messages within various sessions. This aspect of the invention enables the SpinNP session layer to multiplex i.e. send requests from channels request windows over any connection that is available at the proper priority level. Any messages delivered over a channel can be annotated at the receiver with the priority level which can speed the processing of higher priority messages through the layers of processing at the receiver. Note that certain numbers of connections are always kept clear of low priority traffic to keep higher priority traffic from being delayed unnecessarily by low priority traffic however any connection can in theory carry any priority of request. It should be noted that a message sent over a channel of a given priority may be sent over any connection of that specified priority or lower. Thus a message sent over a high priority channel may utilize a low medium or high priority connection.

Each session illustratively contains a limited number of channels defined during session negotiation. Initially each channel is opened with a sequence window size of one however the window size for any channel can be subsequently negotiated via a SET SEQ WINDOW SIZE operation. The maximum number of outstanding requests in a session is the sum of the window sizes of all the channels in the session. This total is also negotiated at session creation and can be renegotiated at any time. Every time a channel s sequence window is resized the new window size is counted against the total budget of window size available to the session.

Each channel is identified by a channel number which is unique within the direction of request flow in the session. In addition each request has a sequence number that is guaranteed to be unique for that request and thus that specifies its sequence in the channel. The use of unique sequence numbers for requests prevents re execution of replayed or duplicated requests and allows the detection of lost requests in a session. Sequence numbers in each channel wrap around when the maximum sequence number is reached. The requester is generally required to issue all requests in a channel in strictly increasing order until wrap around without skipping any sequence numbers. At wrap around the sequence decreases from its maximum value to zero then resumes its strictly increasing pattern i.e. S n n mod 2 where S n is the sequence number of the nth request sent on the channel.

Moreover each request is identified by a unique identifier request id which is placed in a request header of the request message. As used herein a request id is illustratively defined as the combination of a channel number and a sequence number. Each response includes the request id of its corresponding request in a response header of the response message. Requests are otherwise distinguished from responses by a protocol tag byte in the message header so that each message in a session is guaranteed to be unique. Note that the session layer does not depend upon ordering or identifying properties of the connections to resolve the association of a request to a channel or its sequence in that channel.

Windowing is used within each channel to accomplish flow control bounding the maximum number of outstanding requests per channel and therefore the total maximum number of outstanding requests per session. Request windowing is defined by the combination of a per request sequence number and a sequence window maintained on the responder. Only requests that fall within the current window of the request channel are accepted for processing by the responder. Any requests outside of the window are failed promptly with a ERR BADSEQ response. The window of requests initially accepted starts at sequence number 0 and extends to the sequence number equal to that channel s sequence window size w minus 1. The window on the responder is only advanced when the responder sends the response to the oldest outstanding request the one with the lowest sequence number . The window of sequence numbers that the requester is allowed to send is correspondingly advanced when it receives the response to the oldest outstanding request. The requester can then advance the window by the number of contiguously numbered responses that it has received at the tail of the window in that channel.

In other words the responder advances the window of requests it will accept in a channel when it sends a response for the oldest outstanding request in the window. At any time the maximum sequence number that can be accepted in a channel equals the lowest sequence number of any request that has not been responded to plus w 1. The requester can send a request with sequence number n w mod 2when it receives the response for the request with sequence number n. Note that the sequence window affects the size of a response cache if such a cache is kept. Response cache entries are pre served in the response cache until the responder receives confirmation that a response has been received. This confirmation is received implicitly for the request with sequence number n when the request with sequence number n w is received where w is the window size.

Once opened the connection is used to initiate the session which illustratively involves two steps. That is in step the session is created using e.g. the CREATE SESSION operation and in step session parameters are negotiated between the blades using a NEGOTIATE SESSION operation. The NEGOTIATE SESSION operation allows the blades to negotiate session parameters such as i the existence and sizes of session context structures including a response cache in the responder ii a number of channels at each level of channel priority in the session as described further herein iii the maximum total number of outstanding requests allowed in the session iv the operation interfaces that will be used in the session and v the version of each of those interfaces. Note that the existence and sizes of session context structures are negotiated separately for each session and can be different for different sessions between the same two participants particularly when the request flow in each of the sessions is different.

In step a determination is made as to whether additional connections should be bounded to the session. Notably additional connections may be bounded to a session after the session is established. As an example connections that accept medium and low priority requests can be opened and bound to the session at any time after the session is created. If no further connections are to be bounded to the connection the procedure jumps to step . Otherwise the additional connections are illustratively opened as described above in step .

In step the blades negotiate the number of channels in each session using the NEGOTIATE SESSION operation. NEGOTIATE SESSION operation requests can be sent independently in each direction in the session to open a number of different channels with at least one channel at each priority level. This operation request also allows each blade to separately negotiate a number of channels to open in the direction of request flow. Note that the SET SEQ WINDOW operation request can be sent in either direction in the session to negotiate sequence window sizes for the channels that have been opened in that direction. In step a determination is made as to whether additional channels should be created. If so the procedure returns to step otherwise the procedure proceeds to step where the created channels are multiplexed over the connections as described above to thereby enable the exchange of requests and responses among the blades in an efficient manner. The procedure then ends at step .

Connections can also be unbound from a session which is generally performed during the process of closing a connection. Unbinding a connection from a session ensures that the connection is flushed of all outstanding requests and responses. All but one connection can be unbound from a session at a time without destroying the session to which it is bound. Unbinding the connection from a session does not cause the termination of the session. An abandoned session will eventually time itself out and terminate. However a session that is reconnected before the timeout period expires does not lose its session state or identity. A connection can buffer and queue requests and responses but it is expected to deliver complete messages to a SpinNP target as quickly as possible.

Specifically a session is closed by a CLOSE SESSION operation which also unbinds the last connection in the session. Individual connections can be disassociated from a session by a UNBIND CONNECTION operation. Session termination unbinds all connections in the session. Safe termination of a session requires that all requests in the connections are delivered and all the matching responses are received before the connections are unbound. Immediate termination of a session unbinds the connections without guaranteeing delivery of outstanding requests or responses. The CLOSE SESSION operation takes an enumerator argument to specify the manner in which connections are unbound in the session. Immediate session termination should only be used in the event of a failure where rapid recovery is needed or in the event of an immediate need to remove a node from the cluster.

Advantageously the SpinNP protocol employs multiple request channels within a session to allow high levels of concurrency i.e. to allow a large number of requests to be outstanding while enabling the requester to specify an order to request processing if desired within each channel. Multiple channels multiplexed over the connections thereby insulate a session from lost throughput due to laggard responses or long running requests i.e. multiple channels allow the requester to continue to make progress even if one channel stalls because of a long running request or a lost request or response. Channels can also be used to guarantee exactly once request execution semantics across any failure mode.

The foregoing description has been directed to particular embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. Specifically it should be noted that the principles of the present invention may be implemented in other distributed systems. Furthermore while this description has been written in terms of N and D blades or elements the teachings of the present invention are equally suitable to systems where the functionality of the N and D blades are implemented in a single system. Alternately the functions of the N and D blades may be distributed among any number of separate systems wherein each system performs one or more of the functions. Additionally the procedures processes layers and or modules described herein may be implemented in hardware software embodied as a computer readable medium having program instructions firmware or a combination thereof. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

