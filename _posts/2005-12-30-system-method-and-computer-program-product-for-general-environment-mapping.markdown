---

title: System, method, and computer program product for general environment mapping
abstract: A reflection image and an environment map are loaded into memory. During rendering of an object, an environment texture sample is retrieved from the environment map based on a reflection vector stored in a pixel of the reflection image. The retrieved environment texture sample is then applied to the object. The object thus rendered is stored in a frame buffer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07561166&OS=07561166&RS=07561166
owner: Microsoft Corporation
number: 07561166
owner_city: Redmond
owner_country: US
publication_date: 20051230
---
This is a continuation of and priority is claimed to co pending U.S. patent application having Ser. No. 09 998 380 a filing date of Nov. 29 2001 for S MCPPGEM of Ungar which claims priority from U.S. Provisional Patent Application Ser. No. 60 253 946 entitled S MCPPGEM filed on Nov. 30 2000. This co pending Non Provisional United States Patent Application is commonly assigned herewith and is hereby incorporated herein by reference for all that it discloses.

Environment mapping is used to model interobject reflections that occur when a surface of an object reflects other objects in its surrounding environment. There are two types of environment maps that are typically used a cube environment map and a sphere environment map.

A cube environment map has six texture images that correspond to the six is faces of a cube. The center of the cube is referred to as the center of projection. At each vertex of an object polygon to be environment mapped a reflection vector is computed. This reflection vector indexes one of the six texture images that make up the cube environment map. If all the vertices of the object generate reflections that point to a single texture image of the cube environment map that texture image can be mapped onto the object using projective texturing. If an object has reflections that point to more than one texture image of the cube environment map the object is subdivided into pieces each of which generates reflection vectors that point to only one texture image. Because a reflection vector is not computed at each pixel this method is not exact. Furthermore the need to subdivide objects that generate reflection vectors that point to more than one texture image of a cube environment map precludes general environment mapping from being implemented using graphics hardware.

A sphere map on the other hand has only a single texture image. This texture image comprises a circle representing the hemisphere of the environment behind a viewer surrounded by an annulus representing the hemisphere in front of the viewer. The texture image is that of a perfectly reflecting sphere located in the environment when the viewer is infinitely far from the sphere. At each object plygon vertex a texture coordinate generation function generates coordinates that index this texture image and these are interpolated across the object. A problem with using a sphere environment map as compared to using a cube environment map is that the entire sphere environment map must be undated each time the viewpoint of a computer scene changes. When using a cube environment map only certain faces of the cube must be updated as the viewpoint changes thus significantly reducing the time needed to update the cube environment map between each computer scene. The need to update an entire sphere environment map each time the viewpoint is changed can cause significant performance issues in computer gaming applications where the viewpoint is rapidly changing.

What is needed are new general environment mapping techniques that overcome the disadvantages and limitations described above.

In one implementation a reflection image and an environment map are loaded into memory. During the rendering of an object an environment texture sample is retrieved from the environment map based on a reflection vector stored in a pixel of the reflection image. The retrieved environment texture sample is then applied to the object. The object thus rendered is stored in a frame buffer. The environment mapping techniques can be implemented in real time using one or more passes through a graphics pipeline of graphics accelerator hardware cards.

The following discussion is directed to a system method and computer program product for general environment mapping. According to a described implementation a first texture sample obtained from a texture map having reflection data is applied to an object using graphics hardware operating under the control of an application program. A second texture sample is then retrieved from an environment map based on the first texture sample. The second texture sample is applied to the object. The rendered object is stored in a frame buffer.

 Image or scene means an array of data values. A typical image might have red green blue and or alpha pixel data or other types of pixel data information as known to a person skilled in the relevant art.

 Pixel means a data structure which is used to represent a picture element. Any type of pixel format can be used.

 Reflection image means an array of pixels texels or intensity values that encode reflection data. The terms reflection image texture image and texture map may be used interchangeably.

 Texture image means an array of texels or intensity values. A texture image can be any array of values that is used to determine a value for a pixel. As used herein the term texture image includes texture maps and environmental maps.

 Texture sample means a sample selected from a texture map or texture image. The sample can represent one texel value or can be formed from two or more texel values blended together. Different weighting factors can be used for each texel blended together to form a texel. The terms texel and texture sample are sometimes used interchangeably.

 Texture unit refers to graphics hardware firmware and or software that can be used to obtain a texture sample e.g. a point sample a bilinearly filtered texture sample or a trilinearly filtered texture sample from a texture image.

 Real time refers to a rate at which successive display images can be redrawn without undue delay upon a user or application. This interactive rate can include but is not limited to a rate equal to or less than approximately 120 frames second. In one preferred example an interactive rate is equal to or less than 60 frames second. In some examples real time can be one update per second.

FIG. I illustrates an exemplary computer architecture having six overlapping layers. Layer represents a high level software application program. Layer represents a three dimensional 3D graphics software tool kit such as OPENGL PERFORMER available from Silicon Graphics Incorporated Mountain View Calif. Layer represents a graphics application programming interface API which can include but is not limited to OPENGL available from Silicon Graphics Incorporated. Layer represents system support such as operating system and or windowing system support. Layer represents firmware. Finally layer represents hardware including graphics hardware. Hardware can be any hardware or graphics hardware including but not limited to a computer graphics processor single chip or multiple chip a specially designed computer an interactive graphics machine a gaming platform a low end game system a game console a network architecture et cetera. Some or all of the layers of architecture will be available in most commercially available computers.

As will be apparent to a person skilled in the relevant art after reading the description herein various features can be implemented in any one of the layers of architecture or in any combination of layers of architecture .

Graphics subsystem includes a vertex operation module a pixel operation module a rasterizer a texture memory and a frame buffer . Texture memory can store one or more texture images . Texture memory is connected to a texture unit by a bus not shown . Rasterizer includes a texture unit and a blending unit . The operation of these features of the graphics system would be known to a person skilled in the relevant art given the description herein.

In one implementation the texture unit can obtain either a point sample a bi linearly filtered texture sample or a tri linearly filtered texture sample from texture image . Blending unit blends texels and or pixel values according to weighting values to produce a single texel or pixel. The output of texture unit and or blending module is stored in frame buffer . Display can be used to display images or scenes stored in frame buffer .

The graphics subsystem supports a multi pass graphics pipeline. It is capable of operating on each pixel of an object image during each pass that the object makes through the graphics pipeline. For each pixel of the object during each pass that the object makes through the graphics pipeline texture unit can obtain a single texture sample from the texture image stored in texture memory .

The pixels of an object are passed to texture unit at an input port. The texture coordinates for a pixel of the object are used to retrieve a texture sample from the texture map in texture memory . The retrieved texture sample contains reflection data. Next the reflection data retrieved from texture map is interpreted as a reflection vector and used to point to a texture sample contained in the environment map . The texture sample retrieved from the environment map is applied to the pixel of the object for example by replacing the color data of the pixel with the texture sample data. This texture dependent texturing process occurs for each pixel of the object as each pixel is processed by texture unit .

With reference again to the teapot is being viewed from a viewpoint . The teapot can be modeled using polygons e.g. triangles in a manner that would be known to a person skilled in the relevant art. A triangular polygon not shown is used at location to model teapot . The triangle has three vertices V V V not shown . Reflection vector Ris associated with vertex V. Reflection vector Ris associated with vertex V. Reflection vector Ris associated with vertex V. Reflection vectors R R and Reach point to a texel or texture sample of cube environment map .

Texture map comprises texels each of which stores predetermined values used to represent reflection vectors. In the illustrated example texture map includes three texels and . Each texel and comprises red green and blue color values. The red color value of texel stores the X component value of reflection vector R. The green color value of texel stores the Y component value of reflection vector R. The blue color value of texel stores the Z component value of reflection vector R. Together the red green and blue color values of texel comprise the reflection vector R. In a similar fashion texel comprises the reflection vector R and texel comprises the reflection vector R. The particular data format in which the values are stored e.g. floating point values RGB888 et cetera is implementation dependant as would be known to a person skilled in the relevant art given this description.

Returning to the illustrated method will now be described with reference to the triangle at location of teapot . At block a reflection image or a texture map having reflection data encoded in its pixels is loaded into a memory. In the implementation the reflection image is loaded into frame buffer . For the implementation the reflection image is loaded into texture memory . The reflection image can be generated using software hardware or a combination of software and hardware.

In one implementation at a point in time prior to the operation of block the texture map is generated and stored in texture memory . The triangle at location of teapot resides in texture unit . Each vertex of the triangle can have an associated set of texture coordinates that are used to retrieve a texture sample from texture image i.e. texture map . For example the triangle might comprise three pixels and of teapot as illustrated in . Pixels and comprise red green and blue color values. Thus texture unit retrieves the three texels and from texture map using the texture coordinates of the triangle and maps these three texels to pixels and respectively of teapot as illustrated in . The result can then be stored in frame buffer .

At a time prior to the operation of block an environment map is generated and stored in texture memory . At block a texture sample from the environment map is retrieved based on a reflection vector stored in a pixel of the reflection image. This can be achieved for example by copying teapot from frame buffer to frame buffer using a pixel copy procedure as described below. Alternatively for the system architecture of this can be achieved by drawing a quad rectangle with the reflection image as a first texture and an environment map as a second texture to be indexed via the result of a first texture lookup.

In one implementation the texture sample is retrieved from environment map based on the values of pixels and . The teapot is copied from frame buffer to frame buffer using a pixel copy procedure. During execution of the pixel copy procedure pixels and pass through rasterizer . During this second pass through the graphics pipeline of graphics subsystem the color values of pixel and are interpreted as being the reflection vectors R R and R. For example reflection vector Rpoints to texel of environment map . Thus during execution of the pixel copy procedure texture unit uses the value of reflection vector Rto retrieve texture sample S i.e. texel from environment map . In a similar fashion the value of pixel is interpreted as reflection vector Rand used to retrieve texture sample S i.e. texel from environment map and the value of pixel is interpreted as reflection vector Rand used to retrieve texture sample S i.e. texel from environment map .

At block the retrieve texture sample is applied to an object. For example the texture samples obtained in block are applied to teapot . In one implementation the value of texel is applied to teapot by blending or accumulating it onto pixel of teapot stored in frame buffer . Texel is blended or accumulated onto pixel by blending texel and pixel according to EQ. 1 with blending module . 1 EQ. 1

In a similar fashion texels and are applied to teapot by blending them with pixels and respectively according to EQ. 1. When a blending factor of one is used the red green and blue color values of pixels and are replaced with the red green and blue color values of texels and .

At block the results are stored in frame buffer for subsequent use. Once the results are stored in frame buffer display can be used to display teapot to a user of application program . Alternatively teapot can be printed using a printer not shown or stored in a memory not shown for retrieval at a later time.

In an alternative implementation the method can be implemented during a single pass through a graphics pipeline having texture unit . In this alternative implementation prior to block both a texture map and an environment map are generated and stored in texture memory . At block a triangle enters texture unit at the input port. The texture coordinates associated with the vertices of the triangle are then used to retrieve a texture sample comprising reflection data from texture map . Unlike the method above however the result is not stored in frame buffer . Rather texture unit uses the texture sample obtained from texture map to immediately retrieve a second texture sample from environment map block which is applied to the triangle block . The output of texture unit is stored in frame buffer block . A graphics processing unit capable of performing the texture dependent texturing process described herein is the NVIDIA GEFORCE2 ULTRA available from NVIDIA Corporation of Santa Clara Calif.

The methods described herein can also be used to create computer scenes having unique image qualities. For example in an optional operation of the method the reflection vector data described herein can be perturbed prior to retrieving a texture sample from environment map using pixel operation module . By perturbing the reflection vectors it is possible to create for example water ripple effects in an image generated using an environment map for water How to perturb the reflection vectors to create ripple effect or other unique image qualities would be known to a person skilled in the relevant art given the description herein.

It is noted that texture maps can be generated in advance of running application program and loaded during the execution of an application program to permit application program to execute in real time. Several texture maps can be created for predetermined views within an environment and stored for subsequent retrieval when application program is executing. Furthermore a procedure of application program can modify available texture maps during execution of application program to generate new texture maps corresponding to particular viewpoints.

It is further noted that ad hoc reflection vectors can be supplied over an object in order to induce arbitrary lookups into an environment map. Furthermore these reflection vectors may by supplied and used per pixel. In this manner the graphics techniques can be used to simulate reflections from a bumpy surface by providing perturbed reflection vectors or to simulate refraction of light from the environment by providing pseudo reflection vectors that really represent refraction directions.

Computer system includes one or more processors such as processor and one or more graphics subsystems such as graphics subsystem . One or more processors and one or more graphics subsystems can execute software and implement all or part of the features described herein. Graphics subsystem can be implemented for example on a single chip as a part of processor or it can be implemented on one or more separate chips located on a graphic board. Each processor is connected to a communication infrastructure e.g. a communications bus cross bar or network . After reading this description it will become apparent to a person skilled in the relevant art how to implement the described implementations using other computer systems and or computer architectures.

Computer system also includes a main memory e.g. random access memory RAM and secondary memory . The secondary memory can include for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive an optical disk drive etc. The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit represents a floppy disk magnetic tape optical disk etc. which is read by and written to by removable storage drive . As will be appreciated the removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

Secondary memory may further include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means can include for example a removable storage unit and an interface . Examples can include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system .

In the illustrated example computer system includes a frame buffer and a display . Frame buffer is in electrical communication with graphics subsystem . Images stored in frame buffer can be viewed using display .

Computer system can also include a communications interface . Communications interface allows software and data to be transferred between computer system and external devices via communications path . Examples of communications interface can include a modem a network interface such as Ethernet card a communications port etc. Software and data transferred via communications interface are in the form of signals which can be electronic electromagnetic optical or other signals capable of being received by communications interface via communications path . Note that communications interface provides a means by which computer system can interface to a network such as the Internet.

Computer system can also include one or more peripheral devices which are coupled to communications infrastructure by graphical user interface . Example peripheral devices which can from a part of computer system include for example a keyboard a pointing device e.g. a mouse a joy stick and a game pad. Other peripheral devices which can form a part of computer system will be known to a person skilled in the relevant art given the description herein.

The graphics system and method can be implemented using software running that is executing in an environment similar to that described above with respect to . In this document the term computer program product is used to generally refer to removable storage unit or a hard disk installed in hard disk drive . A computer useable medium can include magnetic media optical media or other recordable media. These computer program products are means for providing software to computer system .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs can also be received via communications interface . Such computer programs when executed enable the computer system to perform the methods discussed herein. In particular the computer programs when executed enable the processor to perform the processes and techniques described herein. Accordingly such computer programs represent controllers of the computer system .

Any software used to facilitate the graphics functionality may be stored in a computer program product and loaded into computer system using removable storage drive hard drive or communications interface . Alternatively the computer program product may be downloaded to computer system over communications path . The control logic software when executed by the one or more processors causes the processor s to perform the processes described herein.

The graphics system and or methods described herein may be implemented primarily in firmware and or hardware using for example hardware components such as application specific integrated circuits ASICs . Implementation of a hardware state machine so as to perform the functions described herein will be apparent to a person skilled in the relevant art.

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed invention.

