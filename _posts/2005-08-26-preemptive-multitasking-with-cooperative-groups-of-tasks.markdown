---

title: Preemptive multi-tasking with cooperative groups of tasks
abstract: An operating system combines preemptive scheduling with cooperative or non-preemptive scheduling. In particular, tasks are divided into groups of interdependent tasks. Interdependent tasks are tasks that utilize the same modules of code or resources Each group includes tasks that should not be run asynchronously relative to each other. The scheduler in the operating system provides each group with a time slot of processor time. The tasks within the group are cooperatively scheduled to exploit the time slot assigned to the group. Dependencies between modules and tasks are maintained to assure that no difficulties arise amongst preemptively scheduled groups.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07721286&OS=07721286&RS=07721286
owner: Microsoft Corporation
number: 07721286
owner_city: Redmond
owner_country: US
publication_date: 20050826
---
This application is a Continuation of prior U.S. application Ser. No. 09 537 998 filed Mar. 29 2000 which is a Continuation In Part of prior U.S. application Ser. No. 08 667 377 filed Jun. 21 1996 now issued as U.S. Pat. No. 6 052 707 which is a File Wrapper Continuation of U.S. application Ser. No. 08 125 930 filed Sep. 21 1993 priority from the filing date of which is hereby claimed under 35 U.S.C. 120.

The present invention relates generally to data processing systems and more particularly to scheduling of tasks in data processing systems.

The Microsoft WINDOWS Version 3.1 operating system sold by Microsoft Corporation of Redmond Wash. is a message driven operating system. Each program run on the operating system maintains a message queue for holding incoming messages that are destined for some portion of the program. Messages are often destined to windows generated by the program. Each window generated by a program has an associated procedure. Thus the messages are not sent to the window per se but rather are sent to the associated procedure.

Messages are retrieved and processed from the message queue by the associated program through execution of a block of code known as the message loop . is a flow chart of the steps performed by the message loop. These steps are continuously repeated in a looping fashion while the program is active. Initially a message is retrieved from the queue by making a call to the GetMessage function step . The GetMessage function is responsible for retrieving a message if one exists from the queue. Once the message is retrieved from the queue the message is translated if necessary into a usable format by calling the TranslateMessage function which performs some keyboard translation step . Once the message is translated the message is dispatched to the appropriate procedure by calling the DispatchMessage function step . The message includes information that identifies a destination window. The information is used to properly dispatch the message.

The GetMessage function described above also plays a role in the scheduling of tasks in the Microsoft WINDOWS Version 3.1 operating system. The operating system adopts a non preemptive or cooperative multi tasking approach. A task is a section of code such as a subroutine or program that can run independently. Cooperative multi tasking refers to when tasks cooperate with each other by voluntarily passing control over a processor yielding among each other. With preemptive multi tasking in contrast a scheduler determines which task is given the processor and typically provides each task with a given time slot in which it may run. The GetMessage function is an example of a vehicle for implementing the cooperative multi tasking in the operating system. Other operating system provided functions that help implement cooperative multi tasking include the PeekMessage Yield and WaitMessage functions. In order to understand how the GetMessage function and the other named functions play a role in cooperative multi tasking it is helpful to take a closer look at the operation of the GetMessage function.

One difficulty with the cooperative multi tasking approach of the Microsoft WINDOWS Version 3.1 operating system is that a task may monopolize the processor by refusing to yield to other tasks. As long as the task has messages in its message queue it need not yield.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

In accordance with a first aspect of the present invention a method is practiced in a data processing system having at least one processor for running tasks. The tasks are logically partitioned into groups of interdependent tasks that utilize the same modules of code or resources. The groups of tasks are preemptively scheduled to be run such that each group of tasks is given a time slot in which it may run on the processor. The tasks to be run within each group are non preemptively scheduled to be run during the time slot allocated to the group.

In accordance with a further aspect of the present invention a method is practiced in a data processing system having at least one storage device for storing modules of code and at least one processor for running tasks. During the running of each task at least one module of code is run and resources may be allocated. In this method a task dependency list is provided for each task. This task dependency list lists modules and resources that are candidates to be called when the task is run on the processor. The method may include the additional step of providing a module and resource dependency list for each module of code. Each module and resource dependency list lists interdependent modules of code for the module code associated with the list and resources utilized by the module code associated with the list. In such a case the task dependency list for each task is created by taking a logical union of the modules listed in the module and resource dependency list that are candidates to be called when the task is run on the processor. The task dependency lists are examined to logically partition the tasks into groups of interdependent tasks. The groups of tasks are preemptively scheduled to be run such that each group of tasks is given a time slot in a cycle in which its tasks may run on the processor. For each group of tasks the tasks are non preemptively scheduled to be run during the time slot allocated to the group.

In accordance with a still further aspect of the present invention a data processing system includes a partitioning mechanism for partitioning tasks into groups of interdependent tasks. The data processing system also includes an execution mechanism for executing the task. A preemptive scheduler preemptively schedules the group of tasks such that each group is given a time slot in which to execute one of its tasks. A non preemptive scheduler is also provided in the data processing system for non preemptively scheduling tasks within each group.

While illustrative embodiments have been illustrated and described it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention.

The preferred embodiment of the present invention combines preemptive multi tasking with cooperative multi tasking to optimize scheduling of tasks in an operating system. Specifically tasks are logically divided into groups of interdependent tasks. As will be explained in more detail below the interdependent tasks are related such that if they were scheduled asynchronously resource sharing problems could arise. A time slot of processor time is provided for each group. Scheduling within the group however is performed in a cooperative manner much like that performed by the Microsoft WINDOWS Version 3.1 operating system sold by Microsoft Corporation of Redmond Wash. Since groups are preemptively scheduled one task may not monopolize the processor and slow down all executing tasks. In general response time for task completion is improved by the present invention. Furthermore if a task hangs the scheduler may switch to another group so that all tasks will not hang. In addition for compatibility reasons the present invention ensures that dependencies among tasks are not ignored. Earlier versions of the Microsoft WINDOWS operating system used cooperative multi tasking. Thus applications written for such earlier versions of the operating system do not account for preemptive scheduling and thus dependency problems may arise when such applications are run in a preemptively scheduled environment. Failure to recognize these dependencies could cause problems in a purely preemptively scheduled environment.

The preferred embodiment of the present invention is practiced in a data processing system like that shown in . Although the data processing system shown in is a single processor system those skilled in the art will appreciate that the present invention may also be practiced in multiple processor systems such as distributed systems. The data processing system of includes a central processing unit CPU that controls operation of the system. The data processing system also includes a memory and disk storage for storing files and data. The memory may include any of multiple types of memory devices including RAM ROM or other well known types of memory devices. The data processing system may further include a keyboard a mouse and a video display . It should be appreciated that additional or other types of input output devices may likewise be included in the data processing system .

The memory holds a copy of an operating system and modules of code . The operating system may be an embellished version of the Microsoft WINDOWS Version 3.1 operating system that has been embellished to support the preferred embodiment described herein. The operating system includes a scheduler that is responsible for scheduling the execution of tasks on the CPU . The preferred embodiment of the present invention is implemented in large part in the scheduler .

The various groups of tasks to be run on the operating system are scheduled preemptively such that each group is given a particular time slot of processing time to run on the CPU step in . provides an illustration of how time slots may be assigned in an instance where there are four logical groups Group Group Group and Group . In the illustration shown in Group is assigned time slot in cycle and then later assigned time slot in cycle . In the example shown in Group is assigned time slot in cycle Group is assigned time slot in cycle and Group is assigned time slot in cycle . Each group is assigned a corresponding time slot within the next cycle. Thus Group is assigned time slot in cycle Group is assigned time slot in cycle Group is assigned time slot in cycle and Group is assigned time slot in cycle .

As the scheduling is dynamic and groups may be added and or removed over time the sequence of time slots need not remain fixed rather the scheduling may change over time. The scheduler however ensures that each active group gets a time slot in each cycle.

The scheduling of tasks within each group is not performed preemptively rather the scheduling is performed cooperatively step in . As discussed above cooperative multi tasking requires that a task voluntarily yield to another task. The example described in the Background section focused on the GetMessage function as a vehicle for yielding amongst tasks. In general the cooperative multi tasking performed within a group is performed much like scheduling is performed in the Microsoft WINDOWS Version 3.1 operating system. As will be described in more detail below the present invention additionally checks for dependencies before unblocking a task. API s such as GetMessage PeekMessage Yield and WaitMessage allow applications to yield to other tasks in the same group.

In summary each group is given a time slot of processor time in each cycle. Which task runs during the time slot assigned to a group depends upon cooperative scheduling of the tasks within the group. Thus a task that is currently running for a group will continue to run during each consecutive time slot that is assigned to the group until the task yields to another task in the group through a vehicle such as a GetMessage function call.

The operating system maintains data structures for monitoring what tasks are in each group. The primary data structure for this purpose is the group list . The group list may be stored in the data area of the operating system in memory . The group list includes a respective entry A B C and D for each of the tasks included in the group. Each entry A B C and D holds a handle for a task that is part of the group. A handle is a number that uniquely identifies a task amongst those in the system . Likewise a handle may be utilized to uniquely identify resources amongst those in the system . In the example shown in the group list includes entries A B C and D for four tasks task task task and task .

The tasks included in group lists may change over time. is a flow chart illustrating the steps performed to merge groups. Initially a task begins in its own group step . During the course of execution of the task the task performs API calls such as LoadLibrary LoadModule WinExec or certain forms of SendMessage to link to DLLs step . The operating system moves the task into a group with other applications which use the same DLLs to avoid data sharing problems step . Likewise during execution of a task the task may request a resource step using an allocate resource command. The operating system moves the task into a group with other applications which use the same resource to avoid resource sharing problems step .

In order for the scheduler to properly allocate time slots to groups it must know the current status of each group and which task if any is scheduled for execution during the next time slot that is provided for the group. A group status table like that shown in is stored by the operating system in memory in order to assist the scheduler in preemptively scheduling tasks from the various groups. In the example shown in the system currently has four active groups of tasks. A separate entry A B C and D is provided for each group. Each of the entries A B C and D includes a status field A B C and D respectively. The status fields A B C and D hold status information that details whether one of the tasks in the respective groups is scheduled to be running during the next time slot or whether the group is in a synching up state which will be described in more detail below . The status information may be encoded as groups of bits held in the status fields A B C and D. Each entry A B C and D also includes a respective task name field A B C and D. The task name fields A B C and D hold the task names of any tasks that are running during the next available time slot for the groups. Thus if entry A holds status information for group the task name field A holds a name or handle of the task in group that is running.

The operating system also maintains a module and resource dependency list for each of the modules . The module and resource dependency list serves a role in assigning tasks modules to groups when a new task or module is added to a group and when it is determined which group a task will be added to. The module and resource dependency lists are examined to determine what group a task should be assigned. Preemptively scheduled groups always have disjoint module and resource dependency lists. A task module is put in its own group or in a group with interdependent tasks modules and resource usage. An example module and resource dependency list is shown in . Each task may include a single module or multiple modules. The module and resource dependency list lists modules that are candidates to be called or loaded from the associated module. The listed modules and the associated module have an inter dependency. The module and resource dependency list holds entries A B and C for each of modules called or loaded from the module associated with the list. In the module calls or loads module DLL and DLL . Furthermore the module and resource dependency list lists resources that are candidates to be utilized by the associated module. The resources and the associated module therefore have an inter dependency. The module and resource dependency list holds entries D and E for each of the resources allocated by the module associate with the list. In the module allocates RESOURCE and RESOURCE .

The module and resource dependency list is not static rather the list changes over time. is a flow chart illustrating the steps performed to update a module and resource dependency list during the course of execution of the associated module. Initially a module and resource dependency list is maintained for each module step . An action is then performed that adds a module or resource dependency relative to the module associated with the list step . This action may include for instance loading a library module loading a DLL module running an application module getting the address of an exported DLL module or allocating a resource like a printer or disk drive. In the Microsoft WINDOWS Version 3.1 operating system API calls such as LoadLibrary LoadModule GetProcAddress WinExec and AllocateResource add a dependency relative to a module. The new modules that are loaded run or exported by such API calls are then added to the module and resource dependency list Step . Likewise the new resources allocated by the module are also added to the module and resource dependency list. In this fashion the module and resource dependency list may dynamically grow during the course of execution of the associated module.

Since any task may utilize multiple modules and resources the issue arises how to develop a module and resource dependency list for a task. is a flow chart showing the steps performed to create a module and resource dependency list for a task. Initially a task is created step . A task dependency list for the task is then created by taking the union of the module and resource dependency list of the modules of the task step . In this fashion the preferred embodiment in the present invention ensures that all of the module and resource dependencies for a task are taken into account when assigning the task a group.

It is perhaps helpful to summarize the scheduling performed by the scheduler . The scheduler assigns time slots for each of the active groups. The scheduler must also determine which task within a group is to be executed or whether the group is in a synching up state. The currently running task is specified within task name fields A B C and D of entries A B C and D of the group status table . The APIs GetMessage PeekMessage Yield and WaitMessage are embellished in the preferred embodiment of the present invention to update the group status table when yielding or blocking. Thus the group status table contains current information and the appropriate task in each group is scheduled.

While the present invention has been described with reference to a preferred embodiment thereof those skilled in the art will appreciate that various changes in form and scope may be made without departing from the present invention as defined in the appended claims. For example the present invention is well suited for use in a distributed system. Moreover the present invention may be implemented in environments other than the Microsoft WINDOWS Version 3.1 operating system. Still further the present invention need not use a single scheduler rather multiple schedulers may be used in conjunction.

