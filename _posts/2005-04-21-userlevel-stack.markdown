---

title: User-level stack
abstract: A method for transmitting data by means of a data processing system, the system being capable of supporting an operating system and at least one application and having access to a memory and a network interface device capable of supporting a communication link over a network with another network interface device, the method comprising the steps of: forming by means of the application data to be transmitted; requesting by means of the application a non-operating-system functionality of the data processing system to send the data to be transmitted; responsive to that request: writing the data to be transmitted to an area of the memory; and initiating by means of direct communication between the non-operating-system functionality and the network interface device a transmission operation of at least some of the data over the network; and subsequently accessing the memory by means of the operating system and performing at least part of a transmission operation of at least some of the data over the network by means of the network interface device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08005916&OS=08005916&RS=08005916
owner: Solarflare Communications, Inc.
number: 08005916
owner_city: Irvine
owner_country: US
publication_date: 20050421
---
This application claims priority under 35 U.S.C. 119 to UK Application No. GB0408876.1 filed Apr. 21 2004 the disclosure of which is hereby incorporated by reference thereto in its entirety.

This invention relates to a network interface for example an interface device for linking a computer to a network.

The computer may for example be a personal computer a server or a dedicated processing device such as a data logger or controller. In this example it comprises a processor a program store and a memory . The program store stores instructions defining an operating system and applications that can run on that operating system. The operating system provides means such as drivers and interface libraries by means of which applications can access peripheral hardware devices connected to the computer.

It is desirable for the network interface device to be capable of supporting standard transport protocols such as TCP RDMA and ISCSI at user level i.e. in such a way that they can be made accessible to an application program running on computer . Such support enables data transfers which require use of standard protocols to be made without requiring data to traverse the kernel stack. In the network interface device of this example standard transport protocols are implemented within transport libraries accessible to the operating system of the computer .

A typical computer system includes a processor subsystem including one or more processors a memory subsystem including main memory cache memory etc. and a variety of peripheral devices connected to the processor subsystem via a peripheral bus. Peripheral devices may include for example keyboard mouse and display adapters disk drives and CD ROM drives network interface devices and so on. The processor subsystem communicates with the peripheral devices by reading and writing commands and information to specific addresses that have been preassigned to the devices. The addresses may be preassigned regions of a main memory address space an I O address space or another kind of configuration space. Communication with peripheral devices can also take place via direct memory access DMA in which the peripheral devices or another agent on the peripheral bus transfers data directly between the memory subsystem and one of the preassigned regions of address space assigned to the peripheral devices.

Most modern computer systems are multitasking meaning they allow multiple different application programs to execute concurrently on the same processor subsystem. Most modern computer systems also run an operating system which among other things allocates time on the processor subsystem for executing the code of each of the different application programs. One difficulty that might arise in a multitasking system is that different application programs may wish to control the same peripheral device at the same time. In order to prevent such conflicts another job of the operating system is to coordinate control of the peripheral devices. In particular only the operating system can access the peripheral devices directly application programs that wish to access a peripheral devices must do so by calling routines in the operating system. The placement of exclusive control of the peripheral devices in the operating system also helps to modularize the system obviating the need for each separate application program to implement its own software code for controlling the hardware.

The part of the operating system that controls the hardware is usually the kernel. Typically it is the kernel which performs hardware initializations setting and resetting the processor state adjusting the processor internal clock initializing the network interface device and other direct accesses of the hardware. The kernel executes in kernel mode also sometimes called trusted mode or a privileged mode whereas application level processes also called user level processes execute in a user mode. Typically it is the processor subsystem hardware itself which ensures that only trusted code such as the kernel code can access the hardware directly. The processor enforces this in at least two ways certain sensitive instructions will not be executed by the processor unless the current privilege level is high enough and the processor will not allow user level processes to access memory locations including memory mapped addresses associated with specific hardware resources which are outside of a user level physical or virtual address space already allocated to the process. As used herein the term kernel space or kernel address space refers to the address and code space of the executing kernel. This includes kernel data structures and functions internal to the kernel. The kernel can access the memory of user processes as well but kernel space generally means the memory including code and data that is private to the kernel and not accessible by any user process. The term user space or user address space refers to the address and code space allocated by a code that is loaded from an executable and is available to a user process excluding kernel private code data structures. As used herein all four terms are intended to accommodate the possibility of an intervening mapping between the software program s view of its own address space and the physical memory locations to which it corresponds. Typically the software program s view of its address space is contiguous whereas the corresponding physical address space may be discontiguous and out of order and even potentially partly on a swap device such as a hard disk drive.

Although parts of the kernel may execute as separate ongoing kernel processes much of the kernel is not actually a separate process running on the system. Instead it can be thought of as a set of routines to some of which the user processes have access. A user process can call a kernel routine by executing a system call which is a function that causes the kernel to execute some code on behalf of the process. The current process is still the user process but during system calls it is executing inside of the kernel and therefore has access to kernel address space and can execute in a privileged mode. Kernel code is also executed in response to an interrupt issued by a hardware device since the interrupt handler is found within the kernel. The kernel also in its role as process scheduler switches control between processes rapidly using the clock interrupt and other means to trigger a switch from one process to another. Each time a kernel routine is called the current privilege level increases to kernel mode in order to allow the routine to access the hardware directly. When the kernel relinquishes control back to a user process the current privilege level returns to that of the user process.

When a user level process desires to communicate with the NIC conventionally it can do so only through calls to the operating system. The operating system implements a system level protocol processing stack which performs protocol processing on behalf of the application. In particular an application wishing to transmit a data packet using TCP IP calls the operating system API e.g. using a send call with data to be transmitted. This call causes a context switch to invoke kernel routines to copy the data into a kernel data buffer and perform TCP send processing. Here protocol is applied and fully formed TCP IP packets are enqueued with the interface driver for transmission. Another context switch takes place when control is returned to the application program. Note that kernel routines for network protocol processing may be invoked also due to the passing of time. One example is the triggering of retransmission algorithms. Generally the operating system provides all OS modules with time and scheduling services driven by the hardware clock interrupt which enable the TCP stack to implement timers on a per connection basis. The operating system performs context switches in order to handle such timer triggered functions and then again in order to return to the application.

It can be seen that network transmit and receive operations can involve excessive context switching and this can cause significant overhead. The problem is especially severe in networking environments in which data packets are often short causing the amount of required control work to be large as a percentage of the overall network processing work.

One solution that has been attempted in the past has been the creation of user level protocol processing stacks operating in parallel with those of the operating system. Such stacks can enable data transfers using standard protocols to be made without requiring data to traverse the kernel stack.

There are a number of difficulties in implementing transport protocols at user level. Most implementations to date have been based on porting pre existing kernel code bases to user level. Examples of these are Arsenic and Jet stream. These have demonstrated the potential of user level transports but have not addressed a number of the problems required to achieve a complete robust high performance commercially viable implementation.

On packet reception from the network interface hardware e.g. a network interface card NIC the NIC transfers data into pre allocated data buffer a and invokes the OS interrupt handler by means of the interrupt line. Step i . The interrupt handler manages the hardware interface e.g. posts new receive buffers and passes the received in this case Ethernet packet looking for protocol information. If a packet is identified as destined for a valid protocol e.g. TCP IP it is passed not copied to the appropriate receive protocol processing block. Step ii .

TCP receive side processing takes place and the destination part is identified from the packet. If the packet contains valid data for the port then the packet is engaged on the port s data queue step iii and that port marked which may involve the scheduler and the awakening of blocked process as holding valid data.

The TCP receive processing may require other packets to be transmitted step iv for example in the cases that previously transmitted data should be retransmitted or that previously enqueued data perhaps because the TCP window has opened can now be transmitted. In this case packets are enqueued with the OS NDIS driver for transmission.

In order for an application to retrieve a data buffer it must invoke the OS API step v for example by means of a call such as recv select or poll . This has the effect of informing the application that data has been received and in the case of a recv call copying the data from the kernel buffer to the application s buffer. The copy enables the kernel OS to reuse its network buffers which have special attributes such as being DMA accessible and means that the application does not necessarily have to handle data in units provided by the network or that the application needs to know a priori the final destination of the data or that the application must pre allocate buffers which can then be used for data reception.

It should be noted that on the receive side there are at least two distinct threads of control which interact asynchronously the up call from the interrupt and the system call from the application. Many operating systems will also split the up call to avoid executing too much code at interrupt priority for example by means of soft interrupt or deferred procedure call techniques.

The send process behaves similarly except that there is usually one path of execution. The application calls the operating system API e.g. using a send call with data to be transmitted Step vi . This call copies data into a kernel data buffer and invokes TCP send processing. Here protocol is applied and fully formed TCP IP packets are enqueued with the interface driver for transmission.

If successful the system call returns with an indication of the data scheduled by the hardware for transmission. However there are a number of circumstances where data does not become enqueued by the network interface device. For example the transport protocol may queue pending acknowledgements or window updates and the device driver may queue in software pending data transmission requests to the hardware.

A third flow of control through the system is generated by actions which must be performed on the passing of time. One example is the triggering of retransmission algorithms. Generally the operating system provides all OS modules with time and scheduling services driven by the hardware clock interrupt which enable the TCP stack to implement timers on a per connection basis.

If a standard kernel stack were implemented at user level then the structure might be generally as shown in . The application is linked with the transport library rather than directly with the OS interface. The structure is very similar to the kernel stack implementation with services such as timer support provided by user level packages and the device driver interface replaced with user level virtual interface module. However in order to provide the model of a asynchronous processing required by the TCP implementation there must be a number of active threads of execution within the transport library 

It would be desirable to provide a system that at least partially addresses one or more of these problems a to e.

According to one aspect of the present invention roughly described there is provided a method for transmitting data by means of a data processing system the system being capable of supporting an operating system and at least one application and having access to a memory and a network interface device capable of supporting a communication link over a network with another network interface device the method comprising the steps of forming by means of the application data to be transmitted requesting by means of the application a non operating system functionality of the data processing system to send the data to be transmitted responsive to that request writing the data to be transmitted to an area of the memory and initiating by means of direct communication between the non operating system functionality and the network interface device a transmission operation of at least some of the data over the network and subsequently accessing the memory by means of the operating system and performing at least part of a transmission operation of at least some of the data over the network by means of the network interface device.

Preferably the operating system is capable of direct communication with the network interface device.

The said direct communication between the non operating system functionality preferably bypasses the operating system.

The non operating system functionality is preferably implemented by software most preferably by software running on the data processing system. It may conveniently be a transport library. The non operating system functionality most preferably does not require an increase in privilege level in order to accomplish the steps it performs.

The said area of the memory may be mapped to a second area of the memory. The second area of the memory may be accessible to the operating system most preferably directly accessible but not directly accessible to the non operating system functionality.

The method may comprise on initiating a transmission operation of data over the network starting a timer and if the timer reaches a predetermined value before an acknowledgement is received for that data transmitting a failure message from the network interface device to the data processing system.

The method may comprise on initiating a transmission operation of data over the network storing a record of that operation and an indication of the application that was the source of the data and on receiving data for that application starting a timer for each record associated with that application and if such a timer reaches a predetermined value before an acknowledgement is received for that data transmitting a failure message from the network interface device to the data processing system.

The method may comprise cancelling the timer on receiving an acknowledgement for the data and wherein the or each failure message is directed to the operating system.

The step of cancelling the timer may comprise the application signalling the entity on which the timer is run in a manner that bypasses the operating system.

The or each failure message is preferably directed to the application that was the source of the data.

The operating system is preferably responsive to failure messages that are directed to applications that are no longer in communication with the network device to perform the said at least part of a transmission operation in respect of data corresponding to the failure message.

According to a second aspect of the present invention roughly described there is provided a method for receiving data by means of a data processing system the system being capable of supporting at least one application and having access to a memory and a network interface device capable of supporting a communication link over a network with another network interface device the method comprising the steps of establishing by means of a non operating system functionality of the data processing system a channel for reception of data by an application the channel being associated with an area of the memory receiving data through that channel by the network interface device writing received data to the area of the memory and the application reading received data from that area and subsequently if the application is unable to communicate with the network device the operating system reading received data from that area.

Preferably the operating system is arranged to automatically read received data from that area on a determination being made that the application is unable to communicate with the network device.

According to a third aspect of the present invention roughly described there is provided a method for transmitting data by means of a data processing system the system being capable of supporting at least one application and having access to a memory and a network interface device capable of supporting a communication link over a network with another network interface device the method comprising the steps of forming by means of the application data to be transmitted passing that data to the network interface device for transmission transmitting the data by means of the network interface device and optionally on that transmission establishing a timer corresponding to the data and if an acknowledgement is received over the network for the data cancelling the timer or if the timer reaches a predetermined value signalling the operating system by means of the network interface device to indicate that no acknowledgement has been received for the data.

When the timer has been established it may be started upon receipt of data directed to the application that was the source of the data upon whose transmission the timer was established.

The said passing of the data may be performed by a non operating system functionality of the data processing system.

According to a fourth aspect of the present invention roughly described there is provided a method for transmitting or receiving data by means of a data processing system the system supporting an operating system and at least one application and having access to a memory and a network interface device capable of supporting a communication link over a network with another network interface device the method comprising allocating one or more areas of the memory for use as buffers in the transfer of data between the data processing system and the network interface device and directly accessing at least one of the areas of the memory by means of the application for at least one of transmission and reception of data by means of the network interface device and directly accessing the said at least one of the areas of the memory by means of the operating system for at least one of transmission and reception of data by means of the network interface device.

Preferably the method comprises receiving data from the network by means of the network device and writing that data to the said at least one of the areas by means of the network device.

Preferably the network device is configured to signal the operating system to access the said at least one of the areas if the application is determined to be unresponsive and the method comprises performing the said step of directly accessing the said at least one of the areas of the memory by means of the operating system in response to such a signal. The said signal may be an interrupt.

Preferably the network device supports a timer and the method comprises starting the timer to count from a preset initial value when received data is written to the said at least one of the areas and the application is determined to be unresponsive if the timer reaches a preset final value. Preferably the final value is zero.

Preferably the method comprises the step of setting the initial value and or the final value by means of the application. Most preferably the final value is zero and only the initial value is set by means of the application.

The method preferably comprises stopping the timer by means of the application on reading received data by means of the application from the said at least one of the areas.

Preferably each of the said steps of directly accessing at least one of the areas of the memory for at least one of transmission and reception of data by means of the network interface device comprises protocol processing of data received from the network by the network interface device and stored in the said at least one of the areas. The protocol processing may comprise one or more of extracting traffic data from the received data transmitting an acknowledgement and or re transmit message over the network in respect of at least some of the received data checking sequence values of received data units in the received data and calculating checksums in respect of the received data. The protocol may be TCP.

Preferably the method comprises reading data from the said at least one of the areas by means of the network device and transmitting that data over the network by means of the network device.

Preferably each of the said steps of directly accessing at least one of the areas of the memory for at least one of transmission and reception of data by means of the network interface device comprises storing data for transmission in the said at least one of the areas.

Preferably each of the said steps of directly accessing at least one of the areas of the memory for at least one of transmission and reception of data by means of the network interface device comprises triggering the network interface device to perform the said step of reading data from the said at least one of the areas.

Preferably the network device is configured to signal the operating system to access the said at least one of the areas if the application is determined to be unresponsive and the method comprises performing the said step of directly accessing the said at least one of the areas of the memory by means of the operating system in responsive to such a signal.

According to a further aspect of the present invention there is provided a system for performing any of the methods described above.

The following description is presented to enable any person skilled in the art to make and use the invention and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present invention. Thus the present invention is not intended to be limited to the embodiments shown but is to be accorded the widest scope consistent with the principles and features disclosed herein.

The principal differences between the architecture of the example of and conventional architectures are as follows.

It should be noted that the TCP support code for the network interface device is in addition to the generic OS TCP implementation. This is suitably able to co exist with the stack of the network interface device.

In the architecture of buffers are allocated in memory on the data processor for use in cooperation with the NIC for the transmission and or reception of data over the network. In the case of a transmit buffer which is for use in transmitting data the NIC is configured for reading data from that buffer and transmitting it over the network. The NIC may automatically read that data and transmit it or it may be triggered to read the data by an application or the operating system running on the data processor. The trigger can conveniently be an interrupt. In the case of a receive buffer which is for use in receiving data the NIC is configured for writing to that buffer data received over the network. The data in the receive buffer may then be read by the application or the operating system and further processed by it.

The buffers are most conveniently owned by the operating system in the sense that it has control over which entities have access to the buffers it has allocated and or created the buffers and it is responsible for deleting them. However both the application and the operating system can directly access the buffers for reading data from and writing data to them. The circumstances in which these steps occur will be described below.

In the case of transmission of data the application will be expected to write data to a buffer for transmission and then trigger the NIC to read from the buffer to transmit that data. In some situations this alone may be sufficient to allow the data to be transmitted successfully over the network. However the NIC does not perform protocol processing of transmitted or received data. Instead it is performed by the application or the operating system. Therefore if for instance the data is not received successfully by the intended recipient the application or the operating system must process acknowledgements retransmission requests etc. according to the protocol in use and cause the NIC to perform retransmission. Normally this can be expected to be done by the application. When the NIC has data such as an acknowledgement message or a timeout for the application it writes that either to a receive buffer and or an event queue. At the same time it starts a timer running. When the application accesses the data it stops and resets the timer. In that way the NIC knows that the application is responsive. However if the timer reaches a predetermined value then the NIC determines that the application is unresponsive and signals the operating system for example by means of an interrupt to handle the data for the application. This has a number of advantages. First the transmission of the data can be progressed by the operating system even if the application is busy or has been descheduled. Second it gives the application the opportunity to intentionally ignore the data for example by having itself descheduled once it has placed it on the transmit queue since the operating system will take over if necessary. Preferably the application controls the length of the timer for example by setting its initial value. This allows the application to set the timer to suit its priority. The timer is preferably a hardware resource on the NIC to which the application has direct access.

In the case of reception of data the NIC will receive the data and write it to a receive buffer. When doing so it will set a timer as described above and preferably inform the application via an event queue. When the application access the data it resets the timer as described above. This again gives the NIC the possibility of determining when the application is unresponsive. Other means such as periodic scans of the data in the buffer by the NIC could be used for the same purpose if the application is determined to be unresponsive then again the NIC signals the operating system to process the received data. In the case of received data the processing by either the application or the operating system will typically involve protocol processing e.g. checking of packet sequence numbers processing checksums extracting traffic data and or signalling the NIC to transmit an acknowledgement or retransmission request and or removal of data from the buffer for use typically at user level.

Whilst the buffers are preferably allocated by the operating system it is convenient for that to be done in response to a request from an application. Thus if the received data might overflow the available receive buffers for an application the application can request allocation of further buffers by the operating system. The NIC may signal the application by means of an event if this situation arises based on pre stored rules taking into account factors such as the amount of received buffer that remains free. Again it may set a timer when this signalling takes place and if the application does not respond then the NIC can transmit a request to the operating system for a further receive buffer. The operating system can then allocate that buffer and inform the NIC of it so that data can continue to be received for the application even if it is unresponsive.

This requirement is not present for the architecture of since TCP code can either be executed in the transport library as a result of a system API call e.g. recv see step i of or by the kernel as a result of a timer event see step ii of . In ether case the VI virtual interface can be managed and both code paths may access connection state or data buffers whose protection and mutual exclusion may be managed by shared memory locks. As well as allowing the overheads of thread switching at the transport library level to be removed this feature can prevent the requirement for applications to change their thread and signal handling assumptions for example in some situations it can be unacceptable to require a single threaded application to link with a multi threaded library.

This requirement is not present for the architecture of because the network interface device can implement a number of timers which may be allocated to particular virtual interface instances for example there may be one timer per active TCP transport library. These timers can be made programmable see step iii of through a memory mapped VI and result in events see step iv of being issued. Because timers can be set and cleared without a system call without directly involving the operating system the overhead for timer management is greatly reduced.

The network interface device can contain or have access to content addressable memory which can match bits taken from the headers of incoming packets as a parallel hardware match operation. The results of the match can be taken to indicate the destination virtual interface which must be used for delivery and the hardware can proceed to deliver the packet onto buffers which have been pushed on the VI. One possible arrangement for the matching process is described below. The arrangement described below could be extended to de multiplex the larger host addresses associated with IPv6 although this would require a wider CAM or multiple CAM lookups per packet than the arrangement as described.

One alternative to using a CAM for this purpose is to use a hash algorithm that allows data from the packets headers to be processed to determine the virtual interface to be used.

When a network connection is handed over the same system wide resource handle can be passed between the applications. This could for example be a file descriptor. The architecture of the network interface device can attach all state associated with the network connection with that e.g. file descriptor and require the transport library to memory map on to this state. Following a handover of a network connection the new application whether as an application thread or process even if it is executing within a different address space is able to memory map and continue to use the state. Further by means of the same backing primitive as used between the kernel and transport library any number of applications are able to share use of a network connection with the same semantics as specified by standard system APIs.

This step can be achieved in the architecture of the network interface device because connection state and protocol code can remain kernel resident. The OS kernel code can be informed of the change of state of an application in the same manner as the generic TCP TCPk protocol stack. An application which is stopped will then not provide a thread to advance protocol execution but the protocol will continue via timer events for example as is known for prior art kernel stack protocols.

There are a number newly emerging protocols such as IETF RDMA and iSCSI. At least some of these protocols were designed to run in an environment where the TCP and other protocol code executes on the network interface device. Facilities will now be described whereby such protocols can execute on the host CPU i.e. using the processing means of the computer to which a network interface card is connected . Such an implementation is advantageous because it allows a user to take advantage of the price performance lead of main CPU technology as against co processors.

Protocols such as RDMA involve the embedding of framing information and cyclic redundancy check CRC data within the TCP stream. While framing information is trivial to calculate within protocol libraries CRC s in contrast to checksums are computationally intensive and best done by hardware. To accommodate this when a TCP stream is carrying an RDMA or similar encapsulation an option in the virtual interface can be is enabled for example by means of a flag. On detecting this option the NIC will parse each packet on transmission recover the RDMA frame apply the RDMA CRC algorithm and insert the CCRC on the fly during transmission. Analogous procedures can beneficially be used in relation to other protocols such as iSCSI that require computationally relatively intensive calculation of error check data.

In line with this system the network interface device can also verify CRCs on received packets using similar logic. This may for example be performed in a manner akin to the standard TCP checksum off load technique.

Protocols such as RDMA also mandate additional operations such as RDMA READ which in conventional implementations require additional intelligence on the network interface device. This type of implementation has led to the general belief that RDMA TCP should best be implemented by means of a co processor network interface device. In an architecture of the type described herein specific hardware filters can be encoded to trap such upper level protocol requests for a particular network connection. In such a circumstance the NIC can generate an event akin to the timer event in order to request action by software running on the attached computer as well a delivery data message. By triggering an event in such a way the NIC can achieve the result that either the transport library or the kernel helper will act on the request immediately. This can avoid the potential problem of kernel extensions not executing until the transport library is scheduled and can be applied to other upper protocols if required.

One advantage that has been promoted for co processor TCP implementations is the ability to perform zero copy operations on transmit and receive. In practice provided there is no context switch or other cache or TLB transmit look aside buffer flushing operations on the receive path as for the architecture described above there is almost no overhead for a single copy on receive since this serves the purpose of loading the processor with received data. When the application subsequently accesses the data it is not impacted by cache misses which would otherwise be the case for a zero copy interface.

However on transmit a single copy made by the transport library does invoke additional overhead both in processor cycles and in cache pollution. The architecture described above can allow copy on send operations to be avoided if the following mechanisms are for example implemented 

The transport library can simply retain sent buffers until the data from them is acknowledged and data transmitted without copying. This can also be done when asynchronous networking APIs are used by applications.

Even where data copy is unavoidable the transport library can use memory copy routines which execute non temporal stores. These can leave copied data in memory rather than cache thus avoiding cache pollution. The data not being in cache would not be expected to affect performance since the next step for transmission will be expected to be DMA of the data by the network interface device and the performance of this DMA operation is unlikely to be affected by the data being in memory rather than cache.

The network interface device can preferably in hardware interrupt or buffer the flow of incoming packets in order that it can in effect pause the network header. This allows it to identify relevant bit sequences in incoming packets without affecting the flow of data. For TCP and or UDP packets the identification of bit sequences may for example be implemented using a simple decode pipeline because of the simple header layout of such packets. This results in a number of fields held in registers.

It is assumed that zero is neither a valid port number nor a valid IP address and that interfaces in separate processes do not share a local IP address and port pair except where a socket is shared after a fork command or the equivalent . The latter condition means it is safe to disregard the local IP address when demultiplexing received TCP packets.

For a listening TCP socket only the local IP and port number need be considered whereas for an established TCP socket remote IP and both port numbers should be considered. The processing performed by the network interface device should therefore conveniently in hardware determine whether a received packet is a TCP or a UDP packet and for TCP packets must inspect the SYN and ACK bits. It can then form a token accordingly which is looked up in the CAM. The operation of the CAM is illustrated in the following table 

In this table the first column indicates the type of received packet and the remaining columns indicate the content of the first 32 bits of the token the next 16 bits and the final 16 bits respectively. The order of the bits is immaterial provided the same convention is used consistently.

In the examples number 1 illustrates the situation for a local web serve listening on 192.168.123.135 80 number 2 illustrates the situation for a connection accepted by that server from 66.35.250.150 33028 number 3 illustrates a telnet connection to 66.35.250.150 initiated locally and number 4 illustrates the situation for an application receiving UDP packets on port 123.

By separating out the situation where TCP SYN 1 ACK 0 as in the first row of table 1 it can be ensured that such entries match TCP connection request messages destined for sockets in the LISTEN state but do not match connection replies which are destined for sockets in the SYN SENT state .

Other combinations of zero fields could be used to demultiplex on other fields. For example demultiplexing could be performed on the ETHER TYPE field of the Ethernet header.

The logic that determines the configuration of the CAM filter depends on the protocol s that is are to be used. In a practical implementation the CAM could be configured through a virtual interface by means of transport library code allowing it to be set up dynamically for a particular implementation.

Under the UDP protocol each network end point specified in a UDP packet can be uniquely identified by the filter as illustrated in table 1.

Under the TCP protocol the unique identity of an endpoint would normally require all host and port fields in order for it to be unambiguously specified. This requirement arises because the TCP protocol definition allows multiple clients to connect to network endpoints with the same destination host and port addresses a connection to be initiated from either the client or the server or a server network endpoint to accept connection requests on a single endpoint and to spawn new network endpoints to handle the data transfer.

The header in such packets is typically 96 bits long. However constructing a 96 bit filter is inefficient for most commercially available CAMs since they are typically available with widths of 64 or 128 rather than 96 bits. The following mechanism enables 64 bit filters to be constructed more efficiently. The length of the CAM may be chosen to suit the application. A convenient size may be 16 kb.

Note that in this case the identity of the DEST destination host is no longer required in order to identify the correct destination transport library although the library will in the normal course of reception check this field as part of its normal packet validation procedure. This procedure is illustrated with respect to the server passive connection the contents of the CAM programmed by the server transport library and the filters presented to the CAM by the NIC on each packet as illustrated in . This involves the following steps 

As a result of the connect packet the server application may create another network endpoint to handle the network connection. This endpoint may be within its own or another application context and so may be managed by another transport library. In either case a network connection can be created which joins 

This encoding can similarly be employed for active client connections initiated by the host and for all models of communication specified in the TCP and UDP protocol specifications.

One notable benefit of the encoding scheme is that it enables the hardware to determine the address of the virtual interface using only one CAM lookup.

The network interface device preferably also supports a mode of operation in which it simply de multiplexes packets onto transport libraries rather than on to network endpoints. This may be beneficial where the device is handling communications between a network and a server which is required to service large numbers e.g. millions of connections with the network simultaneously. Examples of this may be high capacity web server nodes. Two options are available. One option is to store only filters of the form 

The network interface card could be embodied as a physical card or it could be implemented in another way for example as an integrated circuit that is incorporated on to the motherboard of a data processing device.

In this way TCP IP and UDP IP packets can both be matched using 64 bits of CAM as opposed to the 128 bits that would be required if a standard sized CAM using bit by bit matching over the whole header were to be used.

The applicant hereby discloses in isolation each individual feature described herein and any combination of two or more such features to the extent that such features or combinations are capable of being carried out based on the present specification as a whole in the light of the common general knowledge of a person skilled in the art irrespective of whether such features or combinations of features solve any problems disclosed herein and without limitation to the scope of the claims. The applicant indicates that aspects of the present invention may consist of any such individual feature or combination of features. In view of the foregoing description it will be evident to a person skilled in the art that various modifications may be made within the scope of the invention.

