---

title: Combined speech and alternate input modality to a mobile device
abstract: A method of entering information into a mobile device includes receiving a multi-word speech input from a user, performing speech recognition on the speech input to obtain a multi-word speech recognition result, and sequentially displaying, in a display, words in the speech recognition result for user confirmation or correction, by adding one word at a time to the display. A next word is only displayed after user confirmation or correct has been received for a previously displayed word that is immediately preceding the next word in the speech recognition result. The method also includes calculating a hypothesis lattice indicative of a plurality of speech recognition hypotheses based on the speech input and, prior to finishing calculating the hypothesis lattice and while continuing to calculate the hypothesis lattice, calculating a preliminary hypothesis lattice indicative of only partial speech recognition hypotheses based on the speech input and outputting the preliminary hypotheses lattice.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07941316&OS=07941316&RS=07941316
owner: Microsoft Corporation
number: 07941316
owner_city: Redmond
owner_country: US
publication_date: 20051028
---
Text entry on relatively small mobile devices such as cellular telephones and personal digital assistants is growing in popularity due to an increase in use of applications for such devices. Some such applications include electronic mail e mail and short message service SMS .

However mobile phones personal digital assistants PDAs and other such mobile devices in general do not have a keyboard which is as convenient as that on a desktop computer. For instance mobile phones tend to have only a numeric keypad on which multiple letters are mapped to the same key. Some PDAs have only touch sensitive screens that receive inputs from a stylus or similar item.

Thus such devices currently provide interfaces that allow a user to enter text through the numeric keypad or touch screen or other input device using one of a number of different methods. One such method is a deterministic interface known as a multi tap interface. In the multi tap interface the user depresses a numbered key a given number of times based upon which corresponding letter the user desires. For example when a keypad has the number 2 key corresponding to the letters abc the keystroke 2 corresponds to a the keystrokes 22 correspond to b the keystrokes 222 correspond to c and the keystrokes 2222 correspond to the number 2 . In another example the keystroke entry 8 44 444 7777 would correspond to the word this .

Another known type of interface is a predictive system and is known as the T9 interface by Tegic Communications. The T9 interface allows a user to tap the key corresponding to a desired letter once and uses the previous keystroke sequence to predict the desired word. Although this reduces the number of key presses this type of predictive interface suffers from ambiguity that results from words that share the same key sequences. For example the key sequence 4663 could correspond to the words home good gone hood or hone . In these situations the interface displays a list of predicted words generated from the key sequence and the user presses a next key to scroll through the alternatives. Further since words outside the dictionary or outside the vocabulary of the interface cannot be predicted T9 type interfaces are often combined with other fallback strategies such as multi tap in order to handle out of vocabulary words.

Some current interfaces also provide support for word completion and word prediction. For example based on an initial key sequence of 466 which corresponds to the letters goo one can predict the word good . Similarly from an initial key sequence 6676 which corresponds to the letters morn one can predict the word morning . Similarly one can predict the word a as the next word following the word sequence this is based on an n gram language model prediction.

None of these interfaces are truly susceptible of any type of rapid text entry. In fact novice users of these methods often achieve text entry rates of only 5 10 words per minute.

In order to increase the information input bandwidth on such communication devices some devices implement speech recognition. Speech has a relatively high communication bandwidth which is estimated at approximately 250 words per minute. However the bandwidth for text entry using conventional automatic speech recognition systems is much lower in practice due to the time spent by the user in checking for and correcting speech recognition errors which are inevitable with current speech recognition systems.

In particular some current speech based text input methods allow users to enter text into cellular telephones by speaking an utterance with a slight pause between each word. The speech recognition system then displays a recognition result. Since direct dictation often results in errors especially in the presence of noise the user must select mistakes in the recognition result and then correct them using an alternatives list or fallback entry method.

Isolated word recognition requires the user to speak only one word at a time. That one word is processed and output. The user then corrects that word. Although isolated word recognition does improve recognition accuracy an isolated word recognition interface is unnatural and reduces the data entry rate over that achieved using continuous speech recognition in which a user can speak an entire phrase or sentence at one time.

However error correction in continuous speech recognition presents problems. Traditionally speech recognition results for continuous speech recognition have been presented by displaying the best hypothesis for the entire phrase or sentence. To correct errors the user then selects the misrecognized word and chooses an alternative from a drop down list. Since errors often occur in groups and across word boundaries many systems allow for correcting entire misrecognized phrases. For example the utterance can you recognize speech may be incorrectly recognized as can you wreck a nice beach . In this case it is simply not possible to correct the recognition a word at a time due to incorrect word segmentation. Thus the user is required to select the phrase wreck a nice beach and choose an alternate for the entire phrase.

While such an approach may work well when recognition accuracy is high and a pointing device such as a mouse is available it becomes cumbersome on mobile devices without a pointer and where recognition accuracy cannot be assumed given typically noisy environments and limited processor capabilities. On a device with only hardware buttons a keypad or a touch screen or the like it is difficult to design an interface that allows users to select a range of words for correction while keeping keystrokes to a reasonable number.

The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.

The present invention uses a combination of speech and alternate modality inputs such as keypad inputs to transfer information into a mobile device. The user speaks an utterance which includes multiple words such as a phrase or sentence . The speech recognition result is then presented to the user one word at a time for confirmation or correction. The user is presented on screen with the best hypothesis and a selection list for one word at a time beginning with the first word. If the best hypothesis word presented on the screen is correct the user can simply indicate that. Otherwise if the desired word is in the alternatives list the user can quickly navigate to the alternatives list and enter the word using one of a variety of alternate input modalities with very little effort on the part of the user e.g. with few button depressions keystrokes etc. .

In one embodiment the user can start entering the word using a keypad if it is not found on the alternatives list. Similarly in one embodiment the system can recompute the best hypothesis word and the alternates list using the a posteriori probability obtained by combining information from the keypad entries for the prefix of the word the speech recognition result lattice words prior to the current word which have already been corrected a language model etc. This process can be repeated for subsequent words in the input sentence.

Other input modalities such as a soft keyboard touch screen inputs handwriting inputs etc. can be used instead of the keypad input or in addition to it.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

The present invention deals with combining speech and alternate input modalities in order to improve text entry efficiency and robustness on mobile devices. However prior to describing the present invention in more detail one illustrative environment in which the present invention can be used will be described.

Computing device shown below in typically includes at least some form of computer readable media. Computer readable media can be any available media that can be accessed by device . By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which are part of or can be accessed by device . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any tangible information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

Memory is implemented as non volatile electronic memory such as random access memory RAM with a battery back up module not shown such that information stored in memory is not lost when the general power to the mobile device is shut down. A portion of memory is allocated as addressable memory for program execution while other portions of memory can be used for storage such as to simulate storage on a disk drive.

Memory includes an operating system application programs such as user interface applications personal information managers PIMs scheduling programs word processing programs spreadsheet programs Internet browser programs and speech recognition programs discussed below a user interface component and an object store . During operation the operating system is loaded into and executed by the processor from memory . The operating system in one embodiment is a Windows CE brand operating system commercially available from Microsoft Corporation. The operating system can be designed for mobile devices and implements features which can be utilized by PIMs content viewers speech recognition functions etc. This can be done in any desired way such as through exposed application programming interfaces or through proprietary interfaces or otherwise. The objects in object store can be maintained by PIMs content viewers and the operating system at least partially in response to calls thereto.

User interface component illustratively interacts with other components to provide output displays to a user and to receive inputs from the user. One embodiment of the operation of user interface component in receiving user inputs as combinations of speech and keypad inputs is described below with respect to .

The I O components in one embodiment are provided to facilitate input and output operations from the user of the mobile device . Such components can include among other things displays touch sensitive screens keypads the microphone speakers audio generators vibration devices LEDs buttons rollers or other mechanisms for inputting information to or outputting information from device . These are listed by way of example only. They need not all be present and other or different mechanisms can be provided. Also other communication interfaces and mechanisms can be supported such as wired and wireless modems satellite receivers and broadcast tuners to name a few.

The desktop computer communication interface is optionally provided as any suitable and commercially available communication interface. The interface is used to communicate with a desktop or other computer when wireless transceiver is not used for that purpose. Interface can include for example an infrared transceiver or serial or parallel connection.

The transceiver is a wireless or other type of transceiver adapted to transmit signals or information over a desired transport. In embodiments in which transceiver is a wireless transceiver the signals or information can be transmitted using antenna . Transceiver can also transmit other data over the transport. In some embodiments transceiver receives information from a desktop computer an information source provider or from other mobile or non mobile devices or telephones. The transceiver is coupled to the bus for communication with the processor to store information received and to send information to transmit.

A power supply includes a battery for powering the mobile device . Optionally the mobile device can receive power from an external power source that overrides or recharges the built in battery . For instance the external power source can include a suitable AC or DC adapter or a power docking cradle for the mobile device .

It will be noted that illustrates an example of a suitable operating environment shown in in which the invention may be implemented. The operating environment shown in is only one example of a suitable operating environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Other well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to cellular telephones personal digital assistants pagers hand held or laptop devices multiprocessor systems microprocessor based systems programmable consumer electronics distributed computing environments that include any of the above systems or devices and the like.

It will also be noted that the invention may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

The mobile device shown in also includes a number of user input keys or buttons such as scroll buttons and or keyboard which allow the user to enter data or to scroll through menu options or other display options which are displayed on display without contacting the display . In addition the mobile device shown in also includes a power button which can be used to turn on and off the general power to the mobile device .

It should also be noted that in the embodiment illustrated in the mobile device can include a hand writing area . Hand writing area can be used in conjunction with the stylus such that the user can write messages which are stored in memory for later use by the mobile device . In one embodiment the hand written messages are simply stored in hand written form and can be recalled by the user and displayed on the display such that the user can review the hand written messages entered into the mobile device . In another embodiment the mobile device is provided with a character recognition module such that the user can enter alpha numeric information into the mobile device by writing that alpha numeric information on the area with the stylus . In that instance the character recognition module in the mobile device recognizes the alpha numeric characters and converts the characters into computer recognizable alpha numeric characters which can be used by the application programs in the mobile device .

In one embodiment device also includes a speech recognition system which will be described in greater detail below with respect to so that the user can enter speech information into device through microphone . Similarly device illustratively includes an interface run by interface component in which allows a user to combine speech and keypad inputs to enter information into device . This improves text entry efficiency and robustness particularly on mobile devices which do not have conventional keyboards. This is described in greater detail below with respect to .

In a speaker either a trainer or a user speaks into a microphone . The audio signals detected by microphone are converted into electrical signals that are provided to analog to digital A to D converter .

A to D converter converts the analog signal from microphone into a series of digital values. In several embodiments A to D converter samples the analog signal at 16 kHz and 16 bits per sample thereby creating 32 kilobytes of speech data per second. These digital values are provided to a frame constructor which in one embodiment groups the values into 25 millisecond frames that start 10 milliseconds apart.

The frames of data created by frame constructor are provided to feature extractor which extracts a feature from each frame. Examples of feature extraction modules include modules for performing Linear Predictive Coding LPC LPC derived Cepstrum Perceptive Linear Prediction PLP Auditory model feature extraction and Mel Frequency Cepstrum Coefficients MFCC feature extraction. Note that the invention is not limited to these feature extraction modules and that other modules may be used within the context of the present invention.

The feature extraction module produces a stream of feature vectors that are each associated with a frame of the speech signal.

Noise reduction can also be used so the output from extractor is a series of clean feature vectors. If the input signal is a training signal this series of clean feature vectors is provided to a trainer which uses the clean feature vectors and a training text to train an acoustic model or other models as described in greater detail below.

If the input signal is a test signal the clean feature vectors are provided to a decoder which identifies a most likely sequence of words based on the stream of feature vectors a lexicon a language model and the acoustic model . The particular method used for decoding is not important to the present invention and any of several known methods for decoding may be used.

The most probable sequence of hypothesis words is provided as a speech recognition lattice to a confidence measure module . Confidence measure module identifies which words are most likely to have been improperly identified by the speech recognizer based in part on a secondary acoustic model not shown . Confidence measure module then provides the sequence of hypothesis words in the lattice to an output module along with identifiers indicating which words may have been improperly identified. Those skilled in the art will recognize that confidence measure module is not necessary for the practice of the present invention.

In accordance with one embodiment of the invention the interface allows a user to combine both speech inputs and alternate modality inputs in order to input information into device . The alternate modality inputs can be inputs using any of the above described modalities soft keyboard touch screen inputs handwriting recognition etc. . However the alternate modality inputs will be described herein in terms of keypad inputs for the sake of example only. Therefore in accordance with one embodiment the user first activates the speech recognition system on device such as by holding down a function button or actuating any other desired button on the user interface to provide an activation input . This is indicated by block in . Next the user speaks a multi word speech input such as a phrase or sentence into microphone on device and the speech recognition system within device receives the multi word speech input . This is indicated by block in . Speech recognition system generates speech recognition results in the form of a hypothesis lattice and provides lattice to user interface component . Next user interface component sequentially displays at user interface display the speech recognition results one word at a time for user confirmation or correction using the keypad . This is indicated by block in . The user illustratively uses the keys on keypad to either correct each word as it is displayed in sequence or confirms that the word is correct. As the sequential commit continues corrected or confirmed words are displayed and a next sequential word is added to the display for correction or confirmation. This continues until the entire speech recognition result is displayed.

At first glance the combination of continuous speech recognition with a word by word correction mechanism sometimes referred to herein as a sequential commit mechanism may appear to be sub optimal and is certainly counter intuitive. However it is believed that this contributes to a better overall user experience given current automatic speech recognition systems on mobile devices.

For instance automatic speech recognition errors often involve segmentation errors. As discussed in the background section the hypothetical phrase recognized speech may be misrecognized by an automatic speech recognition system as wreck a nice beach . In this case showing the full automatic speech recognition result leads to difficult choices for the correction interface. Some questions which this leads to are Which words should the user select for correction When the user attempts to correct the word wreck should it cause the rest of the phrase in the speech recognition result to change How would it affect the confidence level of the user if other words begin changing as a side effect of user corrections to a different word 

All of these questions must be resolved in designing the interface and an optimum solution to all of these questions may be very difficult to obtain. Similarly in addressing each of these questions and providing user interface options for the user to resolve them often results in a relatively large number of keystrokes being required for a user to correct a misrecognized sentence or phrase.

By contrast substantially all of these issues are avoided by presenting word by word results sequentially from left to right for either user confirmation or correction. In the hypothetical misrecognition of wreck a nice beach the present invention would first present only the word wreck on the display portion of device for user confirmation or correction. Along with the word wreck the present system would illustratively display alternates as well. Therefore the recognition result would likely include recognize as the second alternate to the word wreck . Once the user has corrected wreck to recognize the present system illustratively recalculates probabilities associated with the various speech recognition hypotheses and would then output the next word as speech as the top hypothesis instead of a given the context of the previous correction wreck to recognize made by the user.

In one illustrative embodiment and as shown in the display portion displays the speech recognition results along with a drop down menu which displays the various alternates for the word currently being confirmed or corrected. The user might simply actuate an Ok button if the displayed word in the speech recognition result is correct or the user can scroll down through the various alternates shown in drop down menu and select the correct alternate for the displayed word. In the embodiment illustrated the Ok button can be in the function button cluster or it can on keypad or it can be one of buttons etc. Of course other embodiments can be used as well.

More specifically in the example shown in with device the user has entered the speech input this is speech recognition . The system has then displayed to the user the first word this and it has been confirmed by the user. The system in is shown having displayed the second word in the recognition hypothesis to the user and the user has selected is from the alternates list in drop down menu . The system then recomputes the probabilities associated with the various recognition hypotheses in order to find the most likely word to be displayed as the third word in the hypothesis which is not yet shown in .

In one illustrative embodiment the alternates drop down menu is a floating list box that appears under the current insertion point in the hypothesized speech recognition results and a currently selected prediction is displayed in line with the recognition result. The display is formatted to highlight the specified prefix. In addition in one illustrative embodiment the height of the list in box may be set to any desirable number and it is believed that a list of approximately four visible items limits the amount of distraction the prediction list introduces. Similarly the width of drop down menu can be adjusted to the longest word in the list. Further if the insertion point in the recognition result is too close to the boundary of the document window such that the list box in drop down menu extends beyond the boundary the insertion point in the recognition result and the prediction list in drop down menu can wrap to the next line.

Receiving the user confirmations or corrections as keypad inputs through the keypad is shown by block in . Of course it will be noted that the user can provide the keypad inputs in a variety of different ways other than simply selecting an alternate from the alternates drop down menu .

With perfect speech recognition the user need only press Ok for each correctly recognized word yielding very efficient text entry. However with imperfect speech recognition the user presses Ok for the correctly recognized words and can either scroll down to a desired alternate and select it from the alternates menu or can begin to spell the correct word one letter at a time until the desired word shows up in the prediction list in drop down menu for misrecognized words.

The suggested word and the alternates first displayed to the user based on the various user inputs just described are illustratively taken from hypothesis lattice generated from the speech recognition system in response to the speech input . However it may happen that the speech recognition system has misrecognized the speech input to such an extent that the correct word to be displayed actually does not appear in the hypothesis lattice . To handle words that do not appear in the lattice predictions from the hypothesis lattice can be merged with predictions from a language model such as an n gram language model and sorted by probability. In this way words in the vocabulary of the speech recognition system even though they do not appear in the hypothesis lattice for the recognition result can often be entered without spelling out the entire word an in some cases without typing a single letter. This significantly reduces the keystrokes required to enter words not found in the original recognition lattice .

It may also happen that the word entered by the user not only does not appear in the recognition lattice but does not appear in the lexicon or vocabulary of the speech recognition system . In that case user interface component in one embodiment is configured to switch to a deterministic letter by letter entry configuration that allows the user to spell the words through keypad that are out of vocabulary. Such letter by letter configurations can include for instance a multi tap input configuration or a keyboard input configuration.

For the keyboard configuration device shown in includes soft keyboard key . When that key is actuated by a user a display of a keyboard is shown and the user can simply use hunt and peck using a stylus to enter words letter by letter that are not in the original vocabulary of the speech recognition system . Those words can then be added to the vocabulary as desired.

Similarly instead of having a constantly displayed keyboard button a keyboard option may be provided at the end of the alternates display in drop down menu or at any other position in the drop down menu . When the user actuates that option from the alternates list the keyboard is again displayed and the user can enter letters one at a time. Once the out of vocabulary word is committed the keyboard illustratively disappears and user interface component in device shifts back into its previous mode of operation which may be displaying one word at a time for confirmation or correction by the user as described above.

Speech recognition latency can also be a problem on mobile devices. However because the present system is a sequential commit system in that it provides the speech recognition results to the user for confirmation or correction one word at a time beginning at the left of the sentence and proceeding to the right the present system can take advantage of intermediate automatic speech recognition hypotheses that are generated from an incomplete hypothesis lattice. In other words the present system can start presenting the word hypotheses one at a time to the user before the automatic speech recognition system has completely finished processing the entire hypothesis lattice for the speech recognition result. Thus the present system can display to the user the first hypothesized word in the speech recognition result after an initial timeout period such as milliseconds or any other desired timeout period but before the speech recognition system has generated a hypothesis for the full text fragment or sentence input by the user. This allows the user to begin correcting or confirming the speech recognition result with a very short latency even though current mobile devices have relatively limited computational resources.

The decoder then determines whether the lattice calculation is complete. This is indicated by block . If not it is determined whether the predetermined timeout period has lapsed. This is indicated by block . In other words even though the complete hypothesis lattice has not been computed the present system will output an intermediate lattice after a pre designated timeout period. Therefore if at block the timeout period has lapsed then the preliminary hypothesis lattice is output by the system and the interface component displays the first hypothesized word in the speech recognition result from the preliminary hypothesis lattice to the user. This is indicated by block in .

During this time the decoder continues to calculate the full hypothesis lattice at block . However the interface component illustratively keeps presenting words to the user for confirmation or correction using the preliminary hypothesis lattice until the full hypothesis lattice is complete. Once the full hypothesis lattice is complete the complete lattice is output for use by the interface component in sequentially presenting words one word at a time to the user for confirmation or correction. This is indicated by block in .

In one alternative embodiment as the decoder is calculating the hypothesis lattice and after it has calculated the preliminary lattice any user confirmations or corrections to the speech recognition result are feedback to the decoder such that it can complete processing the hypothesis lattice taking into account the user confirmation or correction information. This is indicated by block . By providing the committed word sequence to the recognizer this provides information that can be used by the recognizer to narrow the search space. In fact with this information the recognizer can prune all search paths that are not consistent with the committed word sequence to significantly speed up the search process. Of course search path pruning not only speeds up the search but also improves the accuracy by allowing the engine to search more paths consistent with the already committed word sequence that would otherwise possibly be pruned.

An example may enhance understanding at this point. Assume that the user has activated the speech recognition system on device . Assume further that the user has entered the multi word speech input this is speech recognition into the device through its microphone . The automatic speech recognition system in device begins processing that speech input to create a hypothesis lattice indicative of the hypothesized speech recognition result and alternates. However before the entire hypothesis lattice has been calculated by the automatic speech recognition system a preliminary lattice may illustratively be calculated. illustrates one exemplary partial or preliminary hypothesis lattice generated from the exemplary speech input. The hypothesis lattice is generally indicated by numeral in . In accordance with one embodiment lattice is provided to the user interface component such that user interface component can begin presenting the words from the hypothesized speech recognition result to the user one word at a time for confirmation or correction.

Assume that from lattice the word this is the first word in the lattice that represents a best hypothesis word. The word this will therefore be presented to the user for confirmation or correction. illustrates a portion of display of device showing that the word this is presented to the user along with the alternates from hypothesis lattice presented in order of probability score in drop down menu . The alternates listed in menu are Miss and Mrs. . It can be seen from lattice that these are the other possible alternates to this from the lattice. The user can then either accept the displayed result this by simply actuating the Ok button or the user can select one of the alternates as described above.

During the time that the user is making a selection to either confirm or correct the displayed speech recognition result the decoder is continuing to process the speech input in order to complete computation of the speech recognition lattice. This may only take on the order of seconds. Therefore it is likely that even before the user has corrected or confirmed one or two word hypothesis words the decoder will have completely calculated the entire hypothesis lattice.

It will also be noted that in the embodiment shown in drop down menu includes a keyboard option which can be actuated by the user in order to have a keyboard displayed such that the user can enter the word one letter at a time using a stylus or other suitable input mechanism.

The user interface component then outputs a best word hypothesis for the current word in the speech recognition result. For instance if this is the first word to be displayed to the user for correction or confirmation then the user interface component selects the best scoring word from the preliminary hypothesis lattice for the first word position in the speech recognition result and displays that to the user. This is indicated by block in and an example of this is illustrated in .

User interface component then receives the user correction or confirmation input with respect to the currently displayed word. This is indicated by block in . Again this can be by the user selecting an alternate from the alternate list by the user beginning to type a word that is not in the hypothesis lattice but that is still found in the dictionary or vocabulary used by the automatic speech recognition system or by the user entering a new word which was not previously found in the vocabulary or lexicon of the automatic speech recognition system .

It will be noted that in the second case where the user begins to type in a word not found in the hypothesis lattice but one that is found in the lexicon used by the automatic speech recognition system prefix feedback can be used. This is better illustrated in . Assume for instance that the correct word for the speech recognition result under consideration is demonstrates . Assume also that the word demonstrates did not appear in the hypothesis lattice generated by the automatic speech recognition system based on the speech input . However assume that the word demonstrates is in the lexicon used by the automatic speech recognition system . In that case the user will begin typing the word such as by selecting the keyboard option or the multi tap input option one letter at a time. As the user enters each letter the automatic speech recognition system uses predictive word completions based on the prefix letters already entered. In one illustrative embodiment the system also highlights the letters which have been entered by the user so that the user can easily determine which letters have already been entered. It can be seen in that the user has entered the letters demon and the word demonstrates has been predicted.

It will also be noted that this option of entering the word one letter at a time can be used even where the word already appears in the hypothesis lattice. In other words instead of the user scrolling through the alternates list in the drop down menu in order to find the correct alternate the user can simply enter the input configuration which allows the user to enter the word one letter at a time. Based on each letter entered by the user the system recomputes the probabilities of various words and re ranks the displayed alternates based on the highest probability word given the prefixes.

In one embodiment in order to rerank the words reranking is performed not only based on the prefix letters already entered by the user but also on the words appearing in this word position in the speech recognition hypothesis and also based on the prior words already confirmed or corrected by the user and further based on additional ranking components such as a context dependent component e.g. an n gram language model given the context of the previous words recognized by the user and given the prefix letters entered by the user.

In any case receiving the user correction or confirmation input is indicated by block in . User interface component corrects or confirms the word based on the user input as indicated by block in .

If the word just confirmed or corrected is one of the first few words in the speech recognition result it may be that the user interface component is providing hypothesis words to the user based on a preliminary lattice as described above with respect to . Therefore it is determined whether the complete lattice has been received. This is indicated by block in . If so then the complete lattice is used for all future processing as indicated by block . If the complete lattice has not yet been received then the preliminary lattice is again used for processing the next word in the speech recognition result.

Once the current word being processed has been confirmed or corrected by the user the user interface component determines whether there are more words in the hypothesized speech recognition result. This is indicated by block in .

If so then the automatic speech recognition decoder recalculates the scores for each of the possible words that might be proposed as the next word in the speech recognition result. Again this recalculation of scores for the next word can be based on words already confirmed or corrected by the user based on the words found in the hypothesis lattice based on language model scores or based on other desired modeling scores.

In order to generate candidate words from the lattice it is first determined what set of candidate words are reachable from the initial lattice node through the confirmed sequence of words corresponding to this result. This list of words associated with outgoing arcs in the lattice from these candidate nodes form the candidate words predicted by the lattice. For instance in the lattice shown in assuming that the words this is have been confirmed or corrected by the user then the alternates possible given the already confirmed words in the speech recognition result are speech beach and bee .

To determine the probability of each candidate word the forward probability of each candidate node is computed by combining probabilities of matching paths using dynamic programming. For each candidate word transition the overall transition probability is computed from the posterior forward probability local transition probability and backwards score. The final probability of each candidate word is determined by combining the probabilities from corresponding candidate word transitions. In one embodiment probability combination can be computed exactly by adding the probabilities or estimated in the Viterbi style by taking the maximum. In order to reduce computation the candidate nodes and corresponding probabilities are computed incrementally as the user commits each word. It will be noted of course that this is but one way to calculate the scores associated with the next word in the speech recognition result. Recalculating the scores based on this information is indicated by block in .

If at block there are no more words to be processed then the speech recognition result is complete and processing has finished.

It can be seen that by combining keypad and speech inputs for text entry on a mobile device when a word is misrecognized the sequential commit paradigm outperforms traditional random access correction. It takes fewer keystrokes and the utterance allows the system to show word alternates with different segmentations while presenting the results in a very straight forward manner. Therefore when the correct recognition is represented by the recognition lattice users will not have to correct multi word phrases due to incorrect word segmentation resulting in even fewer keystrokes. This also avoids the issue of combinatorial explosion of alternates when multiple words are selected for correction.

Further knowledge of previously committed words allows the system to re rank the hypotheses according to their posterior probabilities based on language model and acoustic alignment with the committed words. Thus perceived accuracy is higher than traditional systems where the hypothesis for the remainder of the utterance cannot change after a correction. By displaying only the next word to be corrected and committed the sequential commit system improves perceived accuracy and leads to a reduction in keystrokes.

Similarly sequential commit is based on the one word at a time entry interface familiar to users of existing text input methods. In situations where speech input is not appropriate the user can simply skip the first step of speaking the desired utterance and start entering text using only the keypad. Thus the system is very flexible.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

