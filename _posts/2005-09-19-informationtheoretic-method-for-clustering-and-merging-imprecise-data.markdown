---

title: Information-theoretic method for clustering and merging imprecise data
abstract: An information-theoretic method clusters and merges bi-variate normal data or ‘error ellipses’ lying in a plane. Two or more error ellipses are clustered and then merged into a single error ellipse if the information lost in the merging process is sufficiently small. This criterion is numerically implemented and tested in a code developed for this purpose.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07590292&OS=07590292&RS=07590292
owner: BAE Systems Advanced Technologies, Inc.
number: 07590292
owner_city: Nashua
owner_country: US
publication_date: 20050919
---
The present invention claims priority to U.S. Provisional Application No. 60 610 693 entitled Information Theoretic Method For Clustering and Merging Imprecise Data filed on Sep. 17 2004 and listing as inventors William Peter and Donald Lemons.

This invention was made with United States Government support under Contract No. MDA 904 01 F 0371 with the Maryland Procurement Office and the United States Government has certain rights in this invention.

The present invention relates to methods for clustering and merging imprecise data and more particularly to methods for clustering and merging of imprecise data in the form of bivariate normal random variables.

Consider the problem of tracking with an imprecise measuring instrument the individual positions of a group of fish as they swim around in an effective two dimensional plane say near the surface of a lake. Furthermore supposing that reflections or rapid swimming during the measurement process cause multiple images of a single fish to be recorded. Because the data is imprecise each position is represented by a pair of random position variables. Therefore the problem of eliminating redundant positions referring to a single fish requires solving the equivalent analytical problem of first clustering and then merging multiple bi variate random variables.

Assuming that these bi variates are normal the random position associated with each piece of data is completely determined by two means two variances and a covariance. Alternatively each bi variate normal is represented by a particular error ellipse defined as a contour of constant probability density with given position size and orientation.

The present invention is an information theoretic solution to the problem of clustering and merging error ellipses. In particular ellipse are used only when such merging loses sufficiently little quantifiable information given that the replacement ellipse preserves the pooled means variances and covariances of the original ellipses. Limiting information loss provides a true similarity criterion since only ellipses that are similar in position size and orientation are merged. This criterion is robust and reduces to a single Boolean test that can be applied either pair wise sequentially or all at once to a group of ellipses. It is that using this criterion to merge and thus to eliminate redundancies in or to reduce and simplify bi variate normal data but it can also be used to cluster error ellipses without subsequent merging.

Cluster analysis has a long history and a large literature of application in the social and natural sciences as disclosed in Aldenderfer M. S. and Roger K. Blashfield Sage Newbury Park 1984 Everitt Brian Heinemann London 1974 and Kaufman Leonard and Peter J. Rousseeuw Wiley New York 1990 the contents all of which are incorporated herein by reference J. H. Ward s entropy criteria for hierarchically grouping data which is disclosed in Ward J. H. Hierarchical grouping to optimize an objective function J. Am. Statist. Ass. 58 236 244 1963 the contents of which is also incorporated herein by reference is also relevant to the present invention. However there are several important structural differences that distinguish typical cluster analysis techniques and the information theoretic method of the present invention. 1 Cluster analysis groups data conceived as realizations of random variables whereas in the present invention bi variate random variables as grouped. 2 Cluster analysis stops at forming groups of data whereas error ellipses are grouped in order to merge them into a single replacement ellipse. 3 And cluster analysis decides whether or not to group data by inspecting the group s statistical properties whereas in the present invention decisions are made by comparing the means variances and covariances of the ellipses to be clustered with those of their potential replacement ellipse.

Because each error ellipse in the x y plane represents a bi variate normal random variable each is uniquely described by two means and two variances and and one covariance . The probability density function of such a bi variate ellipse is

In the following the subscripts 1 2 and m are used to denote quantities associated with the two statistically independent bi variate normals 1 and 2 and the merged bi variate normal m. Thus the position coordinates X Y are described by p x y given by 1 with and or and X Y by p x y likewise given by 1 with and or . We assume that random variables Xand Yare statistically independent of variables Xand Yso that e.g. XX X X .

Points 1 and 2 are merged into the single point m described by the probability density P x y given by 1 with parameters and . These parameters are by definition identical to the means variances and covariance of the pooled probability density p x y p x y 2 i.e. p x y p x y p x y 2 through second order moments. Thus is defined by

In deciding whether to merge two error ellipses we compare the entropy or equivalently the missing information of the two error ellipses with the entropy of the single ellipse into which the two would be merged. Indeed it is only comparative entropies that can be coherently defined for continuous random variables. The so called self entropy of a continuous bi normal random variable with probability density p x y that is ln p x y or

For this reason another quantity the relative entropy of one ellipse with respect to another is exploited as disclosed in Jumarie G. Springer Verlag Berlin 1990 p. 36 the contents of which are incorporated herein by reference. In particular the relative entropy of ellipse 1 with respect to a reference ellipse 0 is defined by

The relative entropy generated when ellipse 1 and 2 are merged into a single ellipse m is given by the difference 0 1 0 2 0 9 between the relative entropy of the merged ellipse and the sum of the relative entropies of the two original ellipses. S 0 for any reference ellipse 0 and also that S is minimum when the merged ellipse m is identified with the reference ellipse 0 or vice versa. This optimization is adapted i.e. 0 m . Since the entropy of an ellipse relative to itself necessarily vanishes e.g. S m m 0 equation 9 becomes 1 2 . 10 Equation 10 is in turn equivalent to 11 However since the moments through second order of P x y are by definition identical to the moments through second order of p x y p x y 2 11 can also be written as 2 12 Thus the entropy generated S by merging two ellipses is the difference between the self entropy associated with two independent merged ellipses minus the self entropy associated with the two original ellipses. Given that each of the probability densities p x y p x y and p x y is that of a correlated bi variate normal 12 becomes

Suppose we wish to test whether or not a group of n ellipses representing n statistically independent bi variate normal variables should be clustered and merged. The generalization from two to many ellipses is quite straightforward. First we determine the parameters describing the merged ellipse in terms of the parameters describing the n unmerged ellipses via the data pooling algorithm. Thus 

While the present invention has been described in connection with the preferred embodiments of the various figures it is to be understood that other similar embodiments may be used or modifications and additions may be made to the described embodiment for performing the same function of the present invention without deviating therefrom. For example the invention may be implemented by a general purpose computer having a processor memory and computer program instructions stored therein. The equations for example may be implemented in a computer program product executed by the computer which causes the computer to process information received from for example a network a database or other memory and or sensors. The present invention should not be limited to any single embodiment but rather construed in breadth and scope in accordance with the recitation of the appended claims.

