---

title: Method and apparatus for visualizing three-dimensional and higher-dimensional image data sets
abstract: In one aspect, the invention provides improvements in a digital data processor of the type that renders a three-dimensional (3D) volume image data into a two-dimensional (2D) image suitable for display. The improvements include a graphics processing unit (GPU) that comprises a plurality of programmable vertex shaders that are coupled to a plurality of programmable pixel shaders, where one or more of the vertex and pixel shaders are adapted to determine intensities of a plurality of pixels in the 2D image as an iterative function of intensities of sample points in the 3D image through which a plurality viewing rays associated with those pixels are passed. The pixel shaders compute, for each ray, multiple iteration steps of the iterative function prior to computing respective steps for a subsequent ray.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08189002&OS=08189002&RS=08189002
owner: PME IP Australia Pty, Ltd.
number: 08189002
owner_city: Richmond, Victoria
owner_country: AU
publication_date: 20051031
---
The present invention claims priority to a U.S. provisional application entitled Method and Apparatus for Visualizing Three dimensional and Higher dimensional Image Data Sets filed Oct. 29 2004 and having a Ser. No. 60 623 411 the teachings of which are incorporated herein by reference.

The present invention relates to digital data processing and particularly to the visualization of three dimensional and higher dimensional images in two dimensions e.g. on a two dimensional display screen. The invention has application by way of non limiting example in medical imaging microscopy and geosciences to name but a few.

Three dimensional 3D volumetric images also referred to as stacks of 2D images occur in many disciplines like medicine geosciences or microscopy. Such 3D images can be acquired using machines like computer tomographs magnetic resonance imaging devices or confocoal microscopes or they can be the result of computation.

The visual perception of natural 3D density distributions like clouds or fire involves projection onto a 2D plane the retina. This process can be mimicked using a computer in order to compute a 2D projection of a 3D image and to display that on the computer screen thus simulating the perception of true physical 3D objects. The 3D image represented as a scalar function on a 3D volume can be visualized in a number of ways for example by color contours on a 2D slice or by a polygonal approximation to a contour surface. A set of such visualization techniques commonly known as direct volume rendering produces a 2D projected image directly from the volume data without intermediate constructs.

Direct volume rendering of a 3D image typically requires some model of the optical properties of that volume e.g. how the data volume emits reflects and scatters light. That model is utilized to compute a 2D projection image e.g. by evaluating the integrated effects of the optical properties along viewing rays corresponding to pixels in the 2D image. Such evaluations can be very computation intensive especially for large 3D volume image data.

An object of this invention is to provide improved methods and apparatus for digital data processing and more particularly by way of non limiting example for image visualization.

More particular objects of the invention are to provide such methods and apparatus as facilitate visualization of three and higher dimensional images. A related object is to provide such methods as facilitate such visualization in two dimensions e.g. as on a two dimensional display screen.

Yet further objects of the invention are to provide such methods and apparatus as can be implemented at lower cost. And a related aspect of the invention is to provide such methods and apparatus as can be implemented using standard off the shelf components.

The above objects are among those attained by the invention that provides in some aspects methods and apparatus for three dimensional and higher dimensional volume rendering that exploit the functions of chips or chip sets boards and or processor configurations known as graphics processing units GPUs or coprocessors providing comparable functions and or having comparable architectures to implement fast and accurate volume rendering machines.

Related aspects of the invention provide such methods and apparatus that utilize the programmability of these GPUs or like coprocessors by means of so called pixel shaders and or vertex shaders to enhance performance rendering speed and or image quality.

In one aspect the invention provides improvements in a digital data processor of the type that renders a three dimensional 3D volume image data into a two dimensional 2D image suitable for display. The improvements include a graphics processing unit GPU that comprises a plurality of programmable vertex shaders that are coupled to a plurality of programmable pixel shaders. One or more of the vertex and pixel shaders are configured to determine intensities of a plurality of pixels in the 2D image as an iterative function of intensities of sample points in the 3D image through which a plurality viewing rays associated with those pixels are passed. The pixel shaders compute for each ray multiple iteration steps of the iterative function prior to computing respective steps for a subsequent ray.

In a related aspect one or more of the vertex shaders compute a viewing ray for each pixel in the 2D image based on input parameters such a view point and a view direction. One or more of the pixel shaders then determine the intensities of one or more sample points in the 3D image along each ray passed through that image. A pixel shader can determine the intensity of a sample point in the 3D image along a given ray by interpolating intensity values of a plurality of neighboring 3D data points.

In another aspect at least one of the pixel shaders determines for a plurality of computed sample points along a portion of a ray whether those sample points lie within the 3D image data. In some cases some pixel shaders test whether sample points along a portion of a ray are within the 3D image data set prior to evaluating the iterative function at those points while other or the same pixel shaders evaluate the function at sample points along another portion of the ray without such testing. The tests are typically performed at points along a portion of the ray that is more likely to fall beyond the 3D image data.

In further aspects of the invention one or more of the pixel shaders store the 2D image in an off screen buffer. The pixel shaders can then effect the display of the buffered 2D image by applying another rendering pass thereto. Moreover the pixel shaders can apply selected filtering operations such as zoom anti aliasing or lower resolution rendering to the stored 2D image. In some cases the GPU generates the 2D image by executing instructions implemented thereon via one application programming interface API and effects the display of the 2D image stored in the off screen buffer by executing instructions implemented thereon via a different API.

In another aspect of the invention improvements are provided in an apparatus for computed tomography of the type that renders a 3D volume image data set into a 2D dimensional displayed image. The improvements include a graphics processing unit GPU comprising a plurality of programmable vertex shaders coupled to a plurality of programmable pixel shaders which are configured to determine a color of each pixel in the 2D image as an iterative function of intensities and gradients at a plurality of sample points in the 3D image. The sample points are selected along viewing rays associated with the pixels which extend through the 3D image. At least one of the pixel shaders computes a gradient at one of those sample points based on differences in intensities of plurality of data points in the 3D image neighboring that sample point.

The pixel shaders can compute gradients by employing any of central differences or on sided differences techniques. In some cases the pixel shaders compute gradients at sample points along a ray in a coordinate system that is rotated relative to a coordinate system in which the 3D image data is represented. The rotated system is preferably chosen such that an axis thereof is aligned along the ray being processed. Once a gradient is computed in the rotated system the pixel shaders can rotate that gradient back to the initial coordinate system.

In another aspect of the invention one or more of the vertex shaders and pixel shaders are configured to determine a color of at least one pixel in the 2D image by passing through the 3D image a viewing ray originating from that pixel and locating a point along the ray that is the nearest point to the pixel with an intensity above or below a predefined threshold. At least one of the pixel shaders assigns a color to that pixel as a function of the intensity of that nearest point. Further for each ray at least one of the pixel shaders evaluates intensities of multiple sample points along that ray to locate the afore mentioned nearest point prior to performing respective evaluations for a subsequent ray.

In a related aspect one or more of the pixel shaders interpolate intensity values of a plurality of data points in the 3D image that lie in vicinity of a sample point along a ray so as to evaluate an intensity for that sample point.

In another aspect of the invention an imaging apparatus is disclosed for rendering a 3D image into a 2D image which comprises a digital data processor having a central processing unit CPU and associated memory in which at least a portion of the 3D image can be stored. The CPU is in communication with a GPU having a plurality of programmable vertex shaders coupled to a plurality of programmable pixel shaders. The CPU partitions the 3D image or at least a portion thereof into a plurality so called bricks. One or more of the vertex shaders and pixel shaders are configured to determine intensities of one or more pixels in the 2D image as an iterative function of intensities of sample points in one or more bricks in the 3D image through which viewing rays associated with those pixels are passed. Any two adjacent bricks preferably have a sufficient overlap such that all points in the 3D image data that are required for evaluating the intensities of the sample points along a ray passing through a brick are located within that brick.

These and other aspects of the invention are evident in the drawings and in the description that follows.

Described below are improved methodologies and apparatus for rendering three dimensional 3D volumetric images into two dimensional 2D images suitable for 2D display. As noted above such three dimensional images occur in many disciplines such as medicine geo sciences or microscopy to name but a few. The 3D images can be acquired by employing imaging systems such as computer tomography devices magnetic resonance imaging devices or confocal microscopes. Alternatively the 3D images can be the result of theoretical computations.

The visual perception of natural 3D density distributions like clouds or fire involves projection onto a 2D plane namely the retina. This projection process can be mimicked using a computer in order to compute a 2D projection of a 3D image of physical 3D objects and to display that projection on a computer screen thus simulating the perception of those objects. This process is commonly known as volume rendering. A set of techniques for volume rendering known as direct volume rendering produce a projected image directly from the volume data without intermediate constructs such as contour surface polygons.

The present invention exploits the functional capabilities of chips or chip sets boards and or processor configurations known as graphics processing units GPUs or those of coprocessors providing comparable functions and or comparable architectures to implement fast and accurate volume rendering and particularly direct volume rendering of 3D image data though the methods and apparatus described herein may be implemented on general purpose processors and other special purpose processors. Still other embodiments use no GPU at all relying on the CPU and or other co processing functionality such as floating point units array processors and so forth to provide or supplement such processing all in accord with the teachings hereof.

In the following embodiments the salient features of the methods and apparatus according to the teachings of the invention are described in connection with 3D images obtained by utilizing an image acquisition device. It should however be understood that the teachings of the invention are equally applicable to rendering of 3D images that are generated theoretically or otherwise.

The invention has application for example in medical imaging such as computed tomography CT position emission tomography PET single photon emission computed tomography SPECT and other medical applications.

Turning to the illustrated embodiment depicts a computer aided tomography system according to one practice of the invention. The system includes an image acquisition apparatus that generates multiple projection images of an object in a volume . In the illustrated embodiment this is accomplished in the conventional manner e.g. by illuminating the object with radiation from a source and detecting by a detector such as a charged coupled device or other 2D sensor array radiation not absorbed by the object . Generally multiple projection images obtained at different respective angles are required for reconstructing a three dimensional representation of the object. Such projection images can be captured by moving the source and or the detector around the volume to illuminate the object from different angles and to detect a portion of the illuminating radiation that is not absorbed by the object.

In one embodiment those projections are generated in accord with the principles of computed tomography CT i.e. with the source at discrete foci on an arc that completely surrounds the volume . In another embodiment those projections are generated in accord with principles of computed tomosynthesis i.e. with the source at discrete foci along a smaller arc above the object. In some embodiments the radiation source is an x ray source and the detector is an x ray detector both mounted at opposite ends of a C arm that rotates about the volume . The rotatable C arm is a support structure that allows rotating the source and the detector around the volume e.g. a long a substantially circular arc to capture a plurality of projection images of the object at different angels. It should however be understood that the teachings of the invention can be applied to a plurality of measured projection images regardless of the implementation of the apparatus that generates those projection images.

In view thereof and without loss of generality vis vis these other apparatus with which the invention has application the apparatus is referred to hereafter as a CAT scanner its attendant source and detector are referred to as an x ray source and an x ray detector respectively and the images generated by the detector are referred to as projections.

By way of illustration schematically depict generation of a measured projection image by apparatus of a volume containing a rib cage . X ray radiation emitted by the source shown at one of its axial positions as it rotates about the volume during a scanning operation travel through the imaged volume . A portion of the x ray radiation not absorbed by the imaged volume impinges on the detector array depicted opposite source vis vis the volume as the detector moves about the volume in tandem with the source. The volume is characterized by x y and z axes as indicated and the detector and specifically the imaging portion thereof is characterized by u and v axes defining an imaging or detection plane that is parallel to the axis of rotation i.e. the z axis and has a normal perpendicular to a tangent of the rotational path . Referring to the imaging arrangement of is shown with the additional superposition on detector of an image of the type generated by projection of x ray radiation from the source through the rib cage . As evident in the drawing the image is a silhouette or as more often referred to herein a projection or a projection image e.g. in the nature of a conventional x ray image.

Referring again to the system further includes a digital data processor that analyzes the images to reconstruct the volume and more specifically to generate a three dimensional representation of the contents of that volume e.g. the object or a portion thereof in a manner discussed in more detail below. Illustrated object is the head of a human patient. However the invention can be used in analyzing images of other objects biological archeological industrial or otherwise.

Illustrated digital data processor is a workstation personal computer mainframe or other general or special purpose computing device of the type conventionally known in the art albeit adapted as discussed below for processing projections . As shown in the drawing it includes a central processing unit CPU dynamic memory RAM and I O section all of the type conventionally known the art. The digital data processor may be coupled via I O section with a monitor or other graphical display or presentation device as shown.

Illustrated digital data processor also includes a graphical processing unit GPU that is coupled to the CPU through which it can access the other elements of the digital data processor as shown. The GPU serves in the illustrated embodiment as a coprocessor operating under the control of the CPU to perform a portion or the totality of the computations needed for reconstructing a 3D image of the volume based on the measured projection images. Other embodiments of the invention employ multiple GPUs for this purpose each responsible for a respective portion of the reconstruction process. Further as discussed in more detail below the GPU renders the 3D image into a 2D image suitable for 2D display. The GPU is preferably of the variety having programmable vertex shaders and programmable pixel shaders that are commercially available from ATI research for example the Radeon 9700 processor NVIDIA for example the GeForce FX and Quadro processors . However it will be appreciated that the invention can be practiced with processing elements other than commercially available GPUs. Thus for example it can be practiced with commercial proprietary or other chips chipsets boards and or processor configurations that are architected in the manner of the GPUs e.g. as described below . It can also be practiced on such chips chipsets boards and or processor configurations that though of other architectures are operated in the manner of GPUs described herein.

Components of the digital data processor are coupled for communication with one another in the conventional manner known in the art. Thus for example a PCI or other bus or backplane industry standard or otherwise may be provided to support communications data transfer and other signaling between the components . Additional coupling may be provided among and between the components in the conventional manner known in the art or otherwise.

A typical architecture of the GPU suitable for use in the practice of the invention is shown by way of expansion graphic in . The GPU includes a geometrical mapping section and a pixel processing section interconnected with one another as well as with a local memory by way of a bus . The GPU communicates with other components of the digital data processor by interfacing with the bus via a bus interface . A further interface is provided between the bus and the CPU by way of one or more interfaces of the type standard in the art or otherwise for CPU GPU intercommunication. In the illustrated embodiment that further interface is a VIP video input port interface and AGP accelerated graphics port interface or otherwise as conventionally known in the art or otherwise.

Local memory supports both the short term and long term storage requirements of the GPU . For example it can be employed to buffer the projection image data iterative estimates of the density distribution of the volume under reconstruction forward projection images generated based on those estimates as well as parameters constants and other information including programming instructions for the vector processors that make up the mapping and pixel processing sections .

In the illustrated embodiment the mapping section comprises a plurality of programmable vertex shaders that generate mappings between the coordinate space of the projection images and that of the volume and generate locations of sample points along a viewing ray extending from a pixel of the 2D image through the 3D image volume. For example the vertex shaders map each pixel in a projection image to one or more voxels in the volume. The pixel processing section comprises a plurality of pixel shaders that can perform computations for reconstructing the 3D image as well as rendering the 3D image into a 2D displayed image.

DMA engines and provide coupling between the local bus and respectively the vertex shaders and pixel shaders facilitating access by those elements to local memory interfaces or otherwise. A further DMS engine provides additional coupling between the pixel shaders and the bus . In addition filters labeled F are coupled between the DMA engine and the prixel shaders as illustrated. These perform interpolation anisotropic filtering or other desired functions. Also coupled to the vertex shaders are respective iterators labeled 1 as illustrated. Each iterator generates addresses in volume space for the voxels that comprise the corresponding vertex shaders .

A variety of methodologies can be utilized to generate the 3D image i.e. reconstruct the volume from the multiple measured projection images. In some embodiments reconstruction methods implemented entirely on the GPU such as those described in co pending patent application entitled Method And Apparatus for Reconstruction of 3D Image Volumes from Projection Images concurrently filed with the present application and herein incorporated by reference are employed. In other embodiments the computational tasks for reconstructing the 3D image are shared between the CPU of the digital data processor and the GPU . Some exemplary reconstruction methods for generating the 3D image are discussed in the above referenced patent application entitled Improved Methods and Apparatus for Back Projection and Forward Projection. Regardless the teachings of the invention can be employed to visualize the 3D images via direct rendering the 3D image data as discussed in more detail below.

In the illustrated embodiment the GPU renders the 3D volume image into a 2D image that can be displayed on the display device . The GPU generates the 2D image pixel by pixel for a given viewing direction by passing rays corresponding to that viewing direction through the 3D image volume and mapping e.g. via a transfer function the intensities at selected points along the rays to the pixels. In general at each point along a viewing ray light can be emitted absorbed or scattered. In order to reduce complexity often scattering is neglected. In such a case each ray can be processed independently from the others.

In many embodiments of the invention the GPU employs optical models that map the 3D image intensities to emission and absorption coefficients or more generally to colors of projected pixels in the 2D image. By way of example after discretization the color C p of a projected pixel p can be represented as a function of discrete sample points xalong the ray associated with the pixel p as follows wherein the function F is referred to herein as the ray formula I denotes the 3D image and P represents a set of additional parameters such as the viewing direction. In many cases the above ray formula can be cast into an iterative format that defines the ray formula for one or n sample points as the result of the previous iterations of the formula for the previously processed sample points. An iterative implementation of the ray formula is as follows . . . 

For many commonly employed emission absorption optical models F represents a sum of blended color and opacity values cand a of the sample points. The color and opacity values can be determined from the intensities of the 3D image by employing an appropriate transfer function or color table. The color values can also be computed or modified by employing a local shading model e.g. shaded volume rendering . This latter approach requires that a gradient vector at each sample point x be computed.

In some embodiments one or more of the vertex shaders compute for each pixel in the 2D image a viewing ray for that pixel. The generated ray can be tested against the boundaries of the 3D image volume to ensure that it intersects that volume. At least one of the pixel shaders iteratively computes the above ray formula at a plurality of sample points generated by at least one or the vertex shaders along that ray. More specifically the pixel shader evaluates the intensity of the 3D image at each sample point e.g. by interpolating the intensity values at a plurality of neighboring 3D image data points. Those evaluated sample point intensities are then employed in the ray formula to obtain a color intensity for the pixel associated with that ray as a function of the integrated sum color and opacity values at the sample points.

In some preferred embodiments one or more of the pixel shaders compute the ray formula for multiple sample points along one ray prior to performing the corresponding computations for a subsequent ray. That is rather than computing one step of the ray formula for all rays followed by computing a subsequent step for those rays which would require storing the intermediate values in the GPU local memory multiple steps of the ray formula for one ray are computed prior to evaluating the ray formula for corresponding steps of a subsequent ray thereby avoiding transfer of intermediate results to the memory. In some such embodiments the pixel shaders test whether a current sample point along a ray for which multiple steps of the ray function are being computed lies within the 3D image volume. Alternatively pixel shaders that provide such testing are employed for processing sample points along selected portions of a ray e.g. those portions in which such testing may potentially be required and pixel shaders without such testing capability are utilized for processing the remaining sample points along that ray.

The looping capabilities of the pixel shaders can be employed to compute the full iterative ray formula for one ray by employing a single invocation rather than multiple invocations of one pixel shader.

In some cases the 3D image volume is subdivided into a plurality of three dimensional segments known as bricks. This subdivision of the 3D image volume can be utilized e.g. when the 3D image data is too large to be loaded at once into the GPU s local memory. In preferred embodiments the 3D image volume is subdivided such that the resulting bricks overlap. Further the overlap between adjacent bricks is chosen to be sufficiently large such that all 3D image points that need to be evaluated when rendering a part of a ray corresponding to a brick are guaranteed to be within that brick.

In some embodiments the 3D image is rendered into an off screen buffer. That is the rendered image i.e. color values of the pixels in the 2D image is stored in the off screen buffer. The GPU displays the buffered rendered image by executing another rendering pass. This allows the volume rendering to be implemented on the GPU by employing a different GPU application programming interface API e.g. DirectX or OpenGL than that utilized to display the image. Such off screen buffering of the rendered image further allows the subsequent rendering pass which is utilized to display the 2D image to apply a zoom or other filtering operations to the 2D image data. For example a lower resolution rendering of the buffered image can be employed to obtain enhanced performance. Other possible filtering operations applied to the off screed buffered image can provide e.g. anti aliasing or other effects.

In some cases the GPU employs optical models for rendering the 3D image that require computing a gradient at each sample point along the ray. In such cases rather than transferring a precomputed image normal volume to the GPU in many embodiments the GPU itself computes the gradient values on the fly while rendering the 3D image. For example a pixel shader computes a gradient value at a sample point by evaluating differences among 3D image values at multiple locations around the sample point. By way of example the pixel shader can employ central differences with six evaluations or one sided differences with four evaluations three in addition to the sample point itself .

When utilizing the four point one sided differences approach for computing a gradient value on the fly the pixel shader can rotate the coordinate system in which the 3D image is represented so as to align one axis thereof with the viewing ray. The pixel shader can then evaluate the gradient value in the rotated coordinate system. This advantageously results in fewer image evaluations as a previous sample point evaluation can be re used for the gradient computation at the current sample point. The pixel shader can transform back the resulting gradient vector to the original coordinate system. Alternatively the lighting parameters can be modified accordingly.

In some embodiments the GPU renders the 3D image into the 2D image by employing an optical model known as isosurface or surface shaded display. In such a case for each ray a ray formula returns the color of the nearest point on the ray nearest point to the pixel corresponding to that ray whose intensity lies above or below a user defined threshold. Typically a standard local shading model such the Phong model is used to determine the color of that point. When utilizing such an approach in preferred embodiments the pixel shaders perform multiple discrete steps evaluations and utilize linear or higher order interpolation to detect a threshold crossing along each ray of sight with sub stepsize accuracy. Alternatively an iteration method such as Newton s method can be employed. The exact position of the threshold is then used for gradient evaluation and or shading calculation.

In some embodiments the GPU utilizes a combination of two or more of the above rendering methods to generate a 2D image suitable for display from a 3D image data.

In further embodiments the GPU sequentially renders a plurality of time dependent 3D image data sets by employing any of the above methods or a combination thereof into a sequence of 2D images that can be displayed in a temporal sequence.

It should be understood that the teachings of the invention are applicable to a wide range of medical and non medical imaging devices and techniques and are not limited to the illustrated embodiment described above. Those having ordinary skill in the art will appreciate that various modifications can be made to the above illustrative embodiments without departing from the scope of the invention. In view of these what is claimed is 

