---

title: System and method adapted to facilitate dimensional transform
abstract: Systems and methods that facilitate dimensional transformations of data points are disclosed. In particular, the subject invention provides for a system and methodology that simplifies dimensional transformations while mitigating variations of a distance property between pairs of points. A set of n data points in d dimensional space is represented as an n×d input matrix, where d also corresponds to the number of attributes per data point. A transformed matrix represents the n data points in a lower dimensionality k after being mapped. The transformed matrix is an n×k matrix, where k is the number of attributes per data point and is less than d. The transformed matrix is obtained by multiplying the input matrix by a suitable projection matrix. The projection matrix is generated by randomly populating the entries of the matrix with binary or ternary values according to a probability distribution. Unlike previous methods, the projection matrix is formed without obtaining an independent sample from a Gaussian distribution for each entry in the projection matrix, without applying a linear algebraic technique to generate the projection matrix and without employing arbitrary floating point numbers. Processes and/or algorithms can utilize the reduced transformed matrix instead of the larger input matrix to facilitate computational efficiency and data compression.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07836115&OS=07836115&RS=07836115
owner: Microsoft Corporation
number: 07836115
owner_city: Redmond
owner_country: US
publication_date: 20051024
---
This application is a continuation of U.S. patent application Ser. No. 10 086 309 filed Mar. 1 2002 now U.S. Pat. No. 7 043 514 and entitled SYSTEM AND METHOD ADAPTED TO FACILITATE DIMENSIONAL TRANSFORM. The entirety of the aforementioned application is incorporated by reference. This application is also related to U.S. patent application Ser. No. 11 074 547 filed Mar. 8 2005 now U.S. Pat. No. 7 318 078 and entitled SYSTEM AND METHOD ADAPTED TO FACILITATE DIMENSIONAL TRANSFORM. 

The present invention relates generally to data manipulation and and more particularly to a system and method adapted to facilitate dimensional transformations of data pointsets in Euclidean space.

The amount of information available via computers has dramatically increased with the wide spread proliferation of computer networks the Internet and digital storage means. With the increased amount of information has come the need to manage sort through and selectively access data to facilitate efficient utilization and manipulation of information.

Much of the information generated today can be organized into matrices or data tables. By way of example online consumer transactions can be organized into a matrix where rows of the matrix correspond to individual consumers and columns of the matrix correspond to consumers or transactional attributes e.g. points of purchase zip codes . Often such information can be represented as a pointset in Euclidean space where the dimensionality of the pointset corresponds to a number of coordinates e.g. attributes that identifies or locates the points in the space.

Euclidean space is a type of metric space that can have an arbitrary number of dimensions. For example common everyday space has three dimensions. On the other hand Euclidean spaces such as that which may be representative of one or more data processing applications can have hundreds of thousands of dimensions and many millions of corresponding data points. In such situations it is often desirable to map the original set of points into a new set of equally many points residing in a lower dimensional Euclidean space. By mapping the original points to a lower dimensional space a benefit of data compression is obtained since fewer attributes are required to represent each point. As such storage requirements and processing capabilities can be significantly reduced. At the same time though it is understood that in general the new representation cannot perfectly capture all information present in the original high dimensional representation.

As an example one common technique for mapping data to a lower dimensional space is to project the original data on the hyperplane spanned by the eigenvectors corresponding to the k largest singular values of the original data. While such projections have a number of useful properties they may fail to preserve distances between data points referred to as a pairwise distance property. That is pairs of points represented in the lower dimensionality may have distances significantly different from their distances in the original dimensional space. Therefore algorithms that look to pairwise distances properties as input data can not benefit from this type of mapping as inconsistent results may occur.

As such it may be desirable to maintain pairwise distance properties so that for every pair of points their distance in low dimensional space substantially approximates their distance in high dimensional space. The reason that such a property may be important is that many data processing algorithms are not concerned with other structural properties of the data beyond interpoint distances. As a result by applying a distance preserving dimensionality reduction before applying such algorithms a benefit of compression is obtained while the produced results are consistent with the results that the algorithms would give if they were applied to the original high dimensional data. Besides the compression benefit by running at a lower dimensional space many algorithms perform significantly faster than if executed in the original higher dimensional space.

By way of example such embeddings are useful in solving an approximate nearest neighbor problem where after some preprocessing of a pointset P an answer is given to queries such as given an arbitrary point x find a point y P such that for every point z P x z 1 x . Additionally such embeddings are useful as part of an approximation algorithm for a version of clustering where it is sought to minimize sum of squares of intra cluster distances. Such embeddings can also be useful in data stream computations where there is limited memory and only a single pass over the data stream is allowed.

One approach to performing a transformation that preserves the pairwise distance property is to represent the original data points as an input matrix and to multiply that matrix with a projection matrix R in order to generate a transformed matrix T representative of the transformed or mapped set of data points. The input matrix can be thought of as a set of n points in d dimensional Euclidean space represented as an n d matrix A where each data point is represented as a row vector having d attributes coordinates . The transformed matrix has the same number of n data points as the input matrix but has a reduced number of attributes e.g. k attributes and thus can be represented as an n k matrix. Processes and or algorithms can utilize the transformed matrix instead of the input matrix thereby increasing computational efficiency.

However establishing a suitable projection matrix R and multiplying it by the input matrix A can be non trivial particularly in many practical computational environments where a very large number of data points and corresponding attributes may exist. For instance developing the projection matrix R typically includes generating a random number for each entry in the matrix e.g. Gaussian mean of zero and variance of one truncating the entries to about five to ten digits and applying a linear algebraic transformation to the entries to make the columns of the projection matrix orthonormal. This is often an arduous task since the projection matrix can be very large. Then to perform the matrix multiplication of A by R substantial computations have to be performed. For example to transform a million data points in ten thousand dimensional space into a smaller dimensional space e.g. one thousand dimensional space a million rows each having ten thousand columns have to be multiplied by a matrix having ten thousand rows and one thousand columns.

Although the aforementioned approach preserves a pairwise distance property such approach has deficiencies e.g. a sample of the Gaussian distribution is needed for each entry in R linear algebra techniques are required to obtain the projection matrix R the resulting projection matrix R is a dense matrix composed of arbitrary floating point numbers very few of which are 0 making computations numerous and complicated . Accordingly a more elegant solution to generating a suitable projection matrix in a computationally efficient manner is desired.

The following presents a simplified summary of the invention in order to provide a basic understanding of some aspects of the invention. This summary is not an extensive overview of the invention. It is not intended to identify key critical elements of the invention or to delineate the scope of the invention. Its sole purpose is to present some concepts of the invention in a simplified form as a prelude to the more detailed description that is presented later.

The present invention relates generally to a system and method that facilitates mapping or transforming data point sets from a high dimensionality to a lower dimensionality while mitigating variations in and preserving a pairwise distance property. The present invention accomplishes such mappings in manners that are simpler and faster than conventional techniques while providing comparable results. In particular a projection matrix is produced more efficiently and is utilized to effect such transformation in a computationally efficient and less complex manner than conventional techniques.

Generally a set of n data points is represented as an n d input matrix where d is a number of attributes per data point and is also the number of columns. A transformed matrix T represents the n data points in a lower dimension than the input matrix after being mapped or transformed from the input matrix. It is appreciated that this transformation maintains a pairwise distance property between any two of the set of data points. The transformed matrix is obtained by multiplying the input matrix by a projection matrix. This multiplication projects the data points from a higher dimensional representation the input matrix into a lower dimensional representation the transformed matrix . The projection matrix is randomly populated with binary 1 1 or ternary 1 0 1 values in each case according to a simple probability distribution. After this population is completed the matrix can be used immediately without any further linear algebraic manipulations. The projection matrix is thus generated without obtaining an independent sample from a Gaussian distribution for each entry in the projection matrix without applying a linear algebraic technique and without employing arbitrary floating point numbers. The transformed matrix is represented as an n k matrix where n is the number of data points and k is the number of attributes per data point and where k is less than the number of attributes in the original dimensionality d.

In accordance with an aspect of the present invention a probability distribution for the randomly generated entries populating the projection matrix utilized to reduce dimensionality of a data set is 1 with probability 1 6 0 with probability 2 3 and 1 with probability 1 6. In another embodiment the probability distribution is 1 with probability 1 2 and 1 with probability 1 2.

In accordance with another aspect of the present invention a system that dimensionally transforms a pointset includes a receive matrix component that receives a high dimensional point set an R matrix generator that receives an input matrix from the receive matrix component and generates a projection matrix based thereon. In particular the R matrix generator utilizes the dimensions of the input matrix to produce the projection matrix not the data itself. The projection matrix entries of at least one of 1 0 1. The system also includes a transformation engine that reduces the dimensionality of the pointset via employment of the projection matrix while maintaining integrity of a pairwise distance property.

According to a further aspect of the present invention a transformation engine simplifies matrix multiplication to effect reduced dimensional transformation. The transformation engine produces a transformed matrix and further includes a partition component that for respective entries in the transformed matrix discards calculations wherein attributes are to be multiplied by zero forms a first set of attributes that are to be multiplied by 1 and forms a second set of attributes that are to be multiplied by 1. The transformation engine also includes a first set summer that produces a first sum from the first set of attributes for entries in the transformed matrix a second set summer that produces a second sum from the first set of attributes for respective entries in the transformed matrix and a difference component that subtracts the first and second sums to produce the respective entries for the transformed matrix

According to still another aspect of the present invention a method for transforming n points in d dimensionality represented as an n d input matrix to k dimensionality is disclosed where k is less than d. An n k transformed matrix is produced thereby while variations in a distance property between pairs of the points are mitigated. The method includes multiplying the n d input matrix by a d k projection matrix having entries randomly populated from the group comprising 1 0 1. Then for respective entries in the transformed matrix calculations wherein multiplication would be by 0 are discarded a first sum is produced wherein multiplication would be by 1 and a second sum is produced wherein multiplication would be by 1. Finally respective first and second sums are subtracted to obtain each entry in the transformed matrix.

To the accomplishment of the foregoing and related ends certain illustrative aspects of the invention are described herein in connection with the following description and the annexed drawings. These aspects are indicative however of but a few of the various ways in which the principles of the invention may be employed and the present invention is intended to include all such aspects and their equivalents. Other advantages and novel features of the invention may become apparent from the following detailed description of the invention when considered in conjunction with the drawings.

Appendix A illustrates a proof establishing that a pairwise distance is maintained during transformations in accordance with the present invention and this Appendix is to be considered part of this specification.

The present invention is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present invention. It may be evident however that the present invention may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to facilitate describing the present invention.

As used in this application the terms component and system are intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a server and the server can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

It is to be appreciated that for purposes of the present invention any or all of the functionality associated with modules systems and or components discussed herein can be achieved in any of a variety of ways e.g. combination or individual implementations of active server pages ASPs common gateway interfaces CGIs application programming interfaces API s structured query language SQL component object model COM distributed COM DCOM system object model SOM distributed SOM DSOM ActiveX common object request broker architecture CORBA database management systems DBMSs relational database management systems RDBMSs object oriented database management system ODBMSs object relational database management systems ORDBMS remote method invocation RMI C C practical extraction and reporting language PERL applets HTML dynamic HTML server side includes SSIs extensible markup language XML portable document format PDF wireless markup language WML standard generalized markup language SGML handheld device markup language HDML graphics interchange format GIF joint photographic experts group JPEG binary large object BLOB other script or executable components .

The receive matrix component sends or transfers an input matrix to the transformation engine . The receive matrix component can generate the input matrix from high dimensional data. Additionally the receive matrix component can receive the input matrix from a data store not shown storing high dimensional data. The input matrix is an n d matrix representative of n points in d dimensional Euclidean space where n can be a large number of data points such as a million data points and d can be a high dimensional space such as a space having around ten thousand dimensions. Each row of the input matrix n represents a vector of d attributes. The transformed matrix T is an n k matrix representative of the n points embedded into k dimensional Euclidean space where k

The transformation engine dimensionally transforms the input matrix A into the transformed matrix T while maintaining the pairwise distance within an acceptable degree of error. The pairwise distance is preserved according to the guarantee defined by Eq. 1 shown below such that Eq. 1 is met for a given acceptable degree of error . The acceptable degree of error is selectable and can vary.

Let f be a function that transforms maps points from d dimensional Euclidean space into k dimensional Euclidean space . That is provided a point u in d dimensional Euclidean space f u denotes its k dimensional counterpart as prescribed by f. Similarly for a point v in d dimensional Euclidean space f v denotes its k dimensional counterpart as prescribed by f. To express mathematically that f is a transformation that indeed preserves pairwise distances for the acceptable degree of error the following formula is used 

Given 0 where the parameter controls accuracy in terms of pairwise distance preservation and an integer n let k be a positive integer such that k k 10 log n . For a set P of n points in there exists f such that for all u v P 1 1 Eq. 1

To effect the transformed matrix the transformation engine generates a projection matrix R. The projection matrix is generated with d k dimensions so that the multiplication of the n d input matrix A and the d k projection matrix R produces the n k transformed matrix T. It is to be appreciated that the transformation engine only looks to the dimensions e.g. n points and d attributes of the input matrix A to produce the projection matrix R and not to the contents of the input matrix. According to one or more aspects of the present invention the entries in the projection matrix can be binary or ternary values such as 1 1 or 1 0 1 . In accordance with one or more aspects of the present invention the entries are randomly assigned to the projection matrix according to a probability distribution. Two such possible probability distributions are shown below in association with Eqs. 2 and 3 

For integer k k let R be a d k projection matrix with R i j r where r are independent random variables from either one of the following two probability distributions 

Let P be an arbitrary set of n points in represented as an n d matrix A. Since the projection matrix R is a probabilistic construction is used to control the probability of success. Given 0 let

Thus k should be at least equal to kin order to meet the guarantee of Eq. 1. Additionally Eq. 4 can be used to find the minimum k that yields an acceptable transformation of the input matrix to the transformed matrix. The is also selectable and can vary according to aspects of the invention. The used in Eq. 4 is the same value as used in Eq. 1. It is appreciated that entries of projection matrix can be multiplied by a scaler such as is illustrated in Eq. 3 where entries are multiplied by a scaler of square root over 3 . However this scaling is generally not required because typically only relative distances are desired not absolute distances. Additionally the entries in the projection matrix R 1 1 or 1 0 1 simplify the matrix computations needed to perform the projection of the points from the d dimensional Euclidean space to the k dimensional Euclidean space.

The transformation engine after generating the projection matrix multiplies the input matrix by the projection matrix to generate the transformed matrix. Thus the set of data points represented in d dimensional Euclidean space are mapped or transformed to a set of data points represented in k dimensional Euclidean space. This transformed set of data points can then be utilized more efficiently by other applications.

As support for the present invention a mathematical proof is provided at Appendix A Dimitris Achlioptas ACM Symposium 2001 on Principles of Database Systems pp. 274 281 which is considered part of this specification. The proof establishes that results of a dimensional transformation according to Eqs. 2 4 preserve pairwise distance information in accordance with the guarantee of Eq. 1.

The exemplary matrices discussed below with respect to are simply for illustrative purposes only to facilitate explanation of the transformation operation in accordance with the present invention. The matrices are thus selected to illustrate the transformation operation and the present invention is not limited to the values and dimensions of the exemplary matrices. The values are shown as integers for illustrative purposes only. However the invention can include values as positive or negative real numbers. Furthermore it is to be appreciated that due to the small sizes of these example matrices the guarantee of Eq. 1 may not necessarily be followed. However the examples are provided so as to more clearly describe and facilitate understanding the matrix operations in connection with the present invention as would be applied to very large data point sets in high dimensions e.g. around one million data points each having 10 000 attributes .

The receive matrix component outputs an input matrix containing the high dimensional data that is to be transformed. The input matrix is forwarded to an R matrix generator component and a transformation engine . The R matrix generator component looks to the input matrix to generate a projection matrix. In particular the R matrix component determines the number of rows to include in the projection matrix based upon the number of columns attributes in the input matrix. The R matrix generator component generates the projection matrix with a number of columns equal to the dimensionality to which the input matrix is being transformed. The number of columns are however also controlled to provide a sufficient guarantee per Eq. 1 and an acceptable error range. The R matrix generator component randomly populates entries in the projection matrix according to one of two probability distributions 1 0 1 with probabilities of 1 6 2 3 and 1 6 respectively or 1 1 each with probabilities of 1 2. Other aspects of the invention can utilize other suitable probability distributions.

The transformation engine receives the projection matrix and produces a transformed matrix which is the data point set transformed into a lower dimensional space with a preserved pairwise distance property. Given the probability distributions of the entries within the projection matrix the transformation engine calculates entries within the transformed matrix in manners described above with reference to e.g. omitting two thirds of the calculations obtaining two sums and taking their difference splitting the input matrix . As such the transformation engine does not have to perform many lengthy and complex computations to produce the transformed matrix this mitigates inefficiencies associated with producing such transformations in conventional manners. Thus the entries in the projection matrix 1 1 or 1 0 1 simplify the matrix computations needed to perform the projection of the points from the d dimensional Euclidean space to the k dimensional Euclidean space.

The random generator supplies random numbers to the R matrix generator for use as entries in a projection matrix. According to one or more aspects of the present invention the random generator produces binary values according to the forgoing probabilities.

Like components in perform like functions to that described with respect to similar components in . Accordingly discussion of these components is omitted for sake of brevity. A probability assessment component assigns probabilities to numbers that are generated by a random number generator . In accordance with one aspect of the present invention the probability assessment component assigns probabilities of 1 6 2 3 and 1 6 respectively to numbers 1 0 1 generated by the random number generator. According to another aspect of the present invention the probability assessment component is also adapted to assign equal probabilities of 1 2 to each of the numbers 1 and 1 generated by the random number generator. The numbers generated by the random number generator are provided to a transformation engine which utilizes them as entries in a projection matrix in executing the dimensional transform.

A partition component receives an input matrix. The input matrix represents n data points by n rows or vectors of the input matrix. Each of the n rows contains d attributes or coordinates. The partition component processes each row separately k times. For a given row of the input matrix the partition component partitions the attributes of that row. An amount of the attributes are randomly discarded such as 2 3 and referred to as discarded attributes . It is appreciated that the amount of the attributes discarded can vary so long as the guarantee of Eq. 1 still holds true with respect to a selected error range. The remaining attributes are randomly partitioned into a first set of attributes and a second set of attributes generally evenly. A first set summer sums together the attributes of the first set to obtain a first set sum. A second set summer sums together the attributes of the second set to obtain a second set sum. A difference component subtracts the sum of the second set from the sum of the first set to generate a coordinate c of the transformed matrix where i is an integer from 1 to k and j is an integer from 1 to n corresponding to a current the row of the input matrix and the transformed matrix. A coordinate generator receives coordinates from the difference component . The coordinate generator generates a transformed matrix after all of the coordinates have been generated for the input matrix. The transformed matrix represents n data points by n rows or vectors of the input matrix. Each of the n rows contains k attributes or coordinates where k is less than d.

The partition component determines partitioning based on a probability function or distribution . The probability distribution determines probabilities for discarding attributes and partitioning attributes into the first and second sets of attributes and . One probability distribution that can be used is to discard 2 3 of the attributes partition 1 6 into the first set of attributes and partition 1 6 into the second set of attributes . Another probability distribution that can be used is to partition 1 2 of the attributes into the first set of attributes and 1 2 of the attributes into the second set of attributes . Other probability distributions can be used with the invention.

In view of the exemplary systems shown and described above a methodology that may be implemented in accordance with the present invention will be better appreciated with reference to the flow charts of . While for purposes of simplicity of explanation the methodology is shown and described as a series of blocks it is to be understood and appreciated that the present invention is not limited by the order of the blocks as some blocks may in accordance with the present invention occur in different orders and or concurrently with other blocks from that shown and described herein. Moreover not all illustrated blocks may be required to implement a methodology in accordance with the present invention.

The invention may be described in the general context of computer executable instructions such as program modules executed by one or more components. Generally program modules include routines programs objects data structures etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

Turning to a methodology for projecting a matrix in accordance with one or more aspects of the present invention is illustrated. The method projects an input matrix of d dimensions to a transformed matrix of k dimensions. An input matrix is provided at . The input matrix represents n data points by n rows of the input matrix. The n rows respectively contain d attributes. For respective rows of the transformed matrix perform the following 

Randomly discard 2 3 of the attributes from a row of the input matrix at . Alternate aspects of the invention can randomly discard other amounts of the attributes such as none 1 4 1 2 and the like. The remaining attributes from the row are referred to as end points. The remaining attributes are partitioned into a first set of attributes and a second set of attributes at . Usually the attributes are partitioned evenly such that the number of attributes in the first set of attributes is equal to the number of attributes in the second set of attributes. The first set of attributes is summed to a positive attribute at . The second set of attributes is summed to a negative attribute at . The negative attribute sum of the second set of attributes is subtracted from the positive attribute sum of the first set of attributes at . This difference is a coordinate of the transformed matrix. The method is repeated k times for each row of the input matrix. Then a next row of the input matrix is processed according to and at . After the rows have been processed a transformed matrix is provided at . The transformed matrix has n data points where each row contains k attributes.

In order to provide additional context for various aspects of the present invention and the following discussion are intended to provide a brief general description of one possible suitable computing environment in which the various aspects of the present invention may be implemented. It is to be appreciated that the computing environment is but one possible computing environment and is not intended to limit the computing environments with which the present invention can be employed. While the invention has been described above in the general context of computer executable instructions that may run on one or more computers it is to be recognized that the invention also may be implemented in combination with other program modules and or as a combination of hardware and software. Generally program modules include routines programs components data structures etc. that perform particular tasks or implement particular abstract data types. Moreover one will appreciate that the inventive methods may be practiced with other computer system configurations including single processor or multiprocessor computer systems minicomputers mainframe computers as well as personal computers hand held computing devices microprocessor based or programmable consumer electronics and the like each of which may be operatively coupled to one or more associated devices. The illustrated aspects of the invention may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

With reference to an exemplary environment for implementing various aspects of the invention includes a computer including a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The processing unit may be any of various commercially available processors. Dual microprocessors and other multi processor architectures also can be used as the processing unit .

The system bus may be any of several types of bus structure including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of commercially available bus architectures. The computer memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is stored in ROM .

The computer may further include a hard disk drive a magnetic disk drive e.g. to read from or write to a removable disk and an optical disk drive e.g. for reading a CD ROM disk or to read from or write to other optical media. The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The computer typically includes at least some form of computer readable media. Computer readable media can be any available media that can be accessed by the computer . By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

A number of program modules may be stored in the drives and RAM including an operating system one or more application programs other program modules and program non interrupt data . The operating system in the computer can be any of a number of commercially available operating systems.

A user may enter commands and information into the computer through a keyboard and a pointing device such as a mouse . Other input devices not shown may include a microphone an IR remote control a joystick a game pad a satellite dish a scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port a game port a universal serial bus USB an IR interface etc. A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor a computer typically includes other peripheral output devices not shown such as speakers printers etc.

The computer may operate in a networked environment using logical and or physical connections to one or more remote computers such as a remote computer s . The remote computer s may be a workstation a server computer a router a personal computer microprocessor based entertainment appliance a peer device or other common network node and typically includes many or all of the elements described relative to the computer although for purposes of brevity only a memory storage device is illustrated. The logical connections depicted include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or is connected to a communications server on the LAN or has other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

What has been described above includes examples of the present invention. It is of course not possible to describe every conceivable combination of components or methodologies for purposes of describing the present invention but one of ordinary skill in the art may recognize that many further combinations and permutations of the present invention are possible. Accordingly the present invention is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims. Furthermore to the extent that the term includes is used in either the detailed description or the claims such term is intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

