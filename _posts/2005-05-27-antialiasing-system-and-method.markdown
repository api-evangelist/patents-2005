---

title: Antialiasing system and method
abstract: A system and method for improved antialiasing in video processing is described herein. Embodiments include multiple video processors (VPUs) in a system. Each VPU performs some combination of pixel sampling and pixel center sampling (also referred to as multisampling and supersampling). Each VPU performs sampling on the same pixels or pixel centers, but each VPU creates samples positioned differently from the other VPUs corresponding samples. The VPUs each output frame data that has been multisampled and/or supersampled into a compositor that composites the frame data to produce an antialiased rendered frame. The antialiased rendered frame has an effectively doubled antialiasing factor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08212838&OS=08212838&RS=08212838
owner: ATI Technologies, Inc.
number: 08212838
owner_city: Markham, Ontario
owner_country: CA
publication_date: 20050527
---
Multiple Video Processing Unit VPU Memory Mapping U.S. application Ser. No. 11 139 917 invented by Philip J. Rogers Jeffrey Gongxian Cheng Dmitry Semiannokov and Raja Koduri filed concurrently herewith 

Applying Non Homogeneous Properties to Multiple Video Processing Units VPUs U.S. application Ser. No. 11 140 163 invented by Timothy M. Kelley Jonathan L. Campbell and David A. Gotwalt filed concurrently herewith 

Frame Synchronization in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 140 114 invented by Raja Koduri Timothy M. Kelley and Dominik Behr filed concurrently herewith 

Synchronizing Multiple Cards in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 139 744 invented by Syed Athar Hussain James Hunkins and Jacques Vallieres filed concurrently herewith 

Compositing in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 140 165 invented by James Hunkins and Raja Koduri filed concurrently herewith 

Dynamic Load Balancing in Multiple Video Processing Unit VPU Systems U.S. application Ser. No. 11 139 893 invented by Jonathan L. Campbell and Maurice Ribble filed concurrently herewith and

Computing Device with Flexibly Configurable Expansion Slots and Method of Operation U.S. application Ser. No. 11 140 040 invented by Yaoqiang George Xie and Roumen Saltchev filed May 27 2005.

Graphics and video processing hardware and software continue to become more capable as well as more accessible each year. Graphics and video processing circuitry is typically present on an add on card in a computer system but is also found on the motherboard itself. The graphics processor is responsible for creating the picture displayed by the monitor. In early text based personal computers PCs this was a relatively simple task. However the complexity of modern graphics capable operating systems has dramatically increased the amount of information to be displayed. In fact it is now impractical for the graphics processing to be handled by the main processor or central processing unit CPU of a system. As a result the display activity has typically been handed off to increasingly intelligent graphics cards which include specialized coprocessors referred to as graphics processing units GPUs or video processing units VPUs .

In theory very high quality complex video can be produced by computer systems with known methods. However as in most computer systems quality speed and complexity are limited by cost. For example cost increases when memory requirements and computational complexity increase. Some systems are created with much higher than normal cost limits such as display systems for military flight simulators. These systems are often entire one of a kind computer systems produced in very low numbers. However producing high quality complex video at acceptable speeds can quickly become prohibitively expensive for even high end consumer level systems. It is therefore an ongoing challenge to create VPUs and VPU systems that are affordable for mass production but have ever improved overall quality and capability.

Another challenge is to create VPUs and VPU systems that can deliver affordable higher quality video do not require excessive memory operate at expected speeds and are seamlessly compatible with existing computer systems.

There are various aspects of video processing that typically require some trade off between quality and performance to be made. One example is correcting for aliasing usually referred to as anti aliasing or AA . Aliasing is a well known effect created by the appearance in a displayed frame of artifacts of the rendering process. Rendering is performed by the VPU and involves drawing the pixels to be displayed. Aliasing includes edge aliasing and surface aliasing. Edge aliasing creates stair steps in an edge that should look smooth. Surface aliasing includes flashing or popping of very thin polygons sometimes referred to as moir patterns. Existing AA techniques for alleviating these effects include multisampling and supersampling. Multisampling addresses edge aliasing by creating multiple samples of pixels which are used to generate intermediate points between pixels. The samples are averaged to determine the displayed pixel color value. The displayed edge in the multisampled image has a softened stair step effect. Multisampling has no affect on surface aliasing.

Supersampling will address both edge aliasing and surface aliasing. However supersampling is computationally more expensive than multisampling and is rarely performed in consumer systems. Pixel centers as opposed to pixels carry texture information. In supersampling each pixel is rendered multiple times with different pixel centers to yield multiple color values which are then averaged to give a final pixel color. This gives the entire image a softened effect.

One reason it is inefficient to do either multisampling or supersampling in conventional systems is that the pixel data must be run through the video processing pipeline in the VPU more than once to create offset samples with respect to pixels or pixel centers. This increases the number of computations and increases processing time.

All publications and patent applications mentioned in this specification are herein incorporated by reference to the same extent as if each individual publication or patent application was specifically and individually indicated to be incorporated by reference.

A system and method for antialiasing AA that alleviates both edge aliasing effects and surface aliasing effects is described herein. Embodiments include applying a combination of multisampling and supersampling techniques in a system with at least one graphics processing unit GPU or video processing unit VPU . As used herein GPU and VPU are interchangeable terms. In one embodiment the system is programmable such that sample positions are programmably offset within a pixel from initial positions by one or more VPUs. The initial positions are determined for example by a common video driver of the system. In one embodiment each of the multiple VPUs processes the same video frame in parallel and offsets samples within the same pixels to different programmable positions in each VPU. Video frames processed by each of the multiple VPUs are merged or combined or composited to create a frame to be displayed. In the frame to be displayed the AA sampling factor is effectively multiplied by the number of VPUs. For example if each VPU performs 2 sampling the frame to be displayed includes 4 sampling. In various embodiments the driver is programmable to direct the VPUs to perform multisampling by a selectable multiplying factor supersampling by a selectable multiplying factor or a combination of multisampling by a selectable multiplying factor and supersampling by a selectable multiplying factor.

The API can be any one of the available APIs for running video applications. The API communicates with a driver . The driver is typically written by the manufacturer of the video hardware and translates the standard code received from the API into a native format understood by the hardware. The driver allows input from for example an application process or user to direct settings. Such settings in embodiments described herein include settings for selecting the multisampling factors the supersampling factors or combinations thereof. For example a user can select settings via a user interface UI including a UI supplied to the user with video processing hardware and software as described herein.

In one embodiment the video hardware includes two video processing units VPU A and VPU B . In other embodiments there can be less than two to or more than two VPUs. In various embodiments VPU A and VPU B are identical. In various other embodiments VPU A and VPU B are not identical. The various embodiments which include different configurations of a video processing system will be described in greater detail below.

The driver issues commands to VPU A and VPU B . The commands issued to VPU A and VPU B at the same time are for processing the same frame to be displayed. VPU A and VPU B each execute a series of commands for processing the frame including offsetting sample positions with respect to pixels and or pixel centers in a programmable manner from the sample positions as received from the API. The driver programmably instructs VPU A and VPU B to multisample and or supersample pixels and or pixel centers by an antialiasing AA factor. In one embodiment VPU A and VPU B offset samples with respect to the same pixels and or pixel centers but offset them to different sample positions.

When either of VPU A and VPU B finishes executing the commands for the frame the frame data is sent to a compositor . The compositor is optionally included in an interlink module as described more fully below. The frame data from each of VPU A and VPU B is merged or combined or composited in the compositor to generate a frame to be rendered to a display . In the frame to be displayed the AA sampling factor is effectively multiplied by the number of VPUs. For example if each VPU performs 2 sampling the frame to be displayed includes 4 sampling. In various embodiments the driver is programmable to direct VPU A and VPU B to perform multisampling by a selectable multiplying factor supersampling by a selectable multiplying factor or a combination of multisampling by a selectable multiplying factor and supersampling by a selectable multiplying factor. As used herein the terms combine merge composite mix or interlink all refer to the same capabilities of the IM and compositor as described herein.

Throughout the description for convenience the sample pattern output by a VPU will also be referred to as being the output of the VPU. For example sample pattern is also referred to as output of VPU A . Persons of ordinary skill in the art will understand and appreciate that the sample pattern output by a VPU or as referred to herein as the output of the VPU is in most embodiments not output to the display. Rather the sample pattern output by the VPU or portion thereof is used to generate a frame or portion thereof that is ultimately output to a display such as a LCD flat panel CRT or the like. That is the output sample pattern is in the present and most embodiments used as an input to a further portion of the VPU to generate the frame or portion thereof output to a display.

The samples are averaged by the VPU A in linear space in a known manner. However the pixel data is typically in gamma space and so must be converted to linear space in a degamma operation prior to averaging. The VPU A performs the degamma operation performs the averaging operation and then performs a gamma operation so that the output of the VPU is in gamma space. This is conventionally done because of quality improvement in the displayed image. So to restate in conventional systems the output of the VPU is automatically in gamma space. However in various embodiments herein it is desirable to have the output in linear space for the combining or compositing operation as described below. Accordingly the VPU A performs an additional degamma operation to convert the output to linear space. In one embodiment the texture unit in the video pipeline of the VPU A is used to perform the degamma operation. In other embodiments this degamma operation can be performed external to the VPU for example in the compositor .

As an example of gamma correction U.S. Pat. No. 5 398 076 entitled Gamma Correcting Processing of Video Signals assigned to ATI Technologies Inc. describes a method of processing video signals including gamma correction of pixel data. In addition a gamma correction circuit is described in U.S. Pat. No. 6 020 921 entitled Simple Gamma Correction Circuit for Multimedia assigned to ATI Technologies Inc. . In one embodiment gamma correction is performed according to the function 

In one embodiment the algorithm performed by the compositor can also be stated as follows flatten each of the three colors of each pixel on both input streams from VPU A and VPU B add each individual color between VPU A and VPU B divide by 2 and pass to the next step for example slave green master green 2 pre output green and convert the pre output pixel back into gamma corrected color values. In one embodiment a gamma correction lookup table is used.

Similarly an output from VPU B is shown. The output is a 12 12 grid that demonstrates 2 sampling. For each pixel 2 pixel samples are placed in the 12 12 grid. The 12 12 dimension is for example purposes only and any other workable dimension is contemplated. In the example shown the darkened square is a pixel center and the X es are pixel samples. The pixel samples are offset from an initial default location specified by the API not shown . The offset locations are programmable in the driver and are specified in commands from the driver to the VPU B .

The samples are averaged by the VPU B in linear space in a known manner. However the pixel data is typically in gamma space and so must be converted to linear space in a degamma operation prior to averaging. The VPU B performs the degamma operation performs the averaging operation and then performs a gamma operation so that the output of the VPU is in gamma space. This is conventionally done because of quality improvement in the displayed image. So to restate in conventional systems the output of the VPU is automatically in gamma space. However in various embodiments herein it is desirable to have the output in linear space for the combining or compositing operation as described below. Accordingly the VPU B performs an additional degamma operation to convert the output to linear space. In one embodiment the texture unit in the video pipeline of the VPU B is used to perform the degamma operation.

The linear outputs and are combined in a compositor . The compositor is optionally included in an interlink module as described more fully below. The frame data from each of VPU A and VPU B is merged or combined or composited in the compositor to generate a frame to be rendered to a display not shown . The compositing operation is in linear space. The compositor completes the compositing operation and performs a gamma operation on the result to produce gamma corrected frame data to be displayed. Output includes gamma corrected pixel data and shows how the outputs and have been combined. Each of outputs and are 2 multisampled and the output is 4 multisampled. Accordingly a much improved multisampling result is achieved with one pass through the video pipeline as illustrated in video processing embodiment . As described below with reference to other antialiasing modes are programmably selectable to include various combinations of multisampling and supersampling sampling pixel centers .

Referring to several modes of antialiasing according to the embodiment described are illustrated. In each of the pixels for VPU A are represented as stars the pixel centers for VPU A are represented as a blacked in grid block the pixels for VPU B are represented as striped grid blocks and the pixel centers for VPU B are represented as concentric circles. is a diagram that shows the mode previously described with reference to . This mode is referred to as 4 MSAA with 1 SSAA or 4 multisampling AA with 1 supersampling AA where 4 will be referred to as the MS factor and 1 will be referred to as the SS factor . Each of VPU A and VPU B sample the pixels as shown in and respectively. After and are combined or composited the output to be displayed is as shown.

The antialiasing methods and apparatus described are also applicable to other types of sampling not specifically described including subsampling and oversampling. The methods and apparatus described are also applicable to temporal antialiasing. For example in one embodiment each of multiple VPUs can process a different frame in time. The frames are then composited as described herein.

Various other embodiments also include each of multiple VPUs rendering a same frame in a different manner. For example one VPU performs multisampling by one factor and another VPU performs sampling by another factor. Similarly one VPU can perform multisampling on a frame and another VPU can perform supersampling on a frame. The frames generated by each VPU are composited as described herein. In yet other embodiments one VPU can perform sampling by one sampling factor where sampling may be any type of sampling while another VPU performs sampling by another factor. The frames generated by each VPU are composited as described herein. The sampling factor for each VPU is configurable. In one embodiment the sampling behavior of each VPU is configurable by the user through a UI. In one embodiment the efficiency of the sampling configuration used may form the basis for configuration by the user through a UI or for automatic configuration. Alternatively the performance of relative VPUs may form the basis for configuration by the user through a UI or for automatic configuration.

The API communicates with a driver . The driver is written specifically for the system and translates the standard code received from the API into a native format understood by the VPU components which will be explained more fully below.

In one embodiment the system further includes two VPUs VPU A and VPU B . The invention is not limited to two VPUs. Aspects of the invention as described herein would be workable with one VPU with modifications available to one of ordinary skill in the art. However the system would be less efficient with one VPU than with more than one VPU. Various embodiments also include more than two VPUs. Systems with more than two are workable with modifications available to one of ordinary skill in the art and would provide better efficiency in at least some respects than a system with two VPUs. In various embodiments VPU A and VPU B can be video cards that each includes a video processor and other associated hardware. As will be explained further below the invention is not so limited. For example more than one VPU can be resident on one card or board. However as referred to herein a VPU is intended to include at least a video processor.

VPU A and VPU B receive commands and data from the driver through respective ring buffers A and B . The commands instruct VPU A and VPU B to perform a variety of operations on the data in order to ultimately produce a rendered frame for a display .

The driver has access to a shared memory . In one embodiment the shared memory or system memory is memory on a computer system that is accessible to other components on the computer system bus but the invention is not so limited.

In one embodiment the shared memory VPU A and VPU B all have access to a shared communication bus and therefore to other components on the bus . In one embodiment the shared communication bus is a peripheral component interface express PCIE bus but the invention is not so limited.

The PCIE bus is specifically described in the following documents which are incorporated by reference herein in their entirety 

In one embodiment VPU A and VPU B communicate directly with each other using a peer to peer protocol over the bus but the invention is not so limited. In other embodiments there may be a direct dedicated communication mechanism between VPU A and VPU B .

VPU A and VPU B each have a local video memory and respectively available. In various embodiments one of the VPUs functions as a master VPU and the other VPU functions as a slave VPU but the invention is not so limited. In other embodiments the multiple VPUs could be peers under central control of another component. In one embodiment VPU A acts as a master VPU and VPU B acts as a slave VPU.

In one such embodiment various coordinating and combining functions are performed by an interlink module IM that is resident on a same card as VPU A . This is shown as IM enclosed with a solid line. In such an embodiment VPU A and VPU B communicate with each other via the bus for transferring inter VPU communications e.g. command and control and data. For example when VPU B transfers an output frame to IM on VPU A for compositing as shown in the frame is transferred via the bus .

In various other embodiments the IM is not resident on a VPU card but is an independent component with which both VPU A and VPU B communicate. One such embodiment includes the IM in a dongle that is easily connected to VPU A and VPU B . This is indicated in the figure by the IM enclosed by the dashed line. In such an embodiment VPU A and VPU B perform at least some communication through an IM connection . For example VPU A and VPU B can communicate command and control information using the bus and data such as frame data via the IM connection .

There are many configurations of the system contemplated as different embodiments of the invention. as described below illustrate just some of these embodiments.

The master VPU card includes an IM . In an embodiment in which VPU A and VPU B communicate via the bus each VPU processes a frame including sampling as explained with reference to . As an example in 4 MSAA is shown being performed by the system . Master VPU A generates an output and slave VPU B generates an output . The outputs and are input to the IM for combining as previously described. In one embodiment the slave VPU B transfers it output to the IM via the buses and as shown by the dotted path . In one embodiment the slave VPU B transfers it output to the IM via the dedicated intercard connection as shown by the dotted path . The IM combines the outputs and as previously described to produce a frame for display that includes 4 MSAA. This frame is output to a display by the IM via a connector .

The master VPU card includes connectors and . The slave VPU card includes connectors and . Connectors and are connectors appropriate for the purpose of transmitting the required signals as known in the art. For example the connector is a digital video in DVI connector in one embodiment. There could be more or less than the number of connectors shown in the .

In one embodiment the various embodiments described herein are configurable by a user to employ any number of available VPUs for video processing. For example the system includes two VPUs but the user could choose to use only one VPU in a pass through mode. In such a configuration one of the VPUs would be active and one would not. In such a configuration the antialiasing as described herein would not be available. However the enabled VPU could perform conventional antialiasing. The dotted path from VPU card B to the display indicates that slave VPU B can be used alone for video processing in a pass through mode. Similarly the master VPU A can be used alone for video processing in a pass through mode.

The master VPU card also includes a receiver and a transmitter for receiving and transmitting in one embodiment TDMS signals. A dual connector is a DMS connector in an embodiment. The master card further includes a DVI connector for outputting digital video signals including frame data to a display. The master VPU card further includes a video digital to analog converter DAC . An interlink module IM is connected between the VPU A and the receivers and transmitters as shown. The VPU A includes an integrated transceiver labeled integrated and a digital video out DVO connector.

The slave VPU card includes two DVI connectors and . The slave VPU card includes a DVO connector and an integrated transceiver. As an alternative embodiment to communication over a PCIE bus not shown the master VPU card and the slave VPU card communicate via a dedicated intercard connection .

The system includes all of the multiple VPU also referred to as multiVPU functionality previously described including the antialiasing capabilities described. For example the master VPU A processes and outputs a sampled frame to the IM . The slave VPU B processes and outputs a sampled frame which is transferred to the IM for combining or compositing. The transfer is performed via the PCIE bus or via a dedicated inter VPU connection not shown as previously described with reference to . In either case the composited frame is output from the IM to a display .

It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass through mode to perform video processing alone. This is shown for example by the dashed path which illustrates the slave VPU B connected to a display to output frame data for display. The master VPU A can also operate alone in pass through mode by outputting frame data on path .

The system includes all of the multiVPU functionality previously described including the antialiasing capabilities described. For example the master VPU A processes and outputs a sampled frame to the IM . The slave VPU B processes and outputs a sampled frame which is transferred to the IM for combining or compositing. The transfer is performed via the PCIE bus or via a dedicated inter VPU connection not shown as previously described with reference to . In either case the composited frame is output from the IM to a display not shown .

It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass through mode to perform video processing alone. This is shown for example by the dashed path which illustrates the slave VPU B connected to an output for transferring a frame for display. The master VPU A can also operate alone in pass through mode by outputting frame data on path .

The configurations as shown herein for example in are intended as non limiting examples of possible embodiments. Other configurations are within the scope of the invention as defined by the claims. For example other embodiments include a first VPU installed on or incorporated in a computing device such as a personal computer PC a notebook computer a personal digital assistant PDA a TV a game console a handheld device etc. The first VPU can be an integrated VPU also known as an integrated graphics processor or IGP or a non integrated VPU. A second VPU is installed in or incorporated in a docking station or external enclosed unit. The second VPU can be an integrated VPU or a non integrated VPU.

In one embodiment the docking station is dedicated to supporting the second VPU. The second VPU and the first VPU communicate as described herein to cooperatively perform video processing and produce an output as described. However in such an embodiment the second VPU and the first VPU communicate via a cable or cables or another mechanism that is easy to attach and detach. Such an embodiment is especially useful for allowing computing devices which may be physically small and have limited video processing capability to significantly enhance that capability through cooperating with another VPU.

It will be appreciated by those of ordinary skill in the art that further alternative embodiments could include multiple VPUs on a single die e.g. two VPUs on a single die or multiple cores on a single silicon chip.

The IM includes a master input port that receives a DVO stream from a master VPU. The master VPU input can be from a TDMS receiver in a dongle configuration such as those shown in . The master VPU input can alternatively come from a master VPU on a master VPU card in a multi card configuration as shown for example in . A synchronization register receives the DVO data from the master VPU.

The IM further includes a slave input port that receives a DVO stream from a slave VPU. The slave VPU input can be from a TDMS receiver in a dongle configuration such as those shown in or a card configuration as in . The slave VPU input can alternatively come from a slave VPU on a super VPU card configuration as shown for example in . The IM includes FIFOs on the slave port to help synchronize the input streams between the master VPU and the slave VPU.

The input data from both the master VPU and the slave VPU are transferred to an extended modes mixer and to a multiplexer MUX . In one embodiment the extended modes mixer provides the compositing functionality to perform antialiasing according to the embodiments described herein. The antialiasing functionality as described herein is also referred to as superAA . The IM is configurable to operate in multiple compositing modes including the superAA antialiasing mode as described herein. In one embodiment the superAA mode is one of multiple extended modes. Compositing modes include alternate frame rendering AFR modes in which frames are rendered alternately by different VPUs. Compositing modes further include blacking modes in which each VPU is given a different part of a frame to process. The parts of the frame not processed are designated as containing black pixels. When the parts of the frame processed by both VPUs are combined either by the extended modes mixer or by selecting only non black pixels the entire frame is displayed.

Control logic including a black register and a MUX path logic and black comparator determines which compositing mode the IM operates in. The output of the MUX path logic and black comparator is a select input to the MUX and extended modes mixer and dictates which of these components outputs data. Data is output to a TDMS transmitter or a DAC .

In one embodiment the inter component communication among the VPUs and the IM includes I2C buses and protocols.

The modes are set through a combination of I2C register bits and TMDS control bits as shown in Table 1.

There are two separate data paths through the IM . The two input pixel streams from the respective VPUs are either processed through the MUX in pass thru mode or standard interlink modes or through the mixer in extended modes including super AA mode. As used herein interlink or interlink mode implies any multiVPU mode that is not a pass through mode. In the MUX just one pixel from either VPU A or VPU B is selected to pass through and no processing of pixels is involved. In the extended modes mixer processing is done on a pixel by pixel basis. However the pixels are processed averaged together and reprocessed. In one embodiment the processing steps involve using one or more lookup tables to generate intermediate or final results.

The selection between the MUX path and the mixer path is determined by I2C register bits and control bits. For example the mixer path is selected if 

Aspects of the invention described above may be implemented as functionality programmed into any of a variety of circuitry including but not limited to programmable logic devices PLDs such as field programmable gate arrays FPGAs programmable array logic PAL devices electrically programmable logic and memory devices and standard cell based devices as well as application specific integrated circuits ASICs and fully custom integrated circuits. Some other possibilities for implementing aspects of the invention include microcontrollers with memory such as electronically erasable programmable read only memory EEPROM embedded microprocessors firmware software etc. Furthermore aspects of the invention may be embodied in microprocessors having software based circuit emulation discrete logic sequential and combinatorial custom devices fuzzy neural logic quantum devices and hybrids of any of the above device types. Of course the underlying device technologies may be provided in a variety of component types e.g. metal oxide semiconductor field effect transistor MOSFET technologies like complementary metal oxide semiconductor CMOS bipolar technologies like emitter coupled logic ECL polymer technologies e.g. silicon conjugated polymer and metal conjugated polymer metal structures mixed analog and digital etc.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in a sense of including but not limited to. Words using the singular or plural number also include the plural or singular number respectively. Additionally the words herein hereunder above below and words of similar import when used in this application refer to this application as a whole and not to any particular portions of this application. When the word or is used in reference to a list of two or more items that word covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

The above description of illustrated embodiments of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. The teachings of the invention provided herein can be applied to other systems not only for the system including graphics processing or video processing as described above.

For example an antialiased image produced as described herein may be output to a variety of display devices including computer displays that display moving pictures and printers that print static images.

The various operations described may be performed in a very wide variety of architectures and distributed differently than described. As an example in a distributed system a server may perform some or all of the rendering process. In addition though many configurations are described herein none are intended to be limiting or exclusive. For example the invention can also be embodied in a system that includes an integrated graphics processor IGP or video processor and a discrete graphics or video processor where frame data processed by each of the integrated and discrete processors is merged or composited as described. Further the invention can also be embodied in a system that includes the combination of one or more IGP devices with one or more discrete graphics or video processors.

In other embodiments some or all of the hardware and software capability described herein may exist in a printer camera television handheld device mobile telephone or some other device. The antialiasing techniques described herein may be applied as part of a process of constructing animation from a video sequence.

The elements and acts of the various embodiments described above can be combined to provide further embodiments. These and other changes can be made to the invention in light of the above detailed description.

In general in the following claims the terms used should not be construed to limit the antialiasing method and system to the specific embodiments disclosed in the specification and the claims but should be construed to include any processing systems that operate under the claims to provide antialiasing. Accordingly the antialiasing method and system is not limited by the disclosure but instead the scope of the antialiasing method and system is to be determined entirely by the claims.

While certain aspects of the method and apparatus for antialiasing are presented below in certain claim forms the inventors contemplate the various aspects of the method and apparatus for antialiasing in any number of claim forms. For example while only one aspect of the method and apparatus for antialiasing may be recited as embodied in computer readable medium other aspects may likewise be embodied in computer readable medium. Accordingly the inventors reserve the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the method and apparatus for antialiasing.

