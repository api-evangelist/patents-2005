---

title: Event packaged video sequence
abstract: Methods and systems for packaging video sequences based on user-specified events are described herein. An illustrative method of event-packaging a video sequence may include the steps of acquiring a video stream containing an event of interest, extracting various event information from the video stream and storing one or more event parameters within an event database, extracting a video clip from the video stream containing the event of interest, associating metadata representing the event parameters to the video clip, and exporting the video clip containing the event of interest and associated metadata to an external agent. In certain embodiments, a video image-processing appliance manager and/or one or more appliance modules can be provided to automatically extract event information from the acquired video stream, and to manage the indexing and storage of event parameters within the event database. A graphical user interface may also be provided to permit the event information extracted from the video stream to be compared against a set of user-specified event parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07760908&OS=07760908&RS=07760908
owner: Honeywell International Inc.
number: 07760908
owner_city: Morristown
owner_country: US
publication_date: 20050331
---
The present invention relates generally to the field of video image processing. More specifically the present invention pertains to methods and systems for packaging video sequences based on user specified events.

Video surveillance systems are used in a variety of applications for monitoring objects within an environment. In security applications for example such systems are sometimes employed to track individuals or vehicles entering or leaving a building facility or security gate or to monitor individuals within a store office building hospital or other such setting where the health and or safety of the occupants may be of concern. In the aviation industry for example such systems have been used to monitor the presence of individuals at key locations within an airport such as at a security gate or parking garage.

In certain applications the video surveillance system may be tasked to record video image data for later use in determining the occurrence of a particular event. In forensic investigations for example it is common to task one or more video cameras within the system to indiscriminately record entire video clips that can later be analyzed to detect the occurrence of an event such as a robbery or theft. Such video images are typically stored as either analog video streams or as digital image data on a hard drive optical drive videocassette recorder VCR or other suitable storage means.

To permit prompt action to be taken upon the occurrence of an event it is sometimes desirable to bind portions of the video sequence into a package containing the event and then transmit such package to an external agent for further analysis. In certain security applications for example it may be desirable for a security guard to record a video clip containing facial images of an individual and then transmit such video clip to another agent e.g. a facial image database for further analysis. To accomplish this task many systems require the operator to manually scan the entire video stream until the desired event is found. In some cases the system may require the operator to determine the time and or date of the event as well as the particular camera or cameras used to detect the event. The lack of an automated means for providing video clips directly to an operator can thus result in increased search times and slower response times.

The present invention pertains to methods and systems for packaging video sequences based on user specified events. An illustrative method of event packaging a video sequence may include the steps of acquiring a video stream containing an event of interest extracting various event information from the video stream and storing one or more event parameters relating to the event within an event database extracting a video clip from the video stream containing the event of interest associating the event parameters to the video clip and exporting the video clip containing the event of interest and associated event parameters to an external agent such as a terminal station or networked storage device.

In certain embodiments a video image processing appliance manager and or one or more appliance modules can be provided to automatically extract event information from the acquired video stream and or to manage the indexing and storage of event parameters within the event database. A graphical user interface may be provided to permit the event information extracted from the video stream to be compared against a set of user specified event parameters. In one illustrative embodiment the user specified event parameters may comprise a set of semantic parameters that can be used to detect and analyze various events occurring within one or more regions of interest. Other features such as a means for adjusting the pre record and or post record duration of the extracted video clip and a means for providing annotation information along with the extracted video clip can be further provided on the graphical user interface if desired.

The following description should be read with reference to the drawings in which like elements in different drawings are numbered in like fashion. The drawings which are not necessarily to scale depict selected embodiments and are not intended to limit the scope of the invention. Although examples of algorithms and processes are illustrated for the various elements those skilled in the art will recognize that many of the examples provided have suitable alternatives that may be utilized.

A number of browsers or terminal stations equipped with a user interface e.g. a graphical user interface can be connected to the network and tasked to control the operation of the DVSS s in a particular manner. In some embodiments a terminal monitor e.g. a closed circuit television monitor can also be provided in addition to or in lieu of the browsers or terminal stations to view images acquired from one or more of the DVSS s . The browsers or terminal stations can be configured to interact with a host application software program that can be used to task the DVSS s in a particular manner. Based on user input via the user interface for example the host application software program can be used to change operational parameters of the DVSS s e.g. PTZ settings ROI settings resolution frame rate etc. and or to task a video image processing appliance manager to perform certain user defined tasks such as motion detection motion tracking etc. If for example the user desires to increase the resolution of images received by one or more of the DVSS s in order to perform facial recognition of an individual within a region of interest the host application software program can be configured to accept a command causing one of the DVSS s to zoom in on the subject s face and increase the image capture rate. In the illustrative embodiment of three DVSS s are shown connected to the network each of which can be tasked to acquire video and or still images within a respective field of view FOV represented generally by dashed lines . It should be understood however that a greater or lesser number of DVSS s may be employed if desired. As shown in the DVSS s can be connected to the network directly through the host application software program or both as desired.

As can be further seen in the host application software program can be configured to call a video image processing appliance manager that can be used to facilitate processing of video images received from the DVSS s using a number of plug in appliance modules . The appliance manager can be adapted to interface with the host application software program as well as other components within the system . The video images and or other information acquired by the DVSS s can be fed through the appliance manager which tasks the appropriate appliance modules to determine the occurrence of any events configured within the system . If an event is triggered the appliance manager can be configured to output a response e.g. via the user interface indicating that an event has occurred within a region of interest. If desired the video images triggering the event can be stored on a hard drive magnetic tape or other storage medium allowing the video images to be replayed and or subsequently processed. In some embodiments the video images acquired from the DVSS can also be displayed in real time on the terminal monitor .

The host applications can comprise separate components from the DVSS s e.g. a stand alone software package or can be formed integral with one or more of the DVSS s and provided as a single component if desired. In certain embodiments for example one or more of the DVSS s may comprise a physically separate video camera that is connected to an existing software based host application adapted to run on the Internet an intranet connection and or on an individual workstation equipped with a user interface . In such applications each of the associated DVSS s can be connected to their associated host application using an application program interface API or other suitable interface.

The host applications may comprise one or more existing host application software programs contained on a network server browser terminal station or other platform. The functionality provided by the existing host applications will typically vary depending on their intended use. If for example the host applications are adapted to interface with network based control access and security systems products the host applications may include an existing security software program that can be used to task a number of DVSS s to pan tilt and zoom to a tracked motion within a region of interest. Examples of other types of host applications may include but are not limited to building management applications e.g. HVAC control life safety applications e.g. fire protection medical care etc. asset location applications and energy management applications.

The appliance manager will typically comprise a separate module from the host applications allowing the appliance manager to be linked with the user s existing system without having to significantly modify or reprogram the existing software to accommodate new DVSS clients as they are added to the system. It should be understood however that the appliance manager and host applications could be incorporated together as a single stand alone module if desired.

The appliance manager can be configured to maintain one or more business objects which can include various information about the region or regions of interest to be monitored any events configured by a configurator as well as various configuration information about the host applications connected to the system. In certain embodiments for example the appliance manager can be configured to maintain a camera structure list and an event structure list containing information about the type of DVSS s employed and the type of events configured within the system. Such lists can be stored within a memory unit or database e.g. database and recalled each time the appliance manager receives an initialization call or detection call from one or more of the host applications .

The video monitoring system may include a configurator that can be used in the direct manipulation and configuration of images or other data received by the host applications . A tuning request call received from one or more of the host applications can be used by the configurator to tune the appliance manager and or other desired system components to function in a particular manner. If for example a user desires to increase the frame capture rate of one of the DVSS s e.g. a video camera field of view the host application can be configured to send a tuning request or call to the appliance manager that can be used by the configurator to coordinate such a change. Once the change has been made the appliance manager can then be configured to pass the newly configured video stream through. In some embodiments the configurator can also be configured to send a response to the host application and or to the user indicating whether the tuning invocation succeeded or failed.

The appliance manager can be connected to a database that can be configured to store information received from the DVSS s as well as parameters received by the configurator as directed by the appliance manager and or user via the user interface . In certain embodiments the database can be two separate databases residing at different servers wherein one database can be linked to the host application and the other database can be linked to the appliance manager . In other embodiments the database may comprise a single database or multiple databases existing on a single server.

The appliance manager can be configured to interact with a number of plug in appliance modules each adapted to run various video image processing algorithms or routines that can be used to perform certain user defined image processing functions. In the illustrative embodiment of for example the appliance manager is shown operatively connected to a video motion detection VMD module a video motion tracking VMT module an object classification OC module an event detection module and an action dispatcher module . The various appliance modules can be provided as either software appliances adapted to be run on a network or terminal server or as separate hardware units that can be plugged into the appliance manager vis vis a network bridge or other suitable connection. These modules can be upgraded when needed to enhance performance and or meet specific host application requirements.

The appliance manager can be configured to permit the modular incorporation of future appliance modules as desired. If for example the user desires to add a facial detection module or rapid eye detection module to the video monitoring system the appliance manager can be configured to accept a software call network socket physical port e.g. a USB port Firewire IEEE 1394 port parallel serial port etc. and or wireless port that can be used to add the additional modules. Since an appliance manager is provided to interface with the host applications the addition of future plug in modules does not require the user to re code or re formulate the existing host applications . In addition the appliance manager may provide the user with the ability to change the implementation and or features of existing functionality without significantly affecting the operation of the DVSS s.

The appliance manager can be configured to run a video image processing algorithm or routine that continuously monitors the camera structure list and configured events list to determine whether an event has been detected by one or more of the DVSS s. When an event contained within the event list is detected the appliance manager can be configured to transmit a result back to the host application along with an action request tasking one or more of the DVSS s to operate in a particular manner. If for example the video motion tracking module detects that an object is moving in a particular direction within a region of interest the appliance manager can be configured to provide a result to the appropriate host application informing it that the object is being tracked along with an action request tasking one or more associated DVSS s to track the object.

Turning now to an illustrative method of defining and analyzing events occurring within a video monitoring system will now be described in the context of the illustrative appliance manager of . As shown in method may begin at block wherein a call is received by the appliance manager causing the appliance manager to initialize an algorithm or routine therein that can be used in defining detecting analyzing indexing and or retrieving one or more events of interest. In the context of the illustrative video monitoring system described above with respect to for example such appliance manager may be called when a user and or host application desires to task one or more DVSS s to detect the occurrence of an event within a field of view.

Once invoked the appliance manager can be configured to task one or more of the appliance modules to extract information regarding one or more objects located within a region of interest as indicated generally by reference to block . Information that can be extracted at this step may include for example information about an object s motion trajectory orientation size aspect ratio color lighting temperature and or information about an object s type or classification e.g. human animal vehicle animate inanimate etc. . Such extracted information can be obtained using one or more of the appliance modules described above with respect to . If for example the user wishes to define an event that detects and tracks vehicle motion within a parking garage the appliance manager tasks the video motion detection module and video motion tracking module to run separate algorithms or routines that can be used to perform such tasks. Information regarding the classification of the object in turn can be determined by invoking the object classification module and running an algorithm or routine therein that determines whether an object is a vehicle. In some embodiments the appliance manager can be configured to task a video face detection module and or video face tracking module to run separate algorithms or routines that can be used to gather information to perform facial recognition on individuals. The types of information extracted by the monitoring system will typically vary depending on the types of video cameras employed the location of the video cameras the particular appliance module s available to the system as well as other factors.

Once the information is extracted within a region of interest the appliance manager tasks the event detection module to combine this information in a meaningful manner to detect the occurrence of an event of interest as indicated generally by reference to block . Each event of interest can be specified by a set of conditions and or sub conditions that identify the object and semantically describe its state and or physical features relative to a particular region of interest. In certain embodiments for example each condition and or sub condition can be quantified by a set of semantic parameters that can be compared against a corresponding set of semantic parameters programmed within the event detection module . Examples of such semantic parameters may include but are not limited to information regarding the region of interest e.g. entranceway parking garage security zone conveyor belt etc. actions relating to the object e.g. start stop enter exit etc. and information regarding the direction of the object e.g. left right top bottom etc. . In some embodiments semantic parameters relating to the type or classification of object detected e.g. human animal vehicle animate inanimate other any etc. may also be provided. In other embodiments semantic parameters relating to the type of motion e.g. walk run high speed low speed etc. may also be provided. Semantic parameters relating to the physical appearance e.g. color and size of object single or group of people or for a particular detected face e.g. happy neutral sad etc. may also be provided if desired.

Once the semantic parameters are combined and analyzed to detect the occurrence of an event such information can be compared against a set of user specified events as indicated generally by reference to block . Matching of the detected event with a corresponding user specified event can be accomplished automatically by comparing the semantic parameters determined by the appliance modules with a set of semantic parameters specified by the user. If for example an event occurring within a region of interest is defined using a set of semantic parameters including the text vehicle enters from right and within ROI 1 such event can be compared against a set of user specified semantic parameters containing the text vehicle enters from right in ROI 1 to find a match. In certain embodiments such user specified semantic parameters can be stored as event parameters within an image database e.g. database and can be provided to the event detection module through the appliance manager via a graphical user interface or other suitable interface. Indexing and or subsequent retrieval of such events can also be accomplished in a similar manner using such semantic parameters if desired.

When a match exists the appliance manager invokes the action dispatcher module to set up the appropriate action request or requests and perform an action response as indicated generally by reference to block . In certain embodiments for example the action dispatcher module can be configured to trigger an alarm or other such response to notify a user when a configured event has been detected. The appliance manager can also be configured to record a video clip containing the detected event and or send a video feed to a terminal station browser network server or other such location for further analysis by a user and or host application. In some embodiments the video feed may contain one or more supporting event parameters. Other action responses such as that described below with respect to the illustrative graphical user interface of can also be performed if desired.

The first and second regions of interest may be shaped as any closed polygon in the image defined by the vertices of the polygon. In the illustrative view of for example the first region of interest is shown as a polygon e.g. a rectangle having a left side boundary a top side boundary a right side boundary and a lower side boundary which define a first pixel area within the video frame . In similar fashion the second region of interest is shown as a polygon having a left side boundary a top side boundary a right side boundary and a lower side boundary which define a second pixel area within the video frame . In the illustrative video frame depicted in the pixel areas defined by each respective region of interest are non overlapping such that none of the image pixels contained in the first pixel area overlap with any of the image pixels contained in the second pixel area . It should be understood however that other embodiments are envisioned wherein portions of the regions of interest overlap one another. In some embodiments other polygons having a non rectangular shape may be defined as the ROI. In such case the major and minor axes of the ROI are determined and a rectangular region defined by the major and minor axes can be used for evaluating the event conditions as described below.

As can be further seen in the first and second regions of interest may each define an ROI boundary area which as indicated by shading can be located about the outer periphery of each respective pixel area . Each ROI boundary area can be defined as a percentage or fraction of the total number of pixels contained within the pixel area . In the illustrative video frame of for example the first and second regions of interest may have respective ROI boundary areas defined as percentage values x and x respectively wherein each percentage value x x is expressed as a percentage of the pixel area of the ROI boundary area relative to their corresponding pixel area . The size shape and locations of the ROI boundary areas may vary depending on the type of region selected by the user the characteristics of the objects located within that scene as well as other factors. Thus while rectangular shaped ROI boundary areas are specifically depicted in the illustrative embodiment it should be understood that other types of ROI boundary areas can be utilized. If for example the ROI to be monitored is a building or structure having an irregular shape then the ROI boundary area used to define that ROI may have also have an irregular shape to better approximate the ROI. Such irregular shape may be defined for example by selecting a greater number of reference points on the video frame using curved lines to define the boundary area and or by some other suitable technique. The number of ROI s located within the video frame may vary depending on the number of ROI s to be monitored.

Using the minimum boundary rectangle to represent the general shape of the object OBJ a number of events relating to the object s motion relative to the first region of interest can be determined by comparing the coordinates of the ROI boundary area with a corresponding set of coordinates of the minimum boundary rectangle . In the illustrative embodiment of for example an upper left location and lower right location of the ROI boundary area can be assigned a set of coordinates of R R and R R respectively. In similar fashion an upper left location and lower right location of the minimum boundary rectangle can be assigned a corresponding set of coordinates O O and O O respectively. A similar coordinate scheme can be utilized for other objects and regions of interest situated within the video frame as desired.

While the upper left and lower right locations are selected in as reference points to determine the position of the minimum boundary rectangle relative to the first region of interest it should be understood that other reference locations could also be utilized if desired. In one alternative embodiment for example the lower left and upper right locations of the first ROI boundary area and minimum boundary rectangle could be used as reference points. Moreover while the use of a minimum boundary rectangle is specifically shown in the illustrative view of those of skill will recognize that other boundary shapes could be used to approximate the size and or contour of the object. Moreover annotation information such as object labels motion trails motion direction arrows highlighting of detected objects etc. can be further provided to aid the user in identifying and tracking objects within the video frame if desired.

In certain embodiments and as further shown in Table 1 reproduced below the sets of upper left and lower right coordinates R R R R and O O O O can be used to define various event conditions i.e. semantic parameters relating to the object s location and direction relative to the ROI boundary area by comparing the corresponding coordinate values. If for example the left side of the minimum boundary rectangle is located within the left side boundary of the ROI boundary area then the equation 0

In certain cases multiple event conditions may be satisfied for the same object. If as shown for example in the minimum boundary rectangle of the object OBJ enters the ROI boundary area simultaneously from both the left and bottom side boundaries a Left and Bottom event condition will be detected. In such case the monitoring system can be configured to combine the two semantic parameters into a string of semantic parameters using a suitable Boolean operand such as and or . Once the event conditions i.e. semantic parameters are combined the monitoring system can then be configured to match these event conditions with a corresponding set of event conditions specified by the user.

Turning now to an illustrative method of event packaging a video sequence in accordance with an exemplary embodiment of the present invention will now be described. As shown in method may begin at block wherein a DVSS or network of DVSS s is are tasked to acquire a video stream containing an event of interest block . In certain embodiments for example the acquired video stream may comprise a digital video stream obtained from an analog camera having a digital IP addressed streamer or in the alternative a digital camera having a straight digital IP addressed streamer.

Once a video stream containing an event of interest is acquired a series of algorithms and or management functions can be executed to extract various event information from the video stream that can later be used to package a portion of the video stream into a video clip containing the event of interest. As indicated generally by block for example method may include the step of extracting various event information in a manner similar to that described above with respect to wherein information regarding an object located within a region of interest is compared and matched against a set of event parameters specified by a user. Examples of such event parameters may include metadata such as the date and time of the event a header identifying the configured event the camera or cameras tasked to acquire the video stream containing the event the location of the event the type of event detected the lighting conditions detected by the camera or cameras the classification of the object triggering the event e.g. individual vehicle animal animate inanimate etc. the direction of object motion the color of the object e.g. red blue dark light etc. and or facial information. In certain embodiments such event information can be extracted using the video image processing appliance manager and or one or more of the appliance modules described herein. Once extracted the event information can then be indexed and stored as event parameters within an event database e.g. database for subsequent use.

Once event information has been obtained from the video stream a video clip containing the desired event may be extracted from the video stream and then optionally stored within a video database as indicated generally by reference to block . In certain embodiments a user selectable duration of the video stream can be recorded as a video clip within the video database and can be associated with the one or more of the event parameters e.g. event description date time camera number etc. representing the event. Other characteristics describing the object or objects triggering the event as well as each object s interaction with the region of interest may also contained within the event database if desired. In some embodiments a user interface e.g. a GUI can be employed to permit the user to adjust the pre record and or post record duration of the video clip the space or memory allocated to the video clip the format of the video clip e.g. MPEG MJPEG etc. the aspect ratio of the video frames within the video clip as well as other settings. Annotation information such as object labels motion trails motion direction arrows highlighting of detected objects etc. can also further provided along with the event packaged video clip if desired.

Once an event packaged video clip is extracted and stored within the database the video clip and associated metadata can then be exported to an external agent as indicated generally by reference to block . The event packaged video clip may be sent to the external agent either directly or when prompted by the user via the user interface. The event parameters that supported the detection can be associated and sent with the video clip. The databases containing the event information and associated video clips may then be searched using semantic parameters similar to that described above with respect to . If for example the user desires to search the event database for those events containing an individual entering a particular region of interest the user may input a command into a user interface causing any video clips associated with that particular event to be retrieved from the video database. The video clip containing the event as well as the event parameters used to define the event can then be exported to an external agent for further analysis if desired. In some embodiments for example such event packaged video clip can be exported to the external agent via a network connection electronic mail PDA phone line or other suitable transmission means. The event packaged video clip can also be sent to other locations within the monitoring system such as a terminal station network storage device or other system appliance.

By automatically providing an event packaged video clip containing the event of interest the search time usually required to locate an event within a video sequence may be reduced significantly. Moreover such event packaged video clips may reduce the time required for an operator to respond to an event allowing quicker response times to be achieved in some applications.

Referring now to an illustrative graphical user interface in accordance with an exemplary embodiment of the present invention will now be described in conjunction with the illustrative appliance manager of . Graphical user interface may include a display screen configured to display various information related to events configured within the appliance manager as well as the various appliance modules e.g. the event detection module . In the illustrative embodiment of for example the graphical user interface may include a REGIONS OF INTEREST section that permits the user to identify various regions of interest within the field of view FOV of a DVSS in the monitoring system. The REGION OF INTEREST section may include a DVS ID menu button that can be used to specify where the region of interest is location and a REGION NAME menu button that can be used to name a particular region of interest e.g. Carpark A in which to detect events. The region name uniquely associates with an area in the FOV of the DVSS whose identity is specified by the DVS ID menu button . This area can be displayed and annotated in the display screen of the graphical user interface . When selected via a mouse keyboard keypad touch screen or other suitable selection means the graphical user interface can be configured to display a list of those regions of interest available for detection within the FOV of the DVS ID by the monitoring system.

Other information e.g. the coordinates of the corners of the region of interest can also be displayed and or be configured via the graphical user interface if desired. In the illustrative embodiment of for example the graphical user interface may include a PARAMETER SETTING section that permits the user to specify the parameter values of the various appliance modules. A SCENARIO menu button within the PARAMETER SETTING section can be provided to permit the user to adjust the sensitivity at which events are detected. If for example the selected region of interest is located indoors where lighting conditions are typically bright the user may select Indoors High or other appropriate text using the SCENARIO menu button . Other suitable selections such as Outdoors Low or Mixed Conditions Intermediate may also be implemented using the SCENARIO menu button if desired. In some embodiments a SUB SAMPLING menu button and MINIMUM OBJECT SIZE text box may also be provided to permit the user to adjust the sub sampling rate of images captured and or to set the minimum size of objects to be detected. In some embodiments a CLASSIFIER menu button may be provided to permit the user to specify which classifier and its associated parametric values to be used in classifying the object. Other parameters in addition to those specifically depicted in may also be provided to facilitate operation and or configuration of the monitoring system if desired.

A VIDEO MONITOR section of the graphical user interface can be configured to display video images and or still images acquired by one or more of the DVSS s within the monitoring system. In some embodiments the DVS ID which captures the video image may also be superimposed on the VIDEO MONITOR section . In the illustrative view depicted in for example the graphical user interface is shown displaying a first region of interest in an upper left portion of the VIDEO MONITOR section and a second region of interest in a lower right portion of the VIDEO MONITOR section . Each region of interest can be demarcated on the display screen using a dashed boundary box or other suitable visual indicator. In some embodiments the corresponding region name e.g. Carpark A Security Zone 1 etc. may also be superimposed on each region of interest displayed on the display screen if desired.

An EVENTS TO DETECT WITHIN REGION OF INTEREST section of the graphical user interface can be provided to permit the user to select those event conditions to be detected within the particular region of interest selected via the REGION NAME menu button . A list of event conditions currently programmed within the monitoring system can be displayed within a text box located within section . An ADD icon button located to the right of the text box can be provided to permit the user to add additional event conditions to be detected by the monitoring system. A DELETE icon button also located to the right of the text box in turn can be provided to permit the user to delete one or more event conditions currently programmed within the monitoring system. If desired the current event condition selected within the text box i.e. Red Vehicle Enter Carpark A From Left can be highlighted by blinking text italics inverted text or other suitable visual means. When the ADD icon button is selected the user can be prompted to enter the desired event conditions.

An EVENT CONDITION DETAILS section of the graphical user interface can be configured to permit user entry as well as display those details associated with each event condition configured within the monitoring system. In the illustrative embodiment of for example an OBJECT TYPE menu button and a CONDITION TO DETECT menu button can be provided to permit the user to select the type of object and event condition s to be detected. If for example the user desires to monitor vehicles entering a carpark the user may select vehicle using the OBJECT TYPE menu button and enters region using the CONDITION TO DETECT menu button . Examples of other object types or classifications that can be selected using the OBJECT TYPE menu button may include individual animal animate object inanimate object any object unknown object etc. Examples of other types of event conditions that can be selected using the CONDITION TO DETECT menu button may include start track stop track exits region movement detected etc.

A DIRECTION OF MOTION menu button can be provided to permit the user to select the direction or directions in which an object triggers an event. If for example the user desires to detect only those events in which an object travels through a region of interest from the left the user may select From Left using the DIRECTION OF MOTION menu button causing the monitoring system to perform an action response only when the object is traveling from this direction. Alternatively if the user desires to detect only those events in which an object is traveling from the right from above or from below the user may select From Right From Above and or From Below or other appropriate text using the DIRECTION OF MOTION menu button causing the monitoring system to perform an action response only when the object is traveling from these directions. If desired the graphical user interface may permit the user to select multiple directions e.g. From Left and From Below in which to detect and or track object motion.

In certain embodiments the graphical user interface can be configured to permit the user to specify more complex motion to be detected and tracked. If for example the user desires to detect when an object traverses a serpentine like path within a particular region of interest the user may select Serpentine Path or other appropriate text using the DIRECTION OF MOTION menu button causing the monitoring system to perform an action response when the object travels in such pattern. Other user specified directions and or paths can be further implemented in similar fashion via the DIRECTION OF MOTION menu button if desired.

A VIDEO CAMERA menu button can be provided to permit the user to select those video cameras to be tasked in detecting events. If for example the user desires to separately task one or more video cameras e.g. Camera Camera Cameras etc. to detect object motion within a particular region of interest the user may select the appropriate camera name using the VIDEO CAMERA menu button . Alternatively and as shown in if the user desires to task all of the video cameras to detect a particular event the user may select Any Camera or other appropriate text using the VIDEO CAMERA menu button . In certain embodiments other components e.g. motion sensors temperature sensors etc. used by the video monitoring system to detect events may be tasked in similar fashion using the VIDEO CAMERA menu button if desired.

A DURATION OF CONDITION menu button can be provided on the graphical user interface to permit the user to select the period of time necessary to trigger an event. If for example the user desires to trigger only those events lasting for a duration of two minutes or more the user may select 2 Min or other appropriate text using the DURATION OF CONDITION menu button . Other durations e.g. 1 Min 30 Min 1 Hr. 4 Hrs. 1 Day etc. may also be provided via the DURATION OF CONDITION menu button to permit the user to select other time periods as desired. In some embodiments the graphical user interface can be configured to accept a user specified duration if the user desires to set a time period different than that contained in memory.

In certain embodiments a DOMINANT COLOR menu button and LICENSE NUMBER menu button can be provided to permit the user to select the color and or license number of any vehicles to be detected by the monitoring system. If for example the user desires to detect only those vehicles that are of a particular color e.g. red green blue white light dark etc. or of a particular license plate number or type e.g. AAIK388 etc. the user may enter such information into the graphical user interface via the DOMINANT COLOR and LICENSE NUMBER menu buttons . A set of selection boxes can be selected on the display screen to task the monitoring system to attempt to read license plate numbers and or to count the number of event conditions satisfied. In certain embodiments for example box can be selected if the user desires to count the number of vehicles individuals and or other objects passing in and out of a region of interest such as a security checkpoint.

A WHEN CONDITION IS DETECTED section of the graphical user interface can be provided to permit the user to select those actions to be associated with a particular event. An ALARM selection box can be selected to generate an alarm when an event is detected by the monitoring system or when an error or other user specified condition has occurred. If desired an ALARM LEVEL menu button can be provided to vary the level of the alarm e.g. High Medium Low etc . In certain embodiments an ALARM MODE menu button can be provided to toggle the mode e.g. Audible Only Audible Visual Visual Only of the alarm when activated.

A START RECORDING selection box can be selected to activate a recording when one or more events are detected by the monitoring system. A PRE RECORD TIME menu button and RECORD TIME menu button within section can be provided to permit the user select the amount of time to be allocated to recording before and after the detected event. In the illustrative view depicted in for example No Pre recording and 30 seconds are shown selected using the PRE RECORD TIME and RECORD TIME menu buttons causing the monitoring system to record for a period of 30 seconds after the detection of an event. If the user desires to increase or decrease the time allocated for recording or if the user desires to pre record video prior to the occurrence of an event the user may select menu buttons and make the appropriate adjustments as desired.

A RECORD FRAME RATE menu button can be further provided to permit the user to adjust the frame rate of each video camera tasked by the monitoring system. If for example the user desires to record at a frame rate of 25 fps the user may select 25 frames per second or other appropriate text using the RECORD FRAME RATE menu button . In certain embodiments the graphical user interface can be configured to display an alphanumeric message informing the user of the maximum image bandwidth to be delivered by each video camera tasked by the monitoring system. A DELETE AFTER menu button can also be provided to permit the user to specify a time period e.g. 1 day 2 days 1 week 1 month indefinitely etc. in which to store the recorded video clip prior to being deleted.

A SEND VIDEO TO STATION S selection button can be selected to output video feeds to selected stations upon the detection of an event by the monitoring system. If for example the user desires to output video to a particular terminal or network station the user may select a STATION NUMBER icon button on the graphical user interface and then enter the particular station or stations in which to feed the video using text box . Alternatively if the user desires to output video to all stations tasked to monitor a particular area the user may select the ALL STATIONS IN AREA icon button on the graphical user interface and select the appropriate area e.g. Region A Zone B etc. using menu button .

Having thus described the several embodiments of the present invention those of skill in the art will readily appreciate that other embodiments may be made and used which fall within the scope of the claims attached hereto. Numerous advantages of the invention covered by this document have been set forth in the foregoing description. It will be understood that this disclosure is in many respects only illustrative. Changes can be made with respect to various elements described herein without exceeding the scope of the invention.

