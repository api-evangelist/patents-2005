---

title: Application server architecture
abstract: Embodiments of the invention are generally directed to a system and method for an application server architecture having a common connection manager for at least two heterogeneous application server software suites. One of the software suites is a standards-based application server software suite having a plurality of worker nodes. In one embodiment, the plurality of worker nodes share code and data that is stored in a shared memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07689660&OS=07689660&RS=07689660
owner: SAP AG
number: 07689660
owner_city: Walldorf
owner_country: DE
publication_date: 20050609
---
The field of invention pertains generally to the software arts and more specifically to an application server architecture.

Even though standards based application software e.g. Java based application software has the potential to offer true competition at the software supplier level legacy proprietary software has proven reliability functionality and integration into customer information systems IS infrastructures. Customers are therefore placing operational dependency on standards based software technologies with caution. Not surprisingly present day application software servers tend to include instances of both standard and proprietary software suites and often problems emerge in the operation of the newer standards based software or interoperation and integration of the same with legacy software applications.

The prior art application server depicted in provides a good example. shows a prior art application server having both an Advanced Business Application Programming ABAP legacy proprietary software suite and a Java 2 Platform Enterprise Edition J2EE standards based software suite . A connection manager routes requests e.g. HyperText Transfer Protocol HTTP requests and HTTP with secure socket layer HTTPS requests associated with sessions between server and numerous clients not shown in conducted over a network . A session can be viewed as the back and forth communication over a network between computing systems e.g. a particular client and the server .

The back and forth communication typically involves a client client sending a server server a request that the server interprets into some action to be performed by the server . The server then performs the action and if appropriate returns a response to the client e.g. a result of the action . Often a session will involve multiple perhaps many requests and responses. A single session through its multiple requests may invoke different application software programs.

For each client request that is received by the application server s connection manager the connection manager decides to which software suite the request is to be forwarded. If the request is to be forwarded to the proprietary software suite notification of the request is sent to a proprietary dispatcher and the request itself is forwarded into a request response shared memory . The proprietary dispatcher acts as a load balancer that decides which one of multiple proprietary worker nodes through are to actually handle the request.

A worker node is a focal point for the performance of work. In the context of an application server that responds to client server session requests a worker node is a focal point for executing application software and or issuing application software code for downloading to the client. The term working process generally means an operating system OS process that is used for the performance of work and is also understood to be a type of worker node. For convenience the term worker node is used throughout the present discussion.

When the dispatcher identifies a particular proprietary worker node for handling the aforementioned request the request is transferred from the request response shared memory to the identified worker node. The identified worker node processes the request and writes the response to the request into the request response shared memory . The response is then transferred from the request response shared memory to the connection manager . The connection manager sends the response to the client via network .

Note that the request response shared memory is a memory resource that each of worker nodes through has access to as such it is a shared memory resource . For any request written into the request response shared memory by the connection manager the same request can be retrieved by any of worker nodes through . Likewise any of worker nodes through can write a response into the request response shared memory that can later be retrieved by the connection manager . Thus the request response shared memory provides for the efficient transfer of request response data between the connection manager and the multiple proprietary worker nodes through .

If the request is to be forwarded to the standards based software suite notification of the request is sent to the dispatcher that is associated with the standards based software suite . As observed in the standards based software suite is a Java based software suite in particular a J2EE suite that includes multiple worker nodes through .

A Java Virtual Machine is associated with each worker node for executing the worker node s abstract application software code. For each request dispatcher decides which one of the N worker nodes is best able to handle the request e.g. through a load balancing algorithm . Because no shared memory structure exists within the standards based software suite for transferring client session information between the connection manager and the worker nodes through separate internal connections have to be established to send both notification of the request and the request itself to the dispatcher from connection manager for each worker node. The dispatcher then forwards each request to its proper worker node.

A virtual machine as is well understood in the art is an abstract machine that converts or interprets abstract code into code that is understandable to a particular type of a hardware platform e.g. a particular type of processor . Because virtual machines operate at the instruction level they tend to have processor like characteristics and therefore can be viewed as having their own associated memory. The memory used by a functioning virtual machine is typically modeled as being local or private to the virtual machine. Hence shows local memory . . . N allocated for each of virtual machines . . . N respectively.

Various problems exist with respect to the prior art application server of . For example the establishment of connections between the connection manager and the J2EE dispatcher to process a client session adds overhead inefficiency within the standards based software suite . In an addition the cumulative memory footprint of worker nodes through limits the scalability of standards based software suite . Moreover the crash of a virtual machine is not an uncommon event. In the prior art standards suite of requests that are submitted to a worker node for processing are entered into a queue built into the local memory of the virtual machine that is associated with the worker node. If the virtual machine crashes its in process as well as its locally queued requests will be lost. As such potentially if the requests for a significant number of sessions are queued into the local memory of a virtual machine e.g. as a direct consequence of the virtual machine s concurrent execution of a significant number of threads the crash of the virtual machine will cause a significant number of sessions to be dropped by the application server .

Embodiments of the invention are generally directed to a system and method for an application server architecture. In an embodiment the application server architecture includes a connection manager having an integrated dispatcher to perform dispatching for a standards based software suite. The standards based software suite includes a plurality of worker nodes. In one embodiment the plurality of worker nodes share code and data that is stored in a shared memory. The shared memory may also support a common caching architecture for the plurality of worker nodes. In an embodiment the shared memory reduces the memory footprint of the application server architecture.

Comparing and first note that the role of the connection manager has been enhanced to at least perform dispatching for the standards based software suite so as to remove the additional connection overhead associated with the prior art system s standards based software suite dispatching procedures .

Also the connection manager is protocol independent. A protocol handler can be plugged into the connection manager to support any one of a number of protocols by which a request can be conveyed to the connection manager. For example handlers for protocols such as the hypertext transfer protocol HTTP secure HTTP HTTPS simple mail transfer protocol SMTP and network news transfer protocol NNTP may be provided at the connection manager so that it can receive a request conveyed from a client in accordance with any of these protocols.

In addition the role of a shared memory has been expanded to at least include a a first shared memory region that supports request response data transfers not only for the proprietary suite but also the standards based software suite b a second shared memory region that stores session objects having low level session state information e.g. information that pertains to a request s substantive response such as the identity of a specific servlet invoked through a particular web page and c a third shared memory region that stores high level session state information e.g. information that pertains to the flow management of a request response pair within the application server e.g. the number of outstanding active requests for a session .

Regarding request notification queues Q through QM one queue for each of the worker nodes through has been implemented within the standards based software suite . In an embodiment the shared memory structures and request notification queues help implement a fast session fail over protection mechanism in which a session that is assigned to a first worker node can be readily transferred to a second worker node upon the failure of the first worker node.

Shared memory is memory whose stored content can be reached by multiple worker nodes. Here the contents of the shared memory region can be reached by each of worker nodes in and . Additionally the contents of shared memory regions and can be reached by each of worker nodes through . In one embodiment shared memory region supports shared cache that can be reached by each of worker nodes through .

Different types of shared memory technologies may be utilized within the application server and yet still be deemed as being a shared memory structure. For example shared memory region may be implemented within a connection oriented shared memory technology while shared memory region may be implemented with a shared closure oriented shared memory technology. A more thorough discussion of these two different types of shared memory implementations is provided in more detail below in section 4.0 entitled Implementation Embodiment of Request Response Shared Memory and section 4.0 entitled Implementation Embodiment of Shared Closure Based Shared Memory .

The connection oriented request response shared memory region effectively implements a transport mechanism for request response data between the connection manager and the worker nodes. That is because the connection manager is communicatively coupled to the shared memory and because the shared memory is accessible to each worker node the request response shared memory at perhaps its broadest level of abstraction is a mechanism for transporting request response data between the connection manager and the applicable worker node s for normal operation of sessions e.g. no worker node failure as well as those sessions affected by a worker node crash.

Although the enhancements of the application server of have been directed to improving the reliability of a combined ABAP J2EE application server it is believed that architectural features and methodologies described in more detail further below can be more generally applied to various forms of computing systems that manage communicative sessions whether or not such computing systems contain different types of application software suites and whether any such application software suites are standards based or proprietary. Moreover it is believed that such architectural features and methodologies are generally applicable regardless of any particular type of shared memory technology employed.

In operation the connection manager forwards actual request data to the first shared memory region request response shared memory regardless of whether the request is to be processed by one of the proprietary worker nodes or one of the standards based worker nodes . Likewise the connection manager receives response data for a request from the request response shared memory whether a proprietary worker node or a standards based worker node generates the response.

With the exception of having to share the request response shared memory with the worker nodes of the standards based software suite the operation of the proprietary software suite is essentially the same as that described in the background in one embodiment of the invention. That is the connection manager forwards request notifications to the proprietary dispatcher and forwards the actual requests to the request response shared memory . The proprietary dispatcher then identifies which one of the proprietary worker nodes is to handle the request. The identified worker node subsequently retrieves the request from the request response shared memory processes the request and writes the response into the request response shared memory . The response is then forwarded from the request response shared memory to the connection manager who forwards the response to the client via network .

In an alternative embodiment the ABAP dispatcher is integrated into the connection manager just as the J2EE dispatcher . Indeed it is contemplated that a single dispatcher may encompass the functionality of both dispatchers and . In the case where the dispatcher is integrated into the connection manager the connection manager identifies which one of the proprietary worker nodes is to handle a request and via its integrated dispatcher capabilities forwards the request to the request response shared memory . The identified worker node subsequently retrieves the request from the request response shared memory processes the request and writes the response into the request response shared memory . The response is then forwarded from the request response shared memory to the connection manager who forwards the response to the client via network .

Then the dispatcher for the standards based software suite is invoked. One possible dispatching algorithm that is executed by the dispatcher is described in more detail further below in Section 3.0 entitled Dispatching Algorithm . For purposes of the present discussion it is sufficient to realize that the dispatcher 1 accesses and updates at 1 high level state information for the request s session in the shared memory session table hereinafter referred to as session table 2 determines which one of the M worker nodes should handle the newly arrived request and 3 submits at 2 the request into the request response shared memory and submits at 3 a request notification for the request into a request notification queue Q that is associated with the worker node selected by the dispatching algorithm. For ease of representation only depict the worker node that has been selected by the dispatcher to handle the request.

In an embodiment there is an entry in the session table for each session being supported by the M worker nodes. If the received request is for a new session e.g. the received request is the first request of the session the dispatcher process will create at 1 a new entry in the session table for the new session and assign at 2 one of the M worker nodes to handle the session based on a load balancing algorithm. By contrast if the received request pertains to an already existing session the dispatcher process will access at 1 the already existing entry for the session and use the information therein to effectively determine the proper worker node to handle the request as well as update at 1 the session table entry . In an embodiment as will be described in detail further below in Section 3.0 in the case of an already existing session the determination of the proper worker node may or may not involve the execution of a load balancing algorithm.

In an embodiment the following items are associated with each session table entry 1 a key used to access the session table entry itself e.g. session key SK 2 an active request count ARC that identifies the total number of requests for the session that have been received from network but for which a response has not yet been generated by a worker node 3 an identifier of the worker node that is currently assigned to handle the session s requests e.g. Pr Idx which in an embodiment is the index in the process table of the worker node that is currently assigned to handle the session s requests and 4 some form of identification of the request notification queue Q that provides request notifications to the worker node identified in 3 above.

For each request whether a first request of a new session or a later request for an already established session the dispatcher s dispatching algorithm increments the ARC value and at 3 places a request notification RN  into the request notification queue Q that feeds request notifications to the worker node that is to handle the session. The request notification RN  contains both a pointer to the request data RQD  in the request response shared memory and the session key SK in the session table entry for the session.

The pointer to the request data in request response shared memory is generated by that portion of the connection manager that stores the request data RQD  into shared memory and is provided to the dispatcher . The pointer is used by the worker node to fetch the request data RQD  from the request response shared memory and therefore the term pointer should be understood to mean any data structure that can be used to locate and fetch the request data. The worker node uses the session key or some other data structure in the request notification RNthat can be used to access the session table entry for the session to access and decrement the ARC counter to indicate the worker node has fully responded to the request for that session.

As will be described in more detail below in section 4.0 entitled Implementation Embodiment of Request Response Shared Memory according to a particular implementation the request response shared memory is connection based. Here a connection is established between the targeted assigned worker node and the connection manager through the request response shared memory for each request response cycle that is executed in furtherance of a particular session and a handle for a particular connection is used to retrieve a particular request from the request response shared memory for a particular request response cycle. According to this implementation the pointer in the request notification RN is the handle for the shared memory connection that is used to fetch request data RQD  . The connection between the connection manager and the worker node established to handle a request response cycle should not be confused with a network connection between a client over network that is the source of the request and the application server .

In the case of a first request for a new session the dispatcher determines the worker node to be assigned to handle the session e.g. with the assistance of a load balancing algorithm and places the identity of the worker node s request notification queue Q into a newly created session table entry for the session along with some form of identification of the worker node itself e.g. Pr Idx the index in the process table of the worker node that is currently assigned to handle the session s requests . For already existing sessions the dispatcher simply refers to the identify of the request notification queue Q in the session s session table entry in order to determine into which request notification queue the request notification RN should be entered.

Continuing then with a description of the present example with the appropriate worker node being identified by the dispatcher the dispatcher continues with the submission at 2 of the request RQD  into the request response shared memory and the entry at 3 of a request notification RN  into the queue Q that has been established to supply request notifications to worker node . The request notification RN  sits in its request notification queue Q until the targeted worker node foresees an ability or has the ability to process the corresponding request . Recall that the request notification RN  includes a pointer to the request data itself RQD  as well as a data structure that can be used to access the entry in the session table e.g. the session key SK .

Comparing note that with respect to a separate request notification queue is implemented for each worker node that is there are M queues Q through QM for the M worker nodes through respectively . Having a request notification queue for each worker node allows for the rescue of a session whose request notification s have been entered into the request notification queue of a particular worker node that fails crashes before the request notification s could be serviced from the request notification queue.

When the targeted worker node foresees an ability to process the request it looks to its request notification queue Q and retrieves at 4 the request notification RN  from the request notification queue Q. shows the targeted worker node as having the request notification RN  to reflect the state of the worker node after this retrieval at 4. Recalling that the request notification RN  includes a pointer to the actual request RQD  within the request response shared memory the targeted worker node subsequently retrieves at 5 the appropriate request RQD  from the request response shared memory . shows the targeted worker node as having the request RQD  to reflect the state of the worker node after this retrieval at 5. In an embodiment where the request response shared memory is connection oriented the pointer to RQD  is a handle that the worker node uses to establish a connection with the connection manager and then read at 5 the request RQD  from the request response shared memory.

The targeted worker node also assumes control of one or more session objects S used to persist low level session data. Low level session data pertains to the request s substantive response rather than its routing through the application server. If the request is the first request for a new session the targeted worker node creates the session object s S for the session or if the request is a later request of an existing session the targeted worker node retrieves at 6 previously stored session object s S from the shared closure memory region into the targeted worker node . The session object s S may be implemented as a number of objects that correspond to a shared closure . A discussion of shared closures and an implementation of a shared closure memory region is provided in more detail further below in section 4.0 entitled Implementation Embodiment of Shared Closure Based Shared Memory 

With respect to the handling of a new session the targeted worker node generates a unique identifier for the session object s S according to some scheme. In an embodiment the scheme involves a random component and an identifier of the targeted worker node itself . Moreover information sufficient to identify a session uniquely e.g. a sessionid parameter from a cookie that is stored in the client s browser or the URL path of the request is found in the header of the request RQD  whether the request is the first request of a new session or a later requests of an existing session. This information can then be used to fetch the proper session object s S for the session.

In reviewing the ARC value across note that it represents how many requests for the session the connection manager has received from network but for which no response has yet been generated by a worker node. In the example provided with reference to only one request is outstanding at any one point in time hence the ARC value never exceeds a value of 1. Conceivably multiple requests for the same session could be received from network prior to any responses being generated. In such a case the ARC value will indicate the number of requests that is queued or is currently being processed by one or more worker nodes but for which no response has been generated.

After the response is written at 7 into the request response shared memory it is retrieved at 10 into the connection manager which then sends it to the client over network .

The ARC value for the session is incremented in the session s session table entry and the request notification RN for the session is directed to the request notification queue for the new worker node that has just been assigned to handle the session .

Recall from above that according to a particular implementation the request response shared memory has a connection oriented architecture. Here a connection is established between the targeted worker node and the connection manager across the request response shared memory for each request response cycle between the connection manager and a worker node. Moreover a handle to a particular connection is used to retrieve a particular request from the request response shared memory.

The connection oriented architecture allows for easy session handling transfer from a crashed worker node to a new worker node because the routing of requests to a new targeted worker node is accomplished merely by routing the handle for a specific request response shared memory connection to the new worker node. That is by routing the handle for a request response shared memory connection to a new worker node the new worker node can just as easily connect with the connection manager to obtain a request as the originally targeted but now failed worker node. Here the pointer contained by the request notification is the handle for the request s connection.

In a further embodiment referring to the FCA level is also used to implement each of the request notification queues . As such the request notification queues are also implemented as a shared memory technology. Notably the handlers for the request notification queues provide more permanent associations with their associated worker nodes. That is as described each of the request notification queues is specifically associated with a particular worker node and is on going . By contrast each request response connection established across request response shared memory is made easily useable for any worker node to support fail over to a new worker node and according to an implementation exist only for each request response cycle.

Above the FCA level is the Java FCA jFCA level . The jFCA level is essentially an Application Program Interface API used by the Java worker nodes and relevant Java parts of the connection manager to access the FCA level . In an embodiment the jFCA level is modeled after standard Java Networks Socket technology. At the worker node side however a jFCA connection is created for each separate request response cycle through request response shared memory and a jFCA queue is created for each request notification queue. Thus whereas a standard Java socket will attach to a specific port e.g. a specific TCP IP address according to an implementation the jFCA API will establish a jFCA queue that is configured to implement the request notification queue of the applicable worker node and a jFCA connection for each request response cycle.

Here an instance of the jFCA API includes the instance of one or more objects to 1 establish a jFCA queue to handle the receipt of request notifications from the worker node s request notification queue 2 for each request notification establishing a jFCA connection over request response shared memory with the connection manager so that the corresponding request from the request response shared memory can be received through the jFCA s InputStream and 3 for each received request the writing of a response back to the same request response shared memory connection established for the request through the jFCA s OutputStream .

In the outbound direction e.g. from the worker node to the connection manager in an embodiment the same jFCA connection that is established through the request response shared memory between the worker node and the connection manager for retrieving the request data is used to transport the response back to the connection manager.

In a further embodiment a service e.g. an HTTP service is executed at each worker node that is responsible for managing the flow of requests responses and the application s invoked by the requests sent to the worker node. In a further embodiment in order to improve session handling capability the service is provided its own dedicated thread pool that is separate from the thread pool that is shared by the worker node s other applications. By so doing a fixed percentage of the worker node s processing resources are allocated to the service regardless of the service s actual work load. This permits the service to immediately respond to incoming requests during moments of light actual service work load and guarantees a specific amount of performance under heavy actual service workload.

According to one implementation each thread in the dedicated thread pool is capable of handling any request for any session. An available thread from the dedicated thread pool listens for a request notification arriving over the jFCA queue. The thread services the request from the jFCA queue and establishes the corresponding jFCA connection with the handler associated with the request notification and reads the request from request response shared memory. The thread then further handles the request by interacting with the session information associated with the request s corresponding session.

Each worker node may have its own associated container s in which the service runs. A container is used to confine define the operating environment for the application thread s that are executed within the container. In the context of J2EE containers also provide a family of services that applications executed within the container may use e.g. Java Naming and Directory Interface JNDI Java Database Connectivity JDBC Java Messaging Service JMS among others .

Different types of containers may exist. For example a first type of container may contain instances of pages and servlets for executing a web based presentation for one or more applications. A second type of container may contain granules of functionality generically referred to as components and in the context of Java referred to as beans that reference one another in sequence so that when executed according to the sequence a more comprehensive overall business logic application is realized e.g. stringing revenue calculation expense calculation and tax calculation components together to implement a profit calculation application .

Recall from the Background in the discussion pertaining to that the worker nodes depicted therein engage in an extensive number of application threads per virtual machine. shows worker nodes that can be viewed as a detailed depiction of an implementation for worker nodes of where the worker nodes are configured with fewer application threads per virtual machine than the prior art approach of . Fewer application threads per virtual machine results in less application thread crashes per virtual machine crash which in turn should result in the new standards based suite of exhibiting better reliability than the prior art standards based suite of

According to the depiction of which is an extreme representation of the improved approach only one application thread exists per virtual machine specifically thread is being executed by virtual machine thread is being executed by virtual machine . . . and thread M is being executed by virtual machine M . In practice the worker nodes of may permit a limited number of threads to be concurrently processed by a single virtual machine rather than only one.

In order to concurrently execute a comparable number of application threads as the prior art worker nodes of the improved worker nodes of instantiate more virtual machines than the prior art worker nodes of . That is M N.

Thus for example if the prior art worker nodes of have application threads per virtual machine and 4 virtual machines e.g. one virtual machine per CPU in a computing system having four CPUs for a total of 4 10 40 concurrently executed application threads for the worker nodes as a whole the improved worker nodes of may only permit a maximum of 5 concurrent application threads per virtual machine and 6 virtual machines e.g. 1.5 virtual machines per CPU in a four CPU system to implement a comparable number 5 6 30 of concurrently executed threads as the prior art worker nodes of

In an embodiment J2EE worker nodes provide a fixed number of execution units e.g. threads per CPU based at least in part on the input output ratio of an application. In prior art worker nodes shown in the execution units e.g. threads are distributed over a few virtual machines e.g. operating system processes and therefore there is a high degree of parallelism inside the virtual machines. In contrast worker nodes dramatically reduce the parallelism by increasing the number of virtual machines e.g. operating system processes and decreasing the execution units e.g. threads per virtual machine. In the illustrated embodiment this concept is taken to an isolation level in which one execution unit e.g. M is running inside one virtual machine e.g. M . The thread scheduler not shown of the operating system decides where and when a thread is executed.

Recall from the discussion of that a virtual machine can be associated with its own local memory. Because the improved worker nodes of instantiate more virtual machines than the prior art working nodes of in order to conserve memory resources the virtual machines . . . M of the worker nodes of are configured with less local memory space . . . M than the local memory space . . . N of virtual machines . . . N of . Moreover the virtual machines . . . M of the worker nodes of are configured to use a shared memory . Shared memory is memory space that contains items that can be accessed by more than one virtual machine and typically any virtual machine configured to execute like application threads that is coupled to the shared memory .

Thus whereas the prior art worker nodes of use fewer virtual machines with larger local memory resources containing objects that are private to the virtual machine the worker nodes of by contrast use more virtual machines with less local memory resources. The less local memory resources allocated per virtual machine is compensated for by allowing each virtual machine to access additional memory resources. However owing to limits in the amount of available memory space this additional memory space is made shareable amongst the virtual machines . . . M.

According to an object oriented approach where each of virtual machines . . . M does not have visibility into the local memories of the other virtual machines specific rules are applied that mandate whether or not information is permitted to be stored in shared memory . Specifically to first order according to an embodiment an object residing in shared memory should not contain a reference to an object located in a virtual machine s local memory because an object with a reference to an unreachable object is generally deemed non useable .

That is if an object in shared memory were to have a reference into the local memory of a particular virtual machine the object is essentially non useable to all other virtual machines and if shared memory were to contain an object that was useable to only a single virtual machine the purpose of the shared memory would essentially be defeated.

In order to uphold the above rule and in light of the fact that objects frequently contain references to other objects e.g. to effect a large process by stringing together the processes of individual objects and or to effect relational data structures shareable closures are employed. A closure is a group of one or more objects where every reference stemming from an object in the group that references another object does not reference an object outside the group. That is all the object to object references of the group can be viewed as closing upon and or staying within the confines of the group itself. Note that a single object without any references stemming from can be viewed as meeting the definition of a closure.

If a closure with a non shareable object were to be stored in shared memory the closure itself would not be shareable with other virtual machines which again defeats the purpose of the shared memory . Thus in an implementation in order to keep only shareable objects in shared memory and to prevent a reference from an object in shared memory to an object in a local memory only shareable or shared closures are stored in shared memory . A shared closure is a closure in which each of the closure s objects is shareable .

A shareable object is an object that can be used by other virtual machines that store and retrieve objects from the shared memory . As discussed above in an embodiment one aspect of a shareable object is that it does not possess a reference to another object that is located in a virtual machine s local memory. In an embodiment additional conditions may also apply to a shareable object. For example according to a particular Java embodiment a shareable object must also posses the following characteristics 1 it is an instance of a class that is serializable 2 it is an instance of a class that does not execute any custom serializing or deserializing code 3 it is an instance of a class whose base classes are all serializable 4 it is an instance of a class whose member fields are all serializable 5 it is an instance of a class that does not interfere with proper operation of a garbage collection algorithm and 6 its finalize method is not overwritten.

Exceptions to the above criteria are possible if for example a copy operation used to copy a closure into shared memory or from shared memory into a local memory can be shown to be semantically equivalent to serialization and deserialization of the objects in the closure. Examples include instances of the Java 2 Platform Standard Edition 1.3 java.lang.String class and java.util.Hashtable class.

A container is used to confine define the operating environment for the application thread s that are executed within the container. In the context of J2EE containers also provide a family of services that applications executed within the container may use e.g. e.g. Java Naming and Directory Interface JNDI Java Database Connectivity JDBC Java Messaging Service JMS among others .

Note that the introduction of the shared memory introduces the prospect of a shared cache . Thus the architecture of includes both local memory level caches . . . N and a shared memory cache . shows a depiction of a cache management service that can for example be added to the suite of services offered by a container to support one or more application thread s .

The cache management service is configured to have visibility into the local memory cache of the virtual machine the shared memory cache and one or more other storage resources such as a database or file system used for storing persisted objects. Here different applications whose abstract code e.g. Java byte code in the case of Java is executed by virtual machine can specially configure the cache management service to treat its cached objects in accordance with specific guidelines.

According to various schemes the cache manager effectively configures regions of cache for the storage of objects in local cache memory and or in shared memory cache according to different treatment policies. Multiple cache regions defining different cache treatments may be established for a single application. Cached objects placed in local memory cache may be conveniently utilized by the virtual machine associated with the local memory where local cache resides for quick processing by the application. By contrast cached objects placed in shared memory cache may be utilized by the local virtual machine as well as other virtual machines that have visibility into the shared memory in which the shared memory cache is implemented.

The introduction of a shared memory e.g. shared memory shown in to share objects also introduces the prospect of shared class loaders. is a block diagram illustrating an embodiment in which a number of worker nodes share one or more class loaders. In an embodiment the worker nodes are based at least in part on the J2EE standard. It is to be appreciated however that in an alternative embodiment the worker nodes may be based on a different standard. J2EE worker nodes include local objects local classes and local class loaders . These local objects local classes and local class loaders are only visible to the J2EE worker node that is local to a given object class or class loader.

J2EE worker nodes also each have access to shared memory . In an embodiment shared memory is a shared closure based shared memory substantially similar to shared memory shown in . Shared memory includes shared objects shared classes and shared class loaders . Shared objects are objects that can be shared among J2EE worker nodes . Sharing objects implies that J2EE worker nodes have access to common class definitions. Shared classes provide the common class definitions to support shared objects . In an embodiment J2EE worker nodes can access shared classes without having to physically load the classes.

Shared class loaders are class loaders that reside in shared memory and load shared classes . In an embodiment shared class loaders have certain properties. For example in one embodiment shared class loaders are created through a factory and cannot be modified after they are created. The property that shared class loaders are created through a factory implies that in an embodiment custom shared class loaders are not used. The property that shared class loaders cannot be modified after they are created indicates that references e.g. to other components are not added to or removed from a class loader after it is created.

In an embodiment two shared class loaders are considered identical if all of their properties are identical. For example if a shared class loader can load a number of Java Archive JAR files then another shared class loader would be identical if it has the same properties as the first class loader including the ability to load the same JAR files in the same order. As mentioned above in an embodiment shared class loaders are created by a factory. In one embodiment the factory first checks for the existence of a requested class loader before creating the class loader. If the requested class loader already exists then the factory returns a reference to the preexisting class loader rather than an instance of the shared class loader.

Collectively Java programs may provide the logic for implementing various sub layers e.g. business layer integration layer presentation layer etc. of AS instance . In one embodiment AS instance is a web application server such as Web AS by SAP .NET by Microsoft or the like. In one embodiment AS instance represents a Java 2 Platform Enterprise Edition J2EE instance for providing enterprise software functionality. It should be appreciated that various components of AS instance have been excluded from for the sake of clarity and so as not to obscure the invention. Although illustrates three worker nodes within AS instance more or less worker nodes may be established within AS instance .

During operation work requests may be received at AS instance and assigned to any of worker nodes for servicing. JVMs within each worker node may execute Java programs containing logic for servicing the received work requests . Each work request may require performing one or more tasks e.g. retrieve a name and address from a database which may also include one or more subtasks e.g. fetch data from database render data for output clean memory . To perform multiple tasks in parallel each JVM may maintain a thread pool having a number of available worker threads to perform the tasks. While performing these tasks and subtasks each of the worker threads is capable of reporting thread status information into shared memory .

Once thread status information is reported into shared memory monitoring console can query shared monitoring memory to display thread status information for review by an Information Technology IT technician. Monitoring console may be located locally on the same hardware machine executing AS instance or advantageously executed on a remote machine couple to a network. Monitoring console may further monitor an entire cluster of AS instances all from a single remote machine. Using monitoring console the IT technician can remotely monitor the status and operational health of worker threads within each JVM in real time to ensure AS instance remains in a healthful state. Shared memory working in concert with monitoring console enables the IT technician to make informed decisions when taking preventative and or remedial action to effectively maintain and manage an enterprise system.

Thread manager creates and manages worker threads and thread pool . Each worker thread provides a thread of execution which may be assigned a task to perform. In general worker threads share a common address space and run in a quasi parallel manner. The common address space is reserved by JVM and may contain program text e.g. Java programs and data as well as other resources. Each worker thread may include a program counter that keeps track of which instruction to execute next registers that hold current working variables and a call stack that contains the execution history i.e. procedure call history of the particular worker thread . Worker threads enable each JVM to achieve parallelism to perform multiple tasks in a quasi parallel manner while supporting sequential processes that make use of blocking system calls e.g. disk input output access .

Thread manager acts as a factory for worker threads using an extended thread class which contains reporting methods for reporting thread status information into shared memory . In one embodiment thread manager is an entity e.g. Java object interpreted and executed by JVM . In one embodiment worker threads are Java objects running within JVM . When one of worker threads is created it is instantiated with the extended thread class thereby inheriting the reporting methods and the ability to report thread status information into shared memory . Once one of worker threads is instantiated it may be said that the worker thread is instrumented with reporting functionality.

In one embodiment these reporting methods perform reporting tasks that are interleaved with execution of work tasks. The reporting tasks update shared memory with the current status of the particular worker thread . In one embodiment the reporting tasks are event based. An event based reporting task updates shared memory in response to a work event that has created new thread status information . Event based reporting tasks save time and processing cycles that may otherwise be wasted pulling each worker thread for thread status information that may or may not yet exist.

Upon creation instantiation a new worker thread is placed into thread pool as an idle worker thread available to be assigned a task e.g. THREAD . In one embodiment thread manager assigns new tasks to each worker thread as work requests arrive. Once assigned a task the particular worker thread is removed from the thread pool signifying that it is currently busy and not available to perform other tasks. Thread manager also controls whether or not to delete any of worker threads e.g. to shrink thread pool . In response to deletion of one of worker threads the designated worker thread may clean shared memory of any thread status information corresponding to the designated worker thread just prior to its deletion. Alternatively thread manager may clean shared memory of the corresponding thread status information after the designated worker thread has been deleted.

In one embodiment shared memory includes reporting slots S SN. Each reporting slot may be registered by a worker thread and used by the particular worker thread to store its thread status information . Upon deletion of a particular worker thread its corresponding reporting slot may be cleaned and recycled for use by another worker thread .

Worker threads and in some embodiments thread manager as well access shared memory via shared memory API . In one embodiment shared memory API abstracts access to shared memory through use of function calls. Each worker thread that wishes to report thread status information into shared memory makes a call to one or more functions published internally to worker nodes by shared memory APIs . Worker threads then pass thread status information to the called function. In turn the called function copies thread status information into an appropriate reporting slot S SN.

In one embodiment monitoring console transmits status queries to network interface to request thread status information or a portion thereof. Monitoring console can be implemented using the Microsoft Management Console MMC while network interface may be implemented with a WebService based Start Service. In one embodiment the status queries are conveyed to network interface using a message based protocol such as Simple Object Access Protocol SOAP employing extensible markup language XML syntax to send text commands over the HyperText Transport Protocol HTTP . The status query may be transmitted to AS instance automatically on a periodic basis in response to a specified event or in response to a screen refresh request by an IT technician.

Upon receipt the status query is passed to a monitoring API . Monitoring API accesses the requested portions of shared memory via its own copy of shared memory API . Once monitoring API retrieves the requested portions of thread status information from shared memory thread status information is conveyed to monitoring console . In one embodiment XML syntax is used to convey thread status information to monitoring console .

Monitoring console may further format the received thread status information and render it to a screen for review by an IT technician. Monitoring console may display thread status information received from a number of AS instances to monitor an entire cluster of AS instances . Monitoring console may further optionally generate log files to maintain long term status reports on each AS instance being monitored.

In addition to issuing status requests monitoring console may negotiate a reporting contract with network interface to serve up thread status information on a regular or periodic basis without need of status requests. As such network interface may be capable of pushing thread status information to monitoring console as well as monitoring console pulling thread status information from network interface .

In an embodiment session monitoring can also be implemented using shared memory. is a block diagram illustrating a software system for monitoring sessions between clients and worker nodes in accordance with an embodiment of the invention. The illustrated embodiment of software system includes AS instance and a monitoring console . The illustrated embodiment of AS instance includes one or more worker nodes each including a JVM and shared memory . Java worker nodes provide the runtime environment for JVMs which in turn interpret execute Java programs .

Collectively Java programs may provide the logic for implementing various sub layers e.g. business layer integration layer presentation layer etc. of AS instance . In one embodiment AS instance is a web application server such as Web AS by SAP .NET by Microsoft or the like. In one embodiment AS instance represents a Java 2 Platform Enterprise Edition J2EE instance for providing enterprise software functionality. It should be appreciated that various components of AS instance have been excluded from for the sake of clarity and so as not to obscure the invention. Although illustrates three worker nodes within AS instance more or less worker nodes may be established within AS instance .

During operation work requests may be received at AS instance and assigned to any of worker nodes for servicing. JVMs within each worker node may execute Java programs containing logic for servicing the received work requests . Each work request may require performing one or more tasks e.g. retrieve a name and address from a database which may also include one or more subtasks e.g. fetch data from database render data for output clean memory . To perform multiple tasks in parallel each JVM may maintain a thread pool having a number of available worker threads to perform the tasks. While performing these tasks and subtasks each of the worker threads is capable of reporting session status information into shared memory .

Once session status information is reported into shared memory monitoring console can query shared monitoring memory to display session status information for review by an Information Technology IT technician. Monitoring console may be located locally on the same hardware machine executing AS instance or advantageously executed on a remote machine couple to a network. Monitoring console may further monitor an entire cluster of AS instances all from a single remote machine. Using monitoring console the IT technician can remotely monitor the status of sessions in real time to ensure AS instance remains in a healthful state. Shared memory working in concert with monitoring console enables the IT technician to make informed decisions when taking preventative and or remedial action to effectively maintain and manage an enterprise system.

The architectures and methodologies discussed above may be implemented with various types of computing systems such as an application server that includes a Java 2 Platform Enterprise Edition J2EE server that supports Enterprise JavaBean EJB components and EJB containers at the business layer and or Servlets and Java Server Pages JSP at the presentation layer . Of course other embodiments may be implemented in the context of various different software platforms including by way of example Microsoft .NET Windows NT Microsoft Transaction Server MTS the Advanced Business Application Programming ABAP platforms developed by SAP AG and comparable platforms.

An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as but is not limited to one or more memories e.g. one or more flash memories random access memories static dynamic or other optical disks compact disks read only memory CD ROMs digital versatile video disks DVD ROMs erasable programmable read only memory EPROMs electrically erasable programmable read only memory EEPROMs magnetic or optical cards or other type of computer readable media suitable for storing electronic instructions.

An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as but is not limited to one or more memories e.g. one or more flash memories random access memories static dynamic or other optical disks compact disks read only memory CD ROMs digital versatile video disks DVD ROMs erasable programmable read only memory EPROMs electrically erasable programmable read only memory EEPROMs magnetic or optical cards or other type of machine readable media suitable for storing electronic instructions. Program code may also be downloaded from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a propagation medium e.g. via a communication link e.g. a network connection .

It is believed that processes taught by the discussion above can be practiced within various software environments such as for example object oriented and non object oriented programming environments Java based environments such as a Java 2 Enterprise Edition J2EE environment or environments defined by other releases of the Java standard or other environments e.g. a .NET environment a Windows NT environment each provided by Microsoft Corporation .

In the foregoing specification the invention has been described with reference to specific exemplary embodiments thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

