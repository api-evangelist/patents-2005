---

title: Systems and methods for the real-time and realistic simulation of natural atmospheric lighting phenomenon
abstract: Systems and methods are provided for visually realistic simulation and real-time rendering of natural atmospheric lighting and related phenomena in an outdoor scene represented by an image provided by a simulation environment. The systems and methods of the present invention provide techniques to approximate the visual effects of natural atmospheric lighting and related phenomena that are visually realistic and that can be computed in real-time to render frames of a scene at real-time frame rates per second. The techniques consider the light scattering effects due to sunlight and ambient light in relation to objects, atmospheric particles and other scene elements represented by the image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07710418&OS=07710418&RS=07710418
owner: Linden Acquisition Corporation
number: 07710418
owner_city: San Francisco
owner_country: US
publication_date: 20050204
---
The present invention generally relates to the real time graphical processing and realistic simulation of natural atmospheric lighting phenomena.

Simulated images are used in various applications such as training simulators electronic games and visual planning and modeling tools. Using realistic simulated images in such applications is desirable to visually present and represent real world scenarios as it may be seen by the human eye outside of the application. In particular it would be desirable to realistically simulate an outside scene including terrain and sky and the naturally occurring effects of atmospheric light on the scene. Although some simulation applications such as games provide a believable representation of outside scenes these applications do not represent natural atmospheric lighting phenomena in a visual or photo realistic manner. For example it would be desirable in a military training simulator to present training scenarios that realistically simulate an outside natural scene including terrain sky and lighting effects. Simulations using realistic outside scenes will make the image synthesis process more intuitive and have a broader scope of applications.

However the realistic simulation of outdoor scenes presents significant challenges because of the geometry and lighting effects naturally occurring in such environments. The shapes of natural objects found in outdoor scenes and the effect of light and illumination on these natural objects make it particularly challenging to realistically simulate. Outdoor scenes exhibit great geometric complexity and the sheer scale of outdoor scenes is typically significantly larger than that of indoor scenes. Furthermore outdoor scenes often contain natural objects that have complex shapes. The geometric representation of the physical features of varying land mass sky line and other terrain and atmospheric objects can be quite complex. Another challenge with outdoor scenes is the complexity of the illumination itself. The sky essentially surrounds all objects in the outside scene. Natural illumination from the sun and the sky has special and naturally occurring reflective and optical properties. As such the lighting effects from the natural illumination affect the color and brightness of objects terrain and atmosphere in the outside scene.

The realistic and efficient simulation of outdoor scenes is even further challenging. In order to create realistic simulations of outdoor scenes such as a photo realistic simulation of a terrain and sky simulating and rendering the visual effects from natural atmospheric lighting phenomena is required. The simulation needs to take into account the interaction of atmospheric light with the natural and man made objects in the outside scene and the dynamics of natural systems. However the modeling of such natural atmospheric lighting phenomena is difficult. Although accurate mathematical models of atmospheric lighting phenomena exist the execution of such models in a simulation environment is very time consuming with a heaving computational burden. Moreover because outdoor scenes are geometrically complex the execution of accurate models for atmospheric lighting phenomena integrated with the geometric complexity of the scene is even more time consuming. As such these models are not executed in real time.

Thus it is desired to realistically simulate and render in real time natural atmospheric lighting phenomena in outdoor scenes. Systems and methods are needed to realistically simulate and render in real time the complexity of natural objects in outdoor scenes integrated with the visual effects from atmospheric lighting phenomena.

The present invention provides systems and methods for providing visually realistic simulation and real time rendering of natural atmospheric lighting and related phenomena in an outdoor scene represented by an image provided by a simulation environment. The systems and methods of the present invention provide techniques to approximate the visual effects of natural atmospheric lighting and related phenomena that are visually realistic and that can be computed in real time to render frames of a scene at high frame rates per second. The techniques consider the light scattering effects due to sunlight and ambient light in relation to objects atmospheric particles and other scene elements represented by the image.

Using the techniques the present invention can provide images and simulations having visually realistic representations of sunlight at any time of day including from dawn to twilight along with accurate shadows. Additionally the present invention can simulate a visually realistic representation of a wide range of cloud formations resulting cloud cover over the landscape of a scene and shadows cast by clouds on elements of the scene. Furthermore the present invention provides a realistic simulation of the visual effects from light scattering by the cloud cover and also provides visually realistic simulation of water including accurate reflections refractions and turbulence.

In one aspect the present invention relates to a method for providing a realistic simulation of natural atmospheric lighting phenomenon. The method includes the step of providing in a simulation environment an image realistically representing a scene of natural atmospheric lighting phenomena having an atmosphere atmospheric particles and light. The image may provide a visual or photo realistic representation of an outdoor scene. The method further provides a viewing position and one or more viewing objects associated with a view of the scene. A viewing object may be any element of the image. The method of the present invention determines in real time a color of one or more portions of the image to realistically represent one or more visual effects from the natural atmospheric lighting phenomena of the scene from a change in one or more of the following the view the viewing position one or more viewing objects atmosphere atmospheric particles and light. The method renders in real time images of the scene comprising the color of one or more portions of the image to realistically simulate the one or more visual effects.

In one embodiment the method includes rendering at a frame per second rate of at least 10 frames per second. The method also determines the colors in real time by performing processing at a rate to provide for realistically rendering at a frame per second rate of at least 10 frames per second. In one embodiment the color comprises a Red Green Blue RGB color code and the one or more portions of the image comprises a vector.

In other embodiments the atmospheric particles represent a portion of one or more of the following a cloud rain ice dust fog haze smoke pollutants and air. In a further embodiment at least one of the one or more viewing objects represents one or more of the following a sky a cloud a land mass a celestial body a body of water and a man made item. In the methods of the present invention the light represents a portion of illumination from one of sunlight and scattering of light by atmospheric particles. In one embodiment the step of rendering in the method of the present invention includes depicting a movement of at least one of the viewing objects in the scene.

In another embodiment the method of the present invention determines the color by calculating a realistic approximation of a visible effect on the natural atmospheric lighting phenomenon from one or more of the following in scattering light from atmospheric particles out scattering light from atmospheric particles sunlight illumination ambient illumination cloud appearance cloud density cloud lighting and cloud shadowing.

In a further embodiment the method determines the color from an effect of the atmospheric particles scattering out light between the viewing position and at least one of the one or more viewing objects by calculating an attenuation factor that realistically approximates a proportion of light reduced from the light reaching the viewing position from the viewing object. The attenuation factor may be wavelength dependent and derived from a calculation of a cumulative density of atmospheric particles along a path of the line of sight between the viewing position and at least one viewing object. In some embodiments the cumulative density is proportional to the length of the intersection of a path of the line of sight with the atmosphere.

In one embodiment of the present invention the method determines the color from an effect of the atmospheric particles scattering light into the line of sight between the viewing position and at least one of the one or more viewings object by calculating an additive factor that realistically approximates an increase to the light reaching the viewing position from the viewing object. The additive factor may be dependent on a selected horizon color and derived from a calculation of a cumulative density of atmospheric particles along a path of the line of sight between the viewing position and at least one viewing object. The cumulative density may be proportional to the length of the intersection of a path of the line of sight with the atmosphere.

In an additional embodiment the method of the present invention determines the color from an effect of sunlight illuminating at a point in the atmosphere as viewed from the viewing point by calculating a sunlight attenuation factor that realistically approximates a proportion of sunlight reaching the point in the atmosphere. The sunlight attenuation factor may be derived from a calculation of a cumulative optical density for a dominant point along a path from the viewer towards the viewing object. The dominant point may include a point along the path having a dominant color and intensity of the sunlight.

In another aspect the present invention relates to a system for providing a realistic simulation of natural atmospheric lighting phenomenon. The system includes a simulation environment a simulation engine and a rendering mechanism. The simulation environment provides an image realistically representing a scene of a natural atmospheric lighting phenomenon comprising an atmosphere atmospheric particles and light and provides a viewing position and one or more viewing objects associated with a view of the image. The scene may be any outdoor scene. The one or more viewing objects can includes any element of the image.

The simulation engine of the present invention determines in real time a color of one or more portions of the image to realistically represent one or more visual effects from the natural atmospheric lighting phenomenon of the scene from a change in one or more of the following the view the viewing position one or more viewing objects atmosphere atmospheric particles and light. The rendering mechanism of the present invention renders in real time images of the scene comprising the color of one or more portions of the image to realistically simulate the one or more visible effects.

In one embodiment the rendering mechanism renders images at a frame per second rate of at least 10 frames per second. The simulation engine determines the color at a processing rate to provide an image for the rendering mechanism to render at a frame per second rate of at least 10 frames per second.

In another embodiment the atmospheric particles represent a portion of one or more of the following a cloud rain ice dust fog haze smoke pollutants and air. Additionally at least one of the one or more viewing objects represents one or more of the following a sky a cloud a land mass a celestial body a body of water and a man made physical item. The light represents a portion of illumination from one of sunlight and scattering of light by atmospheric particles. In a further embodiment the simulation provided by the simulation environment depicts a movement of at least one of the viewing objects in the scene.

In one embodiment the simulation engine of the present invention determines the color by calculating a realistic approximation of a visible effect on the natural atmospheric lighting phenomenon from one or more of the following in scattering light from atmospheric particles out scattering light from atmospheric particles sunlight illumination ambient illumination cloud appearance cloud density cloud lighting and cloud shadowing. In one embodiment the color comprises a Red Green Blue RGB color code and the one or more portions of the image comprises a vector.

In another embodiment the simulation engine of the present invention determines the color from an effect of the atmospheric particles scattering out light between the viewing position and at least one of the one or more viewing objects by calculating an attenuation factor that realistically approximates a proportion of light reduced from the light reaching the viewing position from the viewing object. The attenuation factor may be wavelength dependent and derived from a calculation of a cumulative density of atmospheric particles along a path of the line of sight between the viewing position and at least one viewing object. Additionally the cumulative density may be proportional to the length of the intersection of a path of the line of sight with the atmosphere.

In another embodiment of the present invention the simulation engine determines the color from an effect of the atmospheric particles scattering light into the line of sight between the viewing position and at least one of the one or more viewings object by calculating an additive factor that realistically approximates an increase to the light reaching the viewing position from the viewing object. The additive factor may be dependent on a selected horizon color and derived from a calculation of a cumulative density of atmospheric particles along a path of the line of sight between the viewing position and at least one viewing object. The cumulative density may be proportional to the length of the intersection of a path of the line of sight with the atmosphere.

In other embodiments the simulation engine of the present invention determines the color from an effect of sunlight illuminating at a point in the atmosphere as viewed from the viewing point by calculating a sunlight attenuation factor that realistically approximates a proportion of sunlight reaching the point in the atmosphere. Additionally the sunlight attenuation factor may be derived from a calculation of a cumulative optical density for a dominant point along a path from the viewer towards the viewing object. The dominant point can include a point along the path having a dominant color and intensity of the sunlight.

The details of various embodiments of the invention are set forth in the accompanying drawings and the description below.

Certain embodiments of the present invention are described below. It is however expressly noted that the present invention is not limited to these embodiments but rather the intention is that additions and modifications to what is expressly described herein also are included within the scope of the invention. Moreover it is to be understood that the features of the various embodiments described herein are not mutually exclusive and can exist in various combinations and permutations even if such combinations or permutations are not expressly made herein without departing from the spirit and scope of the invention.

The illustrative embodiment of the present invention provides systems and methods for visually realistic simulation and real time rendering of natural atmospheric lighting phenomena in a simulation environment. The simulation environment provides an image of an outdoor scene including naturally occurring elements of an atmosphere such as the sky sun light clouds and other atmospheric particles and celestial objects. The outdoor scene may also include terrain with any naturally occurring land mass body of water and or man made objects and structures. The simulation environment may provide a photo realistic near photo realistic or otherwise substantially realistic representation of the outdoor scene.

The present invention provides approximations for determining the realistic visual effects of natural atmospheric lighting phenomena upon a scene provided by the image such as the effects of light and illumination upon an object in the image. Natural atmospheric lighting phenomena include the out scattering and in scattering of light upon a view of one or more objects from the effects of Rayleigh and Mie scattering. Natural atmospheric lighting phenomena also include attenuation by the atmosphere upon light from the sun e.g. the color of the atmosphere from the effects of a sunrise or sunset. The natural atmospheric lighting phenomena causes visual effects to the color shading and brightness of objects in the scene of the image. Additionally the present invention approximates the realistic appearance of clouds the effect of sky illumination and light from the sun upon clouds self shadowing effects of clouds and shadows cast by clouds onto other objects in the scene.

The approximations are computationally efficient and provide for the real time simulation and rendering of the image upon any type of changes in the scene or for executing a series of changes to the scene over time. The approximations can be executed to take into account the visual effects from natural atmospheric lighting phenomena upon all of the desired objects in the scene. Furthermore the approximations can be executed at a speed to provide a real time simulation frame rate of ten frames per second or greater and in the exemplary embodiment to be discussed herein at frame rates of 120 frames per second or more.

Moreover the approximations provide for the realistic rendering of the natural atmospheric lighting phenomena upon the scene. The approximations provide for the color values of pixels of the image to be rendered on the screen. Although the approximations are more computationally efficient in comparison to more accurate modeling approaches of natural atmospheric lighting phenomenon the approximations produce color values for the natural atmospheric lighting that are visually similar to the more accurate and computationally expensive modeling approaches. As such the present invention also provides for the photo realistic near photo realistic or otherwise substantially realistic representation of natural atmospheric lighting phenomena.

In brief introduction the illustrative embodiment of the present invention provides approximations for natural atmospheric lighting phenomena that are both visually realistic and can be executed in real time. This provides for the simulation of realistic outdoor scenes that can be rendered at a real time frame rate. As such the simulation environment of the present invention can provide for a wide range of graphics and simulation applications where the substantial realistic representation of outdoor scenes is desired. For example the simulation environment of the present invention can be used for driving and flight simulators as well as military and other training environments. Additionally the methods and systems of the present invention may be applied in gaming and entertainment type applications.

The illustrative embodiment will be described solely for illustrative purposes relative to a simulation environment using a shader type program in a programmable graphics processor such as in a graphics card. Although the illustrative embodiment will be described relative to such an environment one of ordinary skill in the art will appreciate that the present invention may be applied to other graphics and simulation environments capable of the operations described herein.

The computing device may include other I O devices such a keyboard and a pointing device for example a mouse for receiving input from a user. Optionally the keyboard and the pointing device may be connected to the visual display device . Additionally the computing device may include any type of input device for receiving user input such as a joystick. In other embodiments the computing device may include any type of haptic device such as a vibration generating mouse or force feedback joystick. In some embodiments the computing device may include any form of input device used for training and simulation such a flight or tank simulation input device of a military training simulator.

The computing device may include other suitable conventional I O peripherals. The computing device may support any suitable installation medium a CD ROM floppy disks tape device USB device hard drive or any other device suitable for installing software programs such as the simulation environment of the present invention. The computing device may further comprise a storage device such as a hard drive or CD ROM for storing an operating system and other related software and for storing application software programs such as the simulation environment of the present invention. Additionally the operating system and the simulation environment can be run from a bootable CD such as for example KNOPPIX a bootable CD for GNU Linux.

The computing device may include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. 802.11 T1 T3 56 kb X.25 broadband connections e.g. ISDN Frame Relay ATM wireless connections or some combination of any or all of the above. The network interface may comprise a built in network adapter network interface card PCMCIA network card card bus network adapter wireless network adapter USB network adapter modem or any other device suitable for interfacing the computing device to any type of network capable of communication and performing the operations described herein. Moreover the computing device may be any type of computer system such as a workstation desktop computer server laptop handheld computer or other form of computing or telecommunications device that has sufficient processor power and memory capacity to perform the operations described herein.

Additionally the computing device may include a graphics card processor for handling one or more graphics processing functions of the computing device for displaying graphics images user interfaces or any other type of visual element to the display device . In one embodiment the computing device includes an expansion card that interprets drawing instructions sent by the central processor CPU processes them via a dedicated graphics processor and writes the resulting frame data to the frame buffer also called or otherwise is part of the video adapter . The graphics processor may perform one or more graphics processing functions such as bitmap transfers and painting window resizing and repositioning line drawing font scaling and polygon drawing. The graphics processor may be designed to handle these tasks in hardware at far greater speeds than the software running on the system s central processor . The graphics processor may be any type of graphics processor such as any graphic processing chip provided or manufactured by Nvidia Corporation of Santa Clara Calif. or ATI Technologies Inc. of Markham Ontario. The graphics processor may be part of any type of graphics card such as any of the graphics cards incorporating the Nvidia graphics processor such as Nvidia s series of nForce and GeForce graphics chip or the Radeon series of graphics cards from ATI Technologies. One ordinarily skilled in the art will recognize and appreciate the various types and wide range of graphics card processors that may be used in the computing device .

Although generally described as a graphics processor or a processor dedicated to graphics processing functions the processor can be any type of general purpose processor GPP or any other type of integrated circuit such as a Field Programmable Gate Array FPGA Programmable Logic Device PLD or Application Specific Integrated Circuit ASIC . Furthermore although the illustrative embodiment of the computing device is described with a separate processor for graphics related processing the central processor may provide for such graphics related processing. Alternatively the computing device may have multiple processors to distribute processing of computing tasks along with any graphics processing functions. In one embodiment the graphics card processor of the computing device has multiple graphics processors such as for example the dual GPU graphics card provided or manufactured by Giga Byte Technology Co. LTD of Taipei Hsien Taiwan. In another embodiment the graphics processor performs graphics oriented operations but also other computations such as any operation of the processor such as a CPU. One ordinarily skilled in the art will recognize and appreciate that any type of computing device with any type of processor may be used to perform the operations of the present invention as described herein.

The present invention provides a simulation environment for generating modeling creating editing or otherwise handling manipulating and processing images. In brief overview the simulation environment provides a platform for image based design processing and simulation of outdoor and or indoor scenes including naturally occurring atmospheres and terrains naturally occurring dynamic systems along with any man made objects structures and or system. The simulation environment may include one or more images representing visually graphically or otherwise a scene such as an outside scene. For example the image may comprise a photo realistic near photo realistic or otherwise substantially realistic representation of an outside scene including an atmosphere such as a sky sun and clouds and optionally any type of terrain such as a landscape mountain range and a body of water.

The simulation environment includes a graphical user interface for interactively creating and working with images and may also provide for simulating editing configuring and processing the images . The simulation environment may read save interpret or otherwise process image files in any format known to one ordinarily skilled in the art. For example the simulation environment may process images comprising data in any terrain data sources known by those skilled in the art. For example the terrain data may be in the form of a digital elevation map DEM and or digital lines graphics DLG of any available granularity and may come from any source such as the Unites States Geographical Survey USGS at www.usgs.gov. In other embodiments the simulation environment may use any available satellite data. As such the images processed by the simulation environment may comprise real world terrain data from actual geographic locations. Additionally any terrain data may be generated created edited or provided to represent a desired terrain. Furthermore the terrain data may be processed from one format to another format as suitable or desired for processing by the simulation environment .

The simulation environment may comprise any suitable configuration mechanism for configuring any elements and properties of the image the simulation and rendering of one or more images and or the simulation environment . The configuration mechanism may comprise any type of user interface such as a graphical user interface or command line interface. As such it may comprise any user interface mechanisms such as menu items forms toolbars etc. as known by ordinarily skilled in the art to provide a user interface to receive user input with regards to configuration.

The simulation environment also comprises one or more libraries to provide for the processing of images and at least a portion of the operations of the present invention described herein. Although described as libraries the libraries may take the form of any type of executable instructions capable of performing the operations described herein. In one embodiment the simulation environment uses a terrain implementation library for providing a terrain processing engine or terrain engine for loading and processing geometric data representing various terrains and atmospheres such as outside scenes. The terrain engine may receive the geometric data for a terrain in the form of an array of heights. In an exemplary embodiment the terrain engine comprises a geo mipmapping system and includes trilinear mipmapping extensions as known by those ordinarily skilled in the art. In one embodiment the terrain implementation library is capable of loading and processing terrain data files .ter provided with the Terragen software manufactured by Planetside Software of Cheshire United Kingdom.

In an exemplary embodiment the libraries include a portion of executable instructions from the Object Oriented Graphics Rendering Engine OGRE manufactured by The OGRE Project. OGRE is a scene oriented flexible 3D engine that uses underlying system libraries like Direct3D DirectX and OpenGL . As such the libraries may include the Direct3D or DirectX SDK manufactured by Microsoft Corporation of Redmond Wash. to provide an application programming interface API in the operating system to graphics and sounds functionality provided by the hardware of the computing device . In some embodiments the libraries include any application programming interfaces APIs supporting the OpenGL standards and specifications as known by those ordinarily skilled in the art.

Additionally the libraries may include any portion of the CG Toolkit manufactured by Nvidia Inc. of Santa Clara Calif. wherein Cg is a high level language for graphics programming. The libraries may also include any portion of executable instructions manufactured by The Freetype Project located at www.freetype.org which is a high quality portable font engine and in other embodiments may include any suitable font engine. Additionally the libraries may include any executable instructions of the Developer s Image Library DevIL manufactured by Denton Woods located at http openil.sourceforge.net. DevIL provides a programmer s library to develop applications with image loading capabilities. DevIL utilizes a simple and powerful syntax to load save convert manipulate filter and display a wide variety of image formats.

The libraries of the simulation environment may include any programming related APIs and libraries such as STLport manufactured by STLport Consulting of San Francisco Calif. Xerces of the Apache XML Project provided by the Apache Software Foundation Inc. of Forest Hill Md. and any publicly available libraries authored by Beman Dawes and David Abrahams located at www.boost.org. Additionally to support file and data compression related functionality in the simulation environment the libraries may include any type of compression libraries such as the Zlib library provided by The GNU Project of the Free Software Foundation of Boston Mass. Furthermore the libraries may include windowing and graphical widgets for graphics APIs and engines such as Crazy Eddie s GUI System located at http www.cegui.org.uk which is a publicly available object orientated tool for building graphical user interface systems.

The simulation environment comprises a simulation engine and rendering mechanism . The simulation engine provides the graphics processing functionality and instructions of the present invention for image simulation and the rendering of the image via the rendering mechanism . The rendering mechanism includes means and mechanisms as known by those ordinarily skilled in the art to cause the rendering of the image to the visual display device of the computing device . In the rendering stage of graphics image processing typically performed by the graphics card processor in conjunction with the video adapter the pixels are drawn to the video display device .

The graphics processing portion of the simulation engine may comprise one or more shader programs such as a pixel shader program and or a vertex shader program . The terms shaders may be used instead of program or shader program to refer to the portions of executable instructions that program certain parts of the graphics processing pipeline. The computational frequency that may be supported in graphics related hardware such as a graphics card processor is per vertex and per pixel fragment. As such there are two different kinds of shaders vertex shaders and pixel shaders . A pixel shader provides graphics processing on a pixel basis and a vertex shader provides graphics processing on a vertex basis.

Pixel shaders may also include or be referred to as fragment shaders. As known by those ordinarily skilled in the art fragments are all the points of three dimensional scene that are projected onto a two dimensional xy plane such as in an OpenGL based implementation. A fragment contains information such as position and texture coordinates and several fragments can be added together when displayed to a pixel on the screen.

As known by those ordinarily skilled in the art a vertex shader is a set of graphics processing instructions used to add special effects to objects in a three dimensional 3D environment by performing mathematical operations on an object s vertex data. Objects in a 3D scene such as those provided by the image of the simulation environment may be described using polygons such as triangles which in turn are defined by their vertices. Vertex data refers to the data set identifying and or describing the vertices of the triangles representing the 3D scene. A vertex shader can change the position or any other attributes of a vertex. Vertex shaders may get executed for each vertex that passes through the graphics processing pipeline.

Pixel shaders as known by those ordinarily skilled in the art are graphics processing instructions that calculate effects on a per pixel basis. In some embodiments the pixel shader receives as input computational results from a vertex shader such as the vertex position. The pixel shader uses input provided by the vertex shader and any other attributes such as user defined attributes generated or modified colors and texture coordinates and combines the information to form a final color value that gets passed to the final stages of rendering. As such per pixel shading provides the lighting color and shading of each pixel. Pixel fragment shaders get executed for each pixel fragment passing through the graphics processing pipeline for rendering.

With the graphics cards processor of the computing device being programmable the pixel shader and vertex shader can comprise customized executable instructions to provide desired graphics processing of vertex and pixel fragment data associated with the image . In an exemplary embodiment the simulation environment provides at least a portion of the real time execution of the realistic approximation of natural atmospheric lighting phenomena of the present invention via one or more vertex shaders and or pixel shaders .

The simulation environment and any portion thereof can be an application module library software component or any other type of computer program or executable instruction which is designed to and capable of executing the functionality of the simulation environment as described herein. Additionally the simulation environment and any portion thereof may be executed as an application program service process task or any other form of execution unit known by those skilled in the art. Furthermore the simulation environment and any portion thereof may be designed to run on any type of processor microprocessor operating system or computing device .

The simulation environment can be capable of and configured to operate on and take advantage of different processors of the computing device . For example the simulation environment can run on a 32 bit processor of one computing device and a 64 bit processor of another computing device . Additionally the simulation environment can be capable of and configured to operate with and take advantage of different graphical cards processors of the computing device . For example any shader program of the simulation engine may be designed to operate on and take advantage of any type of graphical processor . Furthermore the simulation environment can operate on computing devices that can be running on different processor architectures with different graphical processing cards and processors in addition to different operating systems. One ordinarily skilled in the art will recognize the various combinations of operating systems processors or graphical cards that can be running on the computing device . In summary the simulation environment may be deployed across a wide range of different computing devices different operating systems and different processors in various configurations. One ordinarily skilled in the art will appreciate the various ways the present invention may be practiced in a computing device.

In one aspect of the present invention the image provided by the simulation environment comprises a realistic graphical and or visual representation of an outdoor scene including a natural atmospheric environment. depicts a diagrammatic view of an illustrative image of a scene such as an outdoor scene. In one embodiment the image is a photo realistic near photo realistic or otherwise substantially realistic representation of the outdoor scene which may also be known as or referred to as visual realistic. The scene may comprise any combination of naturally occurring and or man made objects. In brief overview the scene may comprise a terrain and an atmosphere . The terrain may include any physical features and characteristics of a planet s surface such as the earth or any other orbiting celestial object . As such the terrain may include a landscape with any type of land mass and one or more bodies of water . For example the land mass may include any type of mountain or hill or any range of mountains and hills. The bodies of water may be any type of water such as a puddle pond lake sea or ocean. Additionally the terrain may include any man made objects and or structures such as vehicles buildings houses and bridges. For example the terrain may provide a realistic representation of any man made structures or objects seen in any city town or country side known in the world. Also the terrain may include any flora or any other type of animal or creatures either living or fictional. Additionally the terrain may include any fauna or any other type of plant life or vegetation either actual or fictional.

The atmosphere represented by the scene of the image may include the sky a sun one or more clouds one or more celestial objects and one or more types of atmospheric particles . The clouds may be any type and or any portion of a formation of a cloud. The atmosphere may represent any portion of the atmosphere of the earth or any other planet or orbiting celestial land mass. The celestial objects may be any naturally occurring objects in the atmosphere sky or space such as the sun moon a planet and a star. The atmosphere generally represents air molecules such as clean air molecules that may be available in any portion of the sky or atmosphere of the scene . The atmosphere may include any man made objects such as aircraft or satellites. Additionally the atmosphere may include any flora or any other type of animal or creature either living or fictional. The atmospheric particles represent portions of the atmosphere other than air molecules such as ice rain water droplets crystals snow fog haze dust smoke pollutants and any other particles solid or otherwise that may be an element of the atmosphere and or sky .

Although the scene is generally described as a photo or near photo realistic representation of known and existing terrain and atmosphere the scene may provide a photo or visual realistic representation of fictional terrain and atmosphere . Instead of the terrain and or atmosphere of the scene of the image being provided by terrain data related to actual measurements of terrain and atmospheric components related to the earth the terrain and or atmosphere may be generated or otherwise provided to realistically represent an imaginary scene . As such the scene may not be a scene of a terrain and atmosphere existing in the world but nevertheless may look as an actual existing terrain and atmosphere due to the photolistic or visual realism of the image .

In order to provide for photolistic realism or otherwise visually realistic representation of the scene the effect of the physics of light and optics needs to be considered for the many objects of the terrain and or atmosphere and the dynamic interactions between them. For example the effect of light from the sun and the sky along with shadows casted by clouds need to be considered to determine the color of a rendered object in the image as seen by a viewer from a certain viewing position with respect to a view of the scene.

In another aspect the present invention relates to the simulation and rendering of the natural atmospheric lighting phenomena associated with the scene of the image and any objects of the scene . is a diagrammatic view of natural atmospheric lighting phenomena considered by the methods and systems of the present invention. The realistic simulation and rendering of a sky and the atmosphere relies on the determination and calculation of two types of scattering phenomenon Rayleigh scattering and Mie scattering. The illumination and color of the sky and the gradual extinction and attenuation of the color of a viewed object in the scene is caused by atmospheric light scattering.

Scattering is the process by which small particles such as atmospheric particles suspended in a medium of a different index of refraction diffuse a portion of the incident light in all directions. Along with absorption scattering is a major cause of the attenuation of light from the sun and the sky by the atmosphere . Scattering varies as a function of the ratio of the atmospheric particle diameter to the wavelength of the light. As known by those ordinarily skilled in the art Rayleigh scattering is the scattering of light by particles smaller than the wavelength of the light. Rayleigh scattering occurs when light travels in transparent solids and liquids but is most prominently seen in gases. The amount of Rayleigh scattering that occurs to a beam or ray of light is dependent upon the size of the atmospheric particles and the wavelength of the light. By Rayleigh s law the intensity of scattered light varies inversely with the wavelength of the light.

A scattering of sunlight from atmospheric particles is the reason why the light from the sky is blue. The strong wavelength dependence of the scattering means that blue light is scattered much more than red light. In the atmosphere this results in blue photons being scattered across the sky to a greater extent than photons of a longer wavelength and so one sees blue light coming from all regions of the sky whereas the rest is still mainly coming directly from the sun . A notable exception occurs during sunrise and sunset. The light of the sun passes through a much greater thickness of the atmosphere to reach a viewer on the ground. This extra distance causes multiple scatterings of blue light with relatively little scattering of red light. This is seen by the viewer as a pronounced red hued sky in the direction towards the sun .

If the size of the atmospheric particles are larger than the wavelength of light the light is not separated and all wavelengths are scattered as by a cloud which appears white. Scattering of light from the sky and or sun from atmospheric particles of about the same size or larger as the wavelength of the light is handled by the mathematical physical theory of Mie s law. Under Mie s law as one ordinarily skilled in the art will appreciate the scattering of all atmospheric particle diameters to light wavelength ratios are considered. One ordinarily skilled in the art will recognize and appreciate Mie and Rayleigh s law and the natural atmospheric phenomenon of light scattering described by the mathematical physical theory of Mie and Rayleigh s law.

In association with the scene and the image a viewing position of a viewer is provided to determine a view of the scene provided by the image . The viewing position of the viewer may be determined to be at a certain height in relation to the terrain and or the atmosphere . The viewing position may comprise a location a height and or orientation of the viewer relative to the scene such as any projected coordinate system used by the simulation environment . A line of sight to a viewing object is formed from the viewing perspective of the viewing position of the viewer to a target object in the scene such as any element of the terrain and or atmosphere . Changes in the viewing position of the viewer changes the view of the scene of the image .

As depicted in atmospheric light scattering can cause light to be scattered into the line of sight e.g. inscatter scattered out of the line of sight e.g. outscatter or aborbed into the line of sight. The natural atmospheric lighting phenomenon caused by atmospheric light scattering will vary by the geometry of the scene and the atmospheric particles along with the position and orientation of objects in the scene . Furthermore natural atmospheric lighting phenomenon caused by atmospheric light scattering will vary with the time of day weather and pollution. Additionally the atmospheric composition of different planet atmospheres will impact atmospheric light scattering.

Although natural atmospheric lighting phenomena is generally discussed above in relation to atmospheric light scattering in view of Rayleigh and Mie scattering theories natural atmospheric lighting phenomena encompasses any of the physical and mathematical relationships of light and optics and associated phenomenon thereof related to any element of the scene represented by the image . Additionally the systems and methods of the present invention takes into account the visual effects of sunlight attenuation by the atmosphere such as the effects of a sunrise and sunset on the color of the sky and any other element of the scene . Furthermore the present invention considers the visual effects associated with clouds such as the density and color of clouds self shadowing by clouds illumination and lights of clouds along with shadows casted by clouds. One ordinarily skilled in the art will appreciate and recognize the many light associated phenomenon that may be taken into account for an outdoor scene used in practicing the operations of the present invention as described herein.

As a realistic representation the image represents a three dimensional 3D view of the outdoor scene . This 3D representation needs to be projected and rendered to a two dimensional 2D display of the visual display device of the computing device . depicts an illustrative scene mesh for geometrically representing the terrain and atmosphere of the scene of the image . A mesh is a graphics object composed of polygons for example triangles or quadrilaterals that share vertexes and edges and thus can be transmitted in a compact format to a graphics processor . The mesh is used to depict project and or transform 3D images to a 2D perspective. As shown in the illustrative mesh used in an exemplary embodiment of the present invention is a series of triangles grouped together to form a surface. In a brief overview the screen mesh comprises a terrain mesh and a sky dome mesh integrated to form a geometric polygon representation of the scene of the image . The terrain mesh provides a mesh for the terrain portion of the scene and the sky dome mesh for the atmosphere and sky portion of the scene . In an exemplary embodiment the atmosphere s geometry is defined as the set of all points below an infinite plane with some user specified height above the viewer although more complex models can be used as known by those ordinarily skilled in the art.

To provides a realistic simulation and rendering of the scene the colors of the triangle primitives need to be determined to provide colors of the viewed object or element represented by the triangle primitive such that the color is visually realistic in view of the simulation of the natural atmospheric lighting phenomena occurring in the scene . In one embodiment a color for each vertex of a triangle primitive is determined and some form of color blending is provided for a smooth transition of color between the vertices of the triangle . For example any form of color averaging or interpolation may be computed. Any suitable color blending technique known by one ordinarily skilled in the art may be used to color the primitive used in the mesh representation of the image .

In graphical processing RGB color codes may be used to provide the colors associated with the triangle primitives . RGB color codes provide values for the primary colors of red green and blue which are mixed to display the color of pixels on a visual display device such as a color monitor. Every color of emitted light can be created by combining the three colors of red green and blue in varying levels. Adding no color such as an RGB color code of 0 0 0 produces black and adding 100 percent of all three colors e.g. RGB color codes of 100 100 100 results in white. Furthermore the color coding schemes of HLS Hue Luminance Saturation and or HSV Hue Saturation Values as known by those skilled in the art may be used in practicing the present invention. As such the color of a primitive a rendered pixel or an object of the scene may be described also in terms of its brightness and or intensity.

Alternatively other color coding schemes may be used such as a CMY or CMYK color codes. CMY is a color space consisting of the subtractive primary colors of cyan magenta and yellow. These three subtractive primary colors are used in color negative printing and some output devices to produce a full gamut of color. CMYK is a cyan magenta yellow and black color space. CMYK are the base colors used in printing processes and also a color mode used to define colors in a digital image. One ordinarily skilled in the art will recognize and appreciate the various color coding that may be used in practicing the present invention as described herein.

In one aspect the present invention provides techniques for determining the color of the triangle primitives of a mesh to graphically render the scene to realistically represent the natural atmospheric lighting phenomena . These techniques enable the graphical processing and rendering of the simulation of the natural atmospheric lighting phenomena to occur at a real time rate of greater than ten frames per second and upwards of 120 frames per second or more depending on the computing device . Furthermore these techniques not only provide for real time rendering speeds but also provide for the photo realistic near photo realistic visually realistic or otherwise substantially realistic simulation of natural atmospheric lighting phenomena . As such the present invention provides a simulation environment that can simulate and render images in real time and in a continuous manner to show the realistic visual effects of natural atmospheric lighting phenomena upon changes to elements of the image . For example the viewing position of the viewer may change causing a different view of the scene to be considered or a different line of sight on an element of object being viewed. Additionally a man made object may be positioned or moved through the scene causing a change of the lighting effects of the scene to be considered. Any of the elements of the terrain and or atmosphere may be changed such as the addition deletion or modification of a portion of atmospheric particles . For example the effect of rain fog or haze may be added or deleted from the scene or the density and or pattern of such atmospheric particles may be adjusted.

In an exemplary embodiment the graphics processing pipeline depicted by illustrative method is programmable via shaders . As such a vertex shader of the graphics processing portion of the simulation engine may provide desired vertex processing operations at step to provide for the realistic simulation and real time rendering of the natural atmospheric lighting phenomena of the present invention. Likewise a pixel shader may provide desired pixel fragment processing operations at step to provide for the realistic simulation and real time rendering of the natural atmospheric lighting phenomena of the present invention.

At step of the illustrative method the final colors of each of the primitives of the mesh representation of the image are rendered as pixels to a visual display device . Via the rendering mechanism pixels are written and or read to the frame buffer of the video adapter of the computing device . There may be hundreds to thousand or more polygons for each frame of a scene which must be updated and transmitted to the frame buffer. The frames are further processed converted or transformed into suitable analog and or digital output signals of the visual display device . The rate of transfer to the frame buffer and or visual display device is known as frame rate and is measured in frames per second fps . Each frame of a scene must be updated and transmitted through the frame buffer at a certain rate to give the illusion of movement.

Typically movies at movie theaters are provided at a rate of 24 frames per second and some television shows at 30 frames per second. The illusion of movement by the human eye can be seen at 10 frames per second or more and typically more fluid motion of a scene at 24 to 30 frames per second or more. As known by ordinarily skilled in the art blurring and sharpness of each frame of the scene affects the perceived fluidity of the movement depicted in the simulation. Also the level of details rendered in the scene affects the frame rate per second needed to provide for fluid movement in a simulation. In general the more frames per second the smoother the simulation. One ordinarily skilled in the art will appreciate and recognize frames per second determinations and associated factors and considerations in the environment of the present invention.

The techniques of the realistic approximations of the natural atmospheric lighting phenomena of the present invention will be discussed in detail below and generally in the context of . In an exemplary embodiment the approximations of the physical and mathematical relationships of the natural atmospheric lighting phenomena will be implemented and executed in one or more vertex and or pixel shader executable instructions. Although discussed as implemented in shaders the techniques of the present invention may be executed as executable instructions in any form and in any processor suitable for practicing the operations of the present invention as described herein.

As discussed above with respect to natural atmospheric lighting phenomena realistic simulation of skies and atmospheres relies on an approximation of the atmospheric light scattering phenomenon Rayleigh scattering and Mie scattering. The techniques of the present invention approximates the most common visible effects of each of these types of scattering in a typical atmosphere while allowing sufficient flexibility to go beyond the limitations of the scattering models. Furthermore the approximations are very quick to compute to provide real time rendering of multiple frames of a scene such as the continuous rendering of a series of frames of a scene for a simulation. In the discussion of the techniques of the present invention below reference to an object or viewing object may be made. An object may be any element of the scene represented by the image in which the techniques of the present invention are desired to be applied.

Outscattering and in scattering phenomenon of atmospheric light scattering are approximated and calculated as an attenuation factor and an additive term respectively. The attenuation factor provides an approximation of light from an object being scattered out of the viewing direction of a viewer by atmosphere particles . The additive term provides an approximation of the atmospheric particles scattering light into the viewing direction of the viewer . As will be discussed further below the attenuation factor and additive term are used to modify the apparent color and brightness of any object in the scene .

At step of the illustrative method the constants for the Rayleigh component r and the Mie components r for the scattering attenuation factor approximation are obtained. In the simulation environment of the present invention an RGB value is specified for the Rayleigh and Mie components of the atmosphere . These constant values may be specified by a user via the configuration mechanism of the simulation environment or may be provided as default suggested or recommended values in the simulation environment . In other embodiments these constants may be set programmatically via any suitable programming means such as an application programming interface API . In accordance with one embodiment of the present invention density is weighted differently according to the wavelength of light to simulate the effects of Rayleigh scattering. In another embodiment weights for the Rayleigh and Mie component may be equal. For realistic results the weights for Rayleigh scattering are highly biased towards blue and green to a lesser extent.

At illustrative step the cumulative density for each color channel or wavelength is determined In the scattering attenuation approximation of the present invention each integral is a user specified density multiplied by the length of the portion of the ray that travels through the atmosphere . However more complex density functions can be used.

At step of the illustrative method the final attenuation factor defined as the proportion of light from an object that reaches the viewer directly is computed as This value is computed for multiple wavelengths or for each of the RGB channels with different values of for each wavelength.

At step of the illustrative method of the present invention the convergence color Cis determined. The details of step are depicted in the illustrated method of in association with illustrative methods and of respectively. At step the attenuation factor Tis obtained see method of for each RGB color channel and or wavelength. At step the additive term O of the present invention is determined as a function of the attenuation factor Tand the convergence color C 1 The convergence color Cis based on the user s chosen horizon colors for the Rayleigh and Mie components rand r. However it is also dependent on the lighting conditions and the viewing angle with respect to the direction of incident sunlight as described in detail below.

In the techniques of the present invention illustrated by methods and the determination and value of Tis wavelength dependent. As such these techniques provides for more realistic colors of objects and results in richer hue variations than with other methods such as alpha blend operations known by one ordinarily skilled in the art.

In another aspect the techniques of the present invention provide for colors of the effects of illumination upon the atmosphere . The techniques of the present invention consider at least two types of light source sunlight and ambient sky . Although ambient light affects the Rayleigh and Mie components of the atmosphere equally sunlight does not. The techniques described herein consider the convergence color of the Rayleigh and Mie components to form a weighted composition of the components using the relative densities of each.

At step of the illustrative method the horizon color Cfor the Rayleigh component is obtained. The Rayleigh horizon color may be specified by any suitable means and or mechanisms such as by a user via the configuration mechanism of the simulation environment . In some embodiments Ccomprises a blue grey color. Furthermore Cshould not be confused with Rayleigh density. At step the color and intensity of ambient light L or other higher order illumination terms is obtained. The Lterm may be considered a constant for any particular scene . As such the Lterm may be user specified via the simulation environment or otherwise be set by any mechanism or means to provide a value suitable for representing the ambient component of light in the scene . At step the color and intensity of sunlight L is obtained see step of for details . At step the convergence color for the Rayleigh component of illumination of the atmosphere e.g. the convergence color of a purely Rayleigh atmosphere is calculated as As such the parameter Ccomprises the composite effects from sun and ambient light.

At step of the illustrative method of the present invention the horizon color Cfor the Mie component is obtained. The Mie horizon color may be specified by any suitable means or mechanisms such as by a user via the configuration mechanism of the simulation environment . At step the angle or phase angle between the viewer and the sunlight as viewed from the object is determined and or obtained. The angle may be determined from a vector from the viewing position and or viewer towards the sun or incident sunlight in the scene .

At illustrative step of the present invention intensity and sharpness values and are obtained. The intensity and sharpness value are adjustable values to control the intensity and sharpness of the glow around the sun or the apparent sun of the scene . In some embodiments these may be positive values that can be specified by a user via any suitable means or mechanisms such as by the configuration mechanism of the simulation environment . At step a value c is obtained to represent a minimum level of back scattering from an anti solar direction. At step a value acute over is obtained that affects the minimum angle from the sun. In some embodiments acute over is a small number.

At step of the illustrative method of the present invention phase is determined as a function of the viewing direction and the direction of incident sunlight as follows max acute over 1 cos At step the convergence color Cof a purely Mie atmosphere is calculated as In accordance with this technique the phase function is relatively quick to compute while appearing to give realistic and desirable results.

In another aspect the techniques of the present invention are directed towards the visually realistic appearance and real time rendering of clouds in a scene . In accordance with the cloud related techniques of the present invention cloud appearance is primarily driven by a cloud density function discussed below. In an exemplary embodiment the cloud density function is implemented as a pixel fragment shader . The cloud appearance technique uses multiple tile able cloud textures with independent scaling and weightings. This approach has multiples benefits including the following 1 large cloud formations can be created with fine details and without the need for large detailed textures 2 distinct cloud patterns can be controlled at individual scales and 3 sophisticated looking time lapse effects are possible by scrolling individual textures.

At illustrative step a cloud density adjustable offset c is obtained. The cloud density adjustable offset may be user specified via the configuration mechanism of the simulation environment . In other embodiments the offset c may be programmatically set or otherwise be specified by the simulation environment . By changing the cloud density adjustable offset while restricting the resulting to non negative values the proportion of cloud filled sky relative 0 to clear sky 0 can be adjusted interactively. In an exemplary embodiment the offset is the sum of the adjustable offset c and a compensation term calculated by the simulation environment of the present invention as described in conjunction with . At each texture coordinate of a cloud the cloud density is determined and calculated at step of illustrative method as follows max 0 . . . 

At step of the present invention the illustrative method obtains weightings w. . . wfor each texture. At step the offset compensation term Cis calculated as follows 0.5 . In an exemplary embodiment a constant value of 0.5 is used to determine the offset compensation term C. In other embodiments other constant values may be suitable to use or may be used to provide a desired offset. At step a specified adjustable offset Cis obtained such as user specified offset. The offset Cmay be specified by any suitable mechanism or means such as by a user via the configuration mechanism of the simulation environment . At step a user adjusted and compensated offset C is determined by adding the user specified offset Cwith the offset compensation term C. In one embodiment the value Of Cis used in the cloud density function at steps and of illustrative method .

In one aspect of the present invention the cloud density function is used to determine the opacity of a cloud as depicted by the illustrative method of . Cloud opacity is used to indicate how much light passes through the cloud object s pixels. At step of illustrative method the density of a cloud is obtained. In one embodiment at step the opacity of the cloud may in one embodiment be calculated as 1 The cloud density is physically based in that it is interpreted as an accurate model of the physical particles and or a distance through the target medium. As such the cloud opacity calculated at step gives a much more desirable and realistic result than simply clamping to the 0 1 range.

However an alternative approach can be use to determine cloud opacity that is quicker to compute and provides similar desirable results as compared to the opacity calculated at step . This approach also avoids visibly undesirable results from a cloud density value clamped at 1. Alternatively after step the illustrative method may perform step and step instead of step . At step a cloud opacity offset can be provided specified by the user and or the simulation environment . In one embodiment this cloud opacity offset has a value greater than 1 and in an exemplary embodiment may beset to 2 for quick execution. At step the following cloud opacity a calculation is performed 1 1 

In another aspect the cloud related techniques of the present invention provides for the lighting of clouds. Cloud lighting is a color value such as an RBG color code that is multiplied by a current cloud color to give the cloud a final color for rendering. In an exemplary embodiment cloud lighting calculations consider both sunlight and ambient terms. In some embodiments the ambient term is considered to be constant throughout the scene on any particular frame. However in other embodiments any suitable and adjustable offset or calculations may be used to represent the ambient term for cloud lighting. With respect to the sunlight term of cloud lighting the sunlight term is related to the color and intensity of sunlight reaching the top of the cloud layer self shadowing effects of the cloud and light scattering within the cloud .

Instead of performing step of illustrative method in an alternative embodiment steps and as illustrated in are performed. At step the illustrative method computes the attenuated cloud color component Ofor the sun term by the following calculation O TC L At step the attenuated cloud color component Ofor the ambient term is computed as follows O TCL In an exemplary embodiment the Oand Ocomputations are performed in a vertex shader prior to computing the final composite attenuated cloud color in the pixel fragment shader by the following calculation 1 O O As such the alternative expression of the attenuated cloud color comprises an approach wherein the attenuated cloud color components for the sunlight and ambient terms are computed separately in the vertex shader .

In another aspect the techniques of the present invention consider the self shadowing of clouds in the realistic simulation and real time rendering of an outdoor scene with clouds . In some embodiments self shadowing is based on the integral of densities within the cloud along a path towards the light source such as the sun . In an exemplary embodiment as depicted in the illustrative method at step computes a single sample of the cloud density function at the current cloud coordinates offset by a small vector in the direction towards the light source. The single sample is performed for computational speed. However in other embodiments more than a single sample of the cloud density function may be used and accomplish the desired computational speed. At step the sampled cloud density is weighted by an obtained or otherwise provided constant . Then at step of the illustrative method the self shadowing opacity a is calculated by either one of the following expressions 1 or 1 1 The above self shadowing opacity calculations are similar to the illustrative method of wherein the value for is greater than 1 and in some embodiments may be set to 2 for computational speed.

In a further aspect the final color of a pixel fragment for the sky can be determined from a composition of the cloud opacity values related to the sun and ambient terms of the cloud coloring along with terms for the cloudless sky and haze. depicts an illustrative method for a technique of the present invention to determine the sky color approximation . The sunlight term for cloud lighting Oas calculated in illustrative method of is obtained at step and the ambient term for cloud lighting Oas calculated in illustrative method of is obtained at step .

At step of the illustrative method the in scattering additive term Ois calculated or otherwise provided to represent an approximation of the haze between the viewer and the cloud . At step the additive term for atmospheric in scattering Oas calculated in illustrative method of is obtained. At steps and the cloud opacity and self shadowing opacity aare provided as discussed in illustrative methods and respectively. Using all the natural atmospheric lighting phenomena related approximations determined calculated or otherwise provided in steps though step the final sky color can be determined at step as follows 1 1 as .

The calculation at step is an alpha blend type operation which composites the cloud over the cloudless sky O which in an exemplary embodiments was computed in the vertex shader . The term Oaccounts for the additive in scattering contribution of haze that is between the viewer and the cloud . As such Ocontributes to the visual realistic simulation of the appearance of clouds. In an exemplary embodiment Ois computed in the vertex shader along with T.

As used in the illustrative methods and as discussed above Tand Oare specific values for Tand O respectively. The technique for calculating Tis discussed above in conjunction of illustrative method of . Likewise the technique for calculating Ois discussed in relation to illustrative method of . Tis the value of Tcomputed using the illustrative method for the ray or beam of light between the viewer and the cloud being considered. Ois the value of Ocomputed using the illustrated method for the light ray between the viewer and the cloud being considered. In this case the atmosphere convergence color Crelies on the sunlight attenuation parameters Land p to derive the sunlight intensity at an appropriate point along the ray. For this the midpoint between the viewer and the cloud is chosen. The sunlight attenuation parameters are discussed below in conjunction with

In one embodiment the present invention is related to techniques for the realistic simulation of shadows cast by clouds onto other objects such as the terrain . The proportion of sunlight that is interrupted by a cloud and prevented from reaching a certain point in the scene is determined by sampling the cloud density function at the cloud layer s intersection with the ray from the point towards the sun. The cloud density function is described in detail above with respect to the illustrative method of .

In an embodiment of the atmosphere of the scene representing the Earth s atmosphere the direct sunlight that reaches any point in the atmosphere is dimmer and redder than the sunlight entering the upper atmosphere . This natural atmospheric lighting phenomenon is due to the Rayleigh and Mie scattering of light away from the direct path of the beam of light. This effect is most pronounced when the sun is low in the sky because the light takes a longer path through the atmosphere . In one embodiment of this natural atmospheric lighting phenomenon there is a grade of color and intensity with respect to altitude often with a dramatic hue shift from white to yellow to red. A resulting consequence of this phenomenon is the rich color gradients one sees in the sky at sunrise and sunset. This effect may also be referred to as the sunrise or sunset effect.

1 Due to the optical density of atmosphere the lower atmosphere partially obscures the upper atmosphere. Therefore the sunlight reaching the lower atmosphere is visually more important than the sunlight reaching the upper atmosphere.

2 The degree to which the lower atmosphere is visually more important than the upper atmosphere depends on the cumulative optical density of the lower atmosphere and therefore is dependent on the observed angle above the horizon.

In an exemplary embodiment of the present invention the visual consequences of the above assumptions for sunlight attenuation are well represented by choosing a single dominant point along the path being observed that receives what is considered or desired to be the dominant color and intensity of sunlight. For observance paths close to the horizon the chosen point along the path should be of lower altitude than for paths close to the zenith.

At step the atmosphere conditions constants k and m are obtained or otherwise provided. These constants are in some embodiments set to a value of 1 but can be adjusted to simulate some atmospheric conditions more accurately. In some embodiments these constants are user specified via the configuration mechanism of the simulation environment . At step the small number value acute over is obtained and or provided to be used in the optical density calculation to prevent division by zero in the optical density calculation in the following step .

At step the optical density of atmosphere above the dominant altitude is calculates as follows max acute over max 0 sin The above calculation provides a value of the optical density that decreases with increasing angles above the horizon 0 of either the observed point on the sky or the incident sunlight. As both angles and approach the value of 0 the optical density value produced tends towards infinity.

At step of the illustrative method a sunlight attenuation factor is then calculated from as determined at step . In an exemplary embodiment the sunlight attention factor is calculated as e. Since the cumulative optical density varies with the wavelength of light the resulting attenuation factor approaches 0 at a rate that depends on the wavelength. Thus the optical density passes through a range of hues as it tends from white where 0 to black where . Where optical density is strongly blue or blue green for example due to atmospheric Rayleigh light scattering the attenuation factor exhibits the red and orange hues that are desirable under such conditions. At illustrative step of the present invention the final color of sunlight used to illuminate the atmosphere not including ambient or higher order illumination is determined using the optical density provided by step 

In another aspect the techniques of the present invention consider sunlight attenuation from the atmosphere when the viewer and the object being considered or viewed such as the terrain are relatively close or nearby. depicts an illustrative method of a technique of the present invention for determining the optical density of atmosphere for relatively close viewer and object. At step a relative closeness ratio is determined from the vertical component of the distance between the viewer and the object divided by the vertical component of the distance between the viewer and the sky . In one embodiment the ratio is expressed as the following object sky This ratio accounts for the relative closeness of the object and therefore the reduced altitude from which the angle is derived for use in the cumulative optical density calculation. The technique of illustrative method replaces the term k.max 0 sin in the cumulative optical density calculation illustrated at step of method with the following term object sky .k max 0 sin As such the cumulative optical density will be calculated for viewers nearby objects to provide a visually realistic and real time simulation of such conditions.

At step of the illustrative method a technique to determine the sunlight reaching other objects directly such as clouds or terrain of a particular altitude is depicted. At step the following variation of the optical density calculation is used object sky max 0 sin max acute over sin As previously discussed in some embodiments the object sky ratio is the vertical component of the viewer object distance divided by the vertical component of the apparent viewer sky distance. This means that for objects in the upper atmosphere is small while for objects close to the viewer is similar to that for the lower atmosphere.

In an exemplary embodiment the techniques of the present invention discussed above are directed towards illustrative methods performed on a frequency of a vertex basis and or pixel fragment basis in a vertex shader and or pixel shader . As such each of the techniques discussed above can be executed for each vertex and or pixel needed to render the image and thus the scene including any visual effects from the natural atmospheric lighting phenomena . A representation of a scene may have tens of thousands to hundreds of thousands or more polygons e.g. triangles and millions of pixels to process to render the desired image . This results in high number of executions of the techniques of the present invention to render a single instance of a scene . The present invention also re executes the above techniques for each frame of a scene in a multiple frame simulation such that the high numbers of executions are repeated for each frame.

In another aspect the techniques of the present invention are applied when any element of the scene is changed or is desired to be changed or any factors driving the scene are changed or are desired to be changed. For example any of the following may cause the present invention to apply these techniques and render the image using these techniques 

The techniques of the present invention may be executed for all the polygons and pixels of the image to realistically simulate the natural atmospheric lighting phenomena . As such the techniques of the present invention executed through the graphics processing pipeline determine a color for each vertex of a polygon primitive and any associated pixels fragments. The determined colors provided by the present invention represent the resulting visual effects from the natural atmospheric lighting and related phenomena that may be present in the scene represented by the image . Although the techniques of the present invention use approximations for such phenomena the techniques provide images that are substantially similar to comparable or equivalent to photographic representations of such phenomena using physically accurate models and calculations and as such can be referred to as realistic approximations. That is the colors rendered in an images provided by the present invention are substantially similar to comparable or equivalent to the colors that would be present in an actual photograph of such phenomena.

Using the systems and methods of the techniques of the present inventions images and simulations can provide visually realistic representations of sunlight in a scene at any time of day including from dawn to twilight. The present invention provides a solar lighting system that produces accurate shadows in the scene along with bright sun flares and dramatically realistic sunsets and sunrises. With the cloud related techniques described above the present invention can simulate a visually realistic representation of a wide range of cumulus and stratus cloud formations and the resulting cloud cover over a terrain . Additionally the present invention provides a visually realistic representation of shadows cast by clouds on the objects e.g. and terrain of the scene . Furthermore the present invention provides a realistic simulation of the visual effects from light scattering by the cloud cover and also provides visually realistic simulation of water including accurate reflections refractions and turbulence.

Moreover the techniques of the present invention not only provide visually realistic images as described above but the present invention can render these images in real time. Even with a complex geometric representation of an image comprising tens of thousands or more polygons the techniques of the present invention can be computed and executed with real time and higher frames rates per second. The simulation engine can process and execute the techniques of the present invention at a rate to support the real time rendering of frames of a simulated image via the rendering mechanism .

In one example embodiment the present invention can execute these techniques at a real time rate of approximately 120 frames per second with an image represented by approximately 80 000 polygons. In this example the computing device comprises a Pentium 3.4 Ghz processor with 1 gigabyte of ram and the graphics card processor is an ATI Technology Radeon X700 graphics card. The images can be rendered at a 1024 768 resolution with 32 bit color to the visual display device . As such the present invention provides very high frame rates per second even on typically available or common computing devices that far exceed minimum required speeds for real time simulation.

In another aspect the techniques of the present invention provide real time visually realistic simulation of natural atmospheric lighting phenomena on a wide variety of screen resolutions of the visual display device in combination with a variety of real time frame rates. The techniques of the present invention can provide real time images and simulation on visual display devices with any of the following pixel screen resolutions 160 160 240 160 320 240 640 480 800 600 1152 864 1280 720 1280 768 1280 960 1280 1024 1024 768 1600 1280 and 2048 1536. In one embodiment the techniques of the present invention can be executed at a rate of at least 10 frames per second with images rendered at any of the above pixel screen resolutions. In another embodiment the techniques of the present invention can be executed at a rate of at least 15 frames per second with images rendered at any of the above pixel screen resolutions. In a further embodiment the techniques of the present invention can be executed at a rate of at least 20 frames per second with images rendered at any of the above pixel screen resolutions. In one embodiment the techniques of the present invention can be executed at a rate of at least 24 frames per second with images rendered at any of the above pixel screen resolutions. In another embodiment the techniques of the present invention can be executed at a rate of at least 30 frames per second with images rendered at any of the above pixel screen resolutions. In another embodiment the techniques of the present invention can be executed at a rate of at least 35 frames per second with images rendered at any of the above pixel screen resolutions. In some embodiments the techniques of the present invention can be executed at a rate of at least 40 50 or 60 frames per second with images rendered at any of the above pixel screen resolutions. One ordinarily skilled in the art will appreciate and recognize that the techniques of the present invention can be executed at any pixel screen resolution supported by the video display device and at any frame rate for real time rendering.

With the combination of the visual realism and real time rendering speeds of the present invention the simulation environment can provide real world outside scenes for many applications such as for games and entertainment related applications and for training such as driving flight or military training tools. Simulations provided by the present invention will make the image synthesis process more intuitive for users and will immerse the user into a visually realistic real world environment and scenario. This will greatly improve the user s experience with the application and make a more effective visual tool for simulation. Furthermore because of the real time rendering capability of the simulation environment the techniques of the present invention can be applied interactively and instantly to develop and design real world scenes for such applications.

In a further aspect the present invention provides a simulation environment for generating visually realistic scenes interactively. The simulation environment of the present invention provides user interfaces such as the illustrative graphical user interfaces depicted in and for modifying the atmospheric cloud sunlight and water conditions of a scene interactively using a slider system to provide parameters mapping to the techniques of the present invention. As such scenarios for training simulation visual planning or for any other purpose can be easily created dynamically and the results of the interactive modifications rendered in real time in the simulation environment .

In the illustrative atmosphere GUI the blue horizon brightness slider is used to set or adjust a color value mapping to the Cparameter used in illustrative method of . The haze horizon slider is used for setting and adjusting the color value for the Cparameter used in the approximation equations illustrated by method of . The blue density slider provides a selectable blue density color value and the haze density slider the density multiplier slider and the max altitude slider provide selectable haze density density multiplier and max altitude real number values to be used in a density distribution function at a particular point s in the scene . The blue density color value maps to a multiplier such that r s at point s is the product of the blue density color and the density distribution function at point s see illustrated method of . The haze density value maps to a multiple such that r s at point s is the product of the blue density color and the density distribution function at point s. In an exemplary embodiment the density distribution function is the value of the density multiplier for points in the atmosphere at or below the max altitude value and is 0 for points above the max altitude value.

In the illustrative lighting GUI the sunlight color slider sets or adjusts a color value mapped to the Lparameter used in the illustrative method at step . In a similar manner the ambient color slider sets or adjusts a color value mapped to the Lparameter used in various techniques of the present invention such as illustrative methods and . The glow brightness slider sets or adjusts three real values mapped to form the parameters k y and acute over as used for the convergence color approximation of illustrative method . For example purposes the glow values provided by the glow brightness slider will be referred to as Glow Glow and Glow . In an exemplary embodiment the glow values forms the k y and acute over parameters in the following manner 

The time of day slider control controls and provide as value for the sun angle. In an exemplary embodiment the sun angle is the declination of the sun above the eastern horizon and provides a normalized vector for the sun direction. In some cases the sun angle can be greater than 2 to give a westerly vector for the sun direction. The sun angle value provided by the time of day slider control is used for providing a sun direction parameter for computing the parameter value as described and used in illustrative methods and . An x y and z component of a sun direction parameter can be expressed in relation to the Sun angle in an exemplary embodiment as follows sunDirection. cos cos SunAngle sunDirection. sin SunAngle sunDirection. sin cos SunAngle 

The sun direction parameter as expressed above is used to compute the cos term used in the approximation equations of the present invention such as used by illustrative method as step .

In the illustrative atmosphere GUI the cloud color slider is used to set or adjust a color value mapping to the Cparameter used in the techniques of the present invention such as illustrated by method . The cloud coverage slider sets or adjusts a value between 0 and 1 that maps to Cand is used to control the could density offset as determined in illustrative method . The value from the cloud coverage slider is also used to factor the proportion of sunlight that is allowed to illuminate the atmosphere below the could layer as illustrated by method of .

The cloud density and cloud detail sliders provide values to be used for the texture offsets and texture weightings in the cloud density function of . For example purposes the value of the cloud density slider is expressed as CloudPosDensity and the cloud detail slider value as CloudPosDensity. In an exemplary embodiment the values of CloudPosDensity and CloudPosDensity are used in conjunction with the cloud density function as follows 

The x and y components are texture offsets such that CloudPosDensity1 CloudPosDensity1 CloudPosDensity2 CloudPosDensity2 

The z components map to weightings for textures and such that w CloudPosDensity1.z w CloudPosDensity2.z

In one embodiment not shown a slider may also be provided in the cloud GUI or any other GUI to allow the user to adjust the apparent vertical position of the atmosphere s horizon and gradient as well as the glow around the sun. This is determined by offsetting the vertical component of the ray towards the object being considered HorizonDrop where HorizonDrop is the value provided by the slider p p is the length of the ray is the vertical component of the ray and is the vertical component of the apparent ray which is used by all subsequent atmosphere calculations such as those performed in illustrative method .

Although slider controls are used in the illustrative graphical user interface and any type of suitable user interface mechanism may be used such as other types of graphical user interface widgets configuration files or data from a database. Additionally the graphical user interfaces and could be combined into a single user interface or separated further into more graphical user interfaces. Furthermore other elements to the graphical user interfaces and and or additional graphical user interfaces could be provided to allow the user to adjust any constant parameter or other factor related to the techniques of the present invention described above to generate or create the desired scene and image .

Many alterations and modifications may be made by those having ordinary skill in the art without departing from the spirit and scope of the invention. Therefore it must be expressly understood that the illustrated embodiments have been shown only for the purposes of example and should not be taken as limiting the invention which is defined by the following claims. These claims are to be read as including what they set forth literally and also those equivalent elements which are insubstantially different even though not identical in other respects to what is shown and described in the above illustrations.

