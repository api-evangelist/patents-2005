---

title: Platform for data services across disparate application frameworks
abstract: Data management between a common data store and multiple applications of multiple disparate application frameworks. A data storage component is provided that facilitates the storage of data, which data includes structured, semi-structured, and unstructured data. A common data platform interfaces to the data storage component to provide data services accessible by a plurality of disparate application frameworks, which data services allow a corresponding application of the different frameworks to access the data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07853961&OS=07853961&RS=07853961
owner: Microsoft Corporation
number: 07853961
owner_city: Redmond
owner_country: US
publication_date: 20050630
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 60 657 556 entitled PLATFORM FOR DATA SERVICES ACROSS DISPARATE APPLICATION FRAMEWORKS and filed Feb. 28 2005. This application also relates to the following U.S. Applications Provisional Patent Application Ser. No. 60 657 295 entitled DATA MODEL FOR OBJECT RELATIONAL DATA filed on Feb. 28 2005 patent application Ser. No. 11 228 731 entitled DATA MODEL FOR OBJECT RELATIONAL DATA filed on Sep. 16 2005 Provisional Patent Application Ser. No. 60 657 522 entitled STORAGE API FOR A COMMON DATA PLATFORM filed on Feb. 28 2005 and patent application Ser. No. 11 195 320 entitled STORAGE API FOR A COMMON DATA PLATFORM filed on Aug. 2 2005 now U.S. Pat. No. 7 685 561 . The entireties of these applications are incorporated herein by reference.

Data has become an important asset in almost every application whether it is a Line of Business LOB application utilized for browsing products and generating orders or a Personal Information Management PIM application used for scheduling a meeting between people. Applications perform both data access manipulation and data management operations on the application data. Typical application operations query a collection of data fetch the result set execute some application logic that changes the state of the data and finally persist the data to the storage medium.

Traditionally client server applications relegated the query and persistence actions to database management systems DBMS deployed in the data tier. If there is data centric logic it is coded as stored procedures in the database system. The database system operated on data in terms of tables and rows and the application in the application tier operated on the data in terms of programming language objects e.g. Classes and Structs . The mismatch in data manipulation services and mechanisms in the application and the data tiers was tolerable in the client server systems. However with the advent of the web technology and Service Oriented Architectures and with wider acceptance of application servers applications are becoming multi tier and more importantly data is now present in every tier.

In such tiered application architectures data is manipulated in multiple tiers. In addition with hardware advances in addressability and large memories more data is becoming memory resident. Applications are also dealing with different types of data such as objects files and XML eXtensible Markup Language data for example.

In hardware and software environments the need for rich data access and manipulation services well integrated with the programming environments is increasing. One conventional implementation introduced to address the aforementioned problems is a data platform. The data platform provides a collection of services mechanisms for applications to access manipulate and manage data that is well integrated with the application programming environment. However such conventional architecture falls short in many respects. Some key requirements for such a data platform include complex object modeling rich relationships the separation of logical and physical data abstractions query rich data model concepts active notifications better integration with middle tier infrastructure.

The following presents a simplified summary of the innovation in order to provide a basic understanding of some aspects of the architecture. This summary is not an extensive overview of the architecture. It is not intended to identify key critical elements of the innovation or to delineate the scope of the innovation. Its sole purpose is to present some concepts of the innovation in a simplified form as a prelude to the more detailed description that is presented later.

The innovation disclosed and claimed herein in one aspect thereof comprises an architecture that facilitates data management between a common data store and multiple applications of multiple disparate application frameworks. It formalizes a mapping layer away from applications to map tables to objects. The architecture bridges the gap between desktop applications and Line of Business LOB application frameworks to allow applications to handle data at the level of application objects rather than tables. Additionally the architecture enables sharing of this data across all frameworks such that a data entity that is defined by an end user application can be used by the LOB application and vice versa.

The architecture includes a data storage component that facilitates the storage of data which data includes structured semi structured and unstructured data. A common data platform interfaces to the data storage component to provide data services accessible by a plurality of disparate application frameworks which data services allow a corresponding application of the different frameworks to access the data. The data platform further comprises an API Application Program Interface that facilitates communicating to applications in the form of public classes interfaces and static helper functions a runtime component that interfaces to the API and provides object relational mapping query mapping and enforces constraints and a constrain security engine that facilitates declarative authoring of constraints and controls access to entities of the data platform.

In another aspect of the subject innovation a common data platform CDP provides data services which are common across a variety of end user application frameworks e.g. PIM Personal Information Manager framework to LOB Line of Business application frameworks. The range of applications include end user applications such as Explorer Mail and Media applications Knowledge Worker applications such as Document Management and Collaboration applications LOB applications such as ERP Enterprise Resource Planning and CRM Customer Relationship Management Web Applications and System Management applications.

In yet another aspect thereof the CDP provides benefits to applications that include a rich store which provides the capability to model and store structured semi structured and unstructured data flexible organization rich query search rich behaviors flexible administration data synchronization sharing schemas and flexible deployment in multi tier environments.

To the accomplishment of the foregoing and related ends certain illustrative aspects of the architecture are described herein in connection with the following description and the annexed drawings. These aspects are indicative however of but a few of the various ways in which the principles of the architecture can be employed and the subject innovation is intended to include all such aspects and their equivalents. Other advantages and novel features of the architecture will become apparent from the following detailed description of the innovation when considered in conjunction with the drawings.

The architecture is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the subject innovation. It may be evident however that the architecture can be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to facilitate describing the architecture.

As used in this application the terms component and system are intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component can be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a server and the server can be a component. One or more components can reside within a process and or thread of execution and a component can be localized on one computer and or distributed between two or more computers.

A data platform is a platform that provides a collection of services or mechanisms for applications to access manipulate and manage data that is well integrated with the application programming environment. The subject innovation is an improvement over the conventional data platform. The architecture is a common data platform CDP that provides data services which are common across a variety of application frameworks e.g. PIM Personal Information Manager framework and LOB Line of Business framework . The range of applications include end user applications such as Explorer Mail and Media applications Knowledge Worker applications such as Document Management and Collaboration applications LOB applications such as ERP Enterprise Resource Planning and CRM Customer Relationship Management Web Applications and System Management applications.

The CDP and associated architecture enables all the benefits described above. Key innovations include a layered architecture a common data model that factors out the modeling concepts common across multiple application frameworks and a CDP component functional architecture.

Referring initially to the drawings illustrates a system that employs a CDP . The CDP is employed to provide data management between data applications and application frameworks and data on a data store . The data store can store for example structured semi structured and unstructured data types. As indicated supra the CDP provides data services which are common across the application frameworks and end user applications associated therewith. The CDP further includes an API that facilitates interfacing with the applications and application frameworks a runtime component and a constraint security engine component . The API provides the programming interface for applications using CDP in the form of public classes interfaces and static helper functions. Examples include StorageContext StorageSearcher Entity TableSet Table EntityReference and TableReference. It is to be appreciated that database programming language integration e.g. C sequence operators can be part of the API .

The CDP runtime component is a layer that implements the various features exposed in the public API layer . It implements the common data model by providing object relational mapping and query mapping enforcing data model constraints etc. More specifically the CDP runtime includes the common data model component implementation a query processor component a sessions and transactions component an object cache which can include a session cache and an explicit cache a services component that includes change tracking conflict detection and eventing a cursors and rules component a business logic hosting component and a persistence and query engine which provides the core persistence and query services. Internal to persistence and query services are the object relational mappings including query update mappings. The CDP also includes the constraint security engine which provides for applying constraints against the data store and security policies for example role based security.

A goal of the CDP is to support rapid application development by enabling support for a variety of application frameworks denoted AF AF . . . AF . The frameworks can include LOB end user and system management application frameworks for example. Applications denoted APP . . . APPS APP . . . APP associated with the application frameworks AF AF and . . . AF respectively can leverage the respective application frameworks the CDP and the underlying stores to develop rich applications. The benefits of a layered approach are described infra.

The store management layer provides support for core data management capabilities e.g. scalability capacity availability and security the CDP layer supports a rich data model mapping querying and data access mechanisms for the application frameworks . The CDP mechanisms are extensible so that multiple application frameworks can be built on the data platform. The application frameworks are additional models and mechanisms specific to application domains e.g. end user applications and LOB applications . The layered architectural approach has several advantages. It allows for each layer to innovate and deploy independently and rapidly. The CDP layer can be more nimble have more freedom for innovation and can innovate more frequently than the store layer . The layered approach aligns the CDP layer with the company strategy. Finally the store layer can focus on the core data management capabilities consistent with the strategy.

Referring now to there is illustrated a methodology of implementing a common data platform. While for purposes of simplicity of explanation the one or more methodologies shown herein e.g. in the form of a flow chart are shown and described as a series of acts it is to be understood and appreciated that the subject architecture is not limited by the order of acts as some acts may in accordance with the innovation occur in a different order and or concurrently with other acts from that shown and described herein. For example those skilled in the art will understand and appreciate that a methodology could alternatively be represented as a series of interrelated states or events such as in a state diagram. Moreover not all illustrated acts may be required to implement a methodology in accordance with the architecture.

At a core data management layer is provided that models and stores structured semi structured and unstructured data types in a data store. At a CDP layer is applied over the core data management layer to provide data services which support a rich data model mapping querying and data access mechanisms for application frameworks. At one or more application frameworks overlay the CDP. At one or more applications are provided within each of the application frameworks that can now access data of the data store via the data services provided by the CDP.

Common Data Model CDM At the center of CDP runtime is a CDM . The intent of the CDM is to factor out the modeling concepts common across multiple application domains from applications working mainly with user data PIM documents etc. to LOB and enterprise data. In addition to providing rich object and relationship abstraction the CDM provides support for structure unstructured and semi structured data.

Row entity data The CDM supports a rich Entity Relationship model to capture the structure and the behavior of structured data e.g. business data . The CDM is a superset of the core relational model with extensions for rich object abstraction and relationship modeling e.g. an Author relationship between Documents and Contacts a Lines relationship between Purchase Orders and Order Lines .

File data The CDM supports the file stream data type to store and manipulate unstructured file data. The file stream data type can store the data as a file and supports file access APIs. The file stream data type is natively supported in SQL Server mapped to an NTFS file stream and supports all the file handle stream based operations. In addition to modeling the unstructured content as a file stream in the CDM using the entity types useful content can be promoted as structured properties. Database based file storage systems define the notion of a file backed item which is an entity that models the structured properties along with the file stream of unstructured content. The file backed items provide for rich querying along with stream based operations on the associated file stream.

XML data XML documents can be modeled to two primary ways in the CDM 1 store it as an XML data type 2 map the XML document to one or more entities e.g. similar to data contracts . CDM supports the XML data type as supported in SQL Server. The XML data type can be type of any entity property the XML data type allows for untyped or typed XML documents to be stored. Strong typing is provided by associating one or more XML schemas with the XML document properties.

Programming Language Integration including Query in the API The core CDP feature components sessions and transactions query persistence cursors services object cache and business logic hosting are encapsulated in several runtime classes available in the CDP API e.g. StorageContext . Based on the types authored in the CDM the CDP design time tools generate strongly typed CLR Common Language Runtime classes. CDP requires a query language over the type system defined by the CDM . CDP may support C Sequence Operators and OPATH as its query language. For the purpose of the subject application the query languages supported by CDP are generally referred to as Common Query Language CQL . CQL is envisioned to subsume the core relational algebra e.g. select join and project operators . While the syntax may not be identical to SQL CQL can be mapped to SQL in a straightforward way. CQL allows rich queries against the object structures that the programmer works with. The goal is to align CQL with the Sequence Operators work being done by the C group. These features effectively provide a strongly typed object based abstraction against data stored in a relational database management system RDBMS or any other CDP enabled store . Furthermore CDP s persistence framework can be used to durably persist and query for Plain Old CLR Objects POCO .

Persistence Engine A persistence engine provides declarative mapping definitions that describe exactly how objects are assembled out of the component pieces that come from the relational stores. The engine includes a query generation component not shown that takes an expression defined by the query processor in terms of an object query expression and then combines it with the declarative mapping. This turns into equivalent query expressions that access the underlying tables in the database. An update generation component not shown looks at change tracking services and with the help of mapping metadata describes how to translate those changes in the world of objects to changes in the world of tables.

Querying searching File and XML data As explained above the CDM stores the unstructured and semi structured data using the file stream and XML data types respectively. The CQL is capable of querying these data types. For file content promoted to structured entities e.g. WinFS file backed items CQL s relational operators can query these entities. The unstructured data stored as file stream can be queried using full text search. The XML content can be queried using XPath or XQuery.

Object Relational Mappings Since CDP provides an object based abstraction on top of a relational tabular storage it needs to provide an O R mapping component. CDP supports both prescriptive mappings CDP decides how mapping occurs and non prescriptive mappings type designer has some flexibility in specifying mappings . Notice that a database based file storage system implementation today uses prescriptive mappings while more general O R persistence frameworks need non prescriptive mappings.

Caching CDP runtime maintains a cache of query results e.g. cursors and uncommitted updates. This is called the session cache. CDP also provides an explicit cache which enables the application to work in a disconnected mode. CDP provides various consistency guarantees for data in the explicit cache. The cache performs identity management by correlating on disk identity of data with the in memory objects.

Query Processor When querying against the store CQL queries are mapped to SQL however when going against the explicit cache CQL queries are processed by the QP component. Database access is via the query processor. The query processor allows multiple frontends to handle multiple query languages to be expressed and then mapped to an internal canonical format. This is done in terms of the domain model and objects of the application it is working on. The queries then get passed to the processor which is a pipeline and then get converted into backend specific queries.

Cursors CDP provides both forward only and scrollable cursors. Cursors support notifications multi level grouping with expand collapse state dynamic sorting and filtering.

Business Logic Host CDP provides a runtime environment to host data centric logic on types instances and on operations. Such data centric business logic is distinct from application business process logic which can be hosted in the application server. Objects are not just rows in a database. When objects get materialized in memory they are actually objects that have behaviors which the application can invoke. There are extension points in the system that are mainly events and callbacks that all operate to extend the CDP at runtime. These objects are not just objects but CLR objects NET objects etc. CDP allows the capability to intercept property ort method calls in those objects. Applications can customize the behavior of these objects.

Services CDP provides a core set of services which are available to all CDP clients. These services include rules change tracking conflict detection eventing and notifications. Eventing extends the CDP runtime from framework level services or for applications to add additional behaviors and also is used for data binding at the user interface.

Constraints The CDP provides the constraints security component to at least one of allow the type designer to author constraints declaratively. These constraints are executed in the store. Typically the scope of CDP constraints encompasses notions such as length precision scale default check and so on. These constraints are enforced by the CDP constraint engine at run time.

Security CDP provides a role based security model the user s credentials determine her role such as administrator power user approver etc. . Each role is assigned a set of access permissions. CDP s security engine enforces these security policies. In addition the CDP provides a security model for controlling access to entities in the CDP. The security model can support authentication of an operating system user authorization level of entities e.g. with separate permissions for read and update etc.

Note that the constraints security component is illustrated separate form the CDP runtime component since it can operate as a separate entity therefrom. Alternatively and perhaps more efficiently the constraints security component is combined with the store component which can be the database system.

Taken together these features provide a powerful platform for developing data centric applications and logic which can be flexibly deployed across different tiers. Note that the positioning of the runtime components or boxes in this diagram does not imply or necessarily prevent any specific deployment across process machine boundaries. It is a schematic diagram used to show functional components.

One of the key advantages of the CDP architecture is that it provides flexibility in implementation. This means two things 

Several features and or components of the CDP are described in more detail hereafter. As stated supra at the center of the CDP is a common data model CDM wherein the intent of the CDM is to factor out the modeling concepts common across multiple application domains from applications working mainly with user data e.g. PIM documents etc. to LOB and enterprise data. In general there are two possible techniques that can be utilized to implement such functionality 1 Model concepts specific to every conceivable or conceivably important domain. For instance define precisely what a Customer means from LOB domain and what a Person means from user domain and so on and 2 Provide a flexible base over which application designers may create their own domain specific types constraints relationships. The CDM utilizes the second approach such that it provides a basic set of types and defines a flexible framework for authoring new types. In this sense the CDM can be both a data model e.g. it actually defines certain types and their semantics and also a data meta model e.g. it allows specification of other models .

Some of the features of the CDM are discussed below but are not to be seen as limiting on the subject application. The data model can subsume the relational data model. In other words the concepts of tables rows queries and updates on tables are exposed by the CDM . The CDM can define a richer object abstraction for data than tables and rows. In particular it enables the modeling of real world artifacts using concepts such as entities relationships among entities inheritance containment and collections of such. In addition the CDM can minimize the impedance mismatch between application structures and storage structures by aligning the programming language type system closely with application abstractions modeled therein. Moreover support for application behaviors e.g. methods functions and a flexible deployment of behaviors to enable two tier and multi tier applications can be provided. The CDM can also capture persistence semantics independently of the underlying physical store allowing the enablement of the CDM to be implemented over a wide variety of stores.

The CDM can invoke a plurality of concepts. The following concepts can be utilized by the meta model to be implemented to design domain specific data models. In particular the following concepts can be considered the core of the CDM 1 an entity type can be an application designer s specification for a grouping of properties and methods wherein an entity is an instance of an entity type. It is to be appreciated that an entity type can be organized through inheritance hierarchies 2 a table is a collection of entities which can be properties of other entities. Using entities inheritance and tables applications can recursively define data hierarchies. The table can be strongly typed in the sense that a given table can only contain entities of a given type or its subtypes 3 a table set can be an entity whose properties are tables. This is the base case for the recursive data hierarchy defined using tables and entities. It can be substantially similar to the concept of a database and 4 A relationship can express semantic connections between entities. It is to be appreciated that the relationship can be extended to define associates containment etc.

An entity relationship and or table set definition can occur in the context of for example a schema. For the purpose of this subject application the primary purpose of the schema is to define a namespace for scoping the names of the elements defined in the schema. A table set can form the top level of the CDM . The storage can be allocated directly and or indirectly by creating a table set. For instance the following pseudo code illustrates an example of a table set 

An Entity type can have properties and methods associated therewith. For specifying the types for properties method parameters and method return values the CDM provides several built in types 1 Simple types Int32 string other CLR value types 2 Enumeration types equivalent to CLR enums 3 Reference types discussed infra and 4 Array types ordered collection of inline types discussed below . Properties of these built in types can be grouped together to form an Inline Type wherein the inline type can have members of other inline types. Below is an example of the above 

The entity can be constructed by utilizing the built in types and or inline types. For example the following pseudo code demonstrates the entity 

An entity reference can be defined as a durable persistent reference to entities. Reference values range over entity identities. Indirecting an entity yields its reference dereferencing a reference yields the entity instance. The primary purpose of references is to enable entity sharing for example all orders for the same customer would have the substantially similar value for the Ref Customer property so the order entities are said to share the customer entity e.g. the sixth line of code in the following code sample is an example .

The data associated with the CDM has relationships among its constituent parts. The relational model does not explicitly support relationships PK FK Referential Integrity provide tools to implement relationships in a limited way. Yet the CDM supports explicit conceptual modeling of relationships using associations and compositions. The following example can be illustrated to understand the capabilities of associations and compositions 

The associations can represent peer to peer relationships between entities. In the above example an order is related to a customer via an association. In the code sample above line 6 shows that the order has an associated customer which is specified by the reference property Customer . The nature of the association is defined in lines 12 15 it says that the OrderCustomer association is from Order to Customer line 15 it also says that for each Customer Multiplicity 1 on line 14 there can be multiple Orders Multiplicity on line 13 . The type of association depicted above can be called a reference association.

CDM defines two other types of associations Value Associations and Association by Association Entities. Value associations allow expression of relationships via any property not just via identity reference e.g. Document.Author property relates to Contact.Name via the equality condition . Association entities allow the modeling of relationships where the relationship itself carries some data e.g. the employment relationship between a company and a person might carry properties like the employment period or the rank and title of the person within the company .

Compositions can represent parent child relationships and or containment relationships. Consider Orders and OrderLines e.g. Order is the sum total of what you put in the shopping cart at a website OrderLine is each individual item in the cart a book a DVD etc. . Each OrderLine makes sense only within the context of an Order. The OrderLine may not independently exist outside of the containing Order. In other words an OrderLine is contained within an Order and its lifetime is determined by the lifetime of the Order.

The above depicted relationships can be modeled using Compositions. Line 8 shows an example of a composition. Lines property and the OrderOrderLines composition lines 18 22 express that an order controls its lines and that lines depend on the order that houses them. It is to be appreciated that the order is the parent and lines are the children. The main difference between compositions and inline types is that compositions involve entities. In other words it will be possible for an OrderLine to be the target of a reference whereas an inline type cannot be in the above example.

One benefit of the CDM and its explicit modeling of relationships is that it supplies metadata support for query. An upstream query can be utilized as well. For instance given a customer find all the orders without having to store explicit backpointers can be invoked by implementing a NavigationProperty within the CDM . This is shown in line 28 of the code fragment seen above and reproduced below for convenience.

The persistence engine can include object relational mappings. In other words the modeling access and query abstractions provided by the CDP is object based. The primary storage technology utilized by the CDP is relational based e.g. SQL . The persistence engine utilizes object relational mappings also referred to as O R mappings wherein the persistence engine can map the language classes to the underlying tabular representation.

The persistence engine can provide two cases when considering O R mappings 1 prescriptive O R mappings and 2 non prescriptive O R mappings. Prescriptive O R mappings are the mapping between CDP types wherein their relational representation can be hard coded into CDP. The type designer has little and or no flexibility in choosing the layout of the underlying tables. An example of this can be a database based file storage system. Non prescriptive O R mappings are where the developer has varying degrees of flexibility to choose how the CLR classes map to the underlying storage structures. There are two sub cases that can be considered. 1 Exposure of an existing relational schema as objects. The type designer uses a high level specification language to design CDM types tools to generate classes based on them and the flexibility to specify how the types map to tables. This scenario arises when CDP applications are deployed side by side in the sense of using the substantially similar data with existing relational applications. For example a car company s IT department can have an LOB application wherein it wants to write a CDP application which goes against the same data probably as part of a step by step migration strategy . But the requirement is that both the LOB application and the new CDP application run together against the same data. 2 Persistence of a collection of classes into a relational schema. The developer does not use generated classes rather they utilize classes of own design. The developer wants to map these classes to a relational schema. It is to be appreciated that there are many different scenarios which generate this requirement

The CDP can further include a programming surface not shown that can be utilized during design time. The programming surface can be made available to a CDP application designer s and or programmer s . The programming surface can be classified into three general areas 1 design time programming tools e.g. tools to enable type designers to author CDM types and constraints thereof generate CLR classes from these types and add behavior to the types 2 API e.g. classes and methods for writing CDP applications and 3 query e.g. language for querying CDM objects such as entity instances. These components of the programming surface work synergistically to provide a strongly typed object based abstraction against the underlying store data.

The CDP provides a declarative Common Schema Definition Language CSDL analogous to SQL s data definition language or C class definitions for defining entity types entity tables relationships among entity types and constraints. There three main design time components.

The programming surface can further include a CDP API wherein programming surface applications can be written against. The CDP API can have three subparts 

CDM can also define a query language the CQL. CQL is designed to allow rich queries against the object structures that the programmer works with. The following are three identified techniques utilized for the basis of the CQL formalism 

Strategically the C Sequence Operators approach makes the most sense for becoming the framework for CQL. CQL is a query language. Creates updates deletes are performed as object operations new property setters etc. . The O R mapping component within the persistence engine can map these operations to underlying DML operations in SQL.

A relationship between CDM types and the programming surface is described below. The concept of a type in CDM can be viewed at three different levels 

The CDP query language targets the application space. This makes sense because a developer wants to query using the substantially similar abstractions that they use for other operations e.g. objects and collections . However the semantics of CQL are described using CDM abstractions the schema space .

The CDP can also include constraints security . Almost all data when examined within their larger semantic context will be constrained over the domain of its type in some form or another. It is thus very important for the CDP to provide a way for type and application designers to express these constraints. The CSDL can be used to author constraints declaratively at the time of type design. Examples of constraints include but are not limited to 1 simple type constraints such as length precision scale default and check 2 array type constraints such as element constraints occurs unique and check and 3 property constraints etc.

These constraints can be enforced by the CDP constraint engine at run time. Note that the very act of conforming to the CDM implies a set of constraints when seen from the level of the underlying relational store. For example CDM requires that every entity has a unique key within the scope of its containing table. This translates to a unique key constraint at the store level. There are several other examples of such constraints. The point here is that the CDP constraint engine enforces two types of constraints those that are implied by and required for the conforming to the CDM and those that are authored by the type designer. In addition to declarative constraints authored in CSDL constraints can also be written using SQL Server stored procedures. This method allows the expression of more complicated constraints than are possible the declarative language.

Moreover the constraints security can provide a security model for controlling access to entities in the CDP. The security model for the CDP must satisfy at least the following scenarios 

Authentication The security model can support authenticating operating system users. This includes users in a domain workgroup or a disconnected client machine. It can also include support for both NTLM and Kerberos based authentication.

Authorization The CDP security model can support authorization of security at least at the entity level. It must also allow managing separate permissions for read and update of the entity. At the minimum the constraint security provides for a property and or a set of properties of an entity to be deemed as the security identifier of an entity. The access rights of an entity are determined by a function associated with the table which takes the security identifier as a parameter. The CDP should also allow separately provisioning the users who can change the security identifier from the users who can change the rest of the entity. It is to be appreciated that the CDP can support a more general role based model which also allows different permissions that just read and write.

The CDP runtime maintains a cache e.g. an object cache of query results e.g. cursors discussed in detail infra and uncommitted updates wherein such cache can be referred to as the session cache because it is tied to the sessions transactions . In addition it comes into existence when a session is created and goes away when the session is terminated. The CDP session is encapsulated within the StorageContext object. An application can instantiate multiple instances of StorageContext thereby initiating multiple sessions and hence multiple session caches. The CDP can also expose another kind of cache called the explicit cache. The explicit cache provides a cache of data from one or more queries. Once data is materialized into the explicit cache the following data consistency guarantees can be provided 1 read only not authoritative 2 write through authoritative and 3 automatic refresh via exogenous notifications. The programming and query model against the explicit cache can be substantially similar as that over store data

The cursor rules are mechanisms that allow the set of data entities returned from CQL to be processed one at a time. An application can create a cursor over the result set by simply copying the entire result set into memory and overlaying a scrolling pattern on top of this in memory structure. But the ubiquity of this requirement and the complexity that is some times involved in implementing a cursor especially when updates paging etc. are taken into account means that any data platform should provide a cursoring model.

CDP provides both forward only and scrollable cursors. In addition to the basic functionality of browsing and scrolling CDP cursors provide the following features 1 exogenous notifications and maintenance 2 multi level grouping with expand collapse state and 3 dynamic sorting and filtering e.g. post processing . It is to be appreciated and understood that cursors may not be a different mechanism to specify a result set result sets are specified by queries and cursors are over these queries.

The CDP can also include the business logic hosting . When multiple applications are manipulating substantially similar data a key requirement is to ensure that the data remains trustworthy that is guaranteeing that data conforms to the various validation rules business rules and any other system of checks and balances instituted by the type designer and or data owner. It is a good assumption that applications in general are not trustworthy. Out of stupidity malice and or the simple exigencies of unforeseen usage patterns applications save and or attempt to save invalid. For example a user can enter as the area code and the application saves such number even though is an invalid area code and hence the value in the telephone number field no longer represents a telephone number. In other words it cannot be trusted to be a telephone number. The usual way to prevent this is to create a trust boundary some body of declarative rules validation code etc. e.g. commonly referred to as business logic which runs in a separate process and inspects data changes made by the application to approve such change. Then it can save these changes to the store. Many times business logic does more than inspect and approve it also enforces business rules causes workflow to happen etc. e.g. when a new customer is inserted email should be sent to the credit check department to ensure credit worthiness .

CDP provides several mechanisms for authoring business logic BL . These mechanisms can be divided into the following 5 categories constraints event handlers static instance methods bindable behaviors and static service methods each of which is discussed in more detail below. The constraints security as discussed supra can be declarative and procedural. These constraints can be executed on the store close in proximity to the data. Thus the constraints are considered to be within the trust boundary. Moreover constraints can be authored by the type designer.

The business logic hosting can employ an event handler. The CDP API raises several events on data change operations. BL authors can hook into these events via handler code. For example consider an order management application. When a new order comes in the application needs to ensure that the value of the order is less than the credit limit authorized for the customer. This logic can be part of event handler code which is run before the order is inserted into the store.

Broadly speaking there can be the following types of events 1 validation e.g. these events provide an opportunity for the interested party to inspect the proposed value and validate it 2 pre save e.g. this event is raised just before saving changes to the store and can be substantially similar in intent and behavior to the BEFORE trigger in an SQL Server and 3 post save e.g. this event is raised after saving changes to the store and can be substantially similar in intent and behavior to the AFTER trigger in an SQL Server . This type of BL runs in the CDP and hence can be run on any tier that the CDP is deployed on. Thus when it runs on a client tier it can be by passed by other applications e.g. it does not run within the trust boundary .

Moreover the business logic hosting can invoke static instance methods. The classes auto generated for CDM types are partial classes. A type designer can complete these partial classes by adding additional methods on them typically to implement logic that makes sense to a particular type or a set of types. Consider the following examples person. GetOnlineStatus where person is an instance of the Person type emailAddr.Is ValidAddress where emailAddr is an instance of SMTPEmailAddress type etc. By its very nature this kind of BL is not enforceable for instance it is up to the application to call IsValidAddress to ensure validity. It is run on any tier that the CDP is deployed on. Thus it does not run within the trust boundary when CDP is on the client tier.

Bindable behaviors are a coding pattern that allows type designers to create plug in points for third party extensions. The classic example is the type for an e mail message. Different e mail programs may be running on a given machine. Each program wants to use the common Message type but each program also needs to customize the behavior of the SendMessage method. The type designer accomplishes this by defining a basic behavior for the SendMessage method and allowing third parties to supply a pointer to the implementation. Bindable behaviors also run on any tier that CDP is deployed on. Thus it does not run within the trust boundary when CDP is on the client tier.

Static service methods are BL written and deployed on the mid tier and remoted to the client tier. In other words BL runs as a web service on the mid tier. For example consider a Calendar Management Service which provides services such as CreateAppointment GetFreeBusy etc. These services static service methods are implemented using CDP and the web service is deployed on the mid tier. The client tier has a web service proxy which is used by the application to invoke these services using a channel discussed infra . This kind of BL can run on the mid tier and be within the trust boundary.

It is to be appreciated that the componentized architecture makes it possible for CDP to remain store agnostic to a certain extent. CDP features such as object cache cursors sessions transactions etc. utilize CDP level abstractions. Mapping to the underlying storage abstractions takes place in the O R mapping and persistence layer. By rewriting the mapping logic CDP can be implemented on different stores.

This example adds an item to a persistent ShoppingCart. Imagine that this method is invoked as part of processing an ASP.NET web page for example.

Line 3 Creating the storage context. The StorageContext is encapsulated by an OrderData object which is created by the application . The OrderData class can represent a table set type that is described in a CDM schema. The OrderData object creates a StorageContext object configured as necessary to interact with the store . The StorageContext s initialization code can be part of the runtime session and transactions component which opens a connection to the store and does the work necessary to initiate a session and create a transaction context. A security context is established in the constraints security component . Finally an instance of the StorageContext is returned by the API to the application . In the 2 tier case getting StorageContext results in a connection to the store . It is to be appreciated that a connection in a 3 tier deployment can be slightly different.

Line 5 Query. The right side of the expression in line 5 is an OPath query. The Persistence and Query Engine exposes a rudimentary interface with methods to retrieve objects based on a CDM query. The CDM Implementation in the CDM calls a method with the specified OPath. The persistence and query engine maps the query into SQL and sends it across the wire as a TDS payload. The constraint security component ensures that security is applied properly and that the application user sees only the data that they are allowed to see. The store executes the query and returns the results back to the CDP runtime . The CDM and persistent query engine work together to hydrate objects from the TDS results and these objects are placed in the object cache e.g. the session cache . The result is that the API returns a ShoppingCart object to the application .

Line 9 Query. Neither this query nor the previous one has resulted in any cursors being created the GetFirst method essentially applies to a top 1 clause to the query . However if the query required a cursor to be created then the cursors rules component performs this operation.

Line 13 Flush Changes. The implementation of SaveChanges on the OrderData object calls SaveChanges on the encapsulated StorageContext object. StorageContext.SaveChanges is part of the business logic hosting component . This involves the following steps. First pre save logic is run. Then the validation code is run followed by post save processes. The validation code is hooked into an event defined by the CDP API . Note that in another implementation the validation code can be hooked to the setter for the object. Next pre save code is run. This code is hooked into an event defined by the CDP API . Write changes to the store. First the hosting component works with the object cache to get a change vector which contains all changes made within this storage context. The persistence engine exposes an interface called IPersist which is a rudimentary interface with methods such as Write etc. The hosting component gets an IPersist from the persistence engine and calls IPersist.Write with the change vector. The persistence engine maps the write request into the appropriate SQL update either the actual UPDATE statement or a stored procedure call and uses this to write the changes to the store . During this process the constraints security component ensures that appropriate security enforcement is done. It also runs any constraint logic. Finally post save code is run. This code is hooked into an event defined by the CDP API .

Note that running of business logic may result in changes to the objects in the cache . These changes are persisted in the store by a call to myStorageContext.SaveChanges which ensures that the business logic is not bypassed. Multiple ISVs Independent Support Vendors may want to run logic on data changes in which case they hook their handlers to the event and the handlers called in FIFO First In First Out order by the CLR. In this example the business logic hosts ISV validation pre save and post save logic.

The universe of all applications written against the CDP can be divided into the following three classes 

Vertical Platforms and Regular Applications are just code they can use CDP any way they want without passion or prejudice. Frameworks are a little different since they add value to CDP without hiding it from the application they can adhere to the following rules 

It is to be appreciated and understood that all of the above rules are intended to ensure that the data saved into CDP by a given framework can be accessible to all applications regardless of whether an application is using this framework or not.

The CDM provides a flexible modeling environment which can be used to describe types required by a diverse set of applications and scenarios. For example user data e.g. documents files photos music . . . LOB data e.g. Customers Orders Order Details . . . PIM data e.g. contacts email calendar tasks . . . can all be modeled utilizing the CDM. This kind of rich modeling which spans structured semi structured and unstructured data and also spans vertical domains makes it possible for a single application to work with different kinds of data using common abstractions and query language. In other words CDP can be used as one store.

The CDP can be utilized as a single data platform that is leveraged by all applications. Moreover the data stored using CDP can be available to all applications to operate on e.g. subject to security policies . Consider the following each application stores data in a format that is opaque to other applications except the application itself e.g. the one that stored the data . To give just two examples the contents of an email mailbox is opaque to all other applications except the email application a CRM application has an elaborate set of schemas which it overlays on top of tables to create abstractions such as Customer Case and so on thus making the notion of a Customer opaque to all other applications e.g. unless the applications know the schema used by the CRM application .

Clearly there is data in the email application which is conceptually similar to the data stored by a CRM application an example is Contact information. As far as the user is concerned a Contact is a Contact is a Contact from this perspective it is difficult to understand why the same Contact information is stored twice once in the CRM and once in the email mailbox. The issues here is not just redundant storage but all the anomalies that this implies making updates happen in both places reconciling deletes and ensuring inserts in both places and so on. Consider what happens when both the email application and CRM application are built on the CDP store . Using the CDM the Contact type can be derived from the Entity type and its structure becomes transparent to both the email application and the CRM application. Thus as long as the two applications agree on the schema for a type disparate applications can use each others data without being aware of each others existence. Because CDP offers a common query model the CRM application for example can query for Contact data regardless of whether a particular instance of Contact belongs to it or not.

The combination of rich modeling data transparency and the platform framework architecture enables many sharing interop scenarios involving combinations of multiple applications and frameworks. It is to be appreciated that the term sharing can refer to an application that can utilize the data as long as it is stored in the CDP regardless of which application stored it and or which framework was utilized to store it.

In particular illustrates a common UAF scenario where multiple applications share data which in this case is a set of UAF types derived from Item . The CDP and store can include a set of UAF types related to a UAF framework . The set of UAF types can derive from an Item wherein the set can include an email a document and a contact . It is to be further appreciated that the Item can be derived from an entity . A plurality of applications can be utilized in conjunction with the CDP and the UAF framework such as but not limited to an email application a rich evite client and a project M . It is to be appreciated and understood that no restriction is place about the tier in which the application CDP UAF reside in. For instance one of the applications in can be executed and or run in the middle tier e.g. a collab application .

Specifically there are various manners in which the pluralities of applications interact with data. The contact management application can utilize CQL to query for a contact it can utilize UAF methods such as item level move copy contact.GetBestEAddress etc. The contact management application can further utilize core CDP runtime classes such as but not limited to StorageContext StorageSearcher and CDP data classes e.g. the contact class and associated getters and setters .

The collab application can utilize CQL to query for Contacts any documents in the doc lib and perhaps even an order . The collab application need not know the existence of the UAF and or the BF to do such queries it can be done purely at the CDP level without utilizing any special code written by the other frameworks. It utilizes operations specific to collab framework to manipulate the doc lib such as AddDocumentToDocLib etc. The collab application can further utilize the CDP level classes such as StorageContext StorageSearcher Contact Order DocLibrary and associated setters and getters.

The CRM application utilizes CQL to query for all orders by a given contact. It is to be appreciated that the CRM application can do this query without any knowledge that the contact was actually created utilizing UAF . It manipulates Orders utilizing methods and services provided by the BF e.g. FindShipStatus . It can further utilize CDP level classes such as StorageContext StorageSearcher Contact Order and associated setters and getters.

When sharing with non CDP stores it is important to note that the CDP does not employ a provider model whereby arbitrary data sources can appear as CDP stores. When a CDP Framework application wants to work with data in a non CDP store it can employ two options 1 use the Sync Adapter architecture which is part of UAF to sync this data into the CDP store and 2 build custom logic to integrate with the non CDP store.

In particular a CDP API and a CDP runtime can both be in the application process associated with an application . Thus the CDP components e.g. the CDP runtime the API and a constraints security can exist in various tiers. For instance the API the CDP runtime and the application can exist in a client tier wherein the components therein can exist in their own process machine boundary. Additionally a store and the constraints security can exist in a server tier wherein the components therein can exist in their own respective process machine boundary. It is to be appreciated that the constraints security can be hosted in the store process while the rest of the CDP components can be in the client process. This is a prime example of how the CDP components can be considered to be mobile.

An application can interact with an API and a CDP runtime wherein various applications can exist with each respective component such that each application API and CDP runtime can have its own machine process boundary illustrated as boundary boundary and boundary . For the sake of brevity three applications e.g. application application and application are illustrated yet it is understood that any number of applications can be employed. The applications can access a shared data within a stare within its own process machine boundary . It is to be appreciated that the constraints security is enforced during such sharing of data between disparate applications.

This is configuration is very important in many user scenarios for example this is the cornerstone in the database based file storage vision of schematized user data which can be leveraged by ISVs to build intelligent data aware applications. Project M can rely on this to accomplish its vision of being a universal canvas for all user data. This is the primary configuration supported by the CDP.

In a 2 tier deployment the CDP has limited support for this configuration. There is no reasonable support for application level security in the SQL Server store consequently a piece of data may not be marked as private to a given application in the strict sense of preventing data access. However this situation can be partially supported in the following ways 

It is to be appreciated that applications can choose some or all of the above methods to have private data.

It can be noted that the CDP architecture by itself may not create an impediment towards implementing a true notion of private data. It is thus conceivable that when application level security becomes available in the underlying platform CDP can easily expose it. Note also that in many cases the private data requirement arises not because of a genuine need to limit visibility but because of the need to enforce application specific business logic on the data. For instance local mailboxes created by an email application have a Calendar folder the rule is that only Calendar items can be placed in this folder. The email application may not care whether another application such as a disparate brand email application can see modify its mailbox or not as long as this rule is enforced. The CDP architecture provides enforcement of all business logic as long as all applications come through the CDP layer. It is to be appreciated that private application data is supported in 3 tier deployments because the middle tier can enforce this.

Continuing with there is illustrated a machine process boundary with an application that interacts with an API and a CDP runtime and a machine process boundary with an application that interacts with an API and a CDP runtime. For the sake of brevity only two applications are illustrated but it is to be appreciated that any number of applications can access shared data and or access respective private data e.g. application private data and application private data within a store within its own machine process boundary .

In this particular deployment it is the responsibility of the application designers and or deployment administrators to make sure that application has its own logic to enforce constraints etc. so that the right thing happens.

Before moving to consideration of the scenarios it is to be appreciated that the topic of multi tier deployment is closely related to the ways in which application actions are remoted across tiers. The term remoting can encompass the following three general approaches to remoting application level or CDP service level operations across tiers 

In particular and illustrate the application logic running on the middle tier e.g. a Web service . The primary scenario for mid tier deployment is the case where application logic runs exclusively in the middle tier the client invokes this logic through a web service mechanism e.g. the web service proxy and web service . It is to be appreciated that the security engine on the server tier can be hosted in the middle tier CDP process. In a 2 tier deployment the CDP calls are processed by the CDP runtime within the client process the runtime contacts the server when necessary. In a 3 tier deployment some CDP calls are processed locally via client tier and some are processed remotely via middle tier . Moreover still others can be processed in both places. A 3 tier deployment defines a methodology for remoting the appropriate calls.

A remoting agent on the client tier that is a component that can use an channel e.g. Indigo to package and send requests to the CDP on the middle tier this is the actual act of a remote procedure call . On the mid tier sits a remoting service seen in which appropriately enough services these requests. This pattern is part of what is commonly known as the Service Oriented Architecture SOA . A characteristic of SOA is that the different tiers communicate with each other by exchanging messages. CDP can utilize the Indigo infrastructure for this purpose

The remoting service provides a set of data oriented services such as execute a query insert delete update create save get an Object given the key get the root key. In keeping with the SOA paradigm these operations can be verbs within a SOAP message. Any action that the client tier wants to have executed on the mid tier is expressed in terms of these simple verbs. These basic messaging verbs are abstracted into methods on 2 interfaces using facilities provided by Indigo in fact these are the IPersist and IQuery interfaces that were discussed supra. Thus the remoting agent and remoting service together act as end points on an Indigo channel to remote the methods of IPersist and IQuery interfaces. It is to be appreciated and understood that the methods in IQuery and IPersist are coarse grained in the following sense they can be used to query for or operate on a large set of objects. For example in response to the SaveChanges method the remoting agent issues IPersist.Write once to the remoting service with the entire set of dirtied objects. Thus interfaces between the client and middle tier are bulk oriented and not chatty.

The following pseudo code example can be depicted to examine data control flow across the various modules shown in and in response to method calls. It is to be appreciated and understood that the following is an example and the subject architecture is not so limited.

In this example the application queries the shared calendar for Anil Nori on the corporate intranet to get his calendar entry for Oct. 29 xxxx at 9 AM. This is represented by the ScheduleEntry object which is a type derived from Entity e.g. ScheduleEntry is part of the PIM Schema and represents an item in the user s schedule . It modifies the ScheduleEntry appends the text important please come to the title of the appointment. It then invokes the CreateAppointment method on a web service called ScheduleService to put this modified ScheduleEntry into Pedro Celis shared calendar. This code fragment illustrates several key points in a 3 tier deployment 

The entire application logic including business logic validation etc. are run on the middle tier by the web service and by CDP s BL hosting engine. This processing is triggered by a call to the CreateAppointment method. The following is a detailed examination of the data flow between across various modules.

Line 1 Creating a Storage Context. A StorageContext object e.g. API on Client Tier is encapsulated by a Data object which is created by the application and or client . The Data class represents a table set type that was described in a CDM schema. The Data object creates a StorageContext object configured as necessary to interact with the store . The StorageContext s initialization code is part of a CDP runtime on the client tier.

Line 2 Query. The RHS of the expression in Line 2 is an OPath query. This query returns with at most one ScheduleEntry object the first entry e.g. Assume that there exists a precise definition of first entry at Oct. 29 2004 9AM. The CDP runtime on the client tier gets the IQuery interface on the remoting agent and calls ExecuteQuery on it. The remoting agent can utilize an Indigo channel and sends this query to the remoting service on the middle tier. The query is mapped and executed just as in the two tier case and the results are returned to the client tier. There are two possibilities here 

Line 3 Manipulating Client Tier Object Cache. Once the ScheduleEntry object is returned to the client tier it is available for further manipulation within the session cache of the CDP runtime on the Client Tier. When the client changes the DisplayName property of ScheduleEntry object this is processed entirely by the CDP runtime on the Client Tier.

Line 4 New ing a web service proxy on the Client Tier. Presumably the client has already added a reference to the appropriate asmx or the Indigo equivalent during design time. Line 4 can create an instance of the web service proxy object on the client. This call is serviced entirely by the Web Service Proxy .

Line 5 Calling the Web Service Method. The CreateAppointment is one of the methods remoted by the web service on the mid tier. This method takes a ScheduleEntry object and a CDP connection string it uses this information to create a ScheduleEntry object within a StorageContext defined by the connection string. Inherent within this write operation is the running of appropriate business logic and validation logic. This method is packaged by the web service proxy and sent via a SOAP message thru the Indigo channel to the web service on the mid tier. The web service implements this method via calls to a CDP API on the middle tier just as if it were any other application. The key thing to note here is that the entire logic for CreateAppointment is run on the mid tier.

As can be seen in the previous examples Line 3 creates the storage context Line 5 and Line 9 relate to the query and Line 12 relates to the update.

An advantage of running BL on both tiers is that in case of errors in validation of pre save logic they can be trapped on the client tier without having to go through the expense of connecting to the mid tier.

A seamless offline experience is one of the goals of the database based file storage system. This can requires a local store which synchronizes data with the remote store. The local store can further include constraints security . In this case the local store is on the substantially similar machine but in a different process which in our definition is still a 2 tier deployment . Since the programming model for 3 tier and 2 tier deployments are symmetrical it is easy for a service such synchronization to operate between the local store and the middle tier and keep the data in sync.

Consider Line 2 of the code example shown above. The query resulted in a tier crossing operation. In this particular example there was one object returned the ScheduleEntry object . In general however this can potentially return a very large result set. Similar comments apply to Line 5 of the previously presented code example. There are two issues that can be considered and which are pertinent in a 3 tier deployment 

The solution is to provide an explicit disconnected model. This is characterized by the following pattern 

Notice how the application can be explicit in when it wants a tier crossing operation to occur the lc.Fill in step 3 so that there is no magic triggered by innocent code. Notice also that all subsequent operations can occur on the local cache and hence tier crossing is minimized along with the concomitant maintenance of state on the mid tier . It is to be appreciated that the model implied by code fragments above are quite similar to the dataset model in ADO.NET. CDP can also provide a disconnected model.

A 2 tier application should not be deployed in a 3 tier environment unless one of the following is true a it uses only the disconnected programming model or b it is re written to use the disconnected programming model.

CDP takes the approach of allowing both connected and disconnected programming models in 3 tier deployments. Applications will be given a guideline that if they expect to be deployed in a 3 tier environment then they should use the disconnected cache. 

To establish context for the following section that discusses CDP stores it is noted that the universe of all SQL Server data is partitioned in the following 4 level hierarchy instance database schema and table. The connectable unit is an instance a database is a container over which backup restore and replication are defined. The combination of a database and a schema provide the context for queries. The CDP uses a 3 level hierarchy store schema and type. A CDP store is the connectable unit a schema provides context for queries. A given schema can be hosted by multiple CDP stores e.g. a set of types CRM schema can be deployed on two different instances of CDP. If sameness is desired then mechanisms outside of the CDP replication bulk copy should be used. A given CDP store can have multiple schemas deployed on it such as an HR schema Accounting schema etc.

The following addresses naming of a CDP store and discovery of available stores. A CDP store is defined more clearly. There are two possibilities 

In the CDP model a storage context identifies a logical store not a physical store. CDP does not specify how the replication backup restore mechanisms work at the level of the physical store.

With respect to a format of a ctor argument the connection string is a Uniform Resource Identifier or URI. Individual frameworks can define an alternative naming format for use by their applications. For example the UAF might choose to let its applications establish a storage context by specifying an UNC name e.g. server share . However it should always be possible to connect to a CDP store by a URI in other words any alternative names used by a framework must have a well defined mapping to the corresponding CDP level URI.

CDP does not specify how stores can be discovered. It is expected that applications can use existing mechanisms and repositories UDDI for example for this purposes. In addition a framework may specify its own methods for discovery.

In this section the additional CDP services that applications can leverage are described. These services include 

Watcher Notification Service. Notifications aka Watchers provide the ability to raise asynchronous notifications of changes to entities data persisted in the underlying store. An application or any other component can use this service to watch for changes in persisted entities. An application will have complete control of what they watch and how often they want to be notified. For example the Rich Application Views RAV Notifications are built using watchers a client side browsing application can use RAVs to actively react to data changes using these notifications.

The CDP programming model supports a Watcher class that is capable of watching changes in entities. The entity watcher mechanism is sufficient for frameworks and applications to build higher level watcher abstractions. For example a database based file storage system can build Item Item Extension and Link watcher abstractions on the entity watcher abstraction e.g. Note that an entity is the most granular piece of data that can be watched .

Synchronization Services. Applications written to the CDP as well as frameworks on top of it will benefit from the following synchronization related services 

Explicit Cache Services. The explicit cache service in the CDP provides improved performance scalability of applications support for disconnected programming model e.g. Note that a disconnected programming model can be implemented without the benefit of a full featured explicit cache and support for transient data. The following can be featured in the explicit cache 

Utility Operations. CDP provide support for variety of administrative and utility operations on entities and collections of entities. A sampling of such operations includes Copy Move Serialize De serialize and Backup Restore.

Turning now to the modeling of items utilizing entities is illustrated. The database based file storage system e.g. WINFS implementation encompasses aspects of both CDP and the User Application Framework UAF . It is noted that the CDP architecture does not mean a re write of the database based file storage system but merely a re segmentation of the components therein.

In this section the UAF is defined and then examined as to how the various components of the database based file storage system can be segmented into UAF and CDP.

The UAF is a CDP framework which is concerned with modeling user data. User data refers to the common everyday data that is pertinent to a typical end user such as document photo music contact etc.

It is to be appreciated and understood that for application developers CDP is the UAF programming model.

Specifically depicts the notion of an item in UAF and how it is actually derived from several entities. A document item can be derived from several entities such as but not limited to a doc a plurality of links and a doc extension . An author item can be derived from several entities such as but not limited to an author and an author extension .

Turning to extensible mechanisms are illustrated to implement various functionalities by implementing the UAF on top of the CDP. Since the UAF is built on top of CDP it can utilize CDP extensibility mechanisms to implement additional functionality. The building of the UAF onto the CDP can include various layers and or components. A store can include a CDP constraint engine wherein the CDP constraint engine includes at least one UAF constraint . A CDP runtime can include a BL host which can include a UAF item behavior . The UAF item behavior can further include a UAF bindable behavior . On top of the CDP runtime any other UAF services can exist.

UAF uses CDP s constraint engine to enforce Item semantics and other type semantics . These are authored using CSDL and the schema generator creates store level constraints for them. Item behaviors such as Move Serialize etc. are implemented using CDP s BL mechanisms. UAF types can have bindable behaviors associated with them. These behaviors are authored by an UAF application developer after the types have been designed and deployed. Other UAF services such as sync metadata handling etc. are implemented as regular CDP code. Taken together these separate pieces of logic running in various layers of the CDP form the UAF.

The below description is applicable to partitioning database based file storage system between CDP and UAF. The following capabilities in the database based file storage system belong in the CDP layer 

The Business Framework BF can consist of the Business Solutions Framework and the Business Application Framework. The Business Solutions Framework provides functionality useful to build most business applications. This includes fundamental business data types such as Money and Quantity application family wide business entities such as customer business unit multi currency information and payment terms the building blocks for implementing common business patterns such as Business Transaction and Account and common business processes patterns such as for posting a business transaction.

The Solutions Framework is written using the Business Application Framework which supports writing components by offering rich services for data access security user interface workflow component programming model and much more. If the business model and rules defined by the Solutions Framework are not appropriate for an application then it can be bypassed and the developer of the application can directly use the Application Framework.

The Business Application Framework provides a prescriptive programming model that takes the NET Framework and focuses its capabilities toward business applications. While quite extensible it makes a number of decisions for the application developer that a more general solution would not increasing productivity and consistency in implementation and structure for all applications in the ecosystem that use it. The Business Application Framework provides a programming model and services for writing web based distributed OLTP applications. It may contain no business logic particular to any product and thus is suitable not only for authoring business applications but also any other application fitting its basic profile. It provides a set of services that provide support for data access messaging such as the use of SOAP and other protocols workflow event brokering instance activation diagnostics configuration metadata management reflection application component security globalization a business desk shell and more. The requirements on CDP primarily come from the Business Application Framework portion of BF particularly in the areas of data access and remoting of data logic.

Entity Persistence EP the data access subsystem in the Business Framework supports a rich data model based on a pragmatic object relational mapping framework. It is object relational in that the developer deals with C objects that are mapped to relational rows. The core data modeling concepts are entities and relationships between entities. The Common Data Model CDM essentially supports the data modeling requirements of BF data access. MBF EP requires support for the following data access actions 

BF prescribes an agent service framework for supporting distributed service oriented configurations. Given some piece of business functionality the agent runs as near to the user of the functionality as possible and the service runs as near to the data as possible. As close as possible differs with each deployment scenario and kind of user. The agent service pattern provides deployment flexibility from 2 tier client server to multi tier deployment. In such deployments services provide interfaces that can be invoked across service boundaries agents typically fetch data close to the client user operate it on it and propagate changes to the service.

In particular illustrates how a LOB framework and or application can utilize the CDP. The framework and application built utilizing the framework can be hosted in an ultra application server on the middle tier. It can provide standard LOB services such as but not limited to work flow messaging business processes etc. in the form of a web services interface to a client application . The ultra application server can utilize the CDP to author store constraints via a CDP constraint engine and data centric business logic . The client application can invoke the web services method e.g. utilizing a web service proxy and a web service interface over an Indigo channel. Additionally it can make use of the CDP on the client tier for its object persistence data access needs.

The following can be satisfied by the CDP 1 Session Management 2 CRUD 3 Common Data Model CDM Support e.g. Entity Abstraction Entity Extension 4 Query e.g. Ad Hoc Entity 5 Running Object Cache implicit 6 Concurrency Management e.g. Optimistic isolation levels conflict detection etc. 7 Business Logic e.g. In method Validation Defaulting Property Patterns Events 8 Security Extension 9 Mapping query schema with Providers e.g. Relational database based file storage system 10 Capability to extend metadata supports other uses of entity 11 Set Operations 12 Capability to call stored procedures and 13 N Tier deployments.

BF entity persistence is a natural fit for the CDP. Most of the BF s persistence requirements are fully supported by the CDP. Some of the SOA requirements are also addressed by CDP. However full support for agent service model BF business operations and processes can be built above the CDP as LOB framework. The Business Solutions Framework of MBF is also layered on top of CDP.

At reference numeral an interface is exposed to retrieve objects based on a CDM query. At reference numeral the query is mapped into SQL while applying the security properly. Furthermore the application user can see only data that is allowed to be seen. At reference numeral the results from the query are returned to the CDP runtime and returned to the application. At reference numeral the save changes function can be called on the encapsulated storage context object in order to flush changes.

Referring now to there is illustrated a block diagram of a computer operable to execute the disclosed architecture of the CDP and associated components and or processes. In order to provide additional context for various aspects of the subject architecture and the following discussion are intended to provide a brief general description of a suitable computing environment in which the various aspects of the innovation can be implemented. While the architecture has been described above in the general context of computer executable instructions that may run on one or more computers those skilled in the art will recognize that the architecture also can be implemented in combination with other program modules and or as a combination of hardware and software.

Generally program modules include routines programs components data structures etc. that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the inventive methods can be practiced with other computer system configurations including single processor or multiprocessor computer systems minicomputers mainframe computers as well as personal computers hand held computing devices microprocessor based or programmable consumer electronics and the like each of which can be operatively coupled to one or more associated devices.

The illustrated aspects may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules can be located in both local and remote memory storage devices.

A computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computer and includes both volatile and non volatile media removable and non removable media. By way of example and not limitation computer readable media can comprise computer storage media and communication media. Computer storage media includes both volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital video disk DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer.

Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

With reference again to the exemplary environment for implementing various aspects includes a computer the computer including a processing unit a system memory and a system bus . The system bus couples system components including but not limited to the system memory to the processing unit . The processing unit can be any of various commercially available processors. Dual microprocessors and other multi processor architectures may also be employed as the processing unit .

The system bus can be any of several types of bus structure that may further interconnect to a memory bus with or without a memory controller a peripheral bus and a local bus using any of a variety of commercially available bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS is stored in a non volatile memory such as ROM EPROM EEPROM which BIOS contains the basic routines that help to transfer information between elements within the computer such as during start up. The RAM can also include a high speed RAM such as static RAM for caching data.

The computer further includes an internal hard disk drive HDD e.g. EIDE SATA which internal hard disk drive may also be configured for external use in a suitable chassis not shown a magnetic floppy disk drive FDD e.g. to read from or write to a removable diskette and an optical disk drive e.g. reading a CD ROM disk or to read from or write to other high capacity optical media such as the DVD . The hard disk drive magnetic disk drive and optical disk drive can be connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The interface for external drive implementations includes at least one or both of Universal Serial Bus USB and IEEE 1394 interface technologies. Other external drive connection technologies are within contemplation.

The drives and their associated computer readable media provide non volatile storage of data data structures computer executable instructions and so forth. For the computer the drives and media accommodate the storage of any data in a suitable digital format. Although the description of computer readable media above refers to a HDD a removable magnetic diskette and a removable optical media such as a CD or DVD it should be appreciated by those skilled in the art that other types of media which are readable by a computer such as zip drives magnetic cassettes flash memory cards cartridges and the like may also be used in the exemplary operating environment and further that any such media may contain computer executable instructions for performing the methods of the architecture.

A number of program modules can be stored in the drives and RAM including an operating system one or more application programs other program modules and program data . All or portions of the operating system applications modules and or data can also be cached in the RAM . It is appreciated that various commercially available operating systems or combinations of operating systems can be implemented with the subject architecture.

A user can enter commands and information into the computer through one or more wired wireless input devices e.g. a keyboard and a pointing device such as a mouse . Other input devices not shown may include a microphone an IR remote control a joystick a game pad a stylus pen touch screen or the like. These and other input devices are often connected to the processing unit through an input device interface that is coupled to the system bus but can be connected by other interfaces such as a parallel port an IEEE 1394 serial port a game port a USB port an IR interface etc.

A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor a computer typically includes other peripheral output devices not shown such as speakers printers etc.

The computer may operate in a networked environment using logical connections via wired and or wireless communications to one or more remote computers such as a remote computer s . The remote computer s can be a workstation a server computer a router a personal computer portable computer microprocessor based entertainment appliance a peer device or other common network node and typically includes many or all of the elements described relative to the computer although for purposes of brevity only a memory storage device is illustrated. The logical connections depicted include wired wireless connectivity to a local area network LAN and or larger networks e.g. a wide area network WAN . Such LAN and WAN networking environments are commonplace in offices and companies and facilitate enterprise wide computer networks such as intranets all of which may connect to a global communications network e.g. the Internet.

When used in a LAN networking environment the computer is connected to the local network through a wired and or wireless communication network interface or adapter . The adaptor may facilitate wired or wireless communication to the LAN which may also include a wireless access point disposed thereon for communicating with the wireless adaptor .

When used in a WAN networking environment the computer can include a modem or is connected to a communications server on the WAN or has other means for establishing communications over the WAN such as by way of the Internet. The modem which can be internal or external and a wired or wireless device is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof can be stored in the remote memory storage device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers can be used.

The computer is operable to communicate with any wireless devices or entities operatively disposed in wireless communication e.g. a printer scanner desktop and or portable computer portable data assistant communications satellite any piece of equipment or location associated with a wirelessly detectable tag e.g. a kiosk news stand restroom and telephone. This includes at least Wi Fi and Bluetooth wireless technologies. Thus the communication can be a predefined structure as with a conventional network or simply an ad hoc communication between at least two devices.

Wi Fi or Wireless Fidelity allows connection to the Internet from a couch at home a bed in a hotel room or a conference room at work without wires. Wi Fi is a wireless technology similar to that used in a cell phone that enables such devices e.g. computers to send and receive data indoors and out anywhere within the range of a base station. Wi Fi networks use radio technologies called IEEE 802.11 a b g etc. to provide secure reliable fast wireless connectivity. A Wi Fi network can be used to connect computers to each other to the Internet and to wired networks which use IEEE 802.3 or Ethernet . Wi Fi networks operate in the unlicensed 2.4 and 5 GHz radio bands at an 11 Mbps 802.11a or 54 Mbps 802.11b data rate for example or with products that contain both bands dual band so the networks can provide real world performance similar to the basic 10BaseT wired Ethernet networks used in many offices.

Referring now to there is illustrated a schematic block diagram of an exemplary computing environment that can be utilized by the CDP and respective components and or processes to provide data management. The system includes one or more client s . The client s can be hardware and or software e.g. threads processes computing devices . The client s can house cookie s and or associated contextual information by employing the architecture for example.

The system also includes one or more server s . The server s can also be hardware and or software e.g. threads processes computing devices . The servers can house threads to perform transformations by employing the architecture for example. One possible communication between a client and a server can be in the form of a data packet adapted to be transmitted between two or more computer processes. The data packet may include a cookie and or associated contextual information for example. The system includes a communication framework e.g. a global communication network such as the Internet that can be employed to facilitate communications between the client s and the server s .

Communications can be facilitated via a wired including optical fiber and or wireless technology. The client s are operatively connected to one or more client data store s that can be employed to store information local to the client s e.g. cookie s and or associated contextual information . Similarly the server s are operatively connected to one or more server data store s that can be employed to store information local to the servers .

What has been described above includes examples. It is of course not possible to describe every conceivable combination of components or methodologies for purposes of describing the subject architecture but one of ordinary skill in the art may recognize that many further combinations and permutations of the architecture are possible. Accordingly the architecture is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims. Furthermore to the extent that the term includes is used in either the detailed description or the claims such term is intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

