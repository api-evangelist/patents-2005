---

title: Calibration based beamforming, non-linear adaptive filtering, and multi-sensor headset
abstract: A first set of signals from an array of one or more microphones, and a second signal from a reference microphone are used to calibrate a set of filter parameters such that the filter parameters minimize a difference between the second signal and a beamformer output signal that is based on the first set of signals. Once calibrated, the filter parameters are used to form a beamformer output signal that is filtered using a non-linear adaptive filter that is adapted based on portions of a signal that do not contain speech, as determined by a speech detection sensor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07813923&OS=07813923&RS=07813923
owner: Microsoft Corporation
number: 07813923
owner_city: Redmond
owner_country: US
publication_date: 20051014
---
The need for hands free communication has led to an increased popularity in the use of headsets with mobile phones and other speech interface devices. Concerns for comfort portability and cachet have led to the desire for headsets with a small form factor. Inherent to this size constraint is the requirement that the microphone be placed farther from the user s mouth generally increasing its susceptibility to environmental noise. This has meant a tradeoff between audio performance and useability features such as comfort portability and cachet.

A first set of signals from an array of one or more microphones and a second signal from a reference microphone are used to calibrate a set of filter parameters such that the filter parameters minimize a difference between the second signal and a beamformer output signal that is based on the first set of signals. Once calibrated the filter parameters are used to form a beamformer output signal that is filtered using a non linear adaptive filter that is adapted based on portions of a signal that do not contain speech as determined by a speech detection sensor.

A variety of other variations and embodiments besides those illustrative examples specifically discussed herein are also contemplated within the scope of the claims for the present invention and will be apparent to those skilled in the art from the entirety of the present disclosure.

A variety of methods and apparatus are encompassed within different embodiments an illustrative sampling of which are described herein. For example illustrates an example of a suitable computing system environment on which embodiments may be implemented. The computing system environment is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment .

Embodiments are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with various embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers telephony systems distributed computing environments that include any of the above systems or devices and the like.

Embodiments may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Some embodiments are designed to be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules are located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing some embodiments includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard a microphone and a pointing device such as a mouse trackball or touch pad. Other input devices not shown may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer is operated in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a hand held device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Memory includes an operating system application programs as well as an object store . During operation operating system is preferably executed by processor from memory . Operating system in one preferred embodiment is a WINDOWS CE brand operating system commercially system is preferably designed for mobile devices and implements database features that can be utilized by applications through a set of exposed application programming interfaces and methods. The objects in object store are maintained by applications and operating system at least partially in response to calls to the exposed application programming interfaces and methods.

Communication interface represents numerous devices and technologies that allow mobile device to send and receive information. The devices include wired and wireless modems satellite receivers and broadcast tuners to name a few. Mobile device can also be directly connected to a computer to exchange data therewith. In such cases communication interface can be an infrared transceiver or a serial or parallel communication connection all of which are capable of transmitting streaming information.

Input output components include a variety of input devices such as a touch sensitive screen buttons rollers and a microphone as well as a variety of output devices including an audio generator a vibrating device and a display. The devices listed above are by way of example and need not all be present on mobile device . In addition other input output devices may be attached to or found with mobile device .

The first two air microphones are preferred direction microphones and are noise canceling. The third microphone is omnidirectional that is it is not a preferred direction microphone. Microphones and are configured to receive primarily the user s speech while microphone is configured to receive ambient noise in addition to the user s speech. The omnidirectional third microphone is thereby used both as part of the microphone array and for capturing ambient noise for downstream adaptive filtering. This difference in function does not necessarily imply difference in structure it is contemplated that all three microphones are physically identical within normal tolerances in one illustrative embodiment although their placement and orientation suit them particularly for their functions. Microphones and face toward the direction expected for the user s mouth while microphone faces in a direction expected to be directly away from the user s ear thus making it more likely for microphone to sample ambient noise in addition to the user s speech. Microphone may be described as omnidirectional not because it receives sounds from every direction necessarily but in the sense that it faces the user s ambient environment rather than being particularly aimed in a preferred direction toward a user s mouth.

Although each of microphones and would each detect and include in their transmitted signals some finite inclusion of both speech and noise the signal associated with the omnidirectional microphone is designated separately as a speech plus noise signal since it is expected to feature a substantially greater noise to speech ratio than the signals received by the preferred direction microphones and .

Although this embodiment is depicted with one omnidirectional microphone and two preferred direction microphones in the microphone array this is illustrative only and many other arrangements may occur in various embodiments. For example in another embodiment there may be only a single preferred direction microphone and a single omnidirectional microphone while in another example three or more preferred direction microphones may be included in an array while in yet another embodiment two or more omnidirectional microphones may be used for example to face two different ambient noise directions away from the user.

Regarding headset the general direction of boom defines a preferred direction for the directional array of microphones as a whole and particularly for microphones and individually. The headset may be worn with the air microphones and oriented generally toward the user s mouth and the microphone oriented along a generally common line with microphones and in this embodiment. Omnidirectional microphone is situated generally at the ear canal in normal use while the bone sensor rests on the skull behind the ear. The bone conductive sensor is highly insensitive to ambient noise and as such provides robust speech activity detection.

Bone sensor is one example of a speech indicator sensor configured for providing an indicator signal that is configured to indicate when the user is speaking and when the user is not speaking. Bone sensor is configured to contact a user s head just behind the ear where it receives vibrations that pass through the user s skull such as those corresponding to speech. Other types of speech indicator sensors may occur in various embodiments including a bone sensor configured to contact the user s jaw or a throat microphone that measures the user s throat vibrations as additional illustrative examples. A speech indicator may also take the form of a function of signal information such as the audio energy received by the microphones. The energy level of the sensor signal may be compared to a stored threshold level of energy pre selected to match the threshold of energy anticipated for the user s speech. Microphones are conventional air conduction microphones used to convert audio vibrations into electrical signals.

The filter parameters used by beamformer are calibrated using a close talking microphone reference signal in one embodiment. Using a small sample of training recordings in which a user s speech is captured by both the microphone array and a close talking reference microphone a calibration algorithm associated with beamformer operates to set the filters for the microphones of array . Close talking microphone is generally only used for calibration then once system is calibrated reference microphone is no longer needed as suggested by the dashed lines associated with reference microphone .

Array may form part of a headset such as headset of or may be formed as part of a device to be held by the user or to stand apart from the user. As applied to an embodiment similar to headset of array may be suspended on a headset pointing in the general direction of a user s mouth though only extend a fraction of the distance to the mouth while reference microphone may be held closely to and directly in front of the user s mouth to provide the clearest possible reference speech signal.

Step includes dividing Yand R into time increments and frequency subbands as Y k and R k . These steps may include additional details such as in one illustrative embodiment that might include conversion of the signals from analog to digital form dividing the signals into time domain samples performing fast Fourier transforms on these time domain samples and thereby providing a signal in the form of subbands of frequency domain frames.

In one illustrative example analog to digital converters sample the analog signals at 16 kHz and 16 bits per sample thereby creating 32 kilobytes of speech data per second. These digital signals are provided in new frames every 10 milliseconds each of which includes 20 milliseconds worth of data. In this particular embodiment therefore the time domain samples are partitioned in increments of 20 milliseconds each with each frame overlapping the previous frame by half. Alternative embodiments may use increments of 25 milliseconds or a timespan anywhere in a range from substantially less than 20 milliseconds to substantially more than 25 milliseconds. The frequency domain frames may also occur in different forms. With each frame overlapping the previous frame by half the number of subbands is designated here as N 2 where N is the size of a Discrete Fourier Transform DFT .

These or other potential method steps will be recognized by those skilled in the art as advantageously contributing to embodiments similar to method . Some of the details of some of these and other potential method steps are also understood in the art and need not be reviewed in detail here.

At step the time ordered frames and frequency subbands of the array signals Y k and the reference signal R k are used to calibrate a set of filter parameters H k for beamformer . This involves solving a linear system which minimizes a function of the difference between the reference signal R k and the output signal Z k which is a function of the set of signals Y k from the array and the filter parameters H k . This linear system and these functions are explained as follows.

In the illustrative example of the subband filter and sum linear forming architecture the kth subband of short time Fourier transform of the signal produced by microphone m at frame t is represented as Y k and the beamformer output can be expressed as 

Equation 2 is therefore a function of the difference between the reference signal R k and the beamformer output signal Z k . Minimizing this function is therefore a method of minimizing the difference between the output R k from a reference microphone and the beamformer output signal Z k produced by a beamformer applying calibration parameters or filter coefficients H k derived from the present method to signals Y k from a headset microphone array according to one illustrative embodiment. Minimizing the function of Equation 2 may be done by taking the partial derivative of Equation 2 with respect to H k where H k represents the complex conjugate of H k and setting the result to zero this gives

The filter coefficients H k . . . H k can then be found by solving the linear system in Equation 4 as represented in step of method of . In particular a separate equation similar to Equation 4 is formed for each microphone. These separate equations are then solved simultaneously to determine the values for the filter coefficients. This optimization is performed over all subbands k 1 . . . N 2 where N is the Discrete Fourier Transform DFT size.

Method can thereby include minimizing the function of the difference between the reference signal R k and the beamformer output signal Z k including by taking the derivative of the function with respect to the complex conjugate H k of the filter parameters H k setting the derivative equal to zero and solving the resulting linear system as in Equation 4 and as depicted in step .

With the filter parameters H k calibrated beamformer is ready to receive a new set of signals Y k from the array at step . These new signals are then used to generate an output signal Z k as a function of the new set of signals and the stored filter parameters H k as depicted in step of method .

The calibrated beamformer will generally not be able to remove all possible ambient noise from the signal. To reflect this the beamformer output Z may be modeled as Eq. 5 where Gis the spectral tilt induced by the array Vis the ambient noise and His the effective filter formed by the beamforming process.

To further enhance the output signal a non linear adaptive filter may be applied to the output of the calibrated beamformer. This filter relies on noise information from an omnidirectional microphone and exploits the precise speech activity detection provided by a speech indicator sensor such as the particular example of the bone conductive sensor in the illustrative embodiment in . This combined system of calibrated beamforming followed by non linear adaptive filtering is depicted in according to one illustrative embodiment. A method for performing beamforming followed by adaptive filtering is shown in the flow diagram of .

In system of audio signals from speech source such as the user s voice are received by microphones of array . Audio signals corresponding to ambient noise are also received by microphones although microphone is especially oriented to receive ambient noise while microphones and face a preferred direction in which the boom on which they are attached is pointed. Based on these audio signals microphones and generate electrical signals that are provided to a calibrated beamformer at step of . During step a speech activity sensor also provides an electrical signal to a speech activity indicator . In some embodiments speech activity sensor is a type of sensor such as bone conduction sensor of which is not sensitive to ambient noise but does produce a strong signal when the user is speaking. In other embodiments rather than being an external component speech activity sensor is a means for using signal information for evaluating whether the signal corresponds to speech such as if the signal exceeds a level of energy anticipated for the user s speech. In whatever form this allows the signal from speech activity sensor to be used to determine when the user is speaking.

At step beamformer uses the signals from microphones and in equation 1 above to form a first signal having a specified noise characteristic. This first signal is a beamform primary speech signal having a noise characteristic that represents a function of the signals from microphones and for example. At step speech activity indicator uses the signal from speech activity sensor to indicate whether a portion of the first signal does not represent speech or which portions of the primary speech signal contain the user s speech. In one method performed in association with speech activity indicator the energy level of the sensor signal is compared to a stored threshold level of energy pre selected to distinguish between speech and the absence of speech as calibrated to the specific instrument to determine if the user is speaking.

Instead of using a separate speech activity sensor other embodiments detect when the user is speaking using the microphone array . Under one embodiment the overall rate of energy being detected by the array of microphones may be used to determine when the user is speaking. Alternatively the rate of energy being detected by a directional array of microphones from a source coinciding with a preferred direction of the array may be used to determine when the user is speaking. Either of these may be calibrated to provide a fairly effective indication of the occurrence or absence of the user s speech. Additional types of speech activity sensors besides these illustrative examples are also contemplated in various embodiments.

Speech activity indicator provides an indicator signal to non linear adaptive filter to indicate when the user is speaking. Non linear adaptive filter also receives the primary speech signal output from beamformer which is formed using equation 1 above and microphone signal from microphone constituting a second signal having a second noise characteristic at step . Microphone is oriented to serve as an omnidirectional microphone rather than a preferred direction microphone and the second signal is anticipated to have a noise characteristic with a greater component of ambient noise.Filter uses these signals to perform non linear adaptive filtering. This includes estimating a magnitude of a noise transfer function based on portions of the first signal and second signal that do not represent speech as depicted in step . Filter then generates a filtered output signal as a function of the primary speech signal the indicator signal and microphone signal as depicted in step . An example of such a mechanism is presented as follows according to one illustrative embodiment. With Ydefined as the omnidirectional microphone signal this signal can be modeled as Y Eq. 6

The following additional variables may also be defined as follows tilde over X GX Eq. 7 tilde over V HV Eq. 8 tilde over G Eq. 9 tilde over H Eq. 10

In essence tilde over G is the signal transfer function between the beamformer output and the omnidirectional microphone while tilde over H is the corresponding noise transfer function.

tilde over H in equation 11 is a function of time. However if this variation over time is modeled as strictly a function of its phase while its magnitude is relatively constant then tilde over H may be rewritten as Eq. 13

If the speech X and the noise V can be modeled to be uncorrelated equations 11 13 can be combined to obtain Eq. 14 Eq. 15

Because the denominator of Equation 16 is constant over time it acts simply as a gain factor. Therefore tilde over X after accounting for the gain factor can be estimated simply as Eq. 17

 Hz is estimated using non speech frames which are identified based on the signal from speech activity indicator . In these frames Equations 14 and 15 simplify to Z tilde over H tilde over V Eq. 20 Y tilde over V Eq. 21

In other embodiments the primary speech signal is formed using a delay and sum beamformer that delays one or more signals in a microphone array and then sums the signals. Specifically the primary speech signal is formed using a function that incorporates a time delay in superposing signals from the microphones of the microphone array to enhance signals representing sound coming from a source in a preferred direction relative to the array. That is the function may impose a time shift on the signals from each microphone in the array prior to superposing their signals into a combined signal.

For example with reference once more to microphones and were placed about 40 millimeters apart and microphones and were placed about 25 millimeters apart all three along a single line segment in that illustrative embodiment. The speed of sound in the Earth s atomsphere under normal conditions of temperature and pressure is approximately 335 meters per second. Therefore as an audio signal travels through the air from a source in the preferred direction of array such as from the source of the user s voice the audio signal will reach microphone approximately 0.040 m 335 m s 120 microseconds after reaching microphone and reach microphone approximately 0.025 m 335 m s 75 microseconds after reaching microphone and 195 microseconds after reaching microphone . Therefore if the function superposes the signals of all three of these microphones after delaying the signals from microphone by 195 microseconds the signals from microphone by 75 microseconds and not delaying the signals from microphone the function should constructively superpose the signals representing the speech source while destructively interfering with signals sourced from outside the preferred direction of the array thereby substantially reducing much of the ambient noise.

In the systems of above the beamformer filter parameters must be fixed before the beamformer can be used to identify a primary speech signal. This training of the filter parameters may be performed at the factory or by the user. If the training is performed at the factory using a headset embodiment as shown in differences in the head size of the trainer and the eventual user will result in less than ideal performance in the beamformer. To address this in some embodiments different headsets may be provided in a variety of morphologies to conform to the sizes and shapes of the heads of a variety of different users providing a specialized fit for each user. A set of array coefficients may be calibrated with reference to these particular and or customized headset morphologies. A codebook of beamformers may be provided in which each codeword corresponds to a certain physical user profile. Calibration then includes searching for the codeword or weighted combination of codewords that provides the best match for a particular user.

Embodiments of calibrated beamformers non linear adaptive filters and associated processes and devices embodying these new technologies such as those illustrative embodiments illustrated herein also have useful applicability to a wide range of technologies. They are applicable in combination with a broad range of additional microphone array processing methods and devices.

These are indicative of a few of the various additional features and elements that may be comprised in different embodiments corresponding to the claims herein. Although the present invention has been described with reference to particular illustrative embodiments workers skilled in the art will recognize that changes may be made in form and detail without departing from the metes and bounds of the claimed invention.

