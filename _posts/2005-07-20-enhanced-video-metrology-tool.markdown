---

title: Enhanced video metrology tool
abstract: A system and method for tool enhancements are provided which allow users to utilize video tools in a controlled manner. The video tools balance a minimal amount of cursor positioning and “mouse clicks” against a level of video tool “customization” control desired by a user when applying the video tools. Tool construction methods using multiple mouse clicks are provided as an alternative to using drag-and-draw and one-click tools. Multi-click-plus tools give more specific information and provide a precise way to rapidly create customized tools.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07627162&OS=07627162&RS=07627162
owner: Mitutoyo Corporation
number: 07627162
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20050720
---
This application claims the benefit of U.S. Provisional Application No. 60 648 956 filed Jan. 31 2005 under the provisions of 35 U.S.C. 119.

The invention relates generally to machine vision inspection systems and more particularly to video metrology tools usable to define inspection operations for such systems.

Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the 3 published January 2003 and the 3 published September 1996 each of which is hereby incorporated by reference in their entirety. This product as exemplified by the QV 302 Pro model for example is able to use a microscope type optical system to provide images of a workpiece at various magnifications and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected given the desired magnification measurement resolution and physical size limitations of such systems.

Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6 542 180 teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the 180 patent automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text based programming for example or through a recording mode which progressively learns the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user or through a combination of both methods. Such a recording mode is often referred to as learn mode or training mode. Once the inspection event sequence is defined in learn mode such a sequence can then be used to automatically acquire and additionally analyze or inspect images of a workpiece during run mode. 

The machine control instructions including the specific inspection event sequence i.e. how to acquire each image and how to analyze inspect each acquired image are generally stored as a part program or workpiece program that is specific to the particular workpiece configuration. For example a part program defines how to acquire each image such as how to position the camera relative to the workpiece at what lighting level at what magnification level etc. Further the part program defines how to analyze inspect an acquired image for example by using one or more video tools such as edge boundary detection video tools.

Video tools may be used manually to accomplish manual inspection and or machine control operations. Also their set up parameters and operation can also be recorded during learn mode in order to create automatic inspection programs or part programs . Such tools may include for example edge boundary detection tools shape or pattern matching tools dimension measuring tools coordinate establishing tools and the like. For example such tools are routinely used in a variety of commercially available machine vision inspection systems such as the QUICK VISION series of vision systems and the associated QVPAK software discussed above.

Video edge boundary detection tools available in QVPAK software include for example Point tool Box tool Circle tool and Arc tool see QVPAK 3D CNC Vision Measuring Machine User s Guide incorporated by reference above . Briefly a Point tool generates locates a data point at the intersection of a single scan line on an image. A Box tool generates a series of parallel scan lines each of which returns a data point where an edge feature is found. A Circle tool generates a series of radial scan lines over 360 centered about an origin each of which returns a point where an edge feature is found. An Arc tool generates a series of radial scan lines centered about an origin each of which returns a point where an edge feature is found useful for returning data points from a rounded corner for example . Each of these tools may be used to automatically detect a particular edge boundary feature in an image.

Proper operation of a video tool depends on correct settings of various machine image acquisition and video tool parameters that affect the image quality and the operation of the video tool. For example for an edge boundary detection video tool to locate a target edge boundary in an image the machine and image acquisition parameters must set a correct level of lighting brightness proper focusing proper magnification etc. Video tool parameters for example for an edge detection video tool may include a region of interest of i.e. the region within a video image that the video tool searches an edge selector a scan direction and other parameters are that set to properly control the operations of the video tool to locate the edge boundary feature that is desired be detected.

The currently available features and graphical user interface GUI controls for video tools and particularly dimensional metrology video tools are limited. Some existing video tools require relatively few setup actions by the user but have the disadvantage that many of the resulting video tool parameters are set to default values that may be inappropriate in many situations. Other existing video tools allow the video tool parameters to be extensively adjusted or customized by the user but have the disadvantage that they require several independent setup actions by the user. Video tools that overcome these and other disadvantages would be desirable.

Currently the users of precision machine vision inspection systems may spend a majority of their part programming time setting up video tools and adjusting their parameters. Thus even small improvements in their ease of use in comparison to their parameter customization capability their GUI features and other ergonomic factors may be highly valued. The present invention is directed to novel and efficient instances of the video tools outlined above as well as other video tools. A system and method for tool enhancements are provided which allow users to utilize video tools in a controlled manner. The video tools balance a minimal amount of cursor positioning and mouse clicks against a level of video tool customization control desired by a user when applying the video tools. Tool construction methods using multiple mouse clicks are provided as an alternative to using known drag and draw and one click tool methods. The multi click plus and or multi click tools disclosed herein may convey more specific tool parameter information than known similar tools and provide a precise way to create tools. The multi click plus and or multi click tools disclosed herein may allow a user to determine a plurality of tool parameters with a single user action. These new video tool methods give users a high level of control over tool parameter creation with a simple and or minimum set of user actions.

The vision measuring machine includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. The machine vision inspection system is also described in copending and commonly assigned U.S. patent application Ser. No. 10 978 227 which is hereby incorporated by reference in its entirety. Various aspects of vision measuring machines and control systems are also described in more detail in copending and commonly assigned U.S. patent application Ser. Nos. 10 808 948 filed Mar. 25 2004 and 10 632 823 filed Aug. 4 2003 which are also hereby incorporated by reference in their entirety.

A workpiece that is to be imaged using the machine vision inspection system is placed on the workpiece stage . One or more of the light sources and emits source light or respectively that is usable to illuminate the workpiece . Light emitted by the light sources and or illuminates the workpiece and is reflected or transmitted as workpiece light which passes through the interchangeable objective lens and the turret lens assembly and is gathered by the camera system . The image of the workpiece captured by the camera system is output on a signal line to the control system portion .

The light sources and that are used to illuminate the workpiece can include a stage light a coaxial light and a surface light such as a ring light or a programmable ring light all connected to the control system portion through signal lines or busses and respectively. As a primary optical assembly of the machine vision inspection system the optical assembly portion may include in addition to the previously discussed components other lenses and other optical elements such as apertures beam splitters and the like such as may be needed for providing coaxial illumination or other desirable machine vision inspection system features. When it is included as a secondary optical assembly of the machine vision inspection system the turret lens assembly includes at least a first turret lens position and lens and a second turret lens position and lens . The control system portion rotates the turret lens assembly along axis between at least the first and second turret lens positions through a signal line or bus .

The distance between the workpiece stage and the optical assembly portion can be adjusted to change the focus of the image of the workpiece captured by the camera system . In particular in various exemplary embodiments the optical assembly portion is movable in the vertical Z axis direction relative to the workpiece stage using a controllable motor that drives an actuator a connecting cable or the like to move the optical assembly portion along the Z axis. The term Z axis as used herein refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor when used is connected to the input output interface via a signal line .

As shown in in various exemplary embodiments the control system portion includes a controller an input output interface a memory a workpiece program generator and executor a CAD file feature extractor and a power supply portion . It will be appreciated that each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface includes a position control element and a speed acceleration control element . However it should be appreciated that in various exemplary embodiments such elements may be merged and or indistinguishable. The lighting control interface includes lighting control elements which control for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system such as the light sources and .

The memory includes an image file memory portion a workpiece program memory portion that may include one or more part programs or the like and a video tool portion . The video tool portion includes tool portions which determine the GUI image processing operation etc. for each of the corresponding tools. Each of the tool portions includes respective mode portions that determine its behavior depending on whether or not that tool is activated in that particular mode. For example the tool portion includes a multi click plus operations portion that determines the behavior of the tool when it is activated in a multi click plus mode described in greater detail below a drag and draw operations portion that determines the behavior of the tool when it is activated in a known drag and draw mode and a one click operations portion that determines the behavior of the tool when it is activated in a known one click mode. Any or all of the other tools of the video tool portion may include similar mode portions for example the final tool portion similarly includes a multi click plus operations portion a drag and draw operations portion and a one click operations portion . The video tool portion also includes a tool mode control memory portion that governs the overall selection and operation of the respective tools modes referred to above. The video tool portion also includes a region of interest generator that supports automatic semi automatic and or manual operations that define various regions of interest that are operable in various video tools included in the video tool portion .

In general the memory portion stores data usable to operate the vision system components portion to capture or acquire an image of the workpiece such that the acquired image of the workpiece has desired image characteristics. The memory portion further stores data usable to operate the machine vision inspection system to perform various inspection and measurement operations on the acquired images either manually or automatically and to output the results through the input output interface . The memory portion also contains data defining a graphical user interface operable through the input output interface .

The signal lines or busses and of the stage light the coaxial light and the surface light respectively are all connected to the input output interface . The signal line from the camera system and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller that initiates image acquisition.

One or more display devices and one or more input devices can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various graphical user interface GUI features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera system and or to directly control the vision system components portion . In a fully automated system having a predefined part program or workpiece program the display devices and or the input devices may be omitted.

With regard to the CAD file feature extractor information such as a CAD file representing a workpiece is frequently available in industrial applications of machine vision inspection systems. The locations of edges and boundaries in the CAD file representation may be determined manually in a semi automated fashion or fully automatically in such information may be useful for workpiece programming or navigating to a desired workpiece feature.

In various exemplary embodiments when a user utilizes the machine vision inspection system to create a workpiece image acquisition program for the workpiece the user generates workpiece program instructions either by explicitly coding the instructions automatically semi automatically or manually using a workpiece programming language or by generating the instructions by moving the machine vision inspection system through an image acquisition training sequence such that the workpiece program instructions capture the training sequence. This process is repeated for multiple images in a set of images that are to be captured. These instructions when executed will cause the machine vision inspection system to manipulate the workpiece stage and or the camera system at certain speed s such that a particular portion of the workpiece is within the field of view of the camera system and at a desired focus state for each of a set of images to be acquired. In addition to the program instructions that control the relative movement of the camera and the workpiece the workpiece image acquisition program also needs to include program instructions that activate one or more of the light sources to provide a desired illumination of the workpiece during each image acquisition.

Once a set of workpiece image acquisition instructions are defined the control system executes the instructions and commands the camera system to capture one or more images of the workpiece according to the instructions. The control system will then under control of the controller input the captured image s through the input output interface and store the captured image s in the memory . The controller may also display the captured images on the display device .

The control system portion is further usable to recall captured and stored workpiece inspection images to inspect and analyze workpiece features in such workpiece inspection images and to store and or output the inspection results. These analysis and inspection methods are typically embodied in various video tools included in the video tool portion of the memory . Some of these tools including edge detection tools shape or pattern matching tools dimension measuring tools coordinate matching tools auto focus tools and the like for example are routinely available in a variety of commercially available machine vision inspection systems such as the QUICK VISION series of vision systems and the associated QVPAK software discussed above. The various methods disclosed herein may be applied to define the video tool parameters used these and other video tools in a novel and more convenient manner. For example parameters associated with the edge boundary detection tools disclosed in co pending and commonly assigned U.S. patent application Ser. No. 09 987 986 filed Nov. 16 2001 and the improved autofocus tools and methods described in co pending U.S. patent application Ser. No. 10 719 210 filed Nov. 24 2003 each of which is hereby incorporated by reference in its entirety may also be defined according to the methods and user interface features disclosed herein.

After the image inspection analysis operation using one or more of these video tools is completed the control system outputs the results of each analysis inspection operation to the input output interface for outputting to various display devices such as a video display printer and the like. The control system may also store the results of each inspection operation in the memory .

In operation in an exemplary tool mode referred to as multi click plus herein when the box tool icon on a video tool bar is selected as described below with reference to a box tool indicator as shown in may appear on the display. The box tool indicator may be associated with a cursor which may appear as a cross hair or the like at a cursor point . The cursor point may provide coordinates that are used by the box tool to determine various parameters of the box tool and or to adjust various features or parameter indicators of the box tool GUI as described in greater detail below. In general for the various tools shown and described herein a tool indicator may continue to appear adjacent to the cursor throughout various operations described herein even if it is omitted from a figure in order to more clearly illustrate other features of the figure.

In the example shown in the user initially places a point along the edge feature at a desired position which bounds one end of the box tool height that is the height of the box tool region of interest box tool ROI shown in . Unless otherwise indicated by description or context throughout this disclosure placing a point may generally comprise the user entering the coordinates of a desired point to be used by a video tool for determining one or more video tool parameters. In this way the user may control the determination or definition of various video tool parameters. For example in exemplary embodiments the user may generally move an input device such as a mouse joystick trackball or the like to move the cursor around on a display of a feature such as the edge feature . When the user has positioned the cursor at a desired position the user may then click an input device button or press enter on a keyboard or the like in order to place a point at the desired position. Placing a point may anchor a tool parameter indicator at the position of the placed point as described below.

After placing the point a parameter indicator such as a crosshair may be anchored at the point and the user may then continue to move the cursor which in some embodiments may be connected to the parameter indicator anchored at point at position by a dotted construction line that may follow the cursor like a taut elastic band. In other embodiments the construction line is not included and the cursor may act as a parameter indicator. As shown in the user has moved the cursor to a second point along the edge feature which tentatively bounds the other end of the box tool ROI height. The cursor or the moving end of the construction line may be regarded as a parameter indicator since it is reflecting a potential dimension of a region of interest of the box tool which will be fixed when the user places a second point as described below. In exemplary embodiments a parameter indicator e.g. the end of the construction line or a cross hair associated with the cursor position or the like may be automatically linked to be dynamically adjusted based on the cursor position which is controlled by the user s input device movement without requiring the user to take or maintain any special action. That is automatic linking as the term is used herein means that the user need not select the dynamically adjusted parameter indicator with an additional mouse click after placing the preceding point and or the user need not continue to depress and or hold down a mouse button or other input device button or the like to drag the dynamically adjusted parameter indicator or the like.

Regarding automatic linking automatic linking is one feature that makes the box tool and various other tools described herein particularly convenient to use and in conjunction with the appearance and operation of the parameter indicators shown and described herein particularly intuitive to learn and use. In embodiments where automatic linking is used the need for the user to select a dynamically adjusted parameter indicator is eliminated which provides that an operation such as a button click may be reserved to operate exclusively as an operation that places a point while the video tool parameters are being established by the user. Otherwise a click might be required to select a parameter indicator that is to dynamically follow the cursor or the like. Thus the user may learn more quickly by associating one operation e.g. a click with one function placing a point while operating the video tool GUI. Furthermore in other conventional drag and draw operations a first point e.g. a box corner is placed by depressing a mouse button or the like then the button must be held in an unstable depressed state while moving to a next desired location e.g. the other corner of the box and then the next desired location is placed by releasing the button. Thus two sequential placed points are placed by two different actions. In contrast automatic linking provides that all sequentially placed points may be placed by the same type of operation and that a button need not be held in an unstable state. Thus in embodiments that use automatic linking the user may avoid an unstable ergonomic state and may also learn more quickly by associating one type of operation e.g. a click with one function e.g. placing a point while operating the video tool GUI.

Continuing as shown in the user places a point at a position which anchors the other end of the box tool ROI height or longitudinal dimension and may cause other parameter indicators of the box tool to appear and be automatically linked to be dynamically adjusted based on the cursor position. The term parameter indicators is used herein to refer to the graphical features of the user interface of a video tool or a video tool GUI that correspond to the current user determined or machine determined or derived or default tool parameters. For example the parameter indicators shown in may include the upper end lower end and sides of the ROI box B the scan direction arrows the midline indicator the sampling direction indicator which is the upward pointing arrowhead located along the midline at the position the edge selector location indicator also called the selector location indicator and the rising falling indicator . The rising falling indicator is empty indicating that the rising falling direction has not yet been determined in . At various times the cursor display may be merged with or indistinguishable from various parameter indicators of the video tool GUI. This might alternatively be described or implemented as using the cursor as a parameter indicator in the GUI at various times or as the cursor representation changing to indicate various parameters or as the various parameter indicators following the cursor. All of these descriptions may fall within the scope of this invention if they serve to implement the various features and operations of the invention outlined herein.

Regarding linking in general as the term is used herein for some linked parameter indicators they may be dynamically adjusted to follow the cursor position. For some linked parameter indicators they may be dynamically adjusted in a manner depending on the cursor position without following the cursor. As one example a first side of the ROI box B may be dynamically adjusted to follow the cursor position while the other side of the ROI box B may dynamically adjusted to a location symmetric to first side about the centerline of the box tool . As another example the direction of the scan direction arrows may dynamically adjusted based on the cursor position e.g. to point along a direction that is from the centerline toward the cursor position regardless of their location which may be an anchored location. As another example the location of the edge selector location indicator may be dynamically adjusted to parallel the cursor position while being restricted to travel along the centerline .

For the example shown in when point is placed thereafter the video tool determines the width or lateral dimension of the ROI box B as being located symmetrically about the centerline joining point and point . Also the point placement sequence determines a sampling direction proceeding from point to point as indicated by the upward pointing sampling direction arrow at the position . The sampling direction is the direction that data sampling and or analysis follows when determining a series of edge points along the edge feature .

After placing point the user may continue to move the cursor . In exemplary embodiments the automatically linked parameter indicators may be dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button. As shown in after placing point and the appearance of the various parameter indicators discussed above the user has moved the cursor to a point down and to the left from point and the automatically linked width of the ROI box B selector location indicator and scan direction arrows have been dynamically adjusted accordingly.

It should be appreciated that the linked width of the ROI box B the linked selector location indicator and the linked scan direction arrows may all be linked and dynamically adjusted at the same time. Linking a plurality of different types of parameter indicators to be dynamically adjusted at the same time is another feature that makes the box tool and various other tools described herein particularly convenient to use and in conjunction with the appearance and operation of the parameter indicators shown and described herein particularly intuitive to learn and use. This may be the case even if the plurality of different types of parameter indicators are linked by operations that are not automatic. However the combination of automatically linking a plurality of different parameter indicators to be dynamically adjusted at the same time is particularly convenient and intuitive and may be preferred in many embodiments.

Regarding the positioning of the edge selector location indicator the edge feature is shown to include a deviating portion . Edge deviations such as the deviating portion may generally create potential problems for properly training an edge finding tool. It will be appreciated that workpiece edges in actual workpiece images may exhibit significant variations along the edge due to lighting or shadow variations contamination effects diffraction effects and the like. For example diffraction effects and or shadows may frequently create a closely spaced family of edge like image features adjacent to the true workpiece edge location in the image. Properly training an edge tool during learn mode operations is critical to locating the proper edge among these potential erroneous edge like features during subsequent inspection operations. During training an edge tool analyzes the pixel intensity variations along a scan line and determines and records the particular intensity variation characteristics that correspond to the desired edge. For example these characteristics may be based on the total intensity variation across the edge the rate of change of the intensity variation across the edge whether the intensity variation is rising or falling across the edge for a particular scan direction whether the intensity variation is the first second third etc. rising or falling variation along the scan line etc. An edge tool may be trained by automatically determining and recording these characteristics by analyzing a desired prototypical edge scan. In various embodiments a user may pick the desired location for the prototypical edge scan by locating the selector location indicator on the desired edge preferably at a location that is relatively free of contamination optical aberrations and the like. In for purposes of illustration the cursor has been temporarily located at a point such that the linked selector location indicator which may traverse along the centerline to parallel the location of the cursor is located slightly away from the edge due to the deviating portion . Such a selector location may lead to erroneous training.

As shown in the user has continued to move the cursor and the automatically linked width of the ROI box B selector location indicator and scan direction arrows have been dynamically adjusted accordingly. The selector location now coincides with a desired prototypical scan location on the edge and the scan direction arrows point along a desired direction. Since the cursor is on the right side of the centerline the arrows are shown to be pointing from left to right. Regarding the scan direction for increased reliability it is generally advantageous to determine the scan direction to proceed from a region where the intensity is more uniform to a region that may have more intensity variation due to texture or image noise for example such that a desired edge transition characteristic is determined along a scan line before unpredictable noise characteristics are encountered.

When the user places point various parameter indicators are anchored and or fixed based on the position of the placed point and any previously undetermined tool parameters associated with the final set of parameter indicators are determined and used such that the tool may be run to automatically teach or train the tool. After the tool is trained the rising falling indicator may be automatically filled with dark and light regions as shown in reflecting the direction of the dark to light transition that was determined by the tool operations during training. Subsequently a series of edge points that are detected along the edge based on the trained parameters may be marked on the display for example using the known methods employed in commercially available machine vision systems. The user may then accept the training results and continue to other operations or reject the training results further modify the tool parameters and retrain the tool until satisfactory results are achieved.

It should be appreciated that in various embodiments an auto trace tool such as that indicated in and included in various commercial machine vision inspection systems may include tool parameters that may be defined by operations substantially similar to those previously described with reference to the box tool . Thus it should be appreciated that one skilled in the art may design and operate an auto trace tool based on this disclosure in conjunction with known auto trace tool techniques found in commercially available machine vision inspection systems.

Continuing as shown in the user places a point at a position on the edge feature which may anchor another parameter indicator and may cause other parameter indicators of the circle tool such as the provisional circle construction line to appear. After placing point the user may continue to move the cursor . In the example shown in after placing point the provisional circle construction line is automatically linked to be dynamically adjusted to be best fit to point point and the position of the cursor without requiring the user to depress and or hold down a mouse button after placing point .

Continuing as shown in the user places a point at a position on the edge feature which may anchor another parameter indicator and or and may cause other parameter indicators of the circle tool to appear. The provision circle construction line may be replaced by or dynamically adjusted to become an anchored nominal circle indicator which is also the circle tool ROI centerline indicator . The nominal circle indicator may have a radius and center location that are best fit to point point and point and that nominally approximates the edge feature . A sampling direction may proceed around the circle in the direction from point to point as indicated by an anchored sampling direction indicator the arrowhead pointing counterclockwise on the circle tool ROI centerline indicator . Other exemplary parameter indicators shown in include the circle tool ROI interior radius or diameter I and exterior radius or diameter E a scan direction arrow a selector location indicator and a rising falling indicator . In exemplary embodiments these other parameter indicators may be automatically linked to be dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button.

For the example shown in when point is placed thereafter the automatically linked radial dimension of the circle tool ROI the selector location indicator and the radial edge scan orientation indicated by the scan direction indicator arrow are dynamically adjusted based on the cursor position. The radial edge scan orientation may be a function of the location of the cursor relative to the circle tool ROI centerline indicator . In the example shown in the user has moved the cursor to a point down from the placed point and the location of the ROI diameter E the radial dimension of the circle tool ROI selector location indicator and scan direction arrows have been dynamically adjusted accordingly. Since the location of the cursor is outside of the circle tool ROI centerline indicator the scan direction as indicated by the scan direction indicator arrow is radially outward whereas if the cursor was moved inside the circle tool ROI centerline indicator the scan direction would be reversed. In the embodiment shown in the exterior diameter E is dynamically adjusted to follow the cursor and the radial dimension of the circle tool ROI is dynamically adjusted symmetrically about the ROI centerline indicator . However in other exemplary embodiments the circle tool ROI interior diameter I and or exterior diameter E may be subsequently or independently adjusted such that the radial dimension of the circle tool ROI is not symmetrical about the ROI centerline indicator .

As shown in the user has continued to move the cursor to the location and the automatically linked radial dimension of the circle tool ROI selector location indicator and scan direction arrow have been dynamically adjusted accordingly. The location of the selector location indicator now coincides with a desired prototypical scan location on the edge feature and the scan direction arrow is oriented along the desired radial direction.

When the user places point at the location various parameter indicators are anchored and or fixed based on the position of the placed point and any previously undetermined tool parameters associated with the final set of parameter indicators are determined and used such that the tool may be run to automatically teach or train the tool. After the tool is trained the rising falling indicator may be automatically filled with dark and light regions as shown in reflecting the direction of the dark to light transition that was determined by the tool operations during training. Subsequently a series of edge points that are detected along the edge feature based on the trained parameters may be marked on the display for example using the known methods employed in commercially available machine vision systems. The user may then accept the training results and continue to other operations or reject the training results further modify the tool parameters and retrain the tool until satisfactory results are achieved.

Continuing as shown in the user places a point at a position on the edge feature which may anchor another parameter indicator and may cause other parameter indicators of the arc tool such as the provisional arc construction line to appear. After placing point the user may continue to move the cursor . In the example shown in after placing point the provisional arc construction line is automatically linked to be dynamically adjusted to be best fit to point point and the position of the cursor without requiring the user to depress and or hold down a mouse button after placing point . In other embodiments the construction line is not included and the cursor may act as a parameter indicator. The cursor or the moving construction line may be regarded as a parameter indicator since it is reflecting a potential parameter of a region of interest of the arc tool which will be fixed when the user places a third point as described below.

Continuing as shown in the user places a point at a desired position at the other end of the arc on the edge feature which may anchor another parameter indicator and or and may cause other parameter indicators of the arc tool to appear. The provisional arc construction line may be replaced by or dynamically adjusted to become an anchored nominal arc indicator which is also the arc tool ROI centerline indicator . The nominal arc indicator may have a radius and center location that are best fit to point point and point and that nominally approximates the edge feature . A sampling direction may proceed around the arc in the direction from point to point as indicated by an anchored sampling direction indicator the arrowhead pointing counterclockwise on the arc tool ROI centerline indicator . Other exemplary parameter indicators shown in include the arc tool ROI interior radius I and exterior radius E scan direction arrows a selector location indicator and a rising falling indicator . In exemplary embodiments these other parameter indicators may be automatically linked and dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button similarly to the analogous elements of the circle tool . In the example shown in the user has continued to move the cursor to a point down from the placed point and the location of the ROI diameter E the radial dimension of the arc tool ROI the selector location indicator and the scan direction arrows have been dynamically adjusted accordingly similarly to the analogous elements of the circle tool .

As shown in the user has continued to move the cursor and places a point at the location and the automatically linked radial dimension of the arc tool ROI selector location indicator and scan direction arrows have been dynamically adjusted accordingly. The location of the selector location indicator now coincides with a desired prototypical scan location on the edge feature and the scan direction arrow is oriented along the desired radial direction. When the user places point at the location various parameter indicators are anchored and or fixed based on the position of the placed point and any previously undetermined tool parameters associated with the final set of parameter indicators are determined and used such that the tool may be run to automatically teach or train the tool. After the tool is trained the rising falling indicator may be automatically filled with dark and light regions as shown in reflecting the direction of the dark to light transition that was determined by the tool operations during training. Subsequently a series of edge points that are detected along the edge feature based on the trained parameters may be marked on the display for example using the known methods employed in commercially available machine vision systems. The user may then accept the training results and continue to other operations or reject the training results further modify the tool parameters and retrain the tool until satisfactory results are achieved.

As shown in the user has moved the cursor to a second point below and to the right of the point which tentatively bounds the other end of the dimension of the auto focus tool ROI box that is bounded by point . Also shown in are four quadrants A B C and D depicted relative to the point which play a role in an operation outlined below. The four quadrants need not be displayed to the user.

Continuing as shown in the user places a point at a position . Placing the point may anchor the other end of the dimension of the auto focus tool ROI box that is bounded by point may optionally cause an associated parameter indicator to appear at point and may cause other parameter indicators of the auto focus tool such as the entire ROI box to appear. In the example shown in after placing point the left side and the upper side of the ROI box are anchored and the right side and the bottom side of the ROI box are automatically linked to be dynamically adjusted based on the position of the cursor without requiring the user to depress and or hold down a mouse button after placing point . After placing point the user may continue to move the cursor . Other exemplary parameter indicators shown in include the auto focus tool ROI box a scan direction arrow and a rising falling indicator . The scan direction may be determined based on which of the four quadrants A B C and D the point falls in for example from left to right in quadrant D from down to up in quadrant A from right to left in quadrant B and from up to down in quadrant C.

Continuing as shown in the user places a point at a position and the width dimension of the auto focus tool ROI is dynamically adjusted and anchored accordingly. Placing the point may anchor the entire auto focus tool ROI box . In the example shown in the left end of the ROI width dimension is located at a default distance away from the dashed construction line that is based on the distance of the point from the dashed construction line . The right end of the ROI width dimension is then determined by the point . However in other embodiments the width dimension may simply be located symmetrically around the location of the dashed construction line based on the location of the point . When the user places point at the location various parameter indicators are anchored and or fixed based on the position of the placed point and any previously undetermined tool parameters associated with the final set of parameter indicators are determined and used such that the tool may be run to automatically teach or train the tool. After the tool is trained the rising falling indicator may be left blank indicating that the rising falling parameter is not an essential tool parameter for the edge auto focus tool . However if desired the rising falling parameter may be set by a user subsequently editing the tool in a related menu or window of the edge auto focus tool user interface. In such a case the rising falling indicator may be filled in accordingly to indicate the rising falling parameter is now set and will be used. Subsequently an autofocus operation may be performed based on the trained parameters using the known methods employed in commercially available machine vision systems. The user may then accept the training results and continue to other operations or reject the training results further modify the tool parameters and retrain the tool until satisfactory results are achieved.

Continuing as shown in the user places a point at a position . Placing the point may anchor the second end of the height or longitudinal dimension of the DAC tool ROI s L and R the location of the centerline indicator may optionally cause an associated parameter indicator to appear at point and may cause other parameter indicators of the DAC tool to appear. In the example shown in after placing point the location of the upper sides and the lower sides of the DAC tool ROI s L and R are anchored and the lateral dimensions of the DAC tool ROI s L and R are automatically linked to be dynamically adjusted based on the position of the cursor without requiring the user to depress and or hold down a mouse button after placing point . After placing point the user may continue to move the cursor .

Continuing as shown in the user places a point at a position and the lateral dimensions of the DAC tool ROI s L and R their individual widths and lateral locations are dynamically adjusted and anchored accordingly. In the example shown in the lateral distance of the interior limits of the ROI s L and R from the centerline indicator is a symmetrical default distance. The lateral distance of the exterior limits of the ROI s L and R from the centerline indicator is a symmetrical distance that corresponds to the location of the point . However in other embodiments the lateral distance from the interior limits of the ROI s L and R from the centerline indicator may simply be a proportion of the distance from the exterior limits to the centerline indicator .

When the user places point at the location various parameter indicators are anchored and or fixed based on the position of the placed point and any previously undetermined tool parameters associated with the final set of parameter indicators are determined and used such that the tool may be run to automatically teach or train the tool. Subsequently a light adjusting operation may be performed based on the results of the trained DAC tool according to known methods employed in commercially available machine vision systems and or as described in the 180 patent. The user may then accept the lighting results and the DAC tool training results and continue to other operations or reject the training results further modify the tool parameters and retrain the tool until satisfactory results are achieved.

At a block when the user places a first point at the first desired location e.g. by the user making a click with a mouse button while the cursor is at the first desired location the video tool parameters associated with the first point are determined. In addition one or more adjusted or added parameter indicators of the video tool GUI corresponding to the entry of the first point are displayed. One or more of the parameter indicators may be anchored.

At a block after the user places the first point one or more parameter indicators may be automatically linked to be dynamically adjusted based on the cursor position e.g. as the cursor moves away from the first point. In various embodiments one or more of the automatically linked parameter indicators may be dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button after placing the first point. At a block the cursor is positioned to match a user input as the user positions the cursor on the image at a second desired location e.g. based on mouse movement .

At a block when the user places a second point at the second desired location e.g. by the user making a click with a mouse button while the cursor is at the second desired location the video tool parameters associated with the second point are determined. In addition one or more adjusted or added parameter indicators of the video tool GUI corresponding to the entry of the second point are displayed. One or more of the of the parameter indicators may be anchored.

As shown in from a point A the routine continues to a block . At block after the user places the preceding point e.g. the second point or a new point one or more of the adjusted or added parameter indicators may be automatically linked to be dynamically adjusted based on the cursor position e.g. as the cursor moves away from the second or new point. In various embodiments one or more of the automatically linked parameter indicators may be dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button after placing the second point. For example when the multi click plus video tool is an edge finding box tool the first time that step is reached after a second point is placed a plurality of parameter indicators are may be automatically linked to be dynamically adjusted based on the cursor position. The plurality may include an edge selector location indicator and an ROI dimension or coordinate indicator. A scan direction indicator may also be linked to be dynamically adjusted based on the cursor position.

At a block the cursor is positioned to match a user input as the user positions the cursor on the image at a new desired location e.g. a third or fourth desired location. At a block when the user places a new point at the new desired location e.g. by the user making a click with a mouse button while the cursor is at the new desired location the video tool parameters associated with the new point are determined. In addition one or more adjusted or added parameter indicators of the video tool GUI corresponding to the entry of the new point may be displayed. One or more of the of the parameter indicators may be anchored. If the new placed point is the final placed point required for determining the video tool parameters an anchored and or finalized set of video tool parameter indicators may be displayed.

At a decision block a determination is made as to whether all of the user determined video tool parameters have been identified. If all of the user determined tool parameters have not yet been identified then the routine returns to block to perform operations for identifying additional tool parameters. For example when the multi click plus video tool is an edge finding arc or circle tool the second time that step is reached after a third point has been placed a plurality of parameter indicators are may be automatically linked to be dynamically adjusted based on the cursor position. The plurality may include an edge selector location indicator and an ROI dimension or coordinate indicator. A scan direction indicator may also be linked to be dynamically adjusted based on the cursor position. Otherwise if all of the user determined tool parameters have been identified then the routine continues to a block . At a block any remaining video tool parameters are automatically determined and or the video tool may be trained and or run based on all the determined parameters. At a block the results of running the trained video tool are recorded displayed or output e.g. during manual or learn mode operations and or if the results are acceptable the determined and trained video tool parameters may be recorded or stored in a part program e.g. during learn mode operations if accepted by a user. 

As shown in in row the first column indicates that the operations of a multi click plus Box tool and or a multi click plus Autotrace tool are summarized in row . Continuing across row column A indicates that when operating the respective video tool GUI s of the subject tools the first click establishes the ROI height end point . Column B indicates that a second click establishes the other end point of the ROI height end point and column C indicates that the second click establishes the ROI angular orientation as well. Column D indicates that a third click establishes the ROI width symmetric about the midline and columns E and F respectively indicate that the third click establishes the selector location and the scan direction as well. Column G indicates that sampling direction is determined to follow a direction from the location of point established by the first click toward the location of point established by the second click

The remainder of the rows in may be understood based on the preceding explanation. A comparison of each respective row describing MC tools with the corresponding MC tool row above it corresponding to similar video tools operated in different modes shows that the MC tools operate similar to the MC tools with the exception that each of the parameters associated with the operations of columns D E F and G are set by default that is the user is only required to perform the clicks indicated in columns A B and C in order to completely define the parameters of the MC tools. Accordingly the MC tool mode has the advantage of offering simpler and more convenient tool operation than the MC mode but it has the disadvantage that the default tool parameters are not customized to a particular feature. Therefore the MC tool mode may not be suitable for performing inspection operations for some features for example some features similar to those shown in . Nevertheless in some embodiments an MC tool may include operating advantages similar to those provided in some embodiments of the MC tools. For example in some embodiments it is advantageous that after a user places a point one or more parameter indicators may be automatically linked to be dynamically adjusted based on the cursor position e.g. as the cursor moves away from the point and that they may be dynamically adjusted based on the cursor position without requiring the user to depress and or hold down a mouse button after placing the point.

While exemplary sequences of operations have been outlined when describing various exemplary embodiments of multi click plus video tools with reference to it will be appreciated that in other exemplary embodiments certain operations may be performed in other sequences and or one or more of the described operating features or GUI features may be omitted and the other inventive aspects of the methods and GUI s disclosed herein may still provide substantial benefits. Thus while the preferred embodiment of the invention has been illustrated and described it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention.

