---

title: Applying multiple texture maps to objects in three-dimensional imaging processes
abstract: Systems and methods for providing multi-pass rendering of three-dimensional objects. A rendering pipeline that includes (N) physical texture units and one or more associated buffers emulates a rendering pipeline containing more texture units (M) than are physically present (N). Multiple rendering passes are performed for each pixel. During each texture pass only N sets of texture coordinates are passed to the texture units. The number of passes required through the pipeline to emulate M texture units is M/N, rounded up to the next integer. The N texture units of the rendering pipeline perform look-ups on a given pass for the corresponding N texture maps. The texture values obtained during the texture passes are blended by texture blenders to provide composite texture values. In successive passes, the buffers are used for temporary data and the most current composite texture values. The process is repeated until all desired texture maps are applied.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07095419&OS=07095419&RS=07095419
owner: Microsoft Corporation
number: 07095419
owner_city: Redmond
owner_country: US
publication_date: 20050831
---
This application is a continuation of U.S. patent application Ser. No. 10 770 054 filed Feb. 2 2004 now U.S. Pat. No. 6 975 327 entitled Applying Multiple Texture Maps to Objects in Three Dimensional Imaging Processes which is a continuation of U.S. patent application Ser. No. 09 939 130 filed Aug. 24 2001 entitled Applying Multiple Texture Maps to Objects in Three Dimensional Imaging Processes now U.S. Pat. No. 6 741 259 which is a continuation in part of U.S. patent application Ser. No. 09 822 659 filed Mar. 30 2001 now abandoned entitled Applying Multiple Texture Maps to Objects Using a Single Texture Unit and which is now abandoned all of which are incorporated herein by reference.

The present invention relates to systems and methods for providing multi pass rendering of three dimensional graphics. More specifically the present invention is directed to systems and methods for utilizing one or more texture units and a plurality of associated frame buffers in a rendering pipeline to perform multiple rendering passes to support the use and storage of extra temporary data and to blend data from multiple texture maps that is applied to a polygon so as to model a three dimensional object.

Adding realism to computer graphics involves rendering an object that has three dimensional characteristics on a two dimensional display device. Such three dimensional characteristics include shadows and variations in color and shade of the object. For each desired three dimensional characteristic a specific texture map is applied to a frame of polygons in order to render the object. When multiple characteristics are desired the corresponding texture maps are blended. Therefore the blending and applying of various corresponding texture maps renders the object as having the desired three dimensional characteristics such as any desired color pattern appearance etc.

A conventional technique for applying multiple texture maps to render a three dimensional image includes utilizing a single texture unit and a single frame buffer. As multiple passes are performed the frame buffer is used as the temporary data storage between passes. While such a technique adequately applies light or shadow maps on opaque objects the conventional technique cannot be adequately utilized for transparent objects since temporary data and current destination pixel data cannot co exist under the conventional technique.

Another technique for applying multiple texture maps to render a three dimensional image uses a rendering pipeline that includes a texture unit for every texture map that is applied. The texture units are placed in series within the rendering pipeline which assembles one or more polygons to represent an object having three dimensional characteristics and applies multiple texture maps to the assembled polygon. Many effects are only renderable if one or more temporary pieces of data are allowed to exist between texture units of a pipeline. Thus under this conventional technique an additional piece of temporary data is passed between the texture units of the rendering pipeline and is fully consumed by the end of the pipeline.

By way of example illustrates a conventional rendering pipeline that includes vertex unit setup unit edge walk unit span walk unit z buffer texture units destination blender and frame buffer . In the rendering pipeline vertex unit assembles data describing the values at each vertex of a polygon. The data includes three dimensional coordinates which represent each of the polygons that together model a three dimensional object and texture coordinates the values for which are determined later in the pipeline through a series of texture units. Vertex unit provides the assembled data to setup unit which generates parametric function coefficients for an interpolation of intermediary points between the three dimensional coordinates. Edge walk unit receives the output of setup unit and determines the starting pixel and the value of the starting pixel for each horizontal row of pixels lying within the bounds of the polygon. Span walk unit then determines the values for all of the pixels for each horizontal row within the polygon. The values determined by edge walk unit and span walk unit are provided to z buffer which determines whether the pixels are occluded or visible so that only currently visible pixels are drawn.

A set of texture coordinates representing the various layers of textures that are to be applied to the generated polygons are passed through a series of texture units . The number of texture units in series corresponds to the number of texture layers that are to be applied. In the example of five texture layers are applied to the generated polygons. Other conventional rendering pipelines may include any number of texture units in series to apply the corresponding number of texture maps.

In each texture unit receives a series of texture coordinate sets for each pixel performs a texture map look up to obtain the values of the coordinate sets related to a texture map and performs a blending operation that may include blending the obtained values with values from one or more previous texture maps. Temporary data is passed between the texture units and is fully consumed by the end of the rendering pipeline.

Therefore with reference to the series of texture units of texture unit receives a series of texture coordinate sets from z buffer for each pixel. An example of a series of texture coordinate sets for a given pixel is u v u v u v u v and u v where u v is the texture coordinate set for the first texture map u v is the texture coordinate set for the second texture map u v is the texture coordinate set for the third texture map u v is the texture coordinate set for the fourth texture map and u v is the texture coordinate set for the fifth texture map. Because the texture units are in series the full complement of texture coordinate sets which in this example include u v u v u v u v and u v are transmitted from z buffer to texture unit . In this manner each of the texture units can select the texture coordinate set it needs to perform a texture map look up operation.

The following example illustrates the conventional technique that is currently performed for each pixel. Texture unit takes the texture coordinate set u v corresponding to the first texture map and performs a look up at texture cache to obtain the texture values for the pixel. Texture blender performs a blending operation to apply the texture values to the pixel corresponding to the first texture map.

Texture unit receives the series of texture coordinate sets for the pixel from texture unit . The texture coordinate set u v which corresponds to the second texture map is selected by texture unit and a look up is performed at texture cache to obtain the texture values for the pixel. Texture blender then performs a blending operation which includes blending the texture values corresponding to texture coordinates u v and u v to apply the texture values to the pixel corresponding to the first and second texture maps.

Texture unit receives from texture unit the series of texture coordinate sets for the pixel. The texture coordinate set u v which corresponds to the third texture map is selected by texture unit and a look up is performed at texture cache to obtain the texture values for the pixel. Texture blender performs a blending operation which includes blending the texture values corresponding to texture coordinates u v u v and u v to apply the texture values to the pixel corresponding to the first second and third texture maps.

Texture unit receives the series of texture coordinate sets for the pixel from texture unit . The texture coordinate set u v which corresponds to the fourth texture map is selected by texture unit and a look up is performed at texture cache to obtain the texture values for the pixel. Texture blender performs a blending operation which includes blending the texture values corresponding to texture coordinates u v u v u v and u v to apply the texture values to the pixel corresponding to the first second third and fourth texture maps.

Texture unit receives the series of texture coordinate sets for the pixel from texture unit . The texture coordinate set u v which corresponds to the fifth texture map is selected by texture unit and a look up is performed at texture cache to obtain the texture values for the pixel. Texture blender performs a blending operation which includes blending the texture values corresponding to texture coordinates u v u v u v u v and u v to apply the texture values to the pixel corresponding to the first second third and fourth texture maps.

The process explained above is performed for each of the pixels and the composite texture values which are the blended texture values for each pixel corresponding to texture coordinates u v u v u v u v and u v . After texturing the pixels are optionally modified by the destination blender which applies optional fog blending iterated specular blending and or alpha blending to the pixels that are then mapped to a frame buffer . Once the completed values for all of the pixels are mapped to frame buffer the display device is refreshed with the rendered image.

Another conventional technique for applying multiple texture maps to render a three dimensional image utilizes a rendering pipeline such as the rendering pipeline illustrated in and an extra piece of temporary data that only exists between texture stages. However with this technique it is possible for the regular multi texturing type of temporary data to concurrently exist between texture stages since previous texture stages could have other texture lookup proceeding. As such there are up to two pieces of temporary inter texture stage data and one piece of destination pixel data in the frame buffer.

Due to significant and sometimes prohibitive amounts of computing resources that are required including a high demand for memory conventional rendering techniques are limited to typically two or three texture units rather than the maximum number of eight. As such the conventional techniques only allow for three stages of multi texturing and the conventional techniques are limited to one pass through the rendering pipeline unless no extra temporary data is required after each pass the pixels are opaque and there is no pixel discarding occurring during each texture stage e.g. color keying .

The present invention relates to systems and methods for providing multi pass rendering of three dimensional graphics. More specifically the present invention is directed to systems and methods for utilizing one or more texture units and a plurality of associated frame buffers in a rendering pipeline to perform multiple rendering passes to support the use and storage of extra temporary data and to blend data from multiple texture maps that is applied to a polygon so as to model a three dimensional object.

Implementation of the present invention includes using a rendering pipeline having one or more texture units and one or more frame buffers to accommodate the application of multiple textures maps onto primitives. The primitives are typically polygons and usually triangles that are used to model a three dimensional object. The values of various parameters used in the rendering process are defined at the vertices of the polygons. These parameters can include x y z 1 w R G B and u v where u and v represent the coordinates of a texture map that is applied to the vertex. Multiple textures can be applied to a given triangle and i represents the texture map number that is applied to the polygon.

In contrast to the processes performed by conventional rendering pipelines the present invention uses one or more texture units and one or more frame buffers to apply multiple texture maps in multiple rendering passes including supporting destination pixel data and temporary data. As such implementation of the present invention includes for example the ability to read from two frame buffers and to write to one frame buffer per pixel. Furthermore each frame buffer can have 32 bit per pixel data split into two 16 bit per pixel pieces of temporary data to allow for the support of up to four pieces of temporary data including the destination pixel data.

Implementation of the present invention includes the ability to render any number of passes 0 8 with the selection of any texture operation. Thus the present invention allows for up to the maximum number of eight completely general purpose texture passes including the bump map and premodulation on any pass.

When a polygon is being rendered a software driver monitors which texture pass is being performed. For each pixel of a frame the only texture coordinate set obtained by the texture unit during the first pass is u v which relates to a first texture map. The texture unit looks up a texture value from a first texture map in a texture map library. The texture value corresponds to the u v texture coordinate set for the pixel and is stored in a temporary frame buffer.

During a second texture pass for the pixel the texture unit obtains a texture coordinate set u v which relates to a second texture map. The texture unit looks up a texture value from a second texture map in the texture map library. The texture value corresponds to the u v texture coordinate set for the pixel. A texture blender blends the texture value of the pixel located in the temporary frame buffer with the texture value obtained during the second pass and stores the composite texture value for the pixel in a second frame buffer. Alternatively the texture value obtained during the second pass is not blended with the texture value of the first pass but is rather stored separately in a second temporary frame buffer. Therefore implementation of the present invention includes supporting the use and or storage of extra temporary data. Depending on the texture operations chosen there are up to two pieces of additional temporary data required between each texture pass and can be supported by implementation of the presenting invention. Thus for example there may not be any additional temporary data required between passes 1 and 2 however two additional pieces of temporary data may be required between two other consecutive passes. A driver examines the texture stage state decides what additional temporary data is required between passes and executes the necessary procedure.

The process described above is repeated so as to allow a texture pass to be performed for every texture map that is to be applied onto a primitive. Furthermore the process is performed for every pixel of a frame. Once performed for every texture map and for every pixel the composite texture values obtained are blended with the destination pixel data stored in a destination frame buffer for all of the pixels of the frame.

Utilization of the invention in rendering a three dimensional object reduces the amount of computing resources that are required to render the object. The only texture coordinate set provided to the texture unit during each pass is the texture coordinate set for the particular texture map that is being processed in the pass. Therefore the elimination of redundant texture coordinate sets for each pixel of every frame optimizes the amount of silicon space i.e. the gates and wires that is required. An alternative implementation allows for multiple cycles per pixel to be taken and saved on successive iterations. Texture data is run through one or more texture units multiple times for maximal throughput. As such in the alternative implementation it is still required to store the extra state for the programmer settings of different texture passes.

Therefore implementation of the present invention utilizes one or more texture units and one or more frame buffers to render a three dimensional object. The frame buffers include up to two frame buffers that can be read on each pass and one frame buffer that can be written to on each pass. Further each buffer can have one piece of data or can be split so as to contain two pieces of data. As such the present invention can accommodate the worst case scenario of one piece of destination frame buffer data and two pieces of texture pass temporary data. Further each texture pass can write a maximum of two pieces of data temporary or otherwise so as to allow for one buffer to be sufficient for which to be written. Additional features and advantages of the invention will be set forth in the description which follows and in part will be obvious from the description or may be learned by the practice of the invention. The features and advantages of the invention may be realized and obtained by means of the instruments and combinations particularly pointed out in the appended claims. These and other features of the present invention will become more fully apparent from the following description and appended claims or may be learned by the practice of the invention as set forth hereinafter.

The present invention extends to both systems and methods for providing multi pass rendering of three dimensional graphics. More specifically the present invention is directed to systems and methods for utilizing one or more texture units and one or more associated frame buffers in a rendering pipeline to perform multiple rendering passes to support the use and storage of extra temporary data and to blend data from multiple texture maps that is applied to a polygon so as to model a three dimensional object.

The embodiments of the present invention may comprise a special purpose or general purpose computer including various computer hardware for rendering three dimensional graphics as will be discussed in greater detail below. Set top boxes that enhance the capabilities of conventional televisions represent an example of a special purpose computer. Examples of a general purpose computer include a personal computer a laptop computer and any other such computer capable of rendering three dimensional graphics.

Embodiments within the scope of the present invention also include computer readable media for carrying or having computer executable instructions or data structures stored thereon. Such computer readable media can be any available media that can be accessed by a general purpose or special purpose computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium which can be used to carry or store desired program code means in the form of computer executable instructions or data structures and which can be accessed by a general purpose or special purpose computer. When information is transferred or provided over a network or another communications connection either hardwired wireless or a combination of hardwired or wireless to a computer the computer properly views the connection as a computer readable medium. Thus any such connection is properly termed a computer readable medium. Combinations of the above should also be included within the scope of computer readable media. Computer executable instructions comprise for example instructions and data which cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions.

Those skilled in the art will appreciate that the invention may be practiced in network computing environments with many types of computer system configurations including personal computers hand held devices multi processor systems microprocessor based or programmable consumer electronics network PCs minicomputers mainframe computers and the like. The invention may also be practiced in distributed computing environments where tasks are performed by local and remote processing devices that are linked either by hardwired links wireless links or by a combination of hardwired or wireless links through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional computer including a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help transfer information between elements within the computer such as during start up may be stored in ROM .

The computer may also include a magnetic hard disk drive for reading from and writing to a magnetic hard disk a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to removable optical disk such as a CD ROM or other optical media. The magnetic hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer executable instructions data structures program modules and other data for the computer . Although the exemplary environment described herein employs a magnetic hard disk a removable magnetic disk and a removable optical disk other types of computer readable media for storing data can be used including magnetic cassettes flash memory cards digital versatile disks Bernoulli cartridges RAMs ROMs and the like.

Program code means comprising one or more program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the computer through keyboard pointing device or other input devices not shown such as a microphone joy stick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface coupled to system bus . Alternatively the input devices may be connected by other interfaces such as a parallel port a game port or a universal serial bus USB . A monitor or another display device is also connected to system bus via an interface such as video adapter . In addition to the monitor personal computers typically include other peripheral output devices not shown such as speakers and printers.

Video adapter generally provides computer with display capabilities which depend on the logical circuitry provided in video adapter and the capabilities of monitor . A video adapter generally provides several different video modes for both text and graphics. In text mode monitor can display only ASCII characters but in graphics mode monitor can display any bitmapped image. A video adapter may include memory not shown so that RAM is not used for storing text and or graphic displays. Furthermore a video adapter may include a graphics co processor not shown for performing graphics calculations.

The computer may operate in a networked environment using logical connections to one or more remote computers such as remote computers and . Remote computers and may each be another personal computer a server a router a network PC a peer device or other common network node and typically include many or all of the elements described above relative to the computer although only memory storage devices and and their associated application programs and have been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN that are presented here by way of example and not limitation. Such networking environments are commonplace in office wide or enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment the computer may include a modem a wireless link or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing communications over wide area network may be used.

While the exemplary system for implementing the present invention illustrated in includes a general purpose computing device in the form of a conventional computer those skilled in the art will appreciate that the present invention may be practiced in a variety of different systems for rendering three dimensional graphics. For example another system for implementing the present invention includes a special purpose computer in the form of a WebTV set top box or similar Internet terminal that has been adapted to perform operations that include composing sending and receiving email browsing the World Wide Web Web accessing other segments of the Internet and otherwise displaying information.

Rendering three dimensional graphics in accordance with the present invention includes utilizing primitives to model the three dimensional objects. The primitives are the basic framing models of the three dimensional objects and are typically made of polygons which are often triangles. Once the polygons are assembled the pixels that are to be included in the polygons are identified and data from texture maps is applied to the polygons to render the three dimensional objects.

A texture map is a graphical image data structure. Each texture map contains graphical image data that can be used to generate text pictures graphical patterns lighting effects etc. The graphical image data can be mapped to individual pixels to render images. Furthermore a plurality of texture maps can be used to map image data to pixels in order to render images with multiple characteristics where each characteristic is obtained from one or more texture maps.

A plurality of texture maps are located in a texture map repository or library so as to be accessible by a texture unit. The image data of a texture map is mapped to x y pixel coordinate positions of the polygons constructed in a rendering pipeline as will be further explained below. An additional discussion as to the use of texture maps is provided in U.S. patent application Ser. No. 09 154 181 entitled DECOMPRESSING AND COMPOSITING GRAPHICAL IMAGE DATA filed Sep. 16 1998 which is incorporated herein by reference.

A process that renders three dimensional objects in accordance with the present invention may be embodied in software as a set of modules or in hardware as a set of processors. Therefore for illustration purposes provides an exemplary relationship among various software modules to perform a process of multi pass rendering of three dimensional objects in accordance with the present invention. The process is generally implemented on a graphics device so as to display the three dimensional objects on a display device . An example of a graphics device is video adapter of .

In structural image data is provided to a pixel setup module . The structural image data includes information specific to the basic framing structure required to model a three dimensional object such as object of . The basic framing structure is generally referred to as a primitive which is typically a triangle but can also be another polygon. An example of a primitive is illustrated in as primitive which is a basic framing structure for a three dimensional sphere. Object is made up of a plurality of primitives most of which are triangles to provide the needed shape to render a three dimensional sphere.

The structural image data of provides coordinate information that corresponds to the various primitives of an object to allow the object such as object of to be assembled and used to model a three dimensional object. Once the primitives are assembled pixel setup module identifies the pixels of a frame that are to be included in the various primitives of the object.

The discrete positioning and relatively low resolution of pixels on a display device cause the vertices of the various polygons to often not correspond directly with a pixel position. Accordingly the positions of the pixels to be lighted on the display device to model the object usually do not precisely correspond to the positions of the vertices of the various polygons. Therefore pixel setup module performs a process of iteratively identifying points that lie within or at the boundary of various polygons and correspond to integer pixel positions. In other words the coordinates defining the polygons are adjusted to integer pixel positions at the screen of the display device as will be further explained below.

Once each polygon of the object is assembled and the corresponding pixels are identified texture maps are referenced and applied to the pixels to render the three dimensional model. The texture maps are located in a map repository or library and texture module performs a look up of the texture coordinate values from the texture map for every pixel identified in pixel setup module . The texture coordinate values looked up for each pixel are stored by buffer module as will be further explained below. When multiple texture characteristics are desired such as a base color and a light source overlaid on the base color one or more texture maps are utilized for each desired texture characteristic in order to obtain texture coordinate values for the identified pixels. Thus for many simple effects for example if two texture characteristics are desired i.e. a base color and a light source two texture maps are referenced. Texture module may also perform other more complicated operations that require the use of a plurality of texture stages whereupon an operation is performed in each stage. One such example is the utilization of the Direct3D BUMPMAP and BUMPMAPENV texture operators where the first stage of BUMPMAP looks up texture data that has been encoded in a texture stored in memory. The texture data is transformed by a matrix to allow the texture to be statically used. The result of the transform is added to a second texture stage s texture coordinates thereby changing the locations that are to be looked up during the second stage. In this example of a more complicated lighting material property effect two textures are required to produce a single effect.

The texture values from the two texture maps for a pixel are blended by blending module and the resulting composite texture coordinate value for the pixel is stored by buffer module . Each of the processes of looking up blending and storing texture coordinate values for pixels is further explained below. Once the texture coordinate values for all of the desired texture maps have been looked up blended and stored the final composite texture coordinate values preserved by buffer module are used to refresh the screen of display device in order to render the desired three dimensional object.

Various parameters are used in the rendering process by the rendering pipeline and once the values are established the parameter values are sent as part of a write command in order to display the three dimension object on a display device. The various rendering parameters include x y z 1 w R G B and u v . As provided above the coordinates of the vertices of the polygons are represented by the coordinates x y and z to establish the position of the polygon in three dimensional space. When rendering a three dimensional object on a two dimensional display screen the coordinate z which corresponds to depth is projected and therefore is not linear on the two dimensional display screen. As such the parameter 1 w which is a homogeneous coordinate is utilized in texturing the polygon. The parameter cc is a blending coefficient that is commonly used to define the transparency of a texture image. The parameter could also be encoded with a fog contribution calculated by the lighting section of the transformation and lighting module. The parameters R G B represent the red green and blue luminous intensity values associated with the particular vertex. When texture maps are used to generate the perception of color on rendered objects the R G B parameters have null values or alternatively have values that are selected to complement the images obtained from the texture maps. The R G B parameters could also be encoded with unit vector coordinates. The parameters u and v represent the coordinates of a texture map where i represents the number of texture maps applied to the polygon. The value of i can be 0 1 2 3 4 5 6 or 7 assuming that the rendering system can accommodate eight texture maps although the number of texture maps is not critical to the invention. In other words up to eight texture maps may be applied to the polygon. The values of the various parameters used in the rendering process are defined at the vertices of the polygons.

In the rendering pipeline includes vertex unit setup unit edge walk unit span walk unit z buffer unit one or more texture address modification units one or more texture units one or more blending units one or more frame buffers texture cache and depth buffer . In response to a command from a user or a software application to render a three dimensional object vertex unit reads a command list that is stored in memory not shown and assembles data that describes the three dimensional values of each vertex of a polygon. The vertex data is passed from vertex unit to setup unit and is expressed in terms of a coordinate system defined by the pixel array of the eventual display screen. As provided above due to the discrete positioning and relatively low resolution of the pixels the vertices of a triangle often do not correspond directly with a pixel position. Accordingly the positions of the pixels to be lighted on the display screen usually do not precisely correspond to the positions of the triangle vertices. Therefore setup unit takes the vertex information for a polygon from vertex unit and computes a few parameters needed by edge walk unit and span walk unit to identify the pixels that are included within the polygon and to perform an interpolation process whereby the values of z 1 w R G B and u v are calculated for the pixel positions based on the value of these parameters at the vertices to perform the process described in greater detail below.

Edge walk unit performs an iterative process of identifying points that lie within or at the boundary of the triangle and correspond to integer pixel positions. Thus edge walk unit determines the starting pixel along with the interpolation parameters of the starting pixel for each horizontal row of pixels lying within the bounds of the polygon. The pixels and the interpolated parameters for all of the pixels of each horizontal row within the polygon are determined by span walk unit .

The coordinates of the pixels and the interpolated parameters are provided to z buffer unit which is a buffer that is large enough to contain a single depth coordinate value for every pixel that is used to render an image. When a rendering pipeline determines that a pixel is to be used to represent a point of a primitive the depth value of the point that is presented by the pixel is transferred to the z buffer unit . Further information relating to the operation of units and is provided in U.S. patent application Ser. No. 09 164 003 entitled SYSTEM AND METHOD FOR ADJUSTING PIXEL PARAMETERS BY SUBPIXEL POSITIONING filed Sep. 30 1998 and U.S. patent application Ser. No. 09 584 463 entitled IDENTIFYING SILHOUETTE EDGES OF OBJECTS TO APPLY ANTI ALIASING filed May 31 2000 both of which are incorporated herein by reference. It is noted that units and are described herein as one example of the components of a rendering pipeline that are used for identifying the parameters of a polygon in preparation for applying multiple texture maps to the polygon and that the multiple pass rendering processes of the invention can be practiced in rendering pipelines that include other units.

Embodiments of the present invention utilize one or more texture units and one or more associated frame buffers in a rendering pipeline. While the rendering pipeline illustrated in includes only one texture unit more than one texture unit may be included in the pipeline to perform separate stages of rendering operations as indicated above. Therefore in one embodiment of the present invention when it is desirable to have a rendering engine to appear to have up to eight texture units the rendering pipeline only includes one or two texture units that are utilized in such a way as to appear as up to eight texture units.

In a single texture unit and multiple frame buffers are respectively illustrated as texture unit and frame buffers . Texture unit is used to access texture maps and apply texture coordinate values in multiple rendering passes and frame buffers store data. Destination frame buffer stores destination pixel data that needs to co exist with temporary data stored in a temporary frame buffer from the passes in order to accommodate the blending of the multiple texture maps that are applied so as to model a transparent three dimensional object. As such embodiments of the present invention can read from two frame buffers and write to one frame buffer per pixel. Furthermore each frame buffer can have the 32 bit per pixel data split into two 16 bit per pixel pieces of data. Therefore embodiments of the present invention also support three pieces of temporary data and one piece of destination pixel data per pixel.

The process for mapping textures to polygons is performed by texture unit frame buffers texture cache and blending unit . While the process is performed on many pixels at the same time in order to improve performance the result is the same as if it were performed on one pixel at a time. In general texture unit receives the implicit x and y coordinates of a pixel and the corresponding u and v texture coordinate values defining a portion of the texture that is to be mapped to the pixel. When the pixel being processed is positioned at a vertex of a polygon the process of identifying the u and v texture coordinate values is relatively simple and involves merely applying the u v texture coordinate values that were explicitly defined at the vertex. However when a pixel positioned at a location other than a vertex of a polygon is processed the appropriate u and v coordinates to be used to map the texture to the pixel are generated by the units and of the rendering pipeline of using an interpolation processed based on the u v texture coordinate values that were explicitly defined at the vertices of the polygon. In this manner texture unit receives the implicit x and y coordinates of pixels and the explicitly defined or interpolated u and v texture coordinate values after they may have been added to the u v values by the texture address modification unit which result from a matrix transform of the original bump map data look up.

When a polygon is being rendered a software driver monitors which texture pass is currently being performed. While up to eight or more texture passes may be performed for each pixel of a frame the following example references a situation where three texture passes are performed for each pixel of a frame. The destination pixel data is stored in the destination frame buffer . In the first texture pass for a particular pixel in the polygon the only u v texture coordinates sent to texture unit are u v . The texture coordinate value is obtained by looking up the value in a desired texture map such as texture map located in a texture map repository or library of texture cache . Therefore texture unit looks up a texture coordinate value for the pixel in texture map of texture cache using the texture coordinates u v and blending units store the texture value e.g. R G B color values associated with the texture coordinates in a temporary frame buffer such as temporary frame buffer

In the second texture pass for the particular pixel the u v texture coordinates are passed to texture unit which looks up a texture coordinate value for the pixel in a second texture map such as texture map of texture cache using the texture coordinates u v . Since texture values associated with a previous texture map was obtained for the pixel from a previous pass blending units blend the texture values for the pixel obtained in the first pass and stored in the temporary frame buffer with the texture value for the pixel obtained in the current pass. The blending of the two sets of texture values results in a composite texture value which is stored in temporary frame buffer

In the third and final texture pass for the particular pixel the u v texture coordinates are passed to texture unit which looks up texture values for the pixel in a third texture map such as texture map of texture cache using the texture coordinates u v . Since composite texture values have been obtained for the pixel from blending the texture values from the two previous pass blending units blend the composite texture value for the pixel that is stored in the temporary frame buffer with the texture values for the pixel obtained in the current texture pass. The blending of the values results in composite texture values that include the texture values obtained from all three passes and is then optionally further blended by blending units with the destination pixel data stored in destination frame buffer . As such an act of modifying the destination pixel data extends to any blending operation between the destination pixel data and texture data from one or more passes or any subsequent texture data that is derived therefrom. The resulting composite texture values for a particular pixel are a set of color luminous intensity values e.g. R G B that are used to control the pixel on the display device when a frame of the display device is refreshed.

While the rendering pipeline of illustrates the use of two frame buffers that are used to store data embodiments of the present invention allow for more than two frame buffers to be utilized to store data. As an example reference is made to that illustrates a portion of another rendering pipeline which includes various collections of modular texture pass units wherein each collection comprises a sufficient set of computing resources to look up and apply a texture contribution. A collection of modular texture pass units comprises for example a texture address modification unit a texture unit and a blending unit. The various collections of modular texture pass units are cascaded N times to result in an embodiment of the present invention with N physical texture stages. The embodiment still presents the same application programming interface behavior of M apparent texture stages by executing multiple passes of the N physical stages until the desired number of apparent texture stages is achieved. As such embodiments of the present invention may present the same application programming interface functionality to an application programmer regardless of the actual number of collections of modular texture pass units assuming at least one such physical collection of modular texture pass units is present. An additional blending unit may also be used to perform other types of blending that are not required on a per texture stage basis.

In the embodiment illustrated in two collections of modular texture pass units e.g. N 2 a texture cache and an additional blending unit are employed. Furthermore while up to eight or more texture passes may be performed for each pixel of a frame the following example references a situation where three texture passes are performed for each pixel of a frame. The destination pixel data is stored in the destination frame buffer . In the first pass for a particular pixel in the polygon the only u v texture coordinates sent to the pipeline are u v and u v . The texture coordinate value for the first coordinate set u v is obtained by utilizing a first collection of modular texture pass units such as modular texture pass units to look up the texture coordinate value in a desired texture map such as texture map located in a texture map repository or library of texture cache . The texture map may represent for example a base map. Therefore modular texture pass units look up a texture coordinate value for the pixel in texture map of texture cache using the texture coordinates u v and blending unit sends the texture values e.g. R G B color values associated with the texture coordinates to the subsequent collection of modular texture pass units namely modular texture pass units .

Modular texture pass units use the u v texture coordinates to look up a texture coordinate value for the pixel in a second texture map such as texture map of texture cache using the texture coordinates u v . Texture map may represent for example a bump map. Instead of being blended with the texture values obtained from the first pass and having the blended texture values stored in a temporary frame buffer temporary frame buffer has been split to create temporary frame buffer and the texture values obtained during the first and second passes are separately stored in temporary frame buffers and . Thus one of the temporary frame buffers e.g. temporary frame buffer would contain the temporary values representing the base map and the other temporary frame buffer e.g. temporary frame buffer would contain temporary values representing the bump map data.

In the final pass texture values from one or more previous passes are utilized to perform a look up for the current pass. Therefore by way of example in the second pass the texture values corresponding to the base map and bump map data are read from temporary frame buffers and and are used by modular texture pass units to perform a look up to a third texture map such as texture map which may represent a specular map. In one example the process includes a matrix transform of the bump map data followed by adding the result to the third set of iterated texture coordinates u v . The results from one or more of the passes are then blended with the destination pixel data stored in the destination frame buffer and used to control the pixels on the display device when a frame of the display device is refreshed.

Therefore if it is determined at decision block that the current pass is not the first pass execution proceeds to step . At step information is retrieved regarding the temporary data output storage frame buffer configuration. This information is retrieved to facilitate frame buffer reading. As provided in step is only executed during non initial passes. Step may also retrieve information regarding any data that is currently stored in the temporary buffer such as the packing and format of the data in order to properly configure the pipeline state that controls the reading of the temporary buffer. Execution then proceeds to step . Alternatively if it is determined at decision block that the current pass is the first pass execution proceeds directly to step .

At step the temporary data output storage that is required for writing on this pass is determined given the texture stage state settings for the current pass number. Subsequently at step the rendering instructions that are specific to the texture stage state for the current pass are written. In other words the driver writes a list of rendering instructions that detail the state implied by the texturing and the texture stage state. These write commands detail the state of the rendering engine which needs to potentially change on a per pass basis due to the various possible multi pass texturing operations that are available on each pass. Execution then proceeds to decision block which determines whether the current pass is the final pass. If it is determined that the current pass is not the final pass execution proceeds directly to step . Alternatively if it is determined that the current pass is the final pass execution proceeds to step where a driver writes the rendering instructions for the final blending. The rendering instructions include among others the alpha blending of the pipeline result with the current data in the destination frame buffer in order to implement transparency. Execution then proceeds to step .

At step rendering instructions are written that are independent of the texture stage for the current pass. Therefore the driver writes rendering instructions that are independent of the multi pass rendering operations and are static for each pass. Execution then proceeds to step which writes the necessary rendering instructions to draw primitives of graphics such as triangles or points. Execution then proceeds to step .

At step the temporary data output storage frame buffer configuration is saved for possible use by the subsequent pass to determine the temporary frame buffer configuration. Step then increments the current pass variable and execution returns to decision block for a determination as to whether or not the multi pass texturing is complete. If it is determined that the multi pass texturing is not complete execution proceeds to decision block which determines that the current pass is not the first pass and then through steps . Execution then returns back to decision block for a determination as to whether or not the multi pass texturing is complete.

Once decision block determines that the multi pass texturing is complete execution proceeds to step which returns to the calling routine. As such the rendering instruction list is now complete for this primitive or group of primitives. The application programming interface driver is called by the application to render each primitive or group of primitives. Then when the scene is complete and the application has sent all of its primitives the application calls the application programming interface driver to indicate that the scene is complete. This indicates to the driver to create additional rendering instructions for the rendering engine to flush caches. The rendering engine is then invoked to complete the rendering of the frame. Once the rendering of the frame has been completed the rendering driver informs the display device driver that a new frame is available and the video refreshing operation flips to this new frame.

Therefore as provided above embodiments of the present invention relate to systems and methods for providing multi pass rendering of three dimensional objects. The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

