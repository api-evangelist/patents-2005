---

title: Dynamic quota policy for queuing mechanism
abstract: Methods and systems for effecting cleanup and other policies for queues and similar data stores, which policies account for preferences of consumers of the data so stored. Queuing policies for local storage of one or more documents for transmission from the local storage to one or more end points for said documents are retrieved from a remote registry. Upon such retrieval, the documents are enqueued according to the queuing policies, unless, prior to such enqueuing the queues into which the documents are to be placed require creation or clean-up, for example according to one or more queue quota policies. In some cases, the documents are queued according to associated qualities of service to be accorded to delivery of said documents. Such qualities of service may be specified in the queuing policy.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07734605&OS=07734605&RS=07734605
owner: Sun Microsystems, Inc.
number: 07734605
owner_city: Santa Clara
owner_country: US
publication_date: 20050822
---
The present invention relates to methods and systems for effecting cleanup and other policies for queues and similar data stores which policies account for preferences of consumers of the data so stored.

Many communication systems employ queuing mechanisms as means for sending and or receiving information. Such mechanisms allow messages information packets or other data items to be collected or otherwise assembled in a holding area prior to transmission at designated transmission times and or to be stored prior to further processing by receivers. The use of these queuing mechanisms thus allows for orderly processing of both incoming and outgoing messages.

All queuing mechanisms implement some form of quota management. By this we mean that queuing mechanisms or the controllers governing same employ some means to limit the size of the storage area e.g. memory used by or accessible to the queues or to handle exceptions such as a full disks memory overruns etc. Such quota managers as implemented by conventional queuing systems are typically not aware of the semantics of the queued messages. However such semantics are often of importance to the end consumers of the queued messages. For example common information types among different messages are often used in different manners by different consumers of such messages and therefore the messages have a different semantics associated with them.

As an example in most quota management systems queue cleanup policies are only loosely coupled to semantics of the messages stored therein as such queues are used as generic containers. While the cleanup policies may include some refinements on how data is selected for removal those policies are generally limited to operating across generic semantics shared by all data types and without regard as to how the data consumer will use or value the data content origin and date.

Consequently what is needed is a queuing mechanism that accounts for preferences or other characteristics of the consumers of the data to be stored in the queues.

In accordance with one embodiment of the present invention a queuing policy for local storage of one or more documents for transmission from the local storage to one or more end points for said documents is retrieved from a remote registry. Both the queuing policy and the remote registry are associated with the offering. Upon such retrieval the documents are enqueued according to the queuing policy unless prior to such enqueuing the queues into which the documents are to be placed require clean up according to one or more queue quota policies. Such queue quota policies may be specified in the queuing policy. In some cases the documents are queued according to associated qualities of service to be accorded to delivery of said documents. Such qualities of service may be specified in the queuing policy. That queuing policy may described in an extensible markup language XML document. Where necessary one or more queues for the documents may be created after retrieving the queuing policy and prior to enqueuing of the documents. In some cases the registry may be co hosted with at least one of the document end points.

In a further embodiment documents are enqueued according to policies associated with an offering prior to delivery to one or more document endpoints. Such enqueuing is preferably to one or more queues of a communication system segregated by quality of service and subject to queue quotas defined by said offerings. The queue quotas may for example define queue cleanups configured to preserve those of said documents useful for said offering to determine trends from data reported by said documents to preserve those of said documents including data indicative of most recent configuration information for assets serviced by said offering and or to preserve documents including data which triggers notifications by said offering. The policies may be prior to such enqueuing retrieved from a registry associated with the offering.

Another embodiment of the present invention provides a system having a first module configured to format a document for transmission from a local document storage location to a remote document endpoint according to first offering specific criteria to produce a so formatted document and a second module communicatively coupled to receive the so formatted document from the first module the second module being configured to enqueue the so formatted document prior to transmission according to second offering specific criteria. The second offering specific criteria may include a queue quota policy for a queue into which the so formatted document is to be enqueued and or may be configured to enqueue the so formatted document into the queue according to a quality of service to be afforded delivery of said so formatted document to said remote document endpoint.

Still a further embodiment of the present invention provides a computer readable medium having stored thereon a set of computer readable instructions which instructions when executed by a computer processor cause the processor to perform a sequence of operations so as to retrieve from a remote registry associated with an offering a queuing policy for local storage of one or more documents for transmission from the local storage to one or more end points for said documents through a communication system accessible by the offering and enqueue said documents according to said queuing policy. Further additional instructions to prior to said enqueuing effect queue quotas by for example certain queue clean up policies as specified by said queuing policy may also be included.

Described herein are methods and systems for effecting cleanup and other policies for queues and similar data stores which policies account for preferences of consumers of the data so stored. Although the present invention will be discussed with reference to certain illustrated embodiments thereof readers should remember that such illustrations and references are not intended to limit the more general scope and nature of the present invention which is best understood by reference to the claims following this description.

Various embodiments of the present invention may be implemented with the aid of computer implemented processes or methods a.k.a. programs or routines that may be rendered in any computer language including without limitation C C C Fortran COBOL PASCAL assembly language markup languages e.g. HTML SGML XML VoXML and the like as well as object oriented environments such as the Common Object Request Broker Architecture CORBA Java and the like. In general however all of the aforementioned terms as used herein are meant to encompass any series of logical steps performed e.g. by a computer processor or other machine in a sequence to accomplish a given purpose.

In view of the above it should be appreciated that some portions of the detailed description that follows are presented in terms of algorithms and symbolic representations of operations on data within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the computer science arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like. It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise it will be appreciated that throughout the description of the present invention use of terms such as processing computing calculating determining displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention can also be implemented with apparatus to perform the operations described herein. These apparatus may be specially constructed for the required purposes or may comprise one or more general purpose computers selectively activated or reconfigured by a computer program stored in or accessible by the computer s . Such a computer program may be stored in a computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The algorithms and processes presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct more specialized apparatus to perform the required method. For example any of the methods according to the present invention can be implemented in hard wired circuitry by programming a general purpose processor or by any combination of hardware and software. One of ordinary skill in the art will immediately appreciate that the invention can be practiced with computer system configurations other than those described below including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics DSP devices network PCs minicomputers mainframe computers and the like. The invention can also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. The required structure for a variety of these systems will appear from the description below.

In one embodiment the present methods and systems are adapted for use within an environment in which offerings i.e. application programs and the like installed at computer systems networks at one ore more user locations communicate with processes running on remote computer systems e.g. servers or other systems as may be installed at data centers service centers etc. . Such an environment may be used for example to provide remote support for the offerings allowing the users of the offerings to be freed from tasks such as installing periodic software updates and patches. Of course many other examples of the use of such an environment exist and the examples presented herein are in no way meant to limit the more general applicability of the present invention. As will become apparent from the discussion below the architecture of this environment includes both an infrastructure made up of common services these may include for example communications data management data visualization etc. and a series of components called offlets that provide customized instances of these common services specific to for an offering.

As the term is used herein an asset can be any element e.g. computer hardware software storage a service processor a mobile phone etc. that can interact with an offering or more generally something the associated offering helps manage or provides some service to. An asset then can be hardware that is adapted to provide a service an operating system running on the hardware and or an application program running on the operating system. The offerings collect information from and or provide information to the assets via network . To support these activities the network includes a common communication architecture managed by a common software infrastructure in particular by instances of a managed services container MSC . The MSC represents the software that can interact either directly or via a proxy with the one or more assets of interest.

Relationships between assets and offlets are flexible inasmuch as servers hosting one or more offlets may be located anywhere and assets can be served by more than one offering through an offlet. Thus the present communications architecture adopts a different model from that found in deployments where a large number of servers report back to a large data center. Such data centers are very expensive to create and to maintain especially for offerings where a large number of assets are participating. By contrast in the present scheme offerings are delivered from any number of different servers that can be distributed anywhere that is network accessible by the assets. No topological restrictions exist. The part of the software infrastructure that supports these sorts of deployments is called the connection offerings platform COP . The COP manages the interfaces provides the infrastructure and contains the common services that offlets need to operate within and hosts the offlets that provide the business technology capabilities to fulfill the overall needs of the offerings.

The second offering incident management is supported by two offlets . One offlet runs on a COP located at a level service provider site the other in the main service provider s premises. Offlets can contain other offlets and in this case the overall incident management offlet contains two offlets. One offlet provides automated incident management and analysis along with a basic knowledge base sufficient to facilitate first level support. If the incident cannot be resolved at this level the incident is escalated by the offlet to a second incident management offlet which contains a more detailed knowledge base so as to facilitate managing the incident to closure.

As shown communication can be MSC to COP e.g. to provide for the transmission of telemetry or the issuing of commands to an offlet for processing and or COP to COP e.g. to support distributed offlet processing . Either or both of these forms of communication can be restricted to an internal network or network of networks or may operate across a wide area network or Internet.

Finally introduces the concept of offering modules which exist within the MSCs to support interaction between the offlets and the assets. The offering modules are designed to facilitate customizations of the common services such as communication services etc. provided by the MSCs for example so as to collect or filter information only relevant to particular assets and offerings.

Recall that an asset can be any combination of hardware and or software. To provide a means of integrating and managing such assets which by their nature can be quite diverse asset modules are provided. Given the diversity of assets available different asset modules for each type of asset monitored or acted upon by offerings provisioned to the MSC may be used to expose the assets native programming communication environment. Stated differently asset modules provide a mapping between that which an asset s native agentry exposes and a common information model e.g. the document model described above used by the MSC . Communication between asset modules and their associated assets can take the form of simple network management protocol SNMP or intelligent platform management interface IPMI communication system calls command scrapings etc.

Asset module thus interacts with the asset and allows for protocol nonnalization i.e. the asset module communicates with the agent using the agent s native protocol or native application programming interface API while providing a common interface inbound into the MSC and data model normalization i.e. the asset module translates the asset s native data model into the common information model used within the network . Asset modules are configured based on the needs of the associated offlet s and abstract the protocol model control variances in the assets.

The documents i.e. messages provided by the asset module are received in the MSC by the offering module . Such offering modules plug directly into the MSC through one or more exposed APIs and access the asset module s as needed through the normalized interface that is exposed to the MSC. Examples of these modules might include modules for asset management software updating hardware fault reporting etc. Each offering module is thus provisioned to support an associated offering hosted on one or more connected COPs .

Upon receipt of a document from the asset module the offering module filters and or formats the document according to the associated offering specific rules for such items. To do so the offering module retrieves the offering rule parameters from a COP registry maintained by the COP hosting the associated offlet. The COP registry is discussed further below. This retrieval may be done via a lookup module which may include a local cache used to store locally copies of the offering parameters i.e. configuration information so as to minimize the need for communications between the offering module and the COP . The offering parameters returned to the offering module may include the destination for the document e.g. a URI of a data store for the message at the COP or elsewhere the quality of service for the delivery of the document filtering patterns to employ e.g. XML path language expressions to specify the locations of structures and data within an XML document and or a method to use in sending the document e.g. simple object access protocol SOAP Java messaging service JMS representational state transfer REST hypertext transfer protocol HTTP etc. .

The offering specific rules obtained from the COP registry or lookup module cache essentially customize the general communications infrastructure provided by the MSC . Based on these rules the offering module prepares and formats the document received from the asset module and passes the now offering specific formatted document to the communication module for delivery to the document endpoint at COP or elsewhere as specified by the URI returned from the registry . Communication module may include one or more queues for storing such documents prior to transmission to the document endpoint for example as a means for providing various document delivery quality of service QoS . Documents are transmitted using the method and QoS defined by the offering.

From the above it should be apparent that COP acts in various capacities for example as a data aggregation point a services aggregation point and a knowledge delivery vehicle. A COP s role in the overall network is defined by the offerings that it supports its relationship with other COPs and its relationships with its MSCs. It is important to note it is the offering that determines the platform s behavior the data transmission and the knowledge application. The COP simply provides the common features that allow this to happen.

The COP registry is a container that persistently stores configuration and topology information for an instance of the COP to operate in the network. To reduce complexity in management and administration of the network everything a COP needs to operate with its associated assets MSCs provisioned offerings and even other COPs may be stored in the registry for example 

Information exchange between the COP and MSC is bidirectional but the communications will always be initiated by the MSC . As indicated above such communications are initiated by the MSC s lookup module seeking for example an address e.g. a URI of a document end point from the COP registry for the specific type of document to be sent. Once the address of the end point is known the MSC can send the document to that address. An inbound message broker not shown at the COP may receive and dispatch the document to an appropriate message handler which may then process and parse the document and trigger the appropriate business process.

The reverse data flow from the COP to the MSC is similar. When an offering needs to send information back to or execute a command on a specific MSC it will perform a lookup to retrieve the specific address for the MSC endpoint. The message is then dispatched to an appropriate outbound message broker for eventual retrieval by the MSC e.g. through an intermittent polling mechanism . The actual data flow may depend on the messaging system used to implement the outbound message broker and or the type of connection that exists between the MSC and the COP . All of these communications may be managed asynchronously such that once a message is committed to an appropriate message broker the sender can continue processing other documents.

The document queues are specific per offering and per QoS transport endpoint. That is different queues may exist for documents having different QoS transmission parameters different transport mechanisms and or different endpoints. Documents are transmitted out of the queues according to triggers which may be event driven or time driven or both under offering specific policy control. Outbound documents are passed to a sender module appropriate for the type of transport to be used and the sender module transmits the documents to the associated endpoint .

To summarize then before inserting a new document in any queue the communication module will call a queue quota manager . The quota manager will for each queue or for the document s targeted queue and based on the policies associated with the subject queue s determine whether or not the subject queue s has have reached its their limits. If so the quota manager will call an associated cleanup procedure. The order of how the queues and quotas are checked is defined either on a per queue based limit or by a global queue limit setting associated with an ordering mechanism to call in order the cleanup processes. This global mechanism will decide in which order the queues will be cleaned up when the global limit is reached. One the clean up procedures have been completed if they were in fact performed then for a document for which the COP registry lookup has returned a quality of service that document is queued in the associated queue for the specific offering and QoS. If such a queue does not yet exist within the communication module the communication module will create it. For a document for which the COP registry lookup has returned no QoS the document will be stored with like documents i.e. those with no associated QoS in a single queue. Documents are transmitted out of their respective queues according to triggers event driven or otherwise .

Thus the present communication mechanism provides the ability to delegate definitions for queue quotas and cleanup policies to the final destination i.e. the offering of the data being queued. Before inserting a new document in a queue the communication module will call a sub component handling queue quota management. The quota manager will for each queue affected by the receipt of the document and based on the policies associated with such queue s determine whether or not the subject queue has reached its quota as defined by the offering parameters. If so the queue manager will call the cleanup procedure s appropriate for the subject queue. The order and manner of the quota check queue cleanups may be defined on a per queue based limit or by one or more global queue settings associated with an ordering mechanism to call in order the cleanup procedures. This global mechanism will decide in which order the queues will be cleaned up when the global limits are reached. In one example the cleanup process may see the non QoS queue cleaned first followed by cleanup of the remaining queues in a priority order.

Importantly the queue cleanups are driven by a dynamic update of the offering associated parameters and on a per QoS queue basis. Among the advantages of such an approach are the ability to dynamically change queuing policies even for the documents already enqueued as the policies are associated with the queues themselves and not the documents and as they can be updated for each new queued documents all the documents of an existing queue may be subjected to the new policy and the ability to let the offering which is the entity having knowledge of the final semantics of the document chose the cleanup policy.

Thus methods and systems for effecting cleanup and other policies for queues and similar data stores which policies account for preferences of consumers of the data so stored have been described. Although discussed with reference to some specific examples however the scope of the invention should only be measured in terms of the claims which follow.

