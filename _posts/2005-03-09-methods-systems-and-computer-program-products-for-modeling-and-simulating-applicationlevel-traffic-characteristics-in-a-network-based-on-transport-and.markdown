---

title: Methods, systems, and computer program products for modeling and simulating application-level traffic characteristics in a network based on transport and network layer header information
abstract: Methods, systems, and computer program products are disclosed for determining application-level traffic characteristics in a network based on transport and network layer header information. Transport and network layer header information is collected from packet traffic in a network. Packets are classified to different connections based on the transport and network layer header information. Each connection is modeled using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions. Application-level characteristics of the packet traffic are determined based on the modeled connections. Simulated traffic that models application-level traffic behavior in a real network may also be generated by simulating traffic connections based on the modeled connections.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07447209&OS=07447209&RS=07447209
owner: The University of North Carolina
number: 07447209
owner_city: Chapel Hill
owner_country: US
publication_date: 20050309
---
This application claims the benefit of U.S. Provisional Application No. 60 551 559 filed Mar. 9 2004 the content of which is incorporated by reference herein in its entirety.

This invention was made with U.S. Government support under Grant Nos. ANI 03 23648 and ITR 00 82870 awarded by the National Science Foundation. The U.S. Government has certain rights in the invention.

The subject matter described herein relates to communication network traffic modeling and simulation. More particularly the subject matter described herein relates to modeling and simulating application level traffic characteristics for a communications network based on transport and network layer header information.

Evaluating the performance of network protocols and mechanisms conventionally requires careful experimentation in simulators and testbed environments. As with any other performance analysis task a critical element of these experiments is the availability of a realistic workload or set of workloads that can stress the technology in a manner that is representative of the deployment conditions. Despite the increasing availability of measurement results and packet traces from real networks there is currently no accepted method for constructing realistic workloads. Consequently networking researchers and performance analysts have relied on simplistic or incomplete models of network traffic for their experiments.

One essential difference between network workloads and other workloads such those of storage systems is the closed feedback loop created by the ubiquitous Transport Control Protocol TCP . This protocol responsible for the end to end delivery of the vast majority of the traffic on the Internet reacts to network conditions by retransmitting lost packets and adjusting sending rates to the perceived level of congestion in the network. As a consequence it is not enough to simply collect a trace of packets traversing a network element and replay the trace to conduct experiments since the new conditions in the experimental environment would have had an effect on the behavior of TCP that is not present in the packet trace. In other words replaying a packet trace breaks the feedback loop of TCP. For example it is incorrect to collect a packet trace in a 1 Gbps link with a mean load of 650 Mbps and use it to evaluate a router servicing an optical carrier OC link transmitting at 622 Mbps OC 12 because the replay would not capture the back off effect of TCP sources as they detect congestion in the overloaded OC link. The analysis of the results of such an experiment would be completely misleading because the traffic represents a set of behaviors of TCP sources that can never occur in practice. For example the rate of queue overflow would be much larger in the experiment than in a real deployment where TCP sources would react to congestion and reduce the aggregate sending rate below the original 650 Mbps thereby quickly reducing the number of drops . In such an scenario an experiment that included estimating a metric related to response time for example by looking at the duration of each TCP connection would result in detecting virtually no difference between the original trace and the replay. In reality however the decrease in sending rate by the TCP sources in the congested scenario would result in much longer response times. Thus valid experiments must preserve the feedback loop in TCP. Traffic generation must be based on some form of closed loop process and not on simple open loop packet level replays.

The fundamental idea of closed loop traffic generation is to characterize the sources of traffic that drive the behavior of TCP. In this approach experimentation generally proceeds by simulating the use of the simulated or real network by a given population of users using applications such as file transfer protocol FTP or web browsers. Synthetic workload generators are therefore used to inject data into the network according to a model of how the applications or users behave. This paradigm of simulation follows the philosophy of using source level descriptions of applications advocated in Wide area traffic the failure of Poisson modeling Floyd et al. IEEE ACM Transactions on Networking 3 3 226 244 1995. The critical problem in doing network simulations is then generating application dependent network independent workloads that correspond to contemporary models of application or user behavior.

The networking community however lacks contemporary models of application workloads. More precisely validated tools and methods to go from measurements of network traffic to the generation of synthetic workloads that are statistically representative of the applications using the network are needed. Current workload modeling efforts tend to focus on one or a few specific applications. One example of a workload modeling method includes modeling web browsers. The status quo today for modeling web workloads uses a set of generators that are based on web browsing measurements that were conducted several years ago. The web browser measurements were based on a limited set of users. The measurements have not been maintained and updated as uses of the web have evolved. Thus even in the case of the most widely studied application there remains no contemporary model of HTTP workloads and no model that accounts for protocol improvements e.g. the use of persistent connections in HTTP v1.1 or newer uses of the web for peer to peer file sharing and remote email access.

A major limitation of current source level modeling approaches is that they construct application specific workload models. Given the complexity inherent in this approach e.g. the effort involved in understanding measuring and modeling specific application layer protocols it is understandable that workload models usually consider only one or a small number of applications. However few if any networks today carry traffic from only one or two applications or application classes. Most links carry traffic from hundreds or perhaps thousands of applications in proportions that vary widely from link to link.

This issue of application mixes is a serious concern for networking researchers. For example in order to evaluate the amount of buffering required in a router under real conditions or the effect of a TCP protocol enhancement one of the factors to be considered is the impact on from the applications that consume the majority of bandwidth on the Internet today and that are projected to do so in the future. It would be natural to consider the performance implications of the scheme on web usage e.g. the impact on throughput or request response response times on peer to peer applications streaming media other non interactive applications such as mail and news and on the ensemble of all applications mixed together. The majority of previous work in workload modeling has focused on the development of source level models of single applications. Because of this there are no models for mixes of networked applications. Worse the use of analytic distribution based models of specific TCP applications does not scale to developing workload models of application mixes comprised of hundreds of applications. Typically when constructing workload models the only means of identifying application specific traffic in a network is to classify connections by port numbers. For connections that use common reserved ports e.g. port 80 one can in theory infer the application level protocol in use HTTP and with knowledge of the operation of the application level protocol construct a source level model of the workload generated by the application. However one problem with this approach for HTTP is that a number of applications such as simple object access protocol SOAP are essentially using port 80 as an access mechanism to penetrate firewalls and middleboxes.

A deeper problem with this approach is that a growing number of applications use port numbers that are not readily known e.g. they have not been registered with the Internet Assigned Numbers Authority IANA . Worse many applications are configured to use port numbers assigned to other applications allegedly as a means of hiding their traffic from detection by network administrators or for passing through firewalls. For example in a study of traffic received from two broadband Internet service providers by AT T in 2003 the source application of 32 48 of the bytes could not be identified. Similarly analyses of backbone traffic in Sprint and Internet2 networks did not identify the source of 25 40 of bytes depending on the studied link. However even if all connections observed on a network could be uniquely associated with an application constructing workload models requires knowledge of the sometimes proprietary or hidden application level protocol to deconstruct a connection and understand its behavior. This is a very time consuming process and doing it for hundreds of applications or even the top twenty in network traffic is a daunting task.

Conventional methods have been unable to construct statistically sound workload models from network packet traces that capture the richness in the mix of applications using a given link without requiring knowledge of the associated application level protocols. Accordingly there exists a need for methods systems and computer program products for modeling and simulating application level traffic characteristics in a network based on transport and network layer header information which is application neutral.

In one aspect of the subject matter disclosed a method is disclosed for determining application level traffic characteristics in a network based on transport and network layer header information. Transport and network layer header information is collected from packet traffic in a network. Packets are classified to different connections based on the transport and network layer header information. Each connection is modeled using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions. Application level characteristics of the packet traffic are determined based on the modeled connections.

In another aspect of the subject matter disclosed a method is disclosed for generating simulated traffic that models application level traffic behavior in a real network. Transport and network layer header information is collected from packet traffic in a network. Packets are classified to different connections based on the transport and network layer header information. Each connection is modeled using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions and recording a start time and an end time for each connection. Simulated traffic connections are generated based on the modeled connections.

In another aspect of the subject matter disclosed a computer program product is disclosed that includes computer executable instructions embodied in a computer readable medium for collecting transport and network layer header information from packet traffic in a network classifying packets to different connections based on the transport and network layer header information modeling each connection using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions and determining application level characteristics of the packet traffic based on the modeled connections.

In another aspect of the subject matter disclosed a computer program product is disclosed that includes computer executable instructions embodied in a computer readable medium for collecting transport and network layer header information from packet traffic in a network classifying packets to different connections based on the transport and network layer header information modeling each connection using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions and recording a start time and an end time for each connection and generating simulated traffic connections based on the modeled connections.

In another aspect of the subject matter disclosed a system is disclosed for determining application level traffic characteristics in a network based on transport and network layer header information the system includes logic configured to collect transport and network layer header information from packet traffic in a network and logic configured to classify packets to different connections based on the transport and network layer header information. The system also includes logic configured to model each connection using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions and logic configured to determine application level characteristics of the packet traffic based on the modeled connections.

In another aspect of the subject matter disclosed a system is disclosed for generating simulated traffic that models application level traffic behavior in a real network. The system includes logic configured to collect transport and network layer header information from packet traffic in a network and logic configured to classify packets to different connections based on the transport and network layer header information. The system also includes logic configured to model each connection using an abstract syntax for characterizing bidirectional interactions between endpoints of each connection and delays between the interactions and recording a start time and an end time for each connection and logic configured to generate simulated traffic connections based on the modeled connections.

To facilitate an understanding of exemplary embodiments many aspects are described in terms of sequences of actions that can be performed by elements of a computer system. For example it will be recognized that in each of the embodiments the various actions can be performed by specialized circuits or circuitry e.g. discrete logic gates interconnected to perform a specialized function by program instructions being executed by one or more processors or by a combination of both.

Moreover the sequences of actions can be embodied in any computer readable medium for use by or in connection with an instruction execution system apparatus or device such as a computer based system processor containing system or other system that can fetch the instructions from a computer readable medium and execute the instructions.

As used herein a computer readable medium can be any means that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device. The computer readable medium can be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus device or propagation medium. More specific examples a non exhaustive list of the computer readable medium can include the following an electrical connection having one or more wires a portable computer diskette a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber and a portable compact disc read only memory CDROM .

Thus the subject matter described herein can be embodied in many different forms and all such forms are contemplated to be within the scope of what is claimed. Any such form of embodiment can be referred to herein as logic configured to perform a described action.

Careful observation has shown that from the perspective of the network the vast majority of application level protocols are based on a few patterns of data exchanges within a logical connection between the endpoint processes. is a block diagram illustrating network traffic seen at different levels of abstraction according to an aspect of the subject matter described herein. As illustrated by the traffic on an Internet link monitored at a point in the link can be seen as an aggregate of packets from many different connections. Each connection is driven by an application running at each of the two associated endpoints. For example a web connection is used to transport requests for uniform resource locators URLs and web objects such as hypertext markup language HTML source code and image files. For TCP applications the arrivals of packets within a connection are a function of the source behavior of the application and the congestion control and windowing mechanisms of the transport protocol. Each application has a different set of messages and objects that are exchanged between the two endpoints.

As illustrated in however there exists a level of abstraction i.e. an abstract source level at which all connections are doing nothing more than sending data back and forth and waiting for application events. This abstract source level may be used for modeling traffic mixes in a manner that is suitable for generating closed loop traffic. According to an important aspect of the subject matter described herein the data exchanges that occur in abstract source level or can be modeled through analysis of network and transport layer header information and without knowledge of the applications . Methods for characterizing source level behavior in a network through analysis of packet traces will be described in detail below. Because application behavior can be characterized without knowledge of the applications themselves traffic modeling and simulation can be simplified over conventional modeling or simulation methods that require simulation of application protocols. In the two endpoint processes exchange data in units defined by their specific application level protocol . The sizes of these application data units ADUs depend only on the application protocol and the data objects used in the application and therefore are largely independent of the sizes of the network dependent data units employed at the transport level and below. For example the sizes of HTTP requests and responses depend on the sizes of headers defined by the HTTP protocol and the sizes of files referenced but not on the sizes of TCP segments used at the transport layer.

One common ADU exchange pattern used by TCP applications arises from the client server model of application structure such as in the case of a web server and browser and includes a single ADU exchange. is a block diagram illustrating a pattern of ADU exchange over time in an HTTP connection between a web browser and a web server that may be modeled or simulated using the methods and systems described herein. In web browser sends an HTTP Request to web server which sends a Response with the requested object s . In this example Request includes 341 bytes due to the HTTP header and the length of the file name for the file being requested. HTTP Response includes 2555 bytes which includes the HTTP header and the file being requested. The time interval between Request and Response depends on network or end system properties that are not directly related to or under the control of the application.

In a sample sequence of ADUs exchanged by two simple mail transfer protocol SMTP servers over an SMTP connection is shown. In this case most data units are small and correspond to application level control messages e.g. the host info message the initial HELO message etc. rather than application objects e.g. the actual email message of 22 568 bytes .

According to an aspect of the subject matter described herein the ADU exchange pattern can be modeled as one or more epochs where each epoch consists of either 0 or 1 ADU from each endpoint followed by an inter epoch time interval or the end of the logical connection . Thus a TCP application can be modeled as generating a number of time separated epochs where each epoch is characterized by ADU sizes and an inter epoch time interval. More particularly the source level behavior in which each TCP connection is represented by a connection vector C e e . . . e can be modeled with n epochs e. Each epoch is a triplet of the form e a b t that describes the data a b and quiet time t parameters of the j th exchange in a connection. Each acaptures the amount of data sent from the initiator of the connection e.g. a web browser to the connection acceptor e.g. a web server and each brepresents data flowing in the other direction. Using this model the connection shown in can be described as where the first ADU a has a size of 341 bytes and the second ADU b has a size of 2 555 bytes and represents the end of the logical connection. Similarly the SMTP connection in can be represented as . As this last connection vector shows application protocols sometimes have a single ADU in an epoch e.g. a 0 for SMTP and b 0 for FTP data . This model referred to hereinafter as the a b t model of a connection captures three essential source level properties of a TCP connection data in the a direction data in the b direction and quiet times t between data units.

One problem with identifying ADU sizes based on network and transport layer information occurs when ADUs between endpoints of a connection overlap in time. When data packets from each connection endpoint overlap in time it may be difficult to determine when an ADU from one endpoint is complete. is a block diagram illustrating a pattern of ADU exchanges that overlap in time i.e. are concurrent between two endpoints of a connection according to another aspect of the subject matter described herein. In an NNTP connection is shown between two NNTP peer servers in which NNTP s streaming mode is used. An article is the last data unit on the initiator side with a size of 15 678 bytes and coincides with two data units and that were sent from the acceptor side two 438 don t send messages . Therefore this connection is said to exhibit data exchange concurrency. In contrast the connections illustrated in FIGS. and A C illustrate exchanging data units in a sequential fashion.

A fundamental difference between concurrent and sequential communication exchanges is that sequential exchanges e.g. request response always take a minimum of one round trip time. Although data exchange concurrency is much less common than sequential communication exchanges application designers make use of data concurrency for two primary purposes. The first is to maximize the use of bandwidth and time associated with the connection i.e. keep the pipe full by making use of requests that overlap with uncompleted responses. This avoids the one round trip time per epoch cost associated with a sequential request response exchange so the connection can be fully utilized. Examples of protocols that attempt to keep the pipe full are the pipelining mode in HTTP the streaming mode in NNTP and the BitTorrent and Rsync protocols. The second purpose is supporting natural concurrency in the sense that some applications do not need to follow the traditional request response paradigm. Examples of protocols applications that support concurrency are instant messaging and Gnutella in which the search messages are simply forwarded to other peers without any response message .

According to an aspect of the subject matter described herein data concurrent connections may be modeled by considering each direction of the connection independently. is a block diagram illustrating parameters that can be used for modeling data concurrent connections according to an aspect of the subject matter disclosed herein. In the blocks and time periods above the time line represent data being sent by endpoint A to endpoint B and the blocks and time periods below the timeline represent data being sent from endpoint B to endpoint A. It can be seen from that aoverlaps with band aoverlaps with b.

Using a modeling method according to an aspect of the subject matter described herein each direction of the connection can be modeled independently by a respective connection vector of the form for packets leaving endpoint A and for packets leaving endpoint B where aand brepresent the size of the j th ADU for each respective direction and tand trepresent the time between respective ADUs. Using two independent vectors provides enough detail to capture the two purposes of the data concurrency described above since in the first case one side of the connection completely dominates so only one of the connection vectors matters and in the second case the two sides are completely independent.

Modeling TCP connections as a pattern of ADU transmissions provides a unified view of Internet information exchanges that does not require knowledge of the specific applications driving each TCP connection. The first step in the modeling process is to acquire empirical data and process that data to produce an a b t model. is a block diagram illustrating a system for monitoring packet traffic on a link according to an aspect of the subject matter disclosed herein. In a packet trace monitor collects packet traces that provide IP source and destination information as well as TCP header information from a link associated with one or more networks . For example packet trace monitor may be a processor based system running computer executable code to perform passive tracing of TCP IP packet headers. An example of packet trace code suitable for collecting TCP IP packet headers includes tcpdump which is accessible by a command on most Unix based operating systems. Packet trace monitor performs packet trace data acquisition for capturing unidirectional and or bidirectional traces. For each packet monitored an IP source address and an IP destination address is determined TCP sequence and port information is determined and a timestamp indicating the relative point in time that the packet was monitored is associated with the packet. Packet trace analyzer analyzes the data and generates the a b t models described above for each connection. Although packet trace monitor and trace analyzer are shown as logically separate functions but it should be appreciated that they may be performed by the same processor based system running computer executable code.

In order to generate the a b t traces trace analyzer preferably analyzes TCP sequence numbers. As a preliminary step trace analyzer may identify packets associated with the same connection using a combination of source IP address destination IP address source TCP port and destination PCT port. TCP connection establishment and connection terminating exchanges may be used to identify the start and end of each connection. Once the packets associated with each connection have been identified data sequence numbers acknowledgement sequence numbers and time stamps may be used to identify ADUs and time periods between ADUs. is a schematic diagram illustrating a TCP packet segment . In TCP header and data together comprise a TCP packet. TCP header includes a 16 bit source port identifying the port used by the source of the packet a 16 bit destination port identifying the port to which the packet is destined a 32 bit sequence number identifying the current position of the first data bytes in the packet within the entire byte stream for the TCP connection after reaching 2 1 this number will wrap around to 0 a 32 bit acknowledgment number identifying the next data byte the sender expects from the receiver one greater than the most recently received data byte and additional bits such as control bits header length window size and others.

According to one aspect of the subject matter described herein sequence numbers and acknowledgment numbers can be used to determine ADU sizes as well as a change in the directionality of data transmission. In for example the boundary between the first data unit a which was transported using a single packet and had a size of 341 bytes and the second data unit b which was transported using two packets and had a size of 2 555 bytes can be detected by analyzing when sequence numbers stop increasing in one direction and start increasing in the opposite direction.

More particularly headers for TCP segments flowing in one direction of a connection may be monitored by packet trace monitor . When unidirectional traces are captured changes in sequence numbers in TCP segments are used to compute ADU sizes flowing in the direction traced and changes in ACK values are used to infer ADU sizes flowing in the opposite not traced direction. Unidirectional trace capture works best with sequential and alternating ADU exchanges one in each direction per exchange as found in FIGS. and A C. In such a case there is an alternating pattern of advances in the ACK sequence number values followed by advances in the data sequence number values or vice versa . Consequently the beginning and ending TCP segments of an ADU and the boundary between exchanges may be determined. Stated differently an advance in the data sequence numbers marks the end of an ADU flowing in the direction opposite to the traced direction and an advance in the ACK sequence number marks the end of an ADU flowing in the direction of the trace. Other events such as FIN or Reset can also mark ADU boundaries. Timestamps indicating when the segments were monitored by the packet trace monitor may be used to mark the beginning or end of an ADU and to compute the inter epoch times and timestamps on the SYN segments may be used to compute connection inter arrival times. Accordingly TCP headers of packets traveling in only one direction may be analyzed to determine the bidirectional traffic on the link according to an aspect of the subject matter disclosed herein.

In for example ADU sizes exchanged in both directions between web browser and web server may be determined based on analyzing sequence numbers and or acknowledgement numbers in TCP packet headers transmitted in one direction from web browser to web server or vice versa . For example web browser transmits messages seqno 341 ackno 1 and ackno 2556 in the direction of web server . Analysis reveals that message includes an acknowledgement number of 1 indicating no application data has been previously sent in the opposite direction. Further analysis reveals that message includes 341 bytes of application data as indicated by sequence number 341. The next transmission from web browser to web server is ACK message with an acknowledgement number of 2556 indicating that 2 555 2 556 1 bytes were transmitted from web server to web browser . The FIN ACK message indicates that no further application data is to be sent for this connection.

Applying the foregoing analysis to a trace of the TCP IP headers from the connection illustrated in an a b t connection vector C with a start time T is produced. The connection vector Cconsists of three epochs corresponding to the three HTTP request response exchanges. This vector represents a web browser and a web server using a TCP connection the browser initiated at Tas a persistent HTTP connection where the browser sends three HTTP requests of 329 403 and 365 bytes respectively and the server responds to each of them with HTTP responses including object content of 403 25821 and 1198 bytes respectively. The second request was sent by the browser 120 milliseconds after the last segment of the first response was received and the third request was sent 3120 milliseconds after the second response was received. There were 29 TCP segments including SYNs and FINs in the original packet header trace but their sizes and timing are network dependent and the analysis has produced a summary representation in this connection vector that models the source level browser and server behaviors.

The logical data ordering described above can create accurate models for data traffic. The accuracy of the network traffic model can be improved however by monitoring data in both directions in order to better consider data concurrent connections such as the one shown in . For example the packet that carried the last b type data unit may have been sent roughly at the same time as another packet carrying some of the data of the a type data unit sent from the other side. Sequence numbers will show that these two packets do not acknowledge each other so it cannot be determined whether the data in one of them was supposed to logically come before the data in the other packet. Accordingly both directions of a link may be monitored separately to produce connection vectors as described above with reference to . This approach results in more accurate network traffic modeling that includes the less common data concurrent connections according to another aspect of the subject matter disclosed herein.

Moreover the observation that sequence numbers of two packets do not acknowledge each other makes it possible to detect data concurrency. According to another aspect of the subject matter disclosed herein a method for detecting data concurrency in a connection is disclosed herein. A connection is considered to be concurrent when there exists at least one pair of non empty TCP packets p and q such that p is sent from the initiator to the acceptor q is sent from the acceptor to the initiator and the two inequalities p qand q pare satisfied. If the conversation between the initiator and the acceptor is sequential then for every pair of segments p and q either p was sent after q reached the initiator in which case q p or q was sent after p reached the acceptor in which case p q. Thus every non concurrent connection can be classified based on the associated sequence numbers and acknowledgment numbers. Using this methodology concurrent exchanges of data are detected not just concurrent exchanges of packets in which a data packet and an acknowledgment packet are sent concurrently. In the latter case the logical ordering of data inside the connection is never broken. Similarly the simultaneous close mechanism in TCP in which two FIN packets are sent concurrently is not considered to be data concurrency.

The methods and systems described herein may be utilized to derive source level behavior from TCP level exchanges even when packets are lost and retransmitted at the TCP level. is a signaling diagram illustrating a TCP level exchange in which a packet is lost and retransmitted. In the first data packet of the ADU sent from the web server is lost somewhere in the network. Web server learns that the data packet with data sequence number was lost when web server receives the acknowledgement message from web browser with an acknowledgement number of 1 rather than 2556. Once this acknowledgment message is received web server retransmits the 1460 byte data packet. Depending on where in the transmission path the analysis is performed before or after the point of loss the analyzed TCP packet header trace may or may not include the first instance of the packet with end sequence number 1460. If this packet is present in the trace the analysis will reveal that the third data packet from a web server is a retransmission so it should be ignored and the size of the data should be 2 555 bytes. If the lost packet is not present in the trace the analysis will reveal the reordering of packets using their sequence number and a size for bof 2 555 bytes.

According to another aspect of the subject matter described herein a packet trace monitor can measure ADU sizes in the presence of arbitrary packet reordering and loss on a connection. For sequential connections the starting point is the observation that despite the possibility of loss and reordering data in a TCP connection has a unique logical ordering otherwise the connection would not be transmitting useful data . For example the data in the retransmitted segment in logically precedes the data in the previous data packet since the sequence number of the retransmitted packet is lower. Accordingly packet trace monitor can monitor packets in arrival order and insert a summary of each packet into a data structure that captures the logical data ordering in a TCP connection and also uses the timestamps to compute the inter epoch quiet times. The timestamp of the SYN packet may be used to compute the connection start time T relative to the beginning of the trace. In practice however the starting sequence numbers of a TCP connection are randomized so the sequence numbers of both the SYN and FIN packets are preferably used to determine the boundaries of the connection. Furthermore packet trace monitor preferably detects sequence number wrap arounds since TCP sequence numbers are represented using only 32 bits.

The a b t model provides a framework for the systematic identification and study of application level communication patterns in Internet traffic. Statistical clustering techniques may be applied to determine application level characteristics of the packet traffic. For example connections can be grouped into traffic classes that represent similar communication patterns. A clustering scheme may be employed to divide a given set of connection vectors having similar features into groups known as clusters. Each connection vector is summarized using a vector of statistical features called a feature vector. Each feature can capture some relevant characteristics of the sequence such as the number of exchanges the total number of bytes sent by the initiator the homogeneity in the sizes of the data units and the like. The similarity between two connection vectors may then be measured by the similarity between their associated feature vectors. More particularly the clustering of source level communication patterns begins by extracting from each connection vector a number of numerical features that are designed to capture important aspects of the two way data transfer it describes. Some features that may be collected for each connection vector include the number of epochs the number of bytes sent by each of the connection endpoints the size of the largest and or smallest epoch in each direction as well as the mean and standard deviation of the set of epochs in each direction. Once these and other features are analyzed feature vectors can be associated with the connection vectors which may then be grouped according to their features to perform application level analysis. That is application level characteristics of each group can be determined.

For example with reference again to feature vectors can be computed for each illustrated connection. A feature vector F a b c d e that includes values for the number of epochs a the number of bytes sent by each of the connection endpoints b c the size of the largest ADU d and the size of the smallest ADU e in that order may be computed for each of the connections illustrated in . The resulting feature vectors F F and Ffor the connections illustrated in B and C respectively are shown below 

The similarity between two connection vectors can be determined by measuring a Euclidean or correlation type distance between their feature vectors. Once the distance between each pair of connection vectors has been determined connection vectors can be grouped using a clustering algorithm. In the current example the similarities between feature vectors F F and Fwill be shown to be limited based on the distance between the vectors. This follows from the fact that each vector is representative of features from a different application. If however a feature vector is computed for a second HTTP connection it will be more similar i.e. closer in distance to feature vector Fthan feature vectors Fand F. Accordingly the second HTTP connection would be more likely to be grouped with the connection illustrated in .

Formally a clustering scheme is a procedure that divides a given set of feature vectors x x . . . x R into k disjoint groups S S . . . S which are known as clusters. The goal of clustering is to find a small number k of clusters such that feature vectors within the same clusters are close together while vectors in different clusters are far apart. Once an application level connection vector is determined from a transport connection the connection vector is summarized using a feature vector. The similarity between two connection vectors can then be determined by the similarity between their associated feature vectors. Two alternative distance measures may be considered here the standard Euclidean distance as shown in Equation 1 below 

As a first step in clustering source level communication patterns a number of numerical features that are designed to capture important aspects of the two way data transfer it describes can be extracted from each connection vector. Let v c . . . c be a given connection vector whose j th epoch is given by the triplet c a b t as described above. The most critical features of v are the number of epochs denoted by e and the total number of bytes sent by each of the connection hosts 

To assess the relationship between the a and b type data units v directionality dir log a b and the lag 0 and 1 cross correlations between B and A denoted pand prespectively can be measured. Rank correlations typically exhibit a more diverse and meaningful spectrum of values across different connections. Thus correlation measurements may be based on a Spearman s rank correlation coefficient rather than the more common Pearson coefficient.

Regarding scale while correlations will range between 1 and 1 features such as e and acan range anywhere from one to several million. To address this disparity one can take logarithms of those features that vary over several orders of magnitude. Each feature is then translated and scaled so that for the vast majority e.g. more than 96 of measured connections its value is between 0 and 1. In exceptional cases e.g. a connection with 10epochs features greater than 1 or less than 0 can be allowed. Allowing features to take values outside the unit interval avoids the possible compression of their dynamic range by a small fraction of outliers.

Once normalized each feature plays a role in determining the Euclidean distance between two feature vectors. The contributions of different features can be weighed differently. Some features e.g. correlations and total variation are not well defined or not meaningful for connection vectors with fewer than three epochs. In this case only the Euclidean distance or correlation between those features that are defined in both associated vectors can be used and then normalize by the number of such active features so that the resulting distance can be compared to distances between longer connections. Table 1 below lists some features that may be used in feature vectors as well as calculations that they be applied to eighteen clustering analysis.

Once a b t traces have been obtained this collection of data may be used for workload modeling and generation in a variety of ways. If the goal is to simply reproduce the workload represented then one may simply replay the traces at the socket application programming interface API with the same sequence of start times that preserves both the order and initiation time of the TCP connections. Another straightforward modeling approach is to derive the distributions for the key random variables that characterize applications at the source level e.g. distributions of ADU sizes time values number of epochs etc. from data collected. These distributions can be used to populate analytic or empirical models of the workload in much the same way as has been done for application specific models. However the simple structure of the a b t trace makes it a flexible tool for a broader range of modeling and generation approaches. For example a representative workload for an entire network can be modeled by processing traces from several links in the network to produce their a b t representation and pooled into a library of TCP connection vectors. From this library random samples may be drawn to create a new trace that would model the aggregate workload. To generate this workload in a simulation start times for each TCP connection could be assigned according to some model of connection arrivals. For example the recorded start times for TCP connections could be replaced with start times randomly selected from a given distribution of inter arrival times in order to study the effects of changes in the connection arrival process. Other possible transforms include replacing the recorded ADU sizes with sizes drawn from analytic distributions e.g. lognormal with different parameter settings. For example all multi epoch connections can be replaced with single epoch connections where the new a and b values are the sums of the original a and b values and the t values are eliminated this is similar to using NetFlow data to model TCP connections . All such transforms provide researchers with a powerful new tool to use in simulations for studying the effects of workload characteristics in networks.

For example consider the replay of an a b t trace containing the connection vector Ci that corresponds to the TCP connection shown in . At time Tthe connection initiator establishes a new TCP connection to the connection acceptor. The initiator then writes 329 bytes to its socket and reads 403 bytes. Conversely the connection acceptor reads 329 bytes from its socket and writes 403 bytes. After the initiator has read the 403 bytes it sleeps for 120 milliseconds and then writes 403 bytes and reads 25 821 bytes. The acceptor reads 403 bytes and writes 25 821 bytes. After sleeping for 3 120 milliseconds the third exchange of data units is handled in the same way and the TCP connection is terminated.

Once the a b t trace T Ti Ci i 1 . . . N has been obtained it may be used for synthetic traffic generation in a variety of ways. As described above a trace may simply be replayed with the same sequence of start times which preserves both the order and initiation time of the applications utilizing the measured link.

However the simple structure of the a b t trace makes it a flexible tool for a broad range of generation tasks. T may be transformed in a variety of ways to produce new traces with different intrinsic and extrinsic properties. Taken together these new traces can provide a diverse library of sources from which to generate synthetic traffic with the choice of source depending on the experiment at hand.

One simple transformation of T is filtering. In filtering one selects from T a subtrace T consisting of all those connections satisfying a prespecified criterion along with their associated start times. For example an initial trace containing all the non concurrent connections can be filtered to obtain a subtrace of all HTTP port 80 connections. In a similar way subtraces of ftp or SMTP connections can be created using port numbers as an identifier. These selection criteria are application specific but one may also choose connections having more general properties such a large number of epochs or an unequal distribution of a and b type ADUs. We note that while port based filtering can be carried out at the packet level more sophisticated filtering based on application level connection features requires an a b t trace or similar information.

Another simple transformation that is frequently employed in this work is scaling. Formally for any scale factor 0 the alpha rescaled version of T is defined by replacing each initiation time Tby T resulting in a new trace T T C i 1 . . . N. The initial trace has scale 1. When 1 connection arrivals are slowed down. For example 1 2 and 2 correspond respectively to doubling and halving the arrival rate.

Scaling affects only the initiation times of connections the connections themselves are unaffected. In particular altering the connection arrival rate does not change inter epoch think times and its effect on the transmission rate of individual data units will depend on external factors like link capacity and congestion. Scaling changes connection arrivals without changing connections which can be referred to as the connection invariance property.

In trace replay experiments it is often necessary to reproduce different synthetic traffic loads on a link or network of interest. This is particularly important in experiments designed to compare and validate active queue management schemes as running links near capacity is a key factor in distinguishing effective methods.

Scaling provides a simple means to increase or decrease the average link load in a trace replay experiment decreasing a will in crease the average load on a link while increasing a will decrease the average load. In particular scaling enables the use of a single a b t trace to reproduce realistic application level traffic at a variety of average loads. In the same way scaling lets us adapt an a b t trace recorded under particular load conditions to an experiment where different load conditions are more appropriate.

Even on an uncongested link the connection between the scale factor a and the average load bytes per unit time resulting from replay of a scaled trace T may not necessarily be linear as a consequence of connection invariance the effect of the interconnection data units and think times on the load may not be captured by the scale factor alone. As a consequence in experiments attempting to achieve a desired average load on a link a sequence of calibration experiments can be undertaken to identify the value of the scale parameter best suited to the task.

It will be understood that various details of the invention may be changed without departing from the scope of the claimed subject matter. Furthermore the foregoing description is for the purpose of illustration only and not for the purpose of limitation as the scope of protection sought is defined by the claims as set forth hereinafter together with any equivalents thereof entitled to.

