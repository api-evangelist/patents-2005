---

title: Smart digital modules and smart digital wall surfaces combining the same, and context aware interactive multimedia system using the same and operation method thereof
abstract: Disclosed are smart digital modules, a smart digital wall combining the smart digital modules, a context-aware interactive multimedia system, and an operating method thereof. The smart digital wall includes local coordinators for controlling the smart digital modules, and a coordination process for controlling the smart digital modules. The smart digital modules sense ambient states and changes of states and independently display corresponding actuations. The coordination process is connected to the smart digital modules via radio communication, and combines smart digital modules to control collective operations of the smart digital modules.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07636365&OS=07636365&RS=07636365
owner: Korea Advanced Institute of Science and Technology (KAIST)
number: 07636365
owner_city: Daejeon
owner_country: KR
publication_date: 20050209
---
This application claims priority to and the benefit of U.S. Provisional Patent Application No. 60 570 685 filed on May 13 2004 in the USPTO and Korea Patent Applications No. 10 2004 62497 filed on Aug. 9 2004 and No. 10 2004 62498 filed on Aug. 9 2004 in the Korean Intellectual Property Office the entire content of which is incorporated herein by reference.

The present invention relates to a smart architectural surface SAS . More specifically the present invention relates to smart digital modules combined by sensing cognition and actuation capabilities every digital module is a complete independent computer with inputs outputs and communications the digital modules are globally coordinated or self organized to solve problems cooperatively and the digital modules stack up or snap into a framework to form a smart digital wall which is a planar construct for interfacing various interactions with a user by using the smart digital modules and a context aware interactive multimedia system and an operation method thereof.

Walls in buildings or houses have various functions as well as physical components for partitioning the space into smaller ones in the home environment. Attempts to apply screens to the walls for projecting images or video thereon have been suggested as information techniques and display technologies have developed. This trend demonstrates that smart homes or ubiquitous homes as interactive environments with inhabitants have appeared in our time.

As to prior art Pinhanez of Watson Laboratory in IBM proposed The Everywhere Displays Projector A Device To Create Ubiquitous Graphical Interfaces in the Proc. Of Ubiquitous Computing 2001 Ubicomp 01 2001 Atlanta Ga. In this transaction the device includes an LCD projector and a rotary mirror and the LCD projector receives information on a location of an inhabitant and displays information desired by a user on a desired location of a screen. However the above noted projector has no device for sensing the location of the user in real time and has a limit specific to beam projectors in that part of the screen is hidden when a subject is provided between the projector and a plane of incidence.

As to another prior art Prante of Germany disclosed Hello. Wall Beyond Ambient Displays in the Video Track and Adjunct Proceedings of the 5Intern. Conference on Ubiquitous Computing Ubicomp 03 Seattle Wash. USA Oct. 12 15 20 which proposes a GossipWall which is an interactive surface for generating different actuated patterns depending on distances from the user and which includes a plurality of cells based on sensors and each cell uses an LED unit and an RFID transmitter to sense passersby and display various beam patterns. Further when the user carries the ViewPort a mobile display with him to approach the GossipWall the ViewPort reads an ID of each cell and allows the user to read display unique information specific to a predetermined cell. However this system fails to provide specialized information to the user and requires an additional mobile device for an interactive interface since it only allows the LED to display very limited categories and amount of information.

The ALIVE system built at the MIT Media Lab by Pattie Maes Bruce Blumberg Sandy Pentland and others was a smart room that tracked a person.

Another piece of prior art applicable to reactive display is Stefan Agamanolis MIT PhD thesis 2001 in which he describes a system called Cabbage which automatically would reconfigure a visual information screen including changing scale as a function of distance and activity measured by a distance sensor attached to the video display. Another project of Agamanolis was for the ID Entity gallery show where portraits in an art gallery reacted as a viewer moved around in front of them.

Glorianna Davenport at the MIT Media Lab produced a video installation of a flock of pigeons that react to what sensors detect about the presence and activity of viewers.

The previous MIT systems discussed above involve single integrated systems rather than scalable sets of smart modular elements that perform the sensing and output functions. In addition conventional skills for utilizing the walls of a building as a screen for projected images and the conventional multimedia reproduction system video conference system and video phone system generally output audio and video data and hence they provide no various interactive operations with the user.

It is an advantage of the present invention to provide a smart digital module which combines sensors information processors and displays with sensing recognition and actuating capabilities and provide a dynamic input output computation ecosystem which is incrementally scalable from a few units to a very large number of units has a minimally fixed or centralized infrastructure and performs globally controlled or self organized collaborative processing to form a smart digital wall which provides interface with users by combining the smart digital modules.

It is another advantage of the present invention to provide a context aware interactive multimedia system and an operation method thereof for sensing a user s state through the smart digital modules and allowing interaction with the user by designing multi sensor processing algorithms to run in a dynamically changing distributed environment.

In one aspect of the present invention a smart digital module for reacting to contextual changes comprises a sensor unit for sensing ambient states and changes of states an actuator unit for displaying various categories of information in correspondence to the ambient states and changes of states a display for displaying visual information and a computer for processing signals output by the sensor and displaying corresponding actuation information to the actuator and the display. The computer changes states of information displayed by the actuator and the display according to the user s location and state sensed by the sensor.

The sensor unit includes sensors for sensing ambient states and changes of states and the sensors include an environment sensor for detecting the ambient states and a behavior sensor for detecting the user s changes of activities.

In another aspect of the present invention a smart digital wall for reacting to contextual changes comprises at least two smart digital modules for sensing ambient states and changes of states and respectively displaying corresponding actuations and a global coordination process or a decentralized peer to peer solution for performing such functions by decision making and coordination among distributed sensing and display devices built in the smart digital modules and controlling a collective operation of the combined smart digital modules the coordination process being connected to the smart digital modules through radio communication. The present invention permits building up a smart space out of individual modules in a way that is incrementally scalable easier to reconfigure and maintain than the traditional model and has no single point of failure.

The coordination process realizes adaptive actuations corresponding to sensed events through the smart digital modules based on the user s request sensed by at least one smart digital module and recognition of contextual information.

In still another aspect of the present invention a context aware video chat system based on a user s location comprises at least two smart digital modules for respectively measuring a distance to the user receiving the user s video and audio and outputting the other party s video and audio and a coordination process for connecting one or more smart digital modules to the other party s video chat system through a wired wireless telephone or Internet network the coordination process being connected to the smart digital modules through radio communication. The coordination process controls a number of the smart digital modules for forming a screen on which the other party s images are reproduced according to the user s location measured by the smart digital modules.

The coordination process controls the volume of the other party s reproduced speech according to the user s location measured by the smart digital modules.

The number of smart digital modules is greater in the case in which the distance to the user from the context aware video chat system is longer than a predetermined distance than the case in which the distance to the user from the context aware video chat system is shorter than the predetermined distance.

The speech volume is greater in the case in which the distance to the user from the context aware video chat system is longer than a predetermined distance than the case in which the distance to the user from the context aware video chat system is shorter than the predetermined distance.

In still yet another aspect of the present invention a context aware video chat system based on a user s location comprises at least two smart digital modules for respectively measuring a distance to the user receiving the user s video and audio and outputting the other party s video and audio and a coordination process for connecting one or more smart digital modules to the other party s video chat system through a wired wireless telephone or Internet network the coordination process being connected to the smart digital modules through radio communication. The coordination process changes the smart digital module to which the other party s images are reproduced according to the user s movement measured by the smart digital modules.

The coordination process changes the smart digital module to which the other party s speech is reproduced according to the user s movement measured by the smart digital modules.

The coordination process uses distance sensors for measuring the distance to the user to perform periodical scanning and sense the user s movement and make the smart digital modules reproduce the other party s images.

In still further another aspect of the present invention a context aware video chat method based on a user s location in a context aware video chat system including at least two smart digital modules for measuring the distance to the user respectively receiving the user s video and audio and respectively outputting the other party s video and audio and a coordination process being connected to smart digital module via radio communication and connecting one or more smart digital modules to the other party s video chat system via a wired wireless telephone or Internet network comprises a controlling the smart digital module reproducing the other party s video to measure the distance to the user b controlling the coordination process to compare the distance measured in a with a predetermined distance and c controlling the coordination process to control the volume of the other party s reproduced speech and the screen size occupied by the other party displayed through the smart digital modules according to the comparison result.

In still further another aspect of the present invention a context aware video chat method based on a user s location in a context aware video chat system including at least two smart digital modules for measuring the distance to the user respectively receiving the user s video and audio and respectively outputting the other party s video and audio and a coordination process being connected to smart digital module via radio communication and connecting one or more smart digital modules to the other party s video chat system via a wired wireless network comprises a controlling the smart digital module reproducing the other party s video to periodically measure the distance to the user in a specific order b controlling the coordination process to determine the video chatting user s movement based on the distance measured in a and c controlling the coordination process to determine a smart digital module to which the other party s video are reproduced according to the determination result.

In an alternative aspect of this invention the above functions are performed without a global coordination process. In this case modules detecting the presence of the user form a group that collaborates in a peer to peer fashion to determine the location and movement of the user and to determine an appropriate module or set of modules which will reproduce the audio and video of the remote party as well as capture video and audio of the user.

In the following detailed description only the preferred embodiment of the invention has been shown and described simply by way of illustration of the best mode contemplated by the inventor s of carrying out the invention. As will be realized the invention is capable of modification in various obvious respects all without departing from the invention. Accordingly the drawings and description are to be regarded as illustrative in nature and not restrictive. To clarify the present invention parts which are not described in the specification are omitted and parts for which same descriptions are provided have the same reference numerals.

A smart digital module according to an exemplary embodiment of the present invention will now be described.

The sensor and actuator unit senses external states or changes of states through various sensors and outputs actuations of the smart digital module . As shown in the sensors of the sensor and actuator unit include environment sensors which detect external environments and include a temperature and humidity sensor for sensing the temperature and humidity and a photometer for sensing luminance and behavior sensors which detect changes of external environments and include a camera for capturing images a microphone for receiving speech a touch sensor for sensing touch inputs and an ultrasonic sensor for sensing the user s location through ultrasonic. Outputs of the respective sensors and are transmitted to the computer through analog digital converters ADC and a buffer and an amplifier .

Referring to the sensor and actuator unit includes a speaker and a light emitting diode LED operable by receiving actuation signals from the computer through an amplifier in the case of the speaker . 

The sensor and actuator unit may further include various sensors for capturing events required by the smart digital modules and various actuators for outputting actuations of events captured by the sensors.

The display receives signals for displaying visual information from the computer and displays a corresponding image and it is assumed in the exemplary embodiment that a liquid crystal display LCD which is more advantageous than a plasma display panel PDP is used in consideration of costs and power consumption. It will be preferable for the LCD to be greater than 15 inches in its size and have a touch screen function.

Referring to the display is provided on the front of the smart digital modules so that the users may easily view visual information thereon.

The sensor and actuator unit is provided on a long stripe type printed circuit board PCB which is located adjacent to the display . Referring to the speaker is provided on the top rear side of the display and two speakers are provided on two top corners respectively when they are stereo speakers.

The computer receives signals from the sensor and actuator unit and processes them to sense various external states or changes of them outputs actuation signals following the states to the sensor and actuator unit and shows appropriate visual information to the display .

The computer includes one or more processors storage means such as a semiconductor and or a magnetic storage wired or wireless communications and interfaces to input and output devices as is well known to one skilled in the art. Specifically the computer includes a central processing unit CPU a display controller a memory a storage and an input output I O unit . The CPU controls various components of the computer including a general purpose CPU the memory temporarily stores data for the operation of the CPU and other types of data for various processes the storage stores data used by the computer and data input and output by the sensor and actuator unit and includes a storage device and the display controller controls visual information displayed to the display according to control by the CPU . Specifications of the CPU the memory and the storage are variable by processing targets and operational purposes of the computer of the smart digital modules .

The computer senses inputs provided by the sensors of the sensor and actuator unit to detect environmental states or changes of the states and displays actuations through the display and the actuators of the sensor and actuator unit . For example the computer senses the user s speech provided through the microphone and displays a corresponding actuation to the display and the actuators of the sensor and actuator unit .

Inputs from multiple sensing devices on multiple smart digital modules are combined in order to provide data for algorithms such as video stereopsis or microphone array processing methods that require observations from multiple spatial locations.

The display controls the size of displayed visual information according to the user s location and movement sensed by the camera and the ultrasonic sensor according to control by the CPU . For example in the case of displaying same information screen the display displays the total information screen when the user is near the smart digital modules and the display displays part of the information screen when the user is far from the smart digital modules . Also the display is controlled to move the displayed screen in the user s walking direction when the user s walking over the front of the display is detected by the sensors of the sensor and actuator unit and is then sensed by the computer .

The electronic components which are assembled in the minimum size through minimizing predictable problems such as electromagnetic interference EMI and generation of heat in consideration of performance of components in the smart digital modules are effectively arranged in a case and an interface for supplying power to the smart digital modules is installed therein.

The above noted smart digital modules are combined to form a smart digital wall which is one of smart digital surfaces which will now be described with reference to drawings.

As shown in the smart digital wall includes a plurality of smart digital modules to N and is controlled by a coordination process .

The smart digital modules to N further include wireless LAN units to N which allow mutual information communication via wireless LANs and information exchange with the coordination process as described with reference to . For example the smart digital modules includes a sensor and actuator unit for sensing external states and changes of states through various sensors and outputting corresponding actuations a display for receiving signals for representing visual information and outputting corresponding images a local coordinator for receiving signals from the sensor and actuator unit processing the signals to sense various external states and changes of state and outputting actuation signals according to the states to the sensor and actuator unit and the display and a wireless LAN unit for controlling information communication between the local coordinator and the coordination process via radio communication. In this instance the local coordinator represents the computer as shown in to which a wireless LAN communication function through the wireless LAN unit is added.

The coordination process is connected to the respective local coordinators to N of the smart digital modules to N through radio communication and controls the local coordinators to N. In detail the coordination process represents a collective decision making module for the smart digital modules to N and controls the local coordinators to N provided in the smart digital modules to N to control collective operations including sensing speech recognition speech synthesis and multimedia reproduction by the smart digital modules to N. Therefore the local coordinators to N gather sensor data e.g. inputs by a microphone and a camera and values by temperature and humidity sensor detected in real time by the sensor and actuator units to N transmit the sensor data to the coordination process through the wireless LAN units to N when receiving a speech instruction from the user receive an instruction from the coordination process collectively use the sensor and actuator units to N and the displays to N and display corresponding information.

The coordination process can be provided to one of the smart digital modules to N forming a smart digital wall or it can be replaced by a decentralized collective decision making process but it will be described in the exemplary embodiment that the coordination process is installed in a computer to thus perform corresponding functions.

The smart digital modules to N are stacked to thus configure a smart digital wall in and they are inserted into a metallic frame to form a smart digital wall in .

Referring to and the smart digital modules to N are combined in a grid manner to build a smart digital wall. In this process the displays to N attached to the fronts of smart digital modules to N are configured such that the screen size may be varied within an allowable range in a like manner of conventional multivisions. Also a grid type metallic frame for supporting the smart digital wall built by the smart digital modules to N is additionally installed in . In this instance a predetermined gap is provided between the original constructed wall and the smart digital wall combined with the metallic frame in consideration of generation of heat from the rear of the smart digital wall. Further cables for supplying sufficient power to the smart digital modules to N are provided in the metallic frame.

As shown the software architecture of the smart digital wall includes hardware including sensors and actuators an operation system O S an application programming interface API for supporting processing of sensor data networking multimedia and a database on the O S basis software components for supporting multi modality including modules for speech recognition and gesture recognition and a local coordinator and a coordination process for system control and various application programs.

As shown the respective smart digital modules to N have a speech recognition program a sensor interface program a media reproduction program and a module management program and a central management program for controlling the module management programs to collectively control the smart digital modules to N is installed in a smart digital module.

The speech recognition program is installed in the computer to receive speech recognition data from the microphone of the sensor and actuator units to N the sensor interface program is installed in the computer to receive sensor data from other sensors and transmit the same to the module management program and the media play program is installed in the computer to receive media data from the module management program and control the media data to be reproduced by the sensor and actuator units to N and the displays to N.

The module management program is installed in the local coordinators to N to receive speech recognition data and sensor data from the speech recognition program and the sensor interface transmit the data to the central management program receive result data processed by the central management program and transmit the result data to the media reproduction program.

The central management program is installed in the coordination process to receive speech recognition data and sensor data from the module management program installed in the respective smart digital modules to N process the data control the respective module management programs and realize an actuation such as collective media reproduction.

In an alternative embodiment the coordination of the processes and states of the multiple modules is handled not by a global coordinator but instead by a process in which the modules exchange information in a peer to peer fashion by means of any of a variety of well known messaging protocols either one to one or multicast. It is also possible for the top level of a hierarchical control structure to migrate from one module to another as application circumstances require for example a module that detects user commands could issue these directly to other modules rather than through a global coordination process.

Functions of the smart digital wall according to the exemplary embodiment of the present invention will be described.

The smart digital wall combines a plurality of interactive smart digital modules to N to provide various functions differing from the conventional output devices such as a multi screen which allows a size adjustable screen and reproduces sound.

One of various functions is to operate as an interactive smart multimedia player. For example when text images video audio and combinations thereof are reproduced by one or plural smart digital modules to N corresponding multimedia files can be stored in one or more smart digital modules to N or can be streamed and downloaded from the above noted various sources the multimedia contents are selected by the user s voice instruction through the sensor and actuator units to N and the size location and contents of the screen of the displays to N for reproducing data based on the user s location and ID information detected by sensor inputs for location awareness and images captured by the camera are determined. For example when the user speaks a favorite singer s name in front of the smart digital wall the coordination process operates a face sensing program to identify the user who is detected by the sensor and actuator unit to N searches for the user s most favorite song from among the songs of the singer in the database outputs a corresponding music video file to the screen on the displays to N based on the user s location and the distance between the user and the smart digital wall detected by the sensor and actuator units to N by controlling the screen size over one or more smart digital modules to N and reproducing the music video file to be thus adapted to the user related environmental factors.

Another function is to operate as a personalized smart information browser. The smart digital wall transmits various categories of information to the user through one or more smart digital modules to N. In this instance the corresponding information file is stored in one or more smart digital modules to N or can be streamed or downloaded through the Internet contents and features of the above noted information are selected based on the user s ID detected through the user s voice instruction or images captured by a camera and the size and location of images are determined according to the user s location sensed by the sensor. For example when the user stands in front of the smart digital wall and speaks a request of a predetermined day s information the coordination process operates the face sensing program to identify the user through the sensor and actuator units to N and displays various types of information which are stored in advance or are downloaded from the Internet or external servers to the smart digital modules to N based on an information list read by the user in the database the information including weather stocks time schedules TV programs shopping and travel. When the user selects one of various types of information displayed on the smart digital wall the coordination process outputs a detailed information screen of specific information items selected based on the user s location identified by the sensor and actuator units to N and the distance between the user and the smart digital wall controls the image size over one or more smart digital modules to N and reproduces the controlled images thereby being adapted to the user related environmental factors. In this instance when the user selects an information item displayed on a specific smart digital module by using an infrared remote controller a PDA or a lantern further detailed information items having a lower rank than the selected information item are displayed on the whole or part of the smart digital wall and the user moves a pointing device up and down in the hierarchical tree structured information to find a desired item. When finding the desired information item the user moves the information item to the user s front to enlarge the item or input necessary information by using various input devices. Also when selecting one of the displayed information items lower rank information items are displayed in a like manner.

The coordination process must support speech recognition for the purpose of interaction with the smart digital wall. The speech recognition function can omit a training process for sensitively responding to the voice of predetermined users so that the speech recognition function may be available for many users and the speech recognition function can require another training process for accurately sensing a restricted group of users.

In detail the respective smart digital modules to N have a speech recognition program and hence when the user utters a voice instruction at a specific location in front of the smart digital wall including a plurality of smart digital modules to N the microphone installed in the sensor and actuator unit to N of the neighboring smart digital modules to N and the speech recognition program which is a speech recognition engine mount in the computer sense the user s utterance convert words and sentences sensed by the modules into letters and transmit the letters to the coordination process through the respective local coordinators to N. When receiving sensed information from the smart digital modules to N the coordination process detects sensed words or construction of sentences with the most frequency from among the sensed words or construction of sentences and performs the user s voice instruction. When assuming in the process that the smart digital modules to N have a speech recognition program with the speech recognition rate of 70 and ten smart digital modules to recognize the speech exemplarily seven smart digital modules correctly recognize the user s voice instruction to thus produce improved performance compared to the case in which one smart digital module recognizes the speech.

For example the whole system is normally operated when three of ten smart digital modules recognize the same words or sentences and other ones recognize them differently.

It is also possible in either a centralized or a peer to peer way to synchronize the digitizing process of microphones in multiple modules enabling them to be used as inputs to well known microphone array algorithms which can improve the signal to noise ratio of captured voices or remove unwanted sounds before passing the processed result to a speech recognition function or a conferencing application.

The speech recognition function has been described but it is also possible for the smart digital wall to convert the given text into speech data based on the speech recognition engine installed in the smart digital modules and transmit the same to the user and to thus perform a speech synthesis function. By using the function it is allowed to provide information desired by the user including weather time stocks temperature humidity and luminescence in the voice format and in particular when the above noted function is combined with the speech recognition function it is possible to provide the interactive operation with the user by asking the user via a synthetic speech and processing the user s answer through a speech recognition module. Since the smart digital modules to N forming a smart digital wall independently have a speech synthesis engine the user can hear the synthesized voice in front of the smart digital wall irrespective of places at which the user interacts with the smart digital wall and the user can concurrently hear various speeches with different voices from the smart digital modules to N. Instructions or information for speech synthesis are transmitted to the respective smart digital modules to N from the coordination process and the smart digital modules to N use the speech synthesis engine installed therein to synthesize the corresponding speech and output the synthesized speech to the user through the speaker .

Also an infrared sensor can be installed in the sensor actuator unit of one or more smart digital modules so that the user may manipulate the smart digital modules by using a wireless keyboard or a mouse. Therefore signals generated by the keyboard or the mouse for wireless manipulation are provided to the infrared sensor installed in the smart digital modules and are then processed by the coordination process . The remote controller for controlling the smart digital modules supports selection of smart digital modules in a like manner in which the user changes television channels by pressing a channel button on the remote controller and the remote controller includes an infrared transmitter which allows the user to transmit a control signal to the selected smart digital module or the smart digital wall which is far from the user by a predetermined distance. Accordingly the infrared sensor installed in the sensor and actuator unit of the smart digital module senses the lengths of infrared signals generated by the infrared transmitter the computer converts the lengths into digital signals and transmits the same to the coordination process and the coordination process converts the digital signals into specific instructions in a software manner by using a matching table to thus activate a specific application service. The user can manipulate and perform instructions for controlling the smart digital modules within a short range by using the remote controller.

Further another interface for controlling the smart digital modules is a touch screen. The user installs an LCD display to N on the smart digital module and performs needed functions by manually manipulating graphic user interface GUI components including pull down menus buttons slide bars and icons output to the smart digital module. The user can control one or more smart digital modules by using the touch screen function and can add GUI components in the developing process of application services for operating the smart digital wall so as to activate the touch screen function.

Also still another interface for remotely controlling and monitoring each smart digital module or the smart digital wall formed by plural smart digital modules is a web based interface. When a web server is installed in one of smart digital modules the user remotely uses a web browser installed in a terminal to access the web server s URL and then accesses the hyper text markup language HTML document which includes a client graphic interface for controlling and monitoring the smart digital module. The HTML document includes GUI components for exchanging data with the server in real time such as ActiveX and JAVA BEANS. The interface components includes buttons pull down menus lists text boxes slide bars check boxes video frames and image frames and the user handles the interface components on the web to remotely control one or plural smart digital modules and receive data such as text images video and audio in real time. The above noted web based remote interface allows the user to select hierarchical visual icons step by step in order to selectively control and monitor a smart digital module provided at a specific location a smart digital wall formed by the smart digital modules and a smart digital space configured by the smart digital walls and communicates desired information in real time by using the pull down menu the text box and the graph. The hierarchical configuration of the user interface for specifying one or more smart digital modules to N corresponding to a target node can be achieved by visualizing the tree structure of icons which display a predetermined building spaces in the building walls which form the spaces and smart digital modules which form the walls. Data communication between the web interface on the client side and the server platform on which the coordination process for controlling the smart digital module and the smart digital wall is installed is executed on the basis of bidirectional socket communication using IP addresses. For example the user at the office remotely monitors a child who stays home through moving pictures on the web browser by using a camera attached on a specific smart digital module and manipulates the web interface and remotely sends a text message to the child who stays in front of the specific smart digital module and the smart digital module then receives the text message and converts the same into speech signals via a text to speech TTS program so that the child may hear the message.

Also another interface for remotely controlling and monitoring the smart digital module and the smart digital wall is a hand held device such as PDA based mobile interface that could be used as an input or output device which could exchange data with the smart digital modules. By this interface the user uses a stylus pen on an LCD screen of the PDA to manipulate a client GUI for controlling and monitoring one or more smart digital modules and remotely exchange desired categories of information. The PDA includes various GUI components which support real time data communication with the server of a specific smart digital module and which include buttons pull down menus lists text boxes slide bars check boxes and video and image frames. The user controls the GUI components on the PDA to remotely control one or more smart digital modules and receive desired data in various formats of text image video and audio from the smart digital modules in real time. No descriptions of the above mentioned PDA based remote interface will be provided since the PDA based remote interface is similar to the web interface and a person skilled in the art will easily understand it when referring to the descriptions on the web interface. The user might also speak into the microphone on the PDA rather than a microphone on the modules and the application software on the modules could route audio to the PDA s speaker and video to the PDA s screen.

The smart digital wall uses ultrasonic sensors which are arranged on the smart digital modules located at regular intervals on the smart digital wall to sense locations periodically scan predetermined distances in front of the smart digital wall measure existence states of persons or goods and the distance from the wall and accordingly use the measured data in various applications.

Further the smart digital wall allows the user to access one or more smart digital modules on the Internet and perform needed functions and monitor desired information.

In addition the smart digital wall captures the user s face image through the camera attached on the smart digital module matches the face image with a plurality of facial images in the database by using a face recognition program installed in the corresponding smart digital module to identify the user and provides application services in consideration of personal preferences. For example when identifying the user after recognizing the user s face the smart digital wall displays the user s favorite songs weather stocks shopping and music video files. As to the configuration of the face recognition interface a camera for controlling the face recognition error rate within a predetermined range and a face recognition algorithm for optimizing variables including a distance from the user and the user s rotated angles to the right and left with reference to the user s front face are used. That is a plurality of cameras forming a smart digital wall is used and a face recognition algorithm for registering 3 dimensional face images into the database and searching the database based on the image rendering scheme is used. In detail images captured by at least two cameras adjacent to the user are used to register 3 dimensional face image data into the database and when the user stands in front of the smart digital wall the database is searched based on the face images with different angles captured by at least two cameras and the user is accordingly identified to increase the recognition rate.

Also it is possible for a smart digital wall to capture the user s images with various angles in real time through a camera grid formed by a set of cameras installed in the smart digital module. In detail it is possible to use the camera grid capture the user s face images in various angles select the best image by a vote mechanism performed by the smart digital modules and use the best image to the face recognition and other application services.

When it is desired to use multiple cameras to make models or measurements of the environment or the users it is necessary to perform a multi camera calibration process using one of various techniques that are well known to those skilled in the art. This can be organized in either a centralized or a distributed fashion. Once the cameras have been calibrated it becomes possible to compute distance to elements in the scene e.g. a face a hand or a person by well known triangulation calculations taking into account the relative sizes and screen positions of features seen by individual cameras.

Also it is possible for a smart digital wall to perform a collaborative audio capture in which a group of modules process their microphone inputs in order to localize sources or get a better copy of a voice or a sound than any single microphone could record.

As to the electronic wallpaper service formed by the smart digital wall an API based multimedia reproduction program is used to combine the text images video and audio contents into electronic wallpapers the electronic wallpapers are stored in the database and the stored electronic wallpapers are dynamically and selectively reproduced according to the identified personal history sensed or input personal emotional states day times and seasons. For example in the case of representing a specific electronic wallpaper stored in a specific database the smart digital modules display the contents of the electronic wallpaper selected by the coordination process e.g. text images and video and audio contents to the displays to N and the speaker according to the instruction by the coordination process .

The electronic wallpaper represented on the smart digital wall can be modified by automatic environmental recognition based on various outputs of the sensors or by the user s direct inputs through the speech recognition interface. In particular when the moving pictures are reproduced on the smart digital wall in the electronic wallpaper format it is possible to adjust locations of some or total moving pictures screen sizes and volumes of background music based on the user s location detected by a distance sensor or the user s own desires. It is also possible to temporarily halt the moving pictures and configure a still image wallpaper.

Digital objects represented on the dynamic electronic wallpaper include a smart digital calendar a clock and a picture they are displayed at a specific location together with the electronic wallpaper on the smart digital wall and they can be easily moved enlarged reduced and eliminated by the user. Advantages of the digital objects are attempts of various types of design free selection of digital objects without additional matter and cost and representation of digital objects to the smart digital wall and flexible modification of locations and sizes thereof.

Further an automatic security and emergency system for processing problems generated in the building can be built by using various sensors and output devices installed in the smart digital modules. One or more smart digital modules detect fire through information acquired by the temperature and humidity sensors and and gas sensors or through data which are generated by a mechanical visual sensor by analyzing the images captured by the camera generates a fire alarm according to a fire algorithm stored in the smart digital modules notifies persons concerned staying in out of the building of the fire and automatically reports the fire to a fire station. In this instance the smart digital wall generates an alarm signal through the speaker and controls the displays to N to flash the red light on and off so that the users within the building may know the emergency. In a like manner the smart digital wall uses various sensors to sense night intruders or first aid patients and quickly process the situations.

As shown in the coordination process controls the sensor and actuator units to N and performs scanning through the local coordinators to N of the smart digital modules to N.

A number of smart digital modules for performing scanning is determined a variable m for representing the number is reset to be 0 and the scanning loop is started in step S.

The ultrasonic sensor of the m 1 th smart digital module is oscillated in step S and a sleep time of about 100 ms is provided in consideration of the time when the ultrasonic is reflected on a body and is returned in step S.

The reflected wave is measured and the distance to the body provided in front of the smart digital modules having the ultrasonic sensor or the distance to the user is calculated and stored in steps S and S.

A sleep time of about 200 ms is given in step of S in order to quench the ultrasonic generated by one smart digital module it is checked in step of S whether the smart digital modules in an area to be scanned have performed scanning and the above described steps S to S are repeated when the scanning is not finished.

When the scanning is finished and the distances for the smart digital modules are measured the coordination process analyzes the distance data measured and stored in step of S in step of S determines whether a person or a body is sensed in front of the smart digital wall in step S and uses location data with the sensed person or body to various applications when the person or body is sensed.

Therefore the above described smart digital wall is applicable to various applications and a context aware video chat system realized by the smart digital wall will be described.

As shown in the context aware video chat system is connected to a computer system for supporting a general video chat function and a video phone through a wired wireless network transmits and receives video and audio data thereto therefrom and reproduces the data to thus perform a video chat.

The context aware video chat system shown in is connected to another context aware video chat system through the wired wireless network transmits and receives video and audio data thereto therefrom and reproduces the data to thus perform a video chat.

The context aware video chat systems and shown in and control images sizes displayed based on the distance from the user and voice volumes and move locations of the displayed images and the reproduced speeches according to the user s movement.

The context aware video chat systems and include a plurality of smart digital modules to N accumulated to be a digital wall and are controlled by the coordination process as described with reference to .

The smart digital modules sense external environments including the user s transmit the corresponding data to the coordination process receive an instruction from the coordination process and displays corresponding actuations such as image display and speech outputs. The smart digital modules are independently operated and each of them can be operated as an individual video chat system.

The smart digital modules to N respectively have a sensor and actuator unit a display a local coordinator and a wireless LAN unit which have been described with reference to .

The coordination process receives video and audio signals for a video chat from the smart digital modules and transmits the sign als to the external video chat systems and through the wired wireless network receives video and audio signals therefrom through the same and transmits the signals to the smart digital modules corresponding to the user so that the user may chat with the other party.

The displays to N control the size of visual information displayed according to the distance from the user sensed by various sensors in particular the camera and the ultrasonic sensor of the sensor and actuator units by control of the CPU and controls movements of information display according to the user s movements. For example in the case of displaying a same information screen the displays are controlled to visualize images on a small information screen provided by one smart digital module to the minimum when the user stays near the video chat system or and are controlled to visualize images on a large information screen composed of the entire set of smart digital modules to the maximum when the user stays far from the video chat system or . Also when the user passes in front of the displays of the video chat system the sensor and actuator unit senses the user s movement and the local coordinators detect the movement and transmit the same to the coordination process the coordination process transmits instructions to the displays for displaying information according to the user s movement to control movement of information following the user s movement.

A process for accessing external video chat systems and by using the context aware video chat system will now be described.

The user uses a sensor such as a touch sensor in a sensor and actuator unit provided to one of the smart digital modules to N when staying in front of the context aware video chat system and starts a context aware video chat in step of S.

When the context aware video chat is selected the coordination process identifies the user in step of S through an ID input process by the user or through a user face recognition process by using the smart digital modules. In this instance in order to recognize the user s face the user s face image at the front of the video chat system is captured by the cameras attached to the smart digital modules and the captured face image is controlled to be matched with a plurality of face images stored in the database by using the face recognition program installed in the corresponding smart digital module thereby identifying the user. As to the configuration of the face recognition interface a face recognition algorithm is used to optimize the variables including the distance between the camera and the user and the user s rotated angles to the right or left with reference to the front the variables being used to control the face recognition error within a predetermined range. That is a plurality of cameras forming a video chat system is used and a face recognition program for storing and searching 3 dimensional face images based on the image rendering scheme is used. In detail the images captured by at least two cameras near users are used to register corresponding 3 dimensional face image data into the database and when a predetermined user stands before the video chat system and the cameras search the database with reference to the captured face images with different angles to identify the user and thus substantially increase the recognition rate.

When the user is identified in the previous step of S the coordination process controls the user to select another party to chat with in step of S. In this instance when the images of remote callers whom the user calls frequently and their brief personal information are stored in advance by the user each caller s image and personal information are displayed on the display for each smart digital module and one of the callers whose information is displayed thereto is selected by the user through a speech or a remote controller.

When the other party to chat with is selected by the user the coordination process attempts a connection for a video chat session with the selected other party through the wired wireless telephone network in step of S. In this instance the coordination process detects the central smart digital module from among the case of selecting the context aware video chat function the case of the speech recognition process in the steps S and S for selecting the other party and the case of the provided smart digital modules which have received the signals from the remote controller and the coordination process establishes the central smart digital module to be the smart digital module for displaying the initial screen of the actual video chat in step S.

The coordination process connects the smart digital module established in the previous step of S and modules in the ambient zone e.g. smart digital modules adjacent to the established smart digital module to the video chat systems and of the other party in step of S. When the context aware video chat system is connected to the other party s video chat systems and video signals and audio signals of more than 10 frames per second captured by the other party s video chat systems and through the camera and the microphone are encoded into a predetermined format of signals e.g. MPEG 4 signals and the MPEG 4 signals are provided to the coordination process in the user datagram protocol UDP multicast format in step of S.

The video and audio signals are reproduced into images and speeches and are output by part or all of the sensor and actuator units of the activated smart digital modules and the displays in step of S.

When the context aware video chat system outputs the images and speeches of the other party the user s video and audio data are to be transmitted to the other party s video chat systems and . The coordination process analyzes information input by the sensor and actuator units of the established smart digital modules in particular the ultrasonic sensor and establishes a smart digital module which is the most adjacent to the user and receives the user s appearance and voice appropriately in step S.

The coordination process receives the user s video and audio signals from the camera and the microphone installed in the established smart digital module in step of S and transmits the signals to the other party s video chat systems and through the wired wireless network in step of S. In this instance the camera grabber based on the Windows DirectShow API can be used for the technique which captures the user s images through the camera of the smart digital module.

The user s video and audio signals have been transmitted after the other party s video and audio signals have been received in the above description and it is obvious that the video and audio signals can be transmitted and received between the user and the other party irrespective of the above noted order in the actual chat.

The context aware video chat system senses the distance from the user and the context caused by the user s movement and reproduces different video and audio signals corresponding to the other party while the user video chats with the other party.

The technique for measuring the distance from the user has been described with reference to and it will be easily understood by a person skilled in the art that the user s movement is sensed by the variation of distance to the user which is periodically measured by using the technique.

An operation for controlling the image size displayed according to the distance to the user will be described.

The coordination process measures the distance to the user from the video chat system through various sensed inputs provided by the ultrasonic sensors of the smart digital modules and uses the measured information for factors of controlling the screen size for the current video chat session.

For example when the distance between the video chat system and the user is given within one meter the video and audio transmitted from the other party s video chat system and are reproduced to the smart digital module provided in front of the user as shown in . When the distance therebetween is more than one meter the coordination process senses the distance to be long and multicasts the video signals transmitted by the other party s video chat systems and to the smart digital modules provided in front of the user the local coordinators to N of the smart digital modules display partial images divided according to the locations of the smart digital modules and accordingly an enlarged image is reproduced and displayed over plural smart digital modules. Therefore media players for dividing the original image data into smaller ones according to the location of the smart digital module and corresponding to the enlarged screen are installed in the local coordinators to N of the smart digital modules and no description on the media players will be provided since they are well known.

Since the screen size for displaying the images of other party can be enlarged or reduced depending on the distance between the user and the video chat system it is needed for the smart digital modules within the ambient zone with reference to the main smart digital module for controlling inputs and outputs of the current video chat that is adjacent smart digital modules to be activated and be prepared for enlargement and reduction of the screen size according to the varied distance between the user and the video chat system and the respective smart digital modules are controlled whether to receive and reproduce the video and audio signals transmitted by the other party s video chat systems and depending on the screen enlargement or reduction instruction by the coordination process .

Also when the distance to the user is long and the image is displayed over at least two smart digital modules the respective smart digital modules display divided parts of the whole image and synchronizes the image frames divided and reproduced by the smart digital modules. In this instance the synchronization is performed by the network time protocol NTP based synchronization algorithm maintained by the coordination process which effectively uses a buffer for the reproduced video signals and controls the video chat system .

An operation for controlling the speech reproduced based on the distance to the user will be described.

The speech volume of the other party can be controlled based on the distance between the video chat system and the user in a like manner of the method for controlling the screen size which displays the other party s image based on the distance between the video chat system and the user.

For example when the distance to the user is shorter than a predetermined length such as one meter speech with a reduced volume transmitted by the other party s video chat systems and is reproduced and output by one or more smart digital modules provided in front of the user. When the distance to the user is longer than one meter the coordination process senses the longer distance and reproduces and outputs the speech with an increased volume through the speaker installed in one or more smart digital modules.

When the distance to the user is far and the image is reproduced over at least two smart digital modules the speech signals reproduced by the smart digital modules are synchronized in a like manner of video signals. The synchronization is performed by the NTP based synchronization algorithm maintained by the coordination process which effectively uses the buffer for the reproduced audio signals and controls the video chat system .

A transition operation of a target smart digital module for inputs and outputs of a video chat session under progress in response to the user s movement will now be described.

The coordination process uses the ultrasonic sensors which sense the distance to the user are installed in the smart digital modules and are provided with a predetermined height and periodically performs scanning to detect the user s movements.

When the user moves to another location while chatting with the other party and the coordination process senses the user s movement through periodical scanning the coordination process establishes one or more smart digital modules corresponding to the user s new location and transmits the video and audio signals transmitted by the other party s video chat systems and to the established one or more smart digital modules to thus reproduce and output the corresponding video and audio. In this instance the smart digital modules which correspond to the user s previous location are either inactivated according to the new location s close status to the previous location or are established to enter a standby mode. Referring to when the user stays on the first left location of the video chat system the video chat system displays the image of the other party to the smart digital module A corresponding to the first location and reproduces speech. Referring to when the user moves to the second central location the video chat system displays the image of the other party to the smart digital module B corresponding to the second location and reproduces speech. In a like manner When the user moves to the third right location the video chat system displays the image of the other party to the smart digital module C corresponding to the third location and reproduces speech. Hence adaptive video chat is allowed by exchanging the smart digital modules as the user moves to other locations.

The smart digital modules with the activated ultrasonic sensors stand by until a video chat is started because of the user s movement while the coordination process performs scanning.

Also it will be easily understood by a person skilled in the art that the user s location based screen size and speech volume are adjusted as the user moves to the other locations including the above described cases in which the user has stayed in front of the video chat system within one meter and has moved to another location to thus be far from the video chat system by more than one meter. For example as shown in when the user stays on the left of the video chat system with the user s distance to the video chat system of less than one meter i.e. he stays at the first location the video chat system displays the other party s image to the smart digital module A and reproduces the speech. As shown in when the moves to the center of the video chat system the second location with the distance to the video chat system of greater than one meter the video chat system enlarges the original image and displays the enlarged image over the smart digital modules A B C and D and reproduces a louder speech.

Therefore the user uses dynamic video chat sessions adaptive to the user s movements through the context aware video chat system .

While this invention has been described in connection with what is presently considered to be the most practical and preferred embodiment it is to be understood that the invention is not limited to the disclosed embodiments but on the contrary is intended to cover various modifications and equivalent arrangements included within the spirit and scope of the appended claims.

For example the case in which the distance to the user from the video chat system is within a predetermined value and the other case in which the distance is more than the predetermined value have been described and in addition without being restricted to these cases the distance can further be divided into plural levels to control the screen size depending on the levels which is also applicable to controlling speech volumes.

Further inconvenience caused by locations is eliminated by automatically adjusting the screen size and speech volume according to the user s location and inconvenience caused by movements is eliminated by adaptively changing the locations of image and speech reproduction according to the user s movement thereby allowing the user to undergo dynamic video chat sessions.

The above described system can also provide a platform for telecollaboration. Combining the video chat function with other collective sensing computation and output processes creates linked interactive visualization spaces for high dimensional data with multimodal interfaces.

1. Modularity Combinations of smart digital modules generate various functional variations by inputting and outputting various categories of information according to the sensed context and effective combinations of computing resources installed in the smart digital modules participating in a specific scenario provide highly controlled collective actuations.

2. Multifunctionality Variable potentialities of functions are given through state transition provided to the smart digital wall a set of smart digital modules. For example the functions of televisions radios computers and videophones can be realized by the same hardwired device.

3. Adaptability The smart digital wall changes its state based on requests by the user or analysis of contextual information acquired by the smart digital wall thereby realizing adaptive actuations corresponding to sensed events.

4. Multi modality The smart digital wall is interactive with the user through various input and output means including speech recognition gesture recognition physical contacts a PDA a laser pen and the Internet.

