---

title: Identifying changes to an image file
abstract: Editing an image is disclosed. Editing may include receiving a marking on the image, activating a command interface in response to the marking, receiving a command via the command interface, and applying the command to a portion of the image, where the portion is determined based at least in part on the marking.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07986298&OS=07986298&RS=07986298
owner: Adobe Systems Incorporated
number: 07986298
owner_city: San Jose
owner_country: US
publication_date: 20051219
---
Digital photographs may be edited using an image editing application. For example a photograph may be edited in order to fix perceived problems with the photograph such as red eye portions being too light or dark or a color cast on the photo. Typically a user knows which problems the user would like to fix in a photo. However the user does not necessarily know which tools or interfaces to use in order to fix these problems. Most image editing applications provide numerous features that a typical user does not use because the user does not understand what the feature does or how to use the feature. For example a user might not understand the terminology used by the application. A user may have a hard time selecting the exact area to which a change should be applied or may not know this is necessary before proceeding. An improved method of editing an image file would be useful.

The invention can be implemented in numerous ways including as a process an apparatus a system a composition of matter a computer readable medium such as a computer readable storage medium or a computer network wherein program instructions are sent over optical or electronic communication links. In this specification these implementations or any other form that the invention may take may be referred to as techniques. A component such as a processor or a memory described as being configured to perform a task includes both a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. In general the order of the steps of disclosed processes may be altered within the scope of the invention.

A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.

A gesture as used herein refers to a mouse or other pointing device movement associated with a meaning. A gesture may include a marking that is associated with a change. For example if an X is associated with the change delete a user could draw an X over an object in a photo to indicate that removal of the object is desired. Alternatively the user could move a mouse in the shape of an X without marking the photo. In another example moving the mouse in the shape of a P may mean print.

At a change is determined based on the marking. A change includes an edit to the image. Various markings may be associated with the same change. For example illustrate examples of various markings. In markup is a circle around a pair of eyes. Text says Remove red eye. A line connects markup to text . The line may be drawn by a user or automatically drawn. For example a user may first draw markup . In response a dialog box or other command interface may open. Alternatively the user could trigger the dialog box for example by double clicking on markup . The dialog box could include a place for entering a command such as text . When the dialog box is closed the markings would appear as shown. In text says Remove red eye from Bob. Text is located adjacent to the image. The user may have previously tagged a face in the picture with Bob for example. In gesture is an X over a pair of eyes. In some embodiments the same change determined for the markings shown in is the same and that is to remove the red eye of the face on the left.

The command interface can be either displayed to the user for entry or not displayed and a command entry made based on an interpretation of the marking. For example if the marking is a gesture then a command associated with that gesture may be entered. A command interface may include an application programming interface API . A command may include a change provided by a user in the user s own words or selected from machine provided choices or a change that is generated based on a marking.

Returning to the change is applied at . For example in the case of a red eye removal technique may be applied to the face on the left. In some embodiments the change is applied as a preview before the change is applied. At it is determined whether a user adjustment is received. For example the user may view the change and decide to adjust a marking or a parameter associated with the change. For example if the change was to lighten a portion of a photo the user may enlarge the portion of the photo e.g. by making a circle bigger that is lightened and or change the percentage by which the photo is lightened. If an adjustment is received the process returns to in which a change is determined. In this case the change is based on the user adjustment. As such the user can continuously adjust a photo until the user is satisfied with the results. If an adjustment is not received at the process ends at .

In some embodiments a plurality of markings are received at . A plurality of changes may be determined at . The changes may all be applied at . Each change may be individually previewed at before applying the change. An adjustment that affects any of the changes may be received at .

In this example a user is in the process of creating markings . Markings include a circle around the spot on the floor. For example the user may have drawn the circle or other shape around the spot on the floor and command interface window may have opened in response. Window may include a place e.g. a text entry field for the user to enter text or select from a menu of changes to apply to the circled portion of the photo. The menu choices may include default menu choices and or choices that are generated based on the marking as more fully described below. The machine s best guess may be pre filled in a text field. For example the area within the circle may be analyzed and it may be automatically determined that there is an undesirable spot on the floor. As a result Remove spot or Remove as shown may be provided as a menu option. Alternatively the user could enter the text Remove. Such a window may include other ways to receive user input such as a slider bar as shown. The slider bar allows the user to indicate using a slider whether to increase or decrease the region the change would affect. For example the spot may be desirable by the user in which case the user may want to resize the spot. Any parameter related to the change may be shown in window . After closing window markings may include text describing the command e.g. Remove in place of window .

Markings include an arrow from the text Remove tan lines to a circle around the tan lines. For example a user may have drawn the circle. The text Remove tan lines may have been selected or entered by the user in an interface such as window .

Markings include arrows from the text Dress is too dark gray to two bullets. In some embodiments markings is a grouping of two markings. For example a user may have drawn one of the bullets and entered the text Dress is too dark. The user may then have drawn the other bullet and entered the text too gray. The two markings may have been grouped or consolidated to combine the text into Dress is too dark gray and the arrows may have been adjusted resulting in markings .

Marking includes text only and is not located on image . In some embodiments text that refers to changes that apply to the entire image are displayed outside of the image.

Interface allows a user to more naturally describe what the user would like adjusted and where. For example the user may describe what the user does not like about the photo what needs to be fixed and or how it should be fixed using markup gestures and or their own text descriptions on the photo. The user may also specify non exact regions for these descriptions by circling the general area pointing to an object etc. The user may use natural language commands such as this photo looks too blue this area is too dark I want to remove this blemish or Just the green in this general area should be brighter. Natural language processing may be used to understand standard words that a user might use and translate them into changes which can be mapped to algorithms to apply to an image.

Marking may be used to indicate a selection of a portion of an image by roughly circling the portion such as an object. Marking may be circular rectangular or any predefined or freeform shape. For example a user could draw a freeform shape that roughly outlines an object in an image. Marking is a line and may be interpreted in various ways. For example marking could indicate an area which the line points to or an area near the line depending on what is near the line in the image.

Markings and may be referred to as sloppy selection. Various techniques can be used to handle sloppy selection e.g. convert a sloppy selection into a precise pixel selection . For example techniques based on Graph Cut GrabCut may be used. In some embodiments the selection is based at least in part on other markings such as text. For example if the user has entered the text lighten next to a circle around an already white object in the image then a portion of the image other than the white object will be selected such as the background.

Marking may be a gesture that is used to indicate the removal of an object. Marking may be a gesture that is used to indicate that a portion of the photo should be pinched. Marking may be a gesture that is used to indicate that the portions of the image the two sides of marking should be blended or healed.

Markings are provided to an interpreter . Interpreter interprets or translates markings to determine changes to apply to the image. Interpreter may interpret markings by performing natural language processing. For example natural language detection techniques may be used to map a user s words to commands that an application supports. For example if the application is Adobe Photoshop Elements the user words too dark can be mapped to change Shadow Highlights with no change to highlights and a lighter change to the shadows. This can be done using natural language techniques and or a library of typical terms used in describing problems with photos.

Interpreter may use gesture recognition to understand that the user is drawing or has drawn a symbol e.g. an X a circle a rectangle etc. and map the gesture to the definition of a region and or command s .

Some gestures can be directly translated to a change. This is done by having a library of typical gestures used in describing problems with photos X remove arrows in pinch etc and matching gestures not in the library to a defined gesture that is similar. The gesture may be mapped to a change similar to how text may be mapped to a change.

In the case where interpreter cannot translate markings to a degree of certainty the interpreter may ask the user for more information and or offer a short list of best guesses to choose from. More information may be received via user input .

Over time or by direct request of the user the interpreter can learn a particular user s language and gestures for more efficient translation. For example the user may decide to start using r.e. instead of typing red eye. 

In some embodiments interpreter generates a set of changes and the user may modify the changes directly or by going back and changing one or more of markings . For example if markup includes an X over a pair of eyes a change generated may be to remove red eye. An interface may be provided for the user to accept or verify modify or reject the change.

In some embodiments interpreter may be used to assist a user with creating markings. For example a user may draw a circle around a pair of eyes. In response a command interface such as a dialog box or other window may open. The window may include generated and or pre defined changes for the user to select. Remove red eye may be a generated change because the machine may have detected that the circle contains red eyes. The change generated may not be a change the user desires. For example the user wants to remove red eye but the generated changes are brighten and sharpen. If a change is not generated or the only generated choices are not what the user wants the user may enter the text remove red eye. 

Interpreter determines changes based on markup gesture and user input . For example interpreter may determine changes based on a selected area which may be determined based on markup gesture and or user input . For example if a pair of eyes is circled changes may include remove red eye. In another example if X is drawn over a pair of eyes changes may include remove red eye.

The changes are provided to technique selector . A technique includes an algorithm or command s . Technique selector selects technique to apply to implement a change. For example to remove red eye on a selected face a technique for removing red eye may be applied to the selected face. To lighten a portion of an image a lightening technique can be applied.

In this example markings and technique are provided as input to image portion selector . Image portion selector selects portion of an image to which to apply one or more changes. Portion may include for example an object in the image. Portion may be selected based on markings and or technique . For example if markings include a circle around a person and technique includes a red eye removal algorithm then image portion selector may select the person s eyes. In another example if user input includes the text Remove red eye from Bob then image portion selector selects the person s eyes if the person has been previously tagged Bob.

In some embodiments for regions standard shapes and closed paths are recognized. If the path is closed the region is taken as the area inside that path. If the path is not closed more interpretation is needed based on properties of the region alone or in conjunction with the text. For example a line pointing to a very dark area may be interpreted as all dark spots touching where this line points to whereas a line pointing to a gray area cannot be interpreted alone. If the text states too gray should be white the region would be interpreted as all grayish colors touching this spot.

In some embodiments image portion selector selects a portion based on change rather than technique . In some embodiments both change and technique are used to select a portion.

Portion selector may select a general region or a more exact region. Once the technique is determined and the portion for the technique is determined an exact area and parameters associated with the technique may be determined. For example consider a region defined by a circle. In some cases some algorithms should not be run on the entire encircled area.

For example to blend out a cut on a person s hand it may be that the heal command should only be applied on the cut and very little of the surrounding skin. Because the command is heal an encircled area may be further refined. An object close to the size of the circle but within it would be determined.

A Lighten Shadows command may run on the dark spots within a given area but not on the light spots. It may be applied in different percentages to different spots depending on how light they already are. The command may also be applied in the surrounding area perhaps with lower intensity in order to create a realistic blended effect. Therefore the selected area may be further broken down into various degrees of dark and light spots. Different levels of lightening may be applied to the different levels of dark spots. In addition the area outside the selected area may be affected with diminishing amounts of lightening applied moving further from the selected area enabling a blending effect.

A Remove Red Eye command removes red from a circular area of a pupil. A circle around two eyes may be further broken down in order to avoid removing other red spots like red eyeglasses. In some embodiments the textual description of the circle maps to the remove red eye command and red circular areas within the general region are found and the fix only applied to those areas.

At a portion of the image is selected based on the selected techniques and the markings. For example image portion selector may be used to select the portion of the image. At the selected techniques are applied to the selected portion.

For example the user may have pointed to a background area in the photo and typed too dark. This may be interpreted as needing to use the lighten shadows function that it has on that background area. Lighten Shadows is run and the area becomes less dark. Similarly the user may have typed lighten this Lighten the shadows a little make brighter or less black which may all be translated to using the lighten shadows function or technique.

The user may have drawn an X over a cut on the hand of someone in the photo. This may be interpreted as needing to use a healing function on that area of the hand. The healing function is run and the cut disappears. Similarly the user may have drawn a naught symbol put lines through the cut or circled the cut and typed remove and this may be translated in the same way.

At an input is received in response to the markup. For example an input window opens in response to the user creating a marking. The window provides an interface for the user to provide input relating to the marking. For example a user draws a circle or an X on a portion of an image and an input window opens. is optional. At a correction is specified. For example the user can use the input window to input the correction. In some embodiments the user may specify the correction using natural language. In some embodiments the user may select the correction from a list of predefined and or machine selected corrections. Alternatively the correction may be implicit in the marking. For example an X may both identify i.e. select an area and indicate that an object in that area should be removed. At the markings are applied. For example the user selects a Go or Apply All button to apply the marking. In some embodiments each marking is applied as soon as they are drawn. In other words the markings are applied real time. At the changes are verified. For example a list of the changes that were made may be provided and the user can go down the list to check the changes. If the user is dissatisfied with a change the user can manually fix it.

In some embodiments each marking can be previewed and applied. For example the right mouse button might include preview apply and undo options. In another example such options might be available from an input window. The input window may open in response to drawing a marking or may open when the user double clicks on the marking or performs another action. In some embodiments markings may be toggled on or off For example when the preview is on the markings are in an on state the markings are shown on the photo. When the markings are in an off state the markings are not shown and a preview of the markings as applied is shown.

Using sidebar a user can insert modify accept or reject a change associated with a marking. For example marking having identifier is displayed at the top of sidebar . As shown marking is associated with a red eye fix. In sidebar the user may have selected the text red eye from a menu or entered the text red eye in free form. As shown markings and are associated with the changes patch shadow highlight and remove respectively. In sidebar various interfaces may be used for each change including menus slider bars freeform text entry etc. In some embodiments sidebar includes a preview and apply button. In some embodiments each change in sidebar includes a preview and apply button.

Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive.

