---

title: Interface for robot motion control
abstract: Systems and methods are presented that enable a higher-level software application to control a robot's motion through a generic motion interface. In one embodiment, a system includes a controller, an interface, and a set of robot driver modules. The interface receives a command from the controller and translates the command into another command to send to the driver modules. The interface includes a client, a server, and a network. The server includes two interfaces: a client interface to communicate with the client and a driver interface to communicate with the driver modules. The server also includes two buffers: a command queue and a reply queue. The command queue stores commands received from the controller (via the client). The reply queue stores replies received from the driver modules.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08060251&OS=08060251&RS=08060251
owner: Honda Motor Co., Ltd.
number: 08060251
owner_city: Tokyo
owner_country: JP
publication_date: 20051206
---
This application claims priority from the following U.S. provisional patent application which is hereby incorporated by reference Ser. No. 60 633 998 filed on Dec. 6 2004 entitled Controlling Arms Bases and Androids Through a Single Motion Interface. 

The present invention relates to enabling a higher level software application to control a robot s motion through a generic motion interface.

Robot motion interfaces do exist but they are either hardware specific or support only very simple non humanoid robots. As a result the motion of a humanoid robot is generally controlled directly via its device drivers. Developers write their own driver interfaces to the specific robot. These driver interfaces are then used by applications in order to control the robot s motion. It is difficult to create these interfaces due to the lack of knowledge about the internal workings of the robot s proprietary software and hardware. The interfaces themselves tend to be very complex in order to provide access to the robot s various capabilities. Also if the robot s hardware changes the driver interfaces and the applications using them also need to change. This is inefficient because the same algorithms have to be reimplemented every time the hardware changes.

What is needed is a generic interface that enables a higher level software application to control a robot s motion.

Systems and methods are presented that enable a higher level software application to control a robot s motion through a generic motion interface. In one embodiment a system includes a controller an interface and a set of robot driver modules. The controller is used to control the robot s motion via the interface. The interface uses the robot driver modules to directly control the robot. The robot can be either a physical entity or a virtual entity.

In one embodiment the interface communicates with the controller using a first application programming interface API and with the driver modules using a second API. The interface receives a command from the controller and translates the command into another command to send to the driver modules. Commands include query commands motion commands and system commands.

In one embodiment the interface includes a client a server and a network. The server includes two interfaces a client interface to communicate with the client and a driver interface to communicate with the driver modules. The server also includes two buffers a command queue and a reply queue. The command queue stores commands received from the controller via the client . The reply queue stores replies received from the driver modules.

In one embodiment the interface can operate in any one of four command modes direct delay playback and broadcast. In direct mode the client sends commands to the server in blocking mode. In delay mode playback mode and broadcast mode the client sends commands to the server in non blocking mode. In delay mode and playback mode the server uses buffering to compensate for possible network congestion. In delay mode the client controls the size of the time delay. In playback mode the server controls the size of the time delay. In broadcast mode one query received from a client can cause a server to query a robot s state periodically.

In one embodiment a system includes multiple controllers. In this embodiment the interface includes multiple clients. In another embodiment a system includes multiple sets of driver modules. In this embodiment the interface includes multiple servers.

In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent however to one skilled in the art that the invention can be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to avoid obscuring the invention.

Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some portions of the detailed descriptions that follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention also relates to an apparatus for performing the operations herein. This apparatus is specially constructed for the required purposes or it comprises a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program is stored in a computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems are used with programs in accordance with the teachings herein or more specialized apparatus are constructed to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

In one embodiment the controller comprises a software application used to control a robot s motion. The controller communicates with the robot not shown via the interface . Signals sent from the controller to the interface include for example commands to be executed by the robot. Signals sent from the interface to the controller include for example the robot s replies to commands that it has received. In one embodiment signals sent between the controller and the interface comply with an application programming interface API that is provided by the interface .

In one embodiment the set of robot driver modules comprises a set of software drivers and or libraries that can be used to directly control a robot not shown . Signals sent from the interface to the set of robot driver modules include for example commands to be executed by the robot. The commands sent are determined based on the commands received from the controller . Signals sent from the set of robot driver modules to the interface include for example the robot s replies to commands that it has received. In one embodiment signals sent between the interface and the set of robot driver modules comply with a second API that is provided by the set of robot driver modules .

The robot that is controlled by the set of robot driver modules can be either a physical entity or a virtual i.e. simulated entity. Physical robots can include a wide range of robot mechanisms from mobile bases such as a Pioneer 2 from ActivMedia Robotics LLC of Amherst N.H. to humanoid robots such as ASIMO from Honda Motor Co. Ltd. of Japan QRIO from Sony Corp. of Japan and PINO from the Kitano Symbiotic Systems Project of the Japan Science and Technology Agency. Virtual entities can include software models that represent robots or other mobile objects or creatures. Such virtual entities are sometimes referred to as kinematic or kinodynamic simulators.

The first API between the controller and the interface provides a unified interface for a controller to control a robot. In one embodiment the API is independent of both the hardware and software of the controller and interface . Since the API commands are translated by the interface into robot driver module commands the API is compatible across various robots at both a software and hardware level. This means that one controller can be used to control multiple robots each of which has different capabilities. The differences between the robots affect the interface but not the controller . Specifically the interface will translate controller commands differently based on the robot driver module API available for each robot. Thus a change in the robot s software or hardware will affect the interface but not the controller .

In one embodiment the first API comprises three types of commands and two types of replies. The commands which are sent from the controller to the interface include query commands motion commands and system commands. The replies which are sent from the interface to the controller include status signals and error signals.

A query command is used to determine a robot s state such as its kinematic configuration. A motion command is used to make a robot move such as by activating one or more motors. A system command is used to query and control system status.

A reply indicates the status of a command that has been received and can be either a status signal or an error signal. In one embodiment there are four possible status signals and . The signal BUSY indicates that the robot cannot start executing the command because it has not finished executing a previous non interruptible command. The signal SUCCESS indicates that the interface has acknowledged the command. Depending on the implementation of the interface and or the set of robot driver modules this acknowledgement can indicate for example that the interface has received the command that the interface has successfully begun executing the command or that the interface has finished executing the command. The signal indicates that the robot supports the command in a limited way e.g. a holonomic command sent to a non holonomic robot . The signal indicates that the robot does not support the command e.g. a locomotion command sent to a fixed base robot such as a robotic arm mounted on a table .

In one embodiment there are three possible error signals and . The signal indicates that the interface cannot execute the command because for example the robot is in an error state e.g. because its parts have overheated or an incompatible state e.g. because performing the command from the robot s current state would cause the robot to collide with something . The signal indicates that execution of a legitimate command has been halted prematurely due to an error. The signal indicates that the robot is in panic mode which is an emergency condition triggered by the controller .

In one embodiment the controller sends a command or set of commands to the interface in blocking mode. In this embodiment the controller waits to receive a reply signal or multiple reply signals one for each command from the interface before it issues the next command or set of commands . In other words after the controller has sent a command or set of commands to the interface the controller s execution stops and resumes only when the controller receives an acknowledgement or multiple acknowledgements one for each command from the interface . In particular the controller does not send a new command or set of commands to the interface until it has received an acknowledgment regarding the previous command or multiple acknowledgements regarding the previous commands . This acknowledgement can indicate for example that the interface has received the command s that the interface has successfully begun executing the command s or that the interface has finished executing the command s . Thus we have the following series of events The controller issues a command or set of commands to the interface the controller receives an acknowledgement or multiple acknowledgements one for each command from the interface and only then does the controller issue a second command or set of commands to the interface .

In another embodiment the controller sends a command or set of commands to the interface in non blocking mode. In this embodiment after the controller has sent a command or set of commands to the interface the controller s execution continues even though it has not received an acknowledgement or multiple acknowledgements one for each command from the interface .

In one embodiment the interface executes a received command as soon as possible. In another embodiment a command includes a starting time that indicates when the command should be executed. In one embodiment a starting time is absolute such as 13 10 30 which represents 1 10 pm and 30 seconds. In another embodiment a starting time is relative and reflects the reverse priority of the command. For example a first command with a starting time of 40 will be executed after a second command with a starting time of 20 even if the first command was received before the second command. In one embodiment a query command is always executed as soon as possible. A motion command usually is not executed as soon as possible. In one embodiment a PANIC signal is always executed immediately.

In one embodiment the starting time represents the number of seconds or milliseconds to wait until executing the command. If the starting time is zero or negative or not provided then the command is executed as soon as possible. In one embodiment commands with the same priority are executed in their arrival order. In one embodiment the starting time is provided as an argument to the command.

In one embodiment a set of configuration descriptors describes a robot s geometric state regardless of whether the robot is a physical or virtual entity. A robot is represented as a set of rigid links connected by a hierarchical tree of joints. Each link has at most two joints one joint shared with a parent link and one joint shared with a child link. There exists at least one root link with no parent link whose position and orientation are defined with respect to the world frame of reference. In a complex humanoid robot the root link might be the torso. In a simple robot the root link might be the only link in the entire robot. In one embodiment a particular link is referred to as the base of the robot. While the base can be any link it is often the root link or the link that is present at the robot s center of mass when the robot is in its resting state.

In one embodiment robot configuration descriptors include links joints and control frames. This representation is sufficient to describe a wide variety of branched articulated chain mechanisms in arbitrary positions. illustrates a robot and various configuration descriptors according to one embodiment of the invention. Each link joint and control frame can be referenced by a name. This enables the use of an intuitive or common labeling or naming scheme. For example various links might be named leftArm torso rightLeg or head .

In one embodiment a link includes parameters such as mass center of mass a location and inertia tensors. These parameters are useful for dynamic simulation and can be useful for the design of appropriate controllers.

In one embodiment a joint stores the local rigid body transformation of a link with respect to its parent. The transformation is defined by a combination of constant parameters and variable degrees of freedom DOFs of the joint. The constant portion includes inboard and outboard vectors that position the joint in the local coordinates of the parent link and child link respectively. A rest matrix represents the joint s local transformation when all of its DOFs equal zero. This enables different initial poses to be defined when the robot s configuration is reset to its rest or home state.

Together the DOFs of each joint comprise the kinematic state of a robot s configuration. In one embodiment each joint has six DOFs which enables a fully unconstrained rigid transformation for each link. A DOF is specified as being either prismatic or revolute with a related axis vector. This enables any combination of these transformations which can produce common robotic joint types such as pin universal gimbal and prismatic joints. A DOF can also include one or more joint limits to constrain movement.

In one embodiment a control frame has a position and orientation in the local frame of its parent link. In contrast to a joint a control frame is fixed to a particular link and does not exhibit motions independent from the link. The primary use of a control frame is to specify the location and orientation of an end effector or task frame used for manipulation. A control frame provides an interface between the robot s generalized coordinates and the desired task.

In one embodiment a query command or motion command operates on a specific part of a robot such as a degree of freedom DOF a control frame a base or the robot as a whole. For example a query command determines the status of the specific part while a motion command sets the status of the specific part. In one embodiment different parts have different characteristics. For example a DOF includes characteristics such as position position limit speed speed limit acceleration acceleration limit lock status stop status limp status and odometer status. A control frame includes characteristics such as position position limit speed speed limit acceleration acceleration limit lock status stop status and odometer status. A base includes characteristics such as position position limit speed speed limit acceleration acceleration limit lock status stop status limp status and odometer status. The robot as a whole includes characteristics such as lock status stop status limp status home status and motion status.

Query Commands As described above a query command is used to determine a robot s state such as its kinematic configuration. In one embodiment executing a query command returns the status of a kinodynamic variable. This status can be a measurement such as an angle of a servo at a joint. If a set of configuration descriptors describes a robot s state then a query command is like a read command for the configuration descriptors.

In one embodiment a query command specifies one or more variables for which status information should be returned. In another embodiment a query command returns the entire set of robot configuration descriptors. In one embodiment the returned information includes information about the structure of the set of robot configuration descriptors. For example the returned information includes offset indices indicating the locations of joint information link information and control frame information within the set of configuration descriptors. The returned information also includes the size of the memory blocks in which the joint information link information and control frame information are stored. Also a joint can be cross referenced with the links that it joins a link can be cross referenced with its parent joint and child joint and a control frame can be cross referenced with its parent link.

In one embodiment the size of a set of configuration descriptors is constant for a particular robot. In other words if the configuration descriptors are written to a file the file will be of a fixed length regardless of the configuration of the robot. This enables the controller to parse the configuration descriptor information in constant time.

Motion Commands As described above a motion command is used to make a robot move such as by activating one or more motors. Different types of robots can have different types of mechanical capabilities. In one embodiment the API includes a unified set of descriptors that can be used to describe motion. Since these motion commands are general enough to describe the motions of a wide variety of robots the API is compatible with different types of robots.

Specific information about a robot s mechanical capabilities is present in the interface rather than in the API. The interface translates an API motion command to specific driver commands. In other words a motion command is implemented differently by different robots. For example the command x y instructs a robot to move from location x to location y. In order to move a legged robot activates its leg drivers while a wheeled robot activates its wheel drivers. Thus for a legged robot the interface would translate a command to commands to activate leg drivers. For a wheeled robot the interface would translate a command to commands to activate wheel drivers. Note that even though making a legged robot walk is difficult due to stability issues this difficulty is shielded from the controller by the API. The controller merely needs to issue a simple motion command such as

Controlling a robot joint depends on whether an actuator is present at the joint. The types of servo commands accepted by an actuator e.g. setPoint setSpeed and setForce depend on how the robot is implemented. In one embodiment each joint and or control frame is associated with a servo command type that indicates the supported motion commands. A joint or control frame can support one or more types of servo commands.

Recall that if a set of configuration descriptors describes a robot s state then a query command is like a read command for the configuration descriptors. A motion command on the other hand causes a robot to move which changes its configuration descriptors and thus is like a write command for the configuration descriptors.

A motion command can include one or more arguments. In one embodiment an argument that represents a physical quantity such as how far to move is expressed in metric MKS units.

System Commands As described above a system command is used to query or control system status. In one embodiment system status includes communication mode and panic mode. Communication mode which can be direct delay playback or broadcast is described below. Panic mode is either on or off. When a robot enters panic mode it can perform one or more actions and or execute one or more processes. For example a robot can cease executing commands until it is no longer in panic mode. In one embodiment the set of robot driver modules controls a robot s response to being put in panic mode and can be customized for each robot.

In one embodiment the client and the server comprise software applications running on top of operating systems. Any programming or scripting language can be used to write the software applications such as C Java and Perl. Any operating system can be used such as Linux Mac OS from Apple Computer Inc. of Cupertino Calif. and Windows from Microsoft Corp. of Redmond Wash. In one embodiment the client and the server use different programming languages different software applications and or different operating systems. In order to preserve compatibility across operating systems in one embodiment the client and or the server are implemented using software libraries that can be ported to various hardware and software platforms. In particular proprietary software tools and libraries are not used.

The server includes two interfaces a client interface and a driver interface and two buffers a command queue and a reply queue . The client interface enables the server to receive signals from and send signals to the client via the network . The driver interface enables the server to receive signals from and send signals to the set of robot driver modules .

As explained above differences between robots affect the interface but not the controller . Specifically the driver interface portion of the interface will translate controller API commands differently based on the robot driver module API available for each robot. Thus a change in a robot s software or hardware will affect the driver interface but not the controller .

In one embodiment described below but not shown here the server includes a third buffer a playback queue . In another embodiment described below but not shown here the client includes one buffer a reply cache .

The network comprises any type of communication mechanism. If the client and the server are co located e.g. software applications running on the same machine the network can include local communication mechanisms such as shared memory. If the client and server are not co located the network can include remote communication mechanisms such as communications protocols running on top of wired or wireless connections. The communications protocols can include for example the Transmission Control Protocol Internet Protocol TCP IP suite the User Datagram Protocol UDP or the Data Distribution Service for Real time Systems Specification from Object Management Group Inc. of Needham Mass.

The communication mechanism regardless of its type supports a communication protocol. The communication protocol supports four command modes which will be described below. In one embodiment the communication protocol is based on network packages each of which includes a header portion and a payload portion. In this embodiment the client and server communicate by sending packages to each other via the network .

In a package sent from the server to the client the payload portion includes one or more replies where a reply is either a status signal or an error signal. In one embodiment each time a reply is placed in the reply queue the server creates a package containing that reply and sends the package to the client via the client interface . In another embodiment the server creates and sends packages periodically for example after a particular period of time has elapsed if any replies have been placed in the reply queue or after a particular number of replies have been placed in the reply queue .

In a package sent from the client to the server the payload portion includes one or more commands. In one embodiment read commands such as query commands or system commands that query system status and write commands such as motion commands or system commands that set system status are not sent in the same package. The header portion is of a fixed length and includes the size of the payload the type of the payload e.g. read or write and a panic flag. When the server receives a package with the panic flag set it puts the robot into panic mode. Thus a robot s panic mode is set by the package header not by the package payload.

The data in a package can be of any format such as binary plain text e.g. XML etc. In one embodiment when the data is in binary format the values within a payload are stored in network byte order integer format to support compatibility across systems. This is to address byte ordering differences among little endian and big endian processors. Thus command parameters and other configuration descriptors are expressed in integers. In one embodiment the client and the server convert arguments into integer representations as necessary.

The network has various characteristics such as latency and bandwidth that will vary based on the communication mechanisms used. For example the network s latency will probably increase as the distance between the client and the server increases. Since the interface is a black box from the controller s perspective the controller works the same way regardless of the connection characteristics. This modularity is achieved by operating the interface in various communication modes which will be explained below. Thus the network is versatile enough to enable both remote and local motion control.

Returning to the server the client interface reads packages received from the client . The one or more commands in each package payload are parsed. Then the commands are executed by the driver interface by translating them into signals for the set of robot driver modules and sending these signals to the robot driver modules .

The commands are not necessarily executed in the order that they arrived. Instead they are stored in a command queue and scheduled for execution according to their starting times as described above. In one embodiment a signal is not stored in the command queue at all. Instead it is executed immediately by the client interface . All other commands are blocked until the signal is reset.

If a robot generates a reply signal in response to a command the reply signal is transmitted to the driver interface via the set of robot driver modules . The reply signals are parsed and then sent by the client interface to the client . The replies are not necessarily sent to the client in the order that they arrived. Instead they are stored in a reply queue . In one embodiment the replies in the reply queue are scheduled for transmission according to their insertion times into the queue.

The interface can operate in four communication modes direct delay playback and broadcast. Before these modes are described consider how a signal generally flows through the interface . illustrates how a signal flows through the elements shown in according to one embodiment of the invention. illustrates the following steps 1 The client sends a package containing a set of one or more commands to the server via the network . 2 The client interface receives the commands. 3 The commands are placed in the command queue . 4 The driver interface accesses a command from the command queue . 5 The driver interface sends a signal to the set of robot driver modules . 6 The robot driver modules cause the robot to execute the command. 7 The robot generates a reply signal which is sent to the driver modules . 8 The driver interface receives the reply signal from the driver modules . 9 The reply signal is placed in the reply queue . 10 The client interface accesses the reply signal from the reply queue . 11 The client interface sends the reply signal to the client via the network .

In direct mode sometimes referred to as direct drive the client sends packages to the server in blocking mode. In other words after the client has sent a package to the server containing a set of one or more commands step the client s execution stops and resumes only when the client receives acknowledgements from the server for all of the commands in the package sent in step . In particular the client does not send a new package to the server until it has received acknowledgments regarding all of the commands in the previous package. An acknowledgement can indicate for example that the server has received the command that the server has successfully begun executing the command or that the server has finished executing the command. Thus we have the following series of events The client issues a first set of one or more commands to the server the client receives acknowledgements from the server regarding all of the commands in the first set and only then does the client issue a second set of commands to the server . Note that in direct mode if the network is slow during step step or both this will increase the amount of time between each command set issuance by the client .

In one embodiment in direct mode once a connection has been established between the client and the server the client and the server synchronize their clocks. Then the client starts accepting signals e.g. API function calls from the controller to control the robot. When an API function call is received the client creates a network package that includes one or more commands to be executed by the robot. Each command is tagged with a unique identifier and the package is sent to the server via the network . The client s execution halts inside the API function call until the client receives from the server acknowledgements regarding all of the commands in the sent package. In one embodiment a time out mechanism is present so that an API function call can return even if the server crashes or the network breaks down.

The server receives the network package from the client . The client interface parses the package header. If the panic flag is set in the header the driver interface puts the robot into panic mode. The server s queues are flushed e.g. the command queue and the reply queue and reject new commands until the robot is no longer in panic mode.

If the panic flag is not set in the header the client interface parses the package payload and places the one or more commands into the command queue . Commands with starting times of zero or a negative number will be executed before commands with positive starting times as described above. Thus in direct mode the transmission and execution of these types of commands follows a hand shake model.

In direct mode if the client s clock and the server s clock have been synchronized the server generally executes the command when its clock is equal to the command s starting time. However if the clocks have not been synchronized the server does not execute the command at this time. Instead the server determines the time offset between its clock and the client s clock and executes the command when its clock is equal to the sum of the time offset and the command s starting time.

Sometimes the server can fall behind in executing commands. In one embodiment the server does not execute a particular command even if the server s clock has reached the appropriate time unless commands that were supposed to precede the particular command have already been executed. For example the driver interface verifies that the starting time of the command with the highest priority has passed with respect to the server clock.

In delay mode playback mode and broadcast mode the client sends packages to the server in non blocking mode. In other words after the client has sent a package to the server the client s execution continues even though it has not received an acknowledgement from the server .

In blocking mode the client waits to receive the one or more reply signals sent in step before it issues the next command or set of commands. Thus replies to all the commands in one package will arrive at the client prior to replies to commands in a subsequent package. In other words if the client issues a first package with a single command and then after receiving a reply a second package with a new command it will always receive the reply to the first command before receiving the reply to the second command. In non blocking mode the client does not wait to receive the reply signal before it issues the next command. Thus replies will not necessarily arrive at the client in the same order that the associated commands were issued. In other words if the client issues a first command and then a second command it might receive a reply to the second command and then a reply to the first command.

There can be many reasons why the replies arrive in a different order. One reason is that the commands might have different priorities so that they are executed in a different order by the server specifically the driver interface . Another reason is that the commands might require different amounts of time in order to generate a reply.

In one embodiment in order to handle replies received out of order the client includes a reply cache not shown that stores replies received from the server . The reply cache can include for example a dictionary data structure. The element keys are the original commands for which the server generated a reply. In one embodiment an element key is the unique identifier that was tagged to the command by the client . The client can periodically query the reply cache to determine whether the reply to a particular command has been received. In one embodiment the dictionary data structure is implemented as a hash map such as the hash multi map described in the C Standard Template Library part of the C Standard Library a standard managed by the International Organization for Standardization ISO and the International Electrotechnical Commission IEC .

Recall that any network including network has various characteristics such as latency and bandwidth that will vary based on the communication mechanisms used. In delay mode and playback mode the server uses buffering to compensate for possible network congestion. In one embodiment the buffering is achieved by delaying on the part of the driver interface and thus the robot the execution of a sequence of commands. This delay helps to preserve the inter frame timing execution timing between commands contained in different packages in the presence of network limitations such as high latency and or low bandwidth. The execution of the commands is delayed but the inter frame timings are preserved because the command queue acts as a buffer. For example a longer delay or larger amount of buffering can be used to help a client command a robot to execute a difficult motion sequence over a congested network connection.

In delay mode the client controls the size of the time delay. In one embodiment in delay mode once a connection has been established between the client and the server the client synchronizes its clock to the server s local time plus the time delay.

The commands contained in the package will thus have a time offset relative to the server s clock. Thus when the driver interface checks the contents of the command queue it will not execute the commands until the time delay has elapsed. In one embodiment the interface operates in delay mode with a time delay of zero. This embodiment is similar to direct mode except that the client operates in non blocking mode so client server transactions do not necessarily obey the hand shake model.

In playback mode the server controls the size of the time delay. In one embodiment the server determines the time delay based on the observed network congestion. In playback mode in one embodiment the server includes a third cache called the playback queue. When the client interface parses a package to obtain a command the command is placed in the playback queue rather than in the command queue .

In one embodiment the server estimates both the average command execution rate and the average command transmission rate for example 2 commands per second . The execution rate is estimated using the starting times of the commands in the playback queue. The transmission rate is estimated using package timestamps. In one embodiment the client timestamps each package before it sends the package to the sever . 

In one embodiment the execution and transmission rates are used to determine how large the playback queue should be before its contents are emptied into the command queue . In one embodiment the playback queue is emptied once the number of commands it contains exceeds the value of execution rate transmission rate duration of motion sequence . In one embodiment once the contents of the playback queue have been emptied into the command queue the remainder of the commands in the motion sequence is stored directly in the command queue after being received by the server .

In one embodiment the starting times of the commands in the motion sequence are delayed by an amount computed by the server. In one embodiment the time delay T is equal to the server time when the playback queue is emptied T minus the starting time of the first command in the motion sequence t . In other words T T t.

The motion sequence is thus delayed and buffered by the server and the driver interface executes the commands at the proper times even during network congestion. In one embodiment after a sufficient number of commands have been parsed the server determines the ratio of the average time between commands to the average time between package arrivals and uses this ratio to determine the time delay.

In playback mode the inter frame timings are important. Thus the clocks of the client and the server do not need to be synchronized. In playback mode the duration of the motion sequence should be known by the client. Also the execution times of the commands should be roughly evenly spaced. In one embodiment if the execution times of the commands are not evenly spaced additional commands can be inserted to change the time spacings. These commands can be for example no operation commands or commands whose values are interpolated based on the values of the previous command and the next command.

In broadcast mode one read command received from a client can cause a server to query a robot s state periodically. In one embodiment the server accomplishes this via a specialized query command that periodically re inserts a delayed copy of itself into the command queue . For example a client transmits a broadcast request and an associated sampling time. The server inserts into the command queue a query about the robot s state. After the query has been executed the state information is sent to the client as a reply. Also a copy of the query is created and reinserted into the command queue with a priority that has been increased by the sampling time. Thus the query command regenerates itself for future execution by the driver interface . The regeneration process stops once the server has received a client request to cancel broadcasts.

Multiple controllers The interface described above with respect to can also be used in a system where multiple controllers control one robot. illustrates a block diagram of a system for enabling multiple higher level software applications to control a robot s motion through a generic motion interface according to one embodiment of the invention. The system includes three controllers A B C an interface and a set of robot driver modules . The system in is similar to the system in except that the system in includes multiple controllers instead of just one. Although the illustrated embodiment shows three controllers any number of controllers can be used.

The controllers A B C in are similar to the controller in . In one embodiment a controller is a software application used to control a robot s motion. In one embodiment each controller runs on a different piece of hardware. In another embodiment multiple controllers run on the same piece of hardware.

The interface in includes three clients A B C a server and a network . The interface in is similar to the interface in except that the interface in includes three clients instead of just one. Although the illustrated embodiment shows three clients any number of clients can be used. In one embodiment the number of clients in the interface is equal to the number of controllers in the system .

When a system includes multiple controllers the controllers can potentially interfere with each other s operation. For example one controller A can issue a command to the robot to move left while another controller B can issue a command to the robot to move right simultaneously. In one embodiment in order to prevent interference between controllers a locking mechanism is used to control access to a robot by various controllers .

Note that in general interference occurs only when multiple controllers are issuing write commands that seek to simultaneously affect the same part of a robot. As discussed above write commands can change a robot s state and include motion commands and system commands that set system status while read commands cannot change a robot s state and include query commands and system commands that query system status. Interference generally does not occur when 1 the commands are read commands 2 the commands do not seek to affect the robot simultaneously or 3 the commands do not seek to affect the same part of the robot.

In one embodiment when one controller puts the robot into panic mode the server blocks all other commands from being executed until the robot is no longer in panic mode even if a different controller issued the commands.

Multiple sets of drivers The interface described above with respect to can also be used in a system where one controller controls multiple sets of robot drivers . illustrates a block diagram of a system for enabling a higher level software application to control multiple sets of robot drivers through a generic motion interface according to one embodiment of the invention. The system includes a controller an interface and three sets of robot driver modules A B C. The system in is similar to the system in except that the system in includes multiple sets of robot driver modules instead of just one. Although the illustrated embodiment shows three sets of robot driver modules any number of sets of robot driver modules can be used.

The illustrated embodiment can be used for example to control a modular robot. A modular robot is a robot that is made of other robots. One example of a modular robot is a robot that includes a mobile base and an arm that is rigidly attached to the base but that can perform motions such as flexion and extension by activating its motors. Another example is a robot that includes a mobile base a left arm and a right arm.

The interface in includes one client three servers A B C and a network . The interface in is similar to the interface in except that the interface in includes three servers instead of just one. Although the illustrated embodiment shows three servers any number of servers can be used. In one embodiment the number of servers in the interface is equal to the number of sets of robot driver modules in the system .

The sets of robot driver modules in are similar to the set of robot driver modules in . In one embodiment each set of robot driver modules in is configured to control a different robot or a different part of a modular robot . For example one set of robot driver modules controls a base while another set of robot driver modules controls an arm.

Note that the functionalities of a modular robot can be greater than the sum of its parts. That is a modular robot can have additional functionalities above and beyond the functionalities of each of its component robots or parts. For example consider a modular robot that includes a left arm and a right arm. Individually each arm can perform particular motions such as flexion extension and grasping ungrasping. Together however they can perform additional motions such as supporting an object by balancing it on top of the two arms.

While the system of can be used to perform such complex motions it is difficult for the controller to coordinate the multiple sets of robot driver modules . The interface described above with respect to can also be used to create a composite robot that hides this complexity.

Note that while and described various systems that included multiple controllers multiple sets of robot driver modules and a composite robot respectively these systems can be combined to form additional types of systems. For example an additional controller can be added to the system of or the system of . As another example an additional set of robot driver modules can be added to the system of or the system of .

Although the invention has been described in considerable detail with reference to certain embodiments thereof other embodiments are possible as will be understood to those skilled in the art. For example another embodiment is described in RoboTalk Controlling Arms Bases and Androids Through a Single Motion Interface by A. Y. Yang H. Gonzalez Bafios V. Ng Thow Hing and J. E. Davis Proceedings of the International Conference on Advanced Robotics ICAR Seattle Wash. Jul. 18 20 2005 which is hereby incorporated by reference.

