---

title: Flexible speech-activated command and control
abstract: A collection of human language terms is obtained. The terms describe a system resource. At least one term in the collection does not describe the identify of the resource. The collection of human language terms is incorporated into a grammar. The grammar is utilized as a basis for identifying spoken user commands.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08620667&OS=08620667&RS=08620667
owner: Microsoft Corporation
number: 08620667
owner_city: Redmond
owner_country: US
publication_date: 20051017
---
Developers of speech activated command and control systems are confronted with a relatively unique challenge in that unlike most other computer implemented means for supporting user input there is typically no visible indication of available alternatives for input operations. Thus when a user sits down in front of a machine it is often difficult for him or her to decide what they are going to say. The user often has been conditioned to point and click as they seek to discover available functions and command alternatives. Performing similar exploration through spoken utterances can be for many a more intimidating process. It can be difficult for individuals to choose words with any kind of certainty that they will be connected with a desirable input operation.

A common user initiated operation is the launching of a software application. A logical way to support speech activation of such an operation is to configure the speech interface to listen for an initial action word e.g. launch run start etc. followed by the name of an application e.g. Microsoft Word Microsoft Excel etc. . A problem with this approach is that it requires a user to be equipped with a significant amount of knowledge as to what name or names have been assigned to various applications.

In some cases a user will likely be familiar with the most probable application identifiers such as when the user purchases a specific software application and installs it on their own machine. In other cases familiarity is less likely. For example many machines come pre bundled with numerous software applications. Often times a purchaser of such a machine doesn t buy based on the value added software but more based on other differentials such as price and or hardware capabilities. This is just one example of a situation in which a user may not be familiar with available software applications.

Users that experiment with speech activated command and control will often choose more general terminology over the more specific. For example a user that purchases a machine having a TV card might choose to say start television rather than start Video Viewer 5 the latter being the actual name of the desired application. These types of misses can frustrate or discourage a user sometimes causing them to give up on voice activated functionality all together.

The discussion above is merely provided for general background information and is not intended for use as an aid in determining the scope of the claimed subject matter. Further it should also be emphasized that the claimed subject matter is not limited to implementations that solve any or all of the disadvantages of any currently known systems noted in this section.

A collection of human language terms is obtained. The terms describe a system resource. At least one term in the collection does not describe the identify of the resource. The collection of human language terms is incorporated into a grammar. The grammar is utilized as a basis for identifying spoken user commands.

This Summary is provided to introduce concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended for use as an aid in determining the scope of the claimed subject matter.

Embodiments are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with various embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers telephony systems distributed computing environments that include any of the above systems or devices and the like.

Embodiments may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Some embodiments are designed to be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules are located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing some embodiments includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard a microphone and a pointing device such as a mouse trackball or touch pad. Other input devices not shown may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer is operated in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a hand held device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

It should be noted that speech recognition engine in actual implementation may not be a single unified component. For example as is shown in dotted lines in the actual system architecture may incorporate functionality of a speech application program interface . One example not by limitation of such an interface is SAPI 5.0 offered by Microsoft Corporation of Redmond Wash. as part of their Windows XP operating system. Generally speaking SAPI 5.0 is a software layer that allows a speech enabled application e.g. application to communicate with a speech recognition engine e.g. engine .

SAPI 5.0 gives developers among other things a rich set of speech services for building high performance applications that run on desktop mobile and server platforms. With SAPI 5.0 a speech enabled application and a speech recognition engine do not communicate directly with each other all communication is instead done via SAPI. In addition SAPI takes responsibility for a number of functions in a speech system including the loading of grammar files a function that will be described below in the context of system . As is shown in grammar files may be provided to SAPI instead of to the actual recognition engine . The present discussion of SAPI 5.0 is intended simply to underscore the fact that actual implementation of system may be more complex than the illustration of .

Speech recognition engine can be configured to incorporate the functionality of one or more supplemental analytical tools to support a correct interpretation of words associated with input . For example recognition engine can be configured to contextually analyze words to ensure correct interpretation for words that sound alike such as write and right . In another example recognition engine can be configured to incorporate a speaker profile not illustrated into the analysis thereby enabling the engine to accommodate a particular user s distinct speech patterns and accent. Those skilled in the art will appreciate that these and other enhancements should be considered within the scope of the present invention.

In order to support a desirable level of speed and accuracy speech recognition engine also incorporates a grammar . Grammar defines a set of recognized words. Generally speaking grammar supplies recognition engine with an expectation of what might be said. The recognition engine will illustratively incorporate this expectation into the analysis of determining what was said. In the command and control context grammar will include a list of words associated with commands or control instructions.

As is illustrated in an indication of recognized speech e.g. a textual representation is forwarded to a command and control application . Application is illustratively configured to facilitate any of a variety of functions based on the output of engine . Such functions might include but are not limited to navigating menus retrieving data navigating toolbars and navigating application dialogs.

System can be implemented so as to enable a user to utilize a speech activated command to initiate loading or otherwise initiate use of a software application. An example will now be provided. A particular speech input illustratively corresponds to a spoken utterance comprising start video viewer express wherein Video Viewer Express is an application designed to enable a viewer to watch movies. Grammar illustratively includes an indication of start and video viewer express as terms that very well might be included in a command. Speech recognition engine analyzes the utterance in light of grammar and determines that the textual components of the utterance include start video viewer express . An indication of this recognized speech is then provided to application . Based on this information application supports an immediate loading of the Video Viewer Express application.

When system is utilized as the example suggests as means for initiating the loading of software applications there is some issue as to how to determine what type of information should be included in grammar . The grammar will assumedly include action words e.g. run launch load start etc. that serve as an indication that the user desires to initiate use of an application. The challenge lies in determining what words to include as indicators of which application to load.

One option is to include actual names of applications in grammar . As is indicated in as optional block such names can be derived based on analysis of one or more file systems to which the user has access. When a piece of software is installed it is generally true that related files are copied to a storage medium often a hard drive. These files will often include at least one link file that serves as a short cut to an executable file.

Link files are often associated with a name that represents a relatively user friendly indication of the application itself. Further the names associated with link files are often prominently displayed to the user thereby informing their vocabulary as to how the application is likely to be referred to within the framework of the speech recognition system. Thus one option is to integrate names associated with link files into the speech recognition grammar . In some cases it may be desirable to incorporate only link files that show up in a particular portion of a user interface e.g. only link files displayed as part of the programs listed under a START menu .

Once the content of links has been incorporated into the grammar the recognition engine can leverage the grammar to become equipped to listen for those words or phrases or at least parts of the phrases. Indications of recognized words or phrases are provided to command and control application to support a determination as to which software application it is that the user desires be activated. A conflict resolution process may be carried out with the user if there are multiple or no matching software applications. Those skilled in the art will appreciate that an indication of a program name other than a link file can be similarly identified from within the file system and similarly without departing from the scope of the present invention.

Thus consistent with the described example one way to configure system is such that when speech support is launched at least some of the content of the file system e.g. the content of the START menu is examined. Application names are recorded and built into the grammar which is incorporated by the recognition engine. Subsequently if the user utters the name or partial name of an application it is matched against the grammar to support a determination as to how many applications may match what the user said e.g. there can be many applications called uninstall .

One problem with constructing the grammar based only on application names is that it greatly limits the user s command vocabulary. It isn t uncommon for a user to be inclined to prefer more general terminology than specific. For example a user that purchases a machine having a TV card might choose to say start television rather than start Video Viewer 5 the latter being the actual name of the desired application. These types of misses can frustrate or discourage a user of a speech activated command system sometimes causing them to give up on the speech activated functionality all together.

Thus it is preferable to extend the user s command vocabulary to include words that are more familiar or intuitive such as application capabilities or characteristics. is a flow chart diagram illustrating steps associated with launching an application based on speech input that includes a capability or characteristic. In accordance with block speech input is received and includes an action key word e.g. start run launch load etc. together with an application capability or characteristic e.g. television photo editor music player burner spreadsheet video conferencing etc. . In accordance with block a determination is made based on the input as to how many applications correspond to the spoken capability or characteristic.

If there are no corresponding applications then in accordance with block a conflict resolution process is initiated. In accordance with block if there is one corresponding application then that application is launched a user confirmation step can optionally be executed prior to launching . If there is more than one corresponding application then interaction with the user is facilitated in order to determine which application is to be launched.

Any user interface means can be utilized to facilitate user selection in accordance with step . For example consideration should be given to the speech command start picture editing. There very well may be four or more applications that include a picture editor. If there are multiple corresponding applications then the user is presented with a list of applications from which to choose. In one embodiment the system is configured to enable the user to eliminate and or add applications to the result set for a given speech command. It should be noted that the user interface for facilitating selection confirmation or other user interactions can be leveraged from an existing source of such interfaces such as the operating system. In one embodiment a UI presented to the user includes a list of applications wherein the UI is configured to support a narrowing of the set based on hierarchy e.g. folder hierarchy . In one embodiment a UI provided to the user is configured to enable the user to use the application capability information as a basis for sorting or otherwise organizing a result set.

It is worth noting that the described speech activated command and control based on application capabilities or characteristics enables intuitive and user friendly discovery of system resources. It is quite conceivable that a user searching to perform a particular task will discover previously unknown means for doing so. This is an added benefit of the proposed system.

One way to extend system to support the functionality described in elation to is to extend grammar to include application capabilities and or characteristics.

A preferable approach is for the applications to expose a richer explanation of what it is they can do. By incorporating such an explanation into the speech activated interface a user will gain the potential of effective and intuitive speech activated application command and control.

In accordance with block speech support is launched. For example this step might be associated with activation of the speech activated command and control application shown in . In accordance with block a query is performed against a search engine interface which is shown in as a search engine API . The query illustratively requests particular attributes for a variety of applications e.g. what is the application name what are its capabilities characteristics what file should get run if the user makes a proper request etc Those skilled in the art will appreciate that the precise nature of a query will vary at least depending on implementation details and preferences.

As is indicated by block application data is retrieved based on the query. The application data illustratively includes application capabilities and or characteristics. Application name information may also be included in the retrieved data. In search engine is generally illustrated as being configured to retrieve the application data directly from a plurality of applications and . This may be an over simplification relative to actual implementation. In one embodiment for each application the search engine API is configured to expose a collection of extra metadata stored in an application associated database. In one embodiment the collection of metadata is separate from its related application files for example the application files stored on a hard disk drive. In one embodiment the metadata for multiple applications is stored for retrieval from a central database which is designated in as a central database shown in dots to indicate an alternative configuration .

In accordance with step in data retrieved by the search engine API is then incorporated into grammar in order to provide support for a broader command and control vocabulary. In one embodiment a user can launch an application by saying an appropriate command word e.g. launch run load open etc. followed by one of the application capabilities characteristics etc. The command execution process can be carried in a manner similar to the process described in relation to .

Thus the proposed system represents an improvement over building the grammar based on a crawling of the file system for application names. Instead search engine functionality such as a search engine API associated with an operating system is leveraged in order to collect rich application data. The application data illustratively comprises properties or database entries added for example by the application developer or manufacturer in order to expose capabilities or characteristics in a way that makes the application more accessible through means involving user initiated speech activated command and control.

It is worth mentioning that additional user created data can be similarly leveraged in the context of the described speech activated command and control system. This user created information can be associated to software applications to support enhanced command and control features. This enables the query for application data to be customized in many potential different ways. In one example the query is formatted as a request for a set of applications limited only to those that the user might actually want to run. The user can illustratively configure the system to manipulate which applications will be included in the query results. For example a user can illustratively designate an application as being one that he or she does not want to run ever or even be tempted to run unless the user set configuration is changed. An application with such a designation can illustratively be automatically filtered out of the query results. This is just one example of many different ways in which the query process can be leveraged in the command and control context.

It is of course conceivable that a change may occur e.g. a new application added an application deleted user makes a change to a relevant attribute etc. after the grammar has been constructed. In one embodiment when a relevant change has occurred a notification comes back from the search engine API. The notification indicates that something has changed. The user may be provided with the opportunity to start the process over e.g. reconstruct the grammar so as to include updated data.

The described command and control scenario does not have to be limited to the software application context. The search API is extensible and generally will not be limited to an expectation of a certain kind of data. The format of a given query generally dictates what attributes are to be retrieved. A query might include a request for all things that the user should be able to initiate through a voice command e.g. initiating applications initiating a peripheral device accessing data from a database etc. .

As is shown in items that can be launched or accessed based on the described command and control system include but are not limited to network resources data software applications hardware devices e.g. cameras telephones external peripheral devices etc. data databases external network based or local and their content data as well as any other component capable of being launched or accessed based on speech activated commands data .

In one embodiment for components that can be speech activated or voice accessed the command and control vocabulary will include support for one or more action key words that serve as an identifier that assists the command and control application in identifying which resource it is that the user wants to exploit. As has been mentioned action key words that initiate applications can include run launch load start etc. . A phone and its functionality can illustratively be initiated by call contact talk to etc. . These are just examples to demonstrate the point.

In one embodiment the command and control vocabulary is also configured to support an additional identifier s that follows an action key word. As has been described for an application the command word might be an application name capability or characteristic. Providing support for other extended command vocabularies is also within the scope of the present invention. For example the command and control system can be configured to support a phone component such that saying call a name e.g. call Jerod Johnson will cause the phone component to be activated and initiate a call to the named person i.e. Jerod Johnson . Assumedly the named Jerod Johnson would have been retrieved by the search engine API and incorporated into the speech grammar. Those skilled in the art will appreciate that this example is only one of many that should be considered within the scope of the present invention.

Another example will help provide further insight as to how the same architecture can be applied in command and control contexts other than the launching of applications. Consideration should be given to a scenario wherein a user s system includes a first database full of pictures and a second database full of music. With regard to the music database in terms of the user s natural speech inclinations the user is most likely use action words such as play or listen to e.g. I want to play song x or I want to listen to song y . For the picture database the user would be more inclined to terms such as look at or view or show. Thus it is desirable for a speech activated command and control system to support a retrieval of music or pictures through commands involving the noted types of intuitive activation key words.

It was noted in relation to that different action key words can be assigned to different system components or resources e.g. the music database the picture database and an application database are all assigned different action key words . In one embodiment each system component or resource or at least each that has its own assigned action key words is associated with a particular query to be executed by the search engine API . The query illustratively relates to a retrieval of identifiers that could potentially follow the particular action key word.

For example as has been described when there is an action key word that corresponds to a software application the query may be configured to target application names capabilities characteristics or any other data that may be exposed to support a better speech activated command and control experience for the user e.g. start picture editor or load television . In contrast when there is an action key word that corresponds to the music database the query can be configured to target song name artist information album information genre information or any other information that may be exposed to support a better speech activated command and control experience for the user e.g. play Billy Joel or listen to smooth jazz . When there is an action key word that corresponds to the picture database the query may be configured to target photo identifiers of photo content information as to when photo was taken context of a picture or any other information that may be exposed to support a better speech activated command and control experience for the user e.g. show me a picture from Christmas last year or show me a picture of Jason Blanco .

Thus not only can extra data be associated with applications to support an improved command and control experience for the user but data can be similarly leveraged to support intuitive access to data stored in databases. The potential for specific applications is essentially unlimited. For example one could imagine a recipe database that is associated with action key words such as cook make prepare etc. The extra info exposed to the command and control system might include specific content identifiers cuisine type dish name category . Based on these identifiers as incorporated into the command and control grammar a user can target specific desired content. For example cook Indian food may lead to a retrieval of all Indian food recipes in the cookbook database. Similarly the user can request prepare meatballs or make a vegetarian meal and receive appropriate results.

In one embodiment results are returned in a user interface that supports some degree of additional browsing by the user for example through files arranged in a hierarchy. In one embodiment one or more UI s are utilized to support a focusing of the user s request. For example a user might say prepare vegetarian meal . This command might cause the speech engine to identify many hits in the database. In such a case a UI can be utilized to focus the search through speech or manual navigation e.g. There are 57 things in the database marked vegetarian which one do you want or You said play the beatles which album do you want .

Another example is a contacts database. This type of database can be configured to support action key words such as talk to dial or call. Attributes retrieved as valid terms that follow the actin key words can include first name last name. Thus a user can say talk to Stan Jones. The terms will be recognized and the appropriate retrieval of information and action will be executed. In this case a default call application may be accessed to actually execute the call. The action that actually occurs when proper commands are received is illustratively configurable for example through settings in the command and control application.

Thus for a given database or a given software application or a given device or a given network resource or any other system component extra data can be provided and leveraged in order to inform a speech activated command and control system as to what kinds of commands and identifiers should be expected. The more components or resources that are incorporated into the architecture the more flexible the speech interface becomes from the user s perspective.

In accordance with block some action occurs that indicates that the user desires to use the speech activated system e.g. speech support application is launched loading is initiated when machine is turned on etc. . In accordance with block a request is made for system components or resources that are configured for speech based access or activation. In accordance with block an indication of the relevant system components or resources is received. In accordance with block the search engine API is leveraged to perform queries for the various systems resources or components queries for the extra data that supports the extended command and control vocabulary . In one embodiment the nature of needed queries is determined based on action key words received in response to the request for resources. In accordance with bock the command and control grammar is constructed so as to at least contain some of the so called extra data. In one embodiment the grammar is handed off to a system designed to support the speech interface e.g. SAPI . It should be noted that without departing from the scope of the present invention any registration system can be utilized to obtain information about system resources or components.

It should be noted that the present invention is not limited to application in the context of a local search engine API. is a schematic diagram demonstrating that a web service can be leveraged as a tool for accessing the data from a source the data including data that is incorporated into grammar . For example in one embodiment a local examination e.g. an examination of the hard drive is conducted to determine all accessible applications. Based on the applications e.g. based on their names or action key words a web query is conducted into order to retrieve associated extra data e.g. capability and or characteristic data . Of course this could just as easily be extended to system resources other than applications.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

