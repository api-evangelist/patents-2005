---

title: Multichip rendering with state control
abstract: Circuits, methods, and apparatus that provide multiple graphics processor systems where specific graphics processors can be instructed to not perform certain rendering operations while continuing to receive state updates, where the state updates are included in the rendering commands for these rendering operations. One embodiment provides commands instructing a graphics processor to start or stop rendering geometries. These commands can be directed to one or more specific processors by use of a set-subsystem device mask.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07629978&OS=07629978&RS=07629978
owner: NVIDIA Corporation
number: 07629978
owner_city: Santa Clara
owner_country: US
publication_date: 20051031
---
The present invention relates to reducing redundant geometry rendering while providing state updates to each processor in a multiple graphical processor system.

Graphics processing subsystems are designed to render graphical images for computer gaming and other electronic systems. These subsystems typically include a graphics processing unit GPU which is a highly complex integrated circuit device optimized to perform graphics computations and its memory which is referred to as a graphics memory.

To meet ever increasing demands for realism and speed some GPUs include more transistors than typical central processing units CPUs . In addition graphics memories have become quite large in order to improve system speed by reducing traffic on a system bus some graphics cards now include as much as 512 MB of memory. But despite these advances a demand for even greater realism and faster rendering persists.

As one approach to meeting this demand NVIDIA Corporation of San Jose Calif. has developed state of the art multi chip SLI graphics processing subsystems in which two or more GPUs operate in parallel. Parallel operation substantially increases the number of rendering operations that can be carried out.

When multiple processors operate in parallel it is desirable that each perform a unique set of processing steps. That is it is desirable that the multiple processors do not perform redundant tasks such as rendering operations. When fewer redundant rendering operations are performed the efficiency of each processor is increased and the benefits that come from using multiple processors is realized to a greater extent.

These rendering operations are controlled by the receipt of rendering commands. Some rendering commands contain information regarding the state of the image these may be referred to as state updates. State updates include changes in point of view lighting and the like. It is important that each processor in a multiple graphics processing system receive these updates.

Accordingly it is desirable to prevent redundant geometry rendering while ensuring that each processor in a multiple graphics processor system receive necessary state updates.

Accordingly embodiments of the present invention provide circuits methods and apparatus where graphics processors in multiple graphics processor systems can be instructed to not perform specific rendering operations while continuing to receive state updates where state updates are included in rendering commands for the rendering operations.

An exemplary embodiment of the present invention provides a combination of two types of commands or instructions that may be used to allow GPUs to avoid unnecessary geometry rendering while continuing to receive state updates. The first type of command instructs GPUs in a multiple GPU system to either ignore or execute one or more subsequent commands. This command can be referred to as a SetSubDeviceMask SSDM .

The second type of commands are instructions to either stop or start pulling geometries. When a stop geometry pulling command is executed by a GPU the GPU retrieves geometries called by rendering commands but does not pass them to its rendering engine and 3 D pipeline. Turning off geometry pulling allows a GPU to receive state update information contained in rendering commands and associated geometries while saving the capacity of its rendering engine and pipeline by not passing geometries to them unnecessarily. When a start geometry command is executed by a GPU the GPU retrieves geometries called by rendering commands and does pass them to its rendering engine and 3 D pipeline. The SSDM command in conjunction with the stop and start geometry pulling commands allow the status of geometry pulling for each GPU to be controlled on an individual basis.

Thus the combination allows geometry pulling to be turned on and off for specific GPUs in a system preventing unnecessary geometry rendering while allowing state updates to be received. The two types of commands used in combination provide an efficient method of rendering with two or more GPUs.

A better understanding of the nature and advantages of the present invention may be gained with reference to the following detailed description and the accompanying drawings.

Computer system includes a central processing unit CPU and a system memory communicating via a bus . User input is received from one or more user input devices such as a keyboard or mouse coupled to bus . Visual output is provided on a display device such as a conventional CRT or LCD based monitor operating under control of a graphics processing subsystem coupled to system bus . A system disk and other components such as one or more removable storage devices e.g. floppy disk drive compact disk CD drive and or DVD drive may also be coupled to system bus .

Graphics processing subsystem includes two or more graphics processing units each with its own graphics memory though in other embodiments these memories can be shared. GPUs and memories may be implemented using one or more integrated circuit devices such as programmable processors application specific integrated circuits ASICs and memory devices. In one embodiment graphics processing subsystem is implemented using one or more expansion cards adapted to be connected to an appropriate bus slot e.g. PCI E on a motherboard of system .

Each of GPUs includes a rendering module a memory interface module and a scanout module . Rendering modules may be configured to perform various tasks related to generating pixel data from graphics data supplied via system bus interacting with respective graphics memories to store and update pixel data and the like. Rendering modules generate pixel data from 2 D or 3 D scene data provided by various programs executing on CPU .

Memory interface modules which communicate with respective rendering modules and scanout modules manage interactions with respective graphics memories . Each memory interface module may also include pathways for writing pixel data received from system bus to the respective graphics memory without processing by rendering module .

Graphics memories may be implemented using one or more integrated circuit memory devices of generally conventional design. The graphics processing subsystem may include any amount of dedicated graphics memory some implementations may have no dedicated graphics memory and may use system memory and dedicated graphics memory in any combination and may each contain various physical or logical subdivisions such as a pixel buffer and a command buffer . Each pixel buffer stores pixel data for an image or for a part of an image that is read and processed by the respective scanout module and transmitted to display device for display. This pixel data may be generated from 2 D or 3 D scene data provided to rendering modules of GPUs via system bus or by various processes executing on CPU and provided to one or more of pixel buffers via system bus . Pixel buffers are advantageously each double buffered so that while data for a first image is being read for display from a front frame buffer data for a second image can be written to a back frame buffer without affecting the currently displayed image.

Command buffers are used to queue commands received via system bus for execution by respective rendering modules and or scanout modules as described below. Other portions of graphics memories may be used to store data required by GPUs such as texture data color lookup tables executable program code for GPUs and so on.

Scanout modules read pixel color data from pixel buffers and transfer the data to display device to be displayed. In one embodiment scanout modules operate isochronously scanning out frames of pixel data at a prescribed refresh rate e.g. 80 Hz regardless of any other activity that may be occurring in GPUs or elsewhere in system . In some embodiments the prescribed refresh rate can be a user selectable parameter and the scanout order may be varied as appropriate to the display format e.g. interlaced or progressive scan .

It will be appreciated by one skilled in the art that the system described is illustrative and that variations modifications are possible. A GPU may be implemented as one or more integrated circuit devices and different GPUs of a multi processor graphics system might or might not be identical in structure capabilities and operation. Any or all of the GPUs or other components may be mounted on an expansion card mounted directly on a system motherboard or integrated into a system chipset component e.g. into the Northbridge chip of one commonly used PC system architecture or a more advanced Integrated Graphics Processor IGP type device available from NVIDIA Corporation of San Jose Calif. . Graphics processing subsystems can be implemented using one or more expansion cards adapted for various bus standards including PCI PCI E AGP and so on. In one embodiment all of the GPUs are mounted on one expansion card. In another embodiment different GPUs are mounted on different interconnected expansion cards. The cards may be interconnected using a system bus e.g. PCI E or a special card to card connector may be provided.

Also while in this and the other figures the processors are shown as being graphics processing units or GPUs other types of processors may be used. For example general purpose processors may be used. Other types of processors for example processors having generalized and specialized processing paths may be used. For example processors including a non specific processing circuit and processing circuit that is specialized for graphics application may be used. Also general purpose processors or other types of processors can be used. These processors may be combined in any appropriate manner.

Interconnection between the GPUs may also be modified. For instance a bridge unit might be provided to interconnect GPUs. A bridge unit which can be in a separate chip or integrated with one of the GPUs receives incoming data from system bus and distributes it appropriately e.g. to all GPUs or to those GPUs identified by a sub device mask . Another bridge unit might be provided to manage selection among candidate pixels during scanout. Graphics processing subsystems embodying the present invention may be incorporated into a variety of devices including general purpose computer systems video game consoles and other special purpose computer systems DVD players handheld devices such as mobile phones or personal digital assistants and so on.

Command buffer stores sets of rendering commands such as rendering command and sets of rendering data such as rendering data . In one embodiment a rendering command is associated with rendering data. The rendering command defines the set of rendering processes to be performed by the GPU on an associated rendering data. In a further embodiment the rendering data is stored in the command buffer adjacent to the corresponding rendering command.

The CPU writes rendering commands and data sets to the command buffer . The command buffer can include a number of rendering commands and data sets. The CPU writes commands and data sets into the command buffer at the location determined by put pointer . Following each CPU write into the command buffer the CPU increments the put pointer to the next unused location in the command buffer . In an embodiment a driver software program executed by the CPU translates high level rendering commands from a rendering application into commands and data sets which are then written into the command buffer . In a further embodiment the driver software program receives high level rendering commands via an application programming interface for example DirectX or OpenGL .

The GPUs and read commands and data sets from the command buffer at a location determined by get pointers and . Following each GPU read from the command buffer the GPUs and increment the get pointers and to the location of the next command or data set in the command buffer . In one embodiment each GPU has a separate get pointer which is incremented in other embodiments this pointer is shared and only one GPU increments the get counter following a GPU read.

The CPU and GPUs and can access the command buffer independently. In an embodiment the CPU periodically adds new commands and data sets to the command buffer . Simultaneously the GPUs and read processes commands and data sets previously stored by the CPU . Provided the CPU stays ahead of the GPUs and the GPUs and are able to render images without waiting for the CPU . In an embodiment the CPU writes commands and data sets for frames several frames ahead of the frame being rendered by the GPUs and .

In an embodiment the command buffer is limited in size. As an example a typical command buffer is five megabytes in size. When either the get pointers and or put pointer reaches the end of the command buffer the pointer is reset to the location of the beginning of the command buffer . In this manner the command buffer wraps around enabling the CPU and GPUs and to access the command buffer in a continuous loop.

In order to make full use of both GPUs and it is desirable that each GPU render a unique set of geometries. The less overlap there is in their rendering workload the higher the efficiency of each GPU. Accordingly it is desirable that each GPU and receive a unique set of geometries and corresponding rendering commands.

But this division of rendering commands has limited practicality and requires a great deal of overhead complexity to achieve. Some rendering commands contain information that is needed by all the GPUs in a system. For example a rendering command may contain state information regarding a change in the point of view referred to as camera position current color or texture current shader program or the like. If these updates are not received by each GPU the image may degrade in a quite striking manner. For example if a change in camera position is not received by each GPU the point of view for images or image portions rendered by different GPUs will vary leading to unfortunate results. Accordingly an embodiment of the present invention provides for rendering commands to be received by each GPU in a system while eliminating or reducing unneeded or redundant rendering and 3 D pipeline tasks. An outline for one method of achieving this is shown below.

The command buffer is shown in this example as storing a number of commands. These commands and associated data are typically provided to the command buffer by a central processing unit not shown . The central processing unit stores commands and data in the command buffer and are later read by the GPUs and .

A set subsystem device mask command SSDM is received by the GPUs and . In this example the format of the command is SSMD where the leading one indicates that the following command or commands are directed towards GPU and the trailing zero indicates that GPU is to ignore the following command or commands. Specifically in various embodiments a zero may be used to mask one or more commands from a GPU. A zero may mask only the next command from a GPU it may mask some number of commands or it may mask all subsequent commands until another SSDM command instructs otherwise.

In this example the following command is an instruction to turn geometry pulling off. Since GPU was instructed to receive this command GPU will pull geometries. Since GPU was instructed to ignore this command GPU does not change state with respect to geometry pulling that is if it was pulling geometries before it remains in that state if it was not pulling geometries it will continue to not pull geometries until instructed to act otherwise.

In a second set subsystem device mask command SSDM is received from the command or push buffer by the graphics processing units GPU and GPU . Again the GPUs receive this command asynchronously that is each GPU may receive this command at the same or at different times. The SSDM command instructs GPU that it is to execute the following command or commands. The SSDM command also instructs GPU to ignore or not execute the following command or commands. That is the SSDM command masks the following command or commands from GPU .

In this example the following command is an instruction to turn geometry pulling on. Since GPU was instructed to receive this command GPU will pull geometries. Since GPU was instructed to ignore this command GPU does not change state with respect to geometry pulling. In this particular case since it was previously instructed to stop geometry pulling it remains in that state.

Whether a GPU has been instructed to start or stop pulling geometries the GPU retrieves geometries called for by received rendering commands. These geometries are typically retrieved by the individual GPUs from a frame buffer or graphics memory. When a GPU is in the geometry pulling mode the geometries are processed by the GPU for example by rendering engines and graphics pipelines. When a GPU is in the stop pulling mode the geometries are not passed to the rendering engines and graphics pipeline.

In a set subsystem device mask command SSDM is received by the GPUs from the push buffers. Again for simplicity the GPUs are shown as receiving the SSDM command at the same time though in various embodiments the GPUs may read from the push buffer asynchronously. This SSDM has a mask 11 indicating that both GPUs are to execute the following command or commands.

In both GPU and GPU receive rendering command from the push buffer . GPU is in the geometry pulling mode so it retrieves geometries called by the rendering command and passes them to its rendering engine and pipeline. GPU is in the stop geometry pulling mode so it retrieves geometries called by the rendering command but does not pass them to its rendering engine and pipeline.

It will be appreciated by one skilled in the art that other variations are possible. For example if an SSDM command only effects the next instruction the SSDM instruction would not be required. This and other variations may be made consistent with embodiments of the present invention.

A second SSDM command is received in line . This has a mask value of 01 which instructs GPU to execute the following commands and further instructs GPU to ignore the following commands. The following command on line is an instruction to turn on geometry pulling. Accordingly GPU ignores this command while GPU turns geometry pulling on. Line is a further SSDM command. This command has a mask value 11 indicating that both GPU and GPU are to execute the following command. In this example the following commands are rendering commands . Accordingly GPU receives geometries that are needed by or called for in the rendering commands and passes them to the rendering engine and graphics pipeline. Conversely GPU receives the geometries called for in the rendering commands but does not pass them to the rendering engine and graphics pipeline.

A command instructing the GPU to ignore one or more following commands is received in act . An instruction to turn off geometry pulling is received in act . Accordingly GPU will turn off geometry pulling while GPU ignores this command and its geometry pulling status remains unchanged.

A command instructing CPU to ignore one or more subsequent commands is received in act . An instruction to turn on geometry pulling is received by the GPUs in act . Accordingly GPU enters the geometry pulling mode while the status of GPU remains unchanged. Specifically since GPU was instructed in act to turn off geometry pulling and instructed in act to ignore the instruction in act to turn on geometry pulling GPU remains in the geometry pulling off mode. Again each GPU may receive commands either synchronously or asynchronously though for clarity it is assumed that each GPU receives instructions synchronously.

An instruction directing both GPUs to execute the following commands is received in act . Rendering commands are received by both GPUs in act . Accordingly in act GPU retrieves the geometries called for by the received rendering commands but does not send them to the rendering engine or graphics pipeline. However in act GPU retrieves the corresponding geometry and does pass them to the rendering engine and graphics pipeline. In this way each GPU can be instructed to either render or not render various geometries while both GPUs receive any geometries needed for state updates.

In a multi chip system the processing burden may be divided among the GPUs in various ways. In the split frame rendering mode multiple GPUs operate in parallel to render different portions of an image for display device . Each GPU renders pixel data for a different portion of the displayable image such as a number of lines of a raster based display. The image portions may correspond to horizontal bands vertical bands or other divisions as desired.

Ideally the display area or screen is partitioned in such a way that each GPU requires an equal amount of time to render its portion of the image. If the rendering times are unequal a GPU that finishes its portion of the frame first will be idle wasting valuable computational resources. In general simply partitioning the display area equally among the GPUs is not an optimal solution because the rendering complexity of different parts of an image can vary widely. For example in a typical scene from a video game the foreground characters and or vehicles which are often complex objects rendered from a large number of primitives tend to appear near the bottom of the image while the top portion of the image is often occupied by a relatively static background that can be rendered from relatively few primitives and texture maps. When such an image is split into top and bottom halves the GPU that renders the top half will generally complete its portion of the image then wait for the other GPU to finish. To avoid this idle time it is desirable to divide the display area unequally with the top portion being larger than the bottom portion. In general the optimal division depends on the particular scene being rendered and may vary over time even within a single video game or other graphics application.

In one embodiment of the present invention each GPU provides feedback data to the graphics driver program or other program executing on CPU . The feedback data provides information about the time taken by a particular GPU to render its portion of the image. The graphics driver program uses this feedback to dynamically balance the load among the GPUs by modifying the clip rectangle from time to time that is by changing the dividing line to a different line P based on the relative processing load and rendering completion time of the two GPUs.

An SSDM command is received. This command has mask 10 indicating that the next command is for GPU and not for GPU. This is followed by a stop pulling geometry command setting GPU in the stop pulling geometry mode.

An SSDM command is received next. This command has mask 01 indicating that the next command is for GPU and not for GPU. This is followed by a start pulling geometry command setting GPU in the start pulling geometry mode but leaving GPU in the geometry pulling off or stopped mode.

An SSDM command with a 11 mask instructing both geometries to execute the following commands is received. Afterward rendering commands for the top of the frame F are received. These rendering commands typically include rendering commands for geometries that are in the top portion of the frame as well as those that straddle the borderline between the top and bottom portions of the frame. At this point GPU can begin to render the top of the frame shown here as time .

The previous sequence can now be implemented in reverse such that GPU renders the bottom portion of the frame specifically those geometries that are in the bottom portion of the frame as well as those that straddle the borderline between the top and bottom portions of the frame.

Specifically an SSDM command having a mask value of 01 is received followed by a stop pulling geometries command . Accordingly GPU enters the stop pulling geometries state. Subsequently an SSDM command having a mask value of 10 is received followed by a start pulling geometries command . Accordingly GPU enters the start pulling geometries state.

An SSDM command with a 11 mask instructing both geometries to execute the following commands is received. Afterward rendering commands for the bottom of the frame F are received. These rendering commands typically include rendering commands for geometries that are in the bottom portion of the frame as well as those that straddle the borderline between the top and bottom portions of the frame. GPU then renders the bottom of the frame shown here as time .

In this way two types of commands are used in combination to provide an efficient method of rendering a frame with two or more GPUs. Specifically a first type of command is used to turn on or off geometry pulling. Turning off geometry pulling allows a GPU to receive state update information contained in a rendering command and associated geometry while saving the capacity of its rendering engine and pipeline by not passing geometries to them unnecessarily. The second type of command the SSDM directs the various GPUs to ignore or execute commands allowing the status of geometry pulling for each GPU to be controlled on individual basis.

It should be noted that this drawing is not to scale. For example the time to render the top of frame and bottom of frame are approximately equal in a typical embodiment of the present invention. Further details regarding the timing of the rendering of these frame portions and for the rendering of successive frames as in the examples below can be found in co pending U.S. patent application number Ser. No. 11 153 931 titled GRAPHICAL REPRESENTATION OF LOAD BALANCING AND OVERLAP by Franck R. Diard which is incorporated by reference.

While in this example the rendering commands for the top and bottom of the frame are shown as being received as groups for simplicity in various embodiments of the present invention they may be intermixed with the GPUs being instructed to turn on and turn off rendering several times each frame. Further rendering commands associated with geometries that straddle the borderline between the top and bottom of a frame may be preceded by an SSDM having a mask value of 11 such that both GPUs render those geometries.

Again in the above example frames are rendered using the technique known as split frame rendering. A second processing workload sharing technique is referred to as alternate frame rendering AFR . In this technique frames to be displayed are rendered sequentially by different graphics processing units. For example where two GPUs are used alternating frames are rendered by each GPU with one GPU rendering odd numbered frames the other rendering even numbered frames. In AFR operation there is no load balancing to be done since the processing load on each GPU is set by the frame to be rendered.

Different systems that may benefit by embodiments of the present invention may employ AFR while others may use SFR. Further some systems may alternate or switch between AFT and SFR depending on the application that is running at any one time.

Subsequently a sequence of commands is used to turnoff geometry pulling for GPU and turn on geometry pulling for GPU. Specifically an SSDM command having a mask value 01 is received. This is followed by a stop geometry pulling command . A second SSDM command having a mask value 10 is received followed by a start geometry pulling command . An SSDM command having a mask value 11 is received followed by rendering commands for frame . As the frame rendering commands are received GPU renders frame during time .

Again in this way two types of commands are used in combination to provide an efficient method of rendering a frame with two or more GPUs. The first type of command is used to turn on or off geometry pulling. Turning off geometry pulling allows a GPU to receive state update information contained in rendering commands and associated geometries while saving the capacity of its rendering engine and pipeline by not passing geometries to them unnecessarily. The second type of command the SSDM directs the various GPUs to ignore or execute commands allowing the status of geometry pulling for each GPU to be controlled on individual basis.

The above description of exemplary embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form described and many modifications and variations are possible in light of the teaching above. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications to thereby enable others skilled in the art to best utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated.

