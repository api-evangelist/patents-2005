---

title: Trusted computing platform
abstract: Whenever a user wishes to interact with the computing platform, he first requests the integrity metric, which he compares with an authentic integrity metric that was measured by a trusted party. If the metrics are the same, the platform is verified and interactions can continue. Otherwise, interaction halts on the basis that the operation of the platform may have been subverted.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07444601&OS=07444601&RS=07444601
owner: Hewlett-Packard Development Company, L.P.
number: 07444601
owner_city: Houston
owner_country: US
publication_date: 20051012
---
This patent application is a continuation application of U.S. Ser. No. 09 913 452 filed on Dec. 5 2001 now U.S. Pat. No. 6 988 250 which is the U.S. national stage of PCT application No. PCT GB00 00528 filed on Feb 15 2000.

The present invention generally relates to trusted devices trusted computing platforms trusted transactions and methods of operating the same.

For commercial applications a client computing platform typically operates in an environment where its behaviour is vulnerable to modification by local or remote entities. This potential insecurity of the platform is a limitation on its use by local parties who might otherwise be willing to use the platform or remote parties who might otherwise communicate with the platform for example for the purposes of E commerce. For the present purposes both local parties and remote parties will be referred to as users unless otherwise stated.

Existing security applications for example virus detection software execute on computing platforms under the assumption that the platform will operate as intended and that the platform will not subvert processes and applications. This is a valid assumption provided that the intended software state has not become unstable or has not been damaged by other software such as viruses. Users therefore typically restrict the use of such platforms to non critical applications and weigh the convenience of using the platforms against the risk to sensitive or business critical data.

Increasing the level of trust in platforms therefore enables greater user confidence in existing security applications such as the Secure Sockets Layer or IPSec or remote management applications. This enables greater reliance on those applications and hence reduced cost of ownership . Greater trust also enables new electronic methods of business since there is greater confidence in the correct operation of both local and remote computing platforms.

In this document the word trust is used in the sense that something can be trusted if it always behaves in the expected manner for the intended purpose.

The present inventors have appreciated that it is desirable to use a physical device in a computing platform to verify and possibly enforce trust in that platform. Typically the device provides trusted measurement and reporting of attributes of the associated platform which indicate the integrity of the platform. Also most preferably the device is tamper resistant.

In accordance with a first aspect the present invention provides computing apparatus comprising mounted on an assembly main processing means and main memory means each being connected for communication with one or more other components on the assembly together with a trusted device mounted on the assembly and being connected for communications with one or more other components on the assembly the trusted device being arranged to acquire a true value of an integrity metric of the computing apparatus.

As used herein for reasons of simplicity of description the term device also encompasses plural devices having equivalent function or equivalent functionality integrated into one or more existing platform devices or assemblies. Additionally the term true as used herein implies that the value is that which correctly reflects the state of the computing apparatus. This may be ensured if the measurement method is substantially un modifiable other than by the trusted device.

In accordance with a second aspect the present invention provides a method of operating a system comprising trusted computing apparatus and a user the trusted computing apparatus incorporating a trusted device being arranged to acquire the true value of an integrity metric of the computing apparatus the method comprising the steps of 

the trusted device acquiring the true value of the integrity metric of the trusted computing apparatus 

the user generating a challenge for the trusted computing apparatus to prove its integrity and submitting the challenge to the trusted computing apparatus 

the trusted computing apparatus receiving the challenge and the trusted device generating a response including the integrity metric and returning the response to the user and

the user receiving the response extracting the integrity metric from the response and comparing the integrity metric with an authenticated metric for the trusted computing apparatus that had been generated by a trusted party.

In accordance with a third aspect the present invention provides a method of establishing a communications channel in a system between trusted computing apparatus and remote computing apparatus the method including the step of the remote computing apparatus verifying the integrity of the trusted computing apparatus using the above method and maintaining the communications channel for further transactions in the event the integrity of the trusted computing apparatus is successfully verified by the remote computing apparatus.

In accordance with a fourth embodiment the present invention provides a method of verifying that trusted computing apparatus is trustworthy for use by a user for processing a particular application the method including the step of the user verifying the integrity of the trusted computing apparatus using the above method and the user using the trusted computing apparatus to process the particular application in the event the integrity of the trusted computing apparatus is successfully verified by the remote computing apparatus.

Other aspects and embodiments of the present invention will become apparent from the following description and claims.

The present exemplary embodiment generally provides the incorporation into a computing platform of a physical trusted device whose function is to bind the identity of the platform to reliably measured data that provides an integrity metric of the platform. The identity and the integrity metric are compared with expected values provided by a trusted party TP that is prepared to vouch for the trustworthiness of the platform. If there is a match the implication is that at least part of the platform is operating correctly depending on the scope of the integrity metric.

A user verifies the correct operation of the platform before exchanging other data with the platform. A user does this by requesting the trusted device to provide its identity and an integrity metric. Optionally the trusted device will refuse to provide evidence of identity if it itself was unable to verify correct operation of the platform. The user receives the proof of identity and the identity metric and compares them against values which it believes to be true. Those proper values are provided by the TP or another entity that is trusted by the user. If data reported by the trusted device is the same as that provided by the TP the user trusts the platform. This is because the user trusts the entity. The entity trusts the platform because it has previously validated the identity and determined the proper integrity metric of the platform.

Once a user has established trusted operation of the platform he exchanges other data with the platform. For a local user the exchange might be by interacting with some software application running on the platform. For a remote user the exchange might involve a secure transaction. In either case the data exchanged is signed by the trusted device. The user can then have greater confidence that data is being exchanged with a platform whose behaviour can be trusted.

The trusted device uses cryptographic processes but does not necessarily provide an external interface to those cryptographic processes. Also a most desirable implementation would be to make the trusted device tamperproof to protect secrets by making them inaccessible to other platform functions and provide an environment that is substantially immune to unauthorised modification. Since tamper proofing is impossible the best approximation is a trusted device that is tamper resistant or tamper detecting. The trusted device therefore preferably consists of one physical component that is tamper resistant.

Techniques relevant to tamper resistance are well known to those skilled in the art of security. These techniques include methods for resisting tampering such as appropriate encapsulation of the trusted device methods for detecting tampering such as detection of out of specification voltages X rays or loss of physical integrity in the trusted device casing and methods for eliminating data when tampering is detected. Further discussion of appropriate techniques can be found at http www.cl.cam.ac.uk mgk25 tamper.html. It will be appreciated that although tamper proofing is a most desirable feature of the present invention it does not enter into the normal operation of the invention and as such is beyond the scope of the present invention and will not be described in any detail herein.

The trusted device is preferably a physical one because it must be difficult to forge. It is most preferably tamper resistant because it must be hard to counterfeit. It typically has an engine capable of using cryptographic processes because it is required to prove identity both locally and at a distance and it contains at least one method of measuring some integrity metric of the platform with which it is associated.

A trusted platform is illustrated in the diagram in . The platform includes the standard features of a keyboard mouse and visual display unit VDU which provide the physical user interface of the platform. This embodiment of a trusted platform also contains a smart card reader a smart card reader is not an essential element of all trusted platforms but is employed in various preferred embodiments described below. Along side the smart card reader there is illustrated a smart card to allow trusted user interaction with the trusted platform as shall be described further below. In the platform there are a plurality of modules these are other functional elements of the trusted platform of essentially any kind appropriate to that platform the functional significance of such elements is not relevant to the present invention and will not be discussed further herein .

As illustrated in the motherboard of the trusted computing platform includes among other standard components a main processor main memory a trusted device a data bus and respective control lines and lines BIOS memory containing the BIOS program for the platform and an Input Output IO device which controls interaction between the components of the motherboard and the smart card reader the keyboard the mouse and the VDU . The main memory is typically random access memory RAM . In operation the platform loads the operating system for example Windows NT into RAM from hard disk not shown . Additionally in operation the platform loads the processes or applications that may be executed by the platform into RAM from hard disk not shown .

Typically in a personal computer the BIOS program is located in a special reserved memory area the upper 64K of the first megabyte do the system memory addresses F h to FFFFh and the main processor is arranged to look at this memory location first in accordance with an industry wide standard.

The significant difference between the platform and a conventional platform is that after reset the main processor is initially controlled by the trusted device which then hands control over to the platform specific BIOS program which in turn initialises all input output devices as normal. After the BIOS program has executed control is handed over as normal by the BIOS program to an operating system program such as Windows NT which is typically loaded into main memory from a hard disk drive not shown .

Clearly this change from the normal procedure requires a modification to the implementation of the industry standard whereby the main processor is directed to address the trusted device to receive its first instructions. This change may be made simply by hard coding a different address into the main processor . Alternatively the trusted device may be assigned the standard BIOS program address in which case there is no need to modify the main processor configuration.

It is highly desirable for the BIOS boot block to be contained within the trusted device . This prevents subversion of the obtaining of the integrity metric which could otherwise occur if rogue software processes are present and prevents rogue software processes creating a situation in which the BIOS even if correct fails to build the proper environment for the operating system.

Although in the preferred embodiment to be described the trusted device is a single discrete component it is envisaged that the functions of the trusted device may alternatively be split into multiple devices on the motherboard or even integrated into one or more of the existing standard devices of the platform. For example it is feasible to integrate one or more of the functions of the trusted device into the main processor itself provided that the functions and their communications cannot be subverted. This however would probably require separate leads on the processor for sole use by the trusted functions. Additionally or alternatively although in the present embodiment the trusted device is a hardware device that is adapted for integration into the motherboard it is anticipated that a trusted device may be implemented as a removable device such as a dongle which could be attached to a platform when required. Whether the trusted device is integrated or removable is a matter of design choice. However where the trusted device is separable a mechanism for providing a logical binding between the trusted device and the platform should be present.

The trusted device comprises a number of blocks as illustrated in . After system reset the trusted device performs a secure boot process to ensure that the operating system of the platform including the system clock and the display on the monitor is running properly and in a secure manner. During the secure boot process the trusted device acquires an integrity metric of the computing platform . The trusted device can also perform secure data transfer and for example authentication between it and a smart card via encryption decryption and signature verification. The trusted device can also securely enforce various security control policies such as locking of the user interface.

Specifically the trusted device comprises a controller programmed to control the overall operation of the trusted device and interact with the other functions on the trusted device and with the other devices on the motherboard a measurement function for acquiring the integrity metric from the platform a cryptographic function for signing encrypting or decrypting specified data an authentication function for authenticating a smart card and interface circuitry having appropriate ports for connecting the trusted device respectively to the data bus control lines and address lines of the motherboard . Each of the blocks in the trusted device has access typically via the controller to appropriate volatile memory areas and or non volatile memory areas of the trusted device . Additionally the trusted device is designed in a known manner to be tamper resistant.

For reasons of performance the trusted device may be implemented as an application specific integrated circuit ASIC . However for flexibility the trusted device is preferably an appropriately programmed micro controller. Both ASICs and micro controllers are well known in the art of microelectronics and will not be considered herein in any further detail.

One item of data stored in the non volatile memory of the trusted device is a certificate . The certificate contains at least a public key of the trusted device and an authenticated value of the platform integrity metric measured by a trusted party TP . The certificate is signed by the TP using the TP s private key prior to it being stored in the trusted device . In later communications sessions a user of the platform can verify the integrity of the platform by comparing the acquired integrity metric with the authentic integrity metric . If there is a match the user can be confident that the platform has not been subverted. Knowledge of the TP s generally available public key enables simple verification of the certificate . The non volatile memory also contains an identity ID label . The ID label is a conventional ID label for example a serial number that is unique within some context. The ID label is generally used for indexing and labelling of data relevant to the trusted device but is insufficient in itself to prove the identity of the platform under trusted conditions.

The trusted device is equipped with at least one method of reliably measuring or acquiring the integrity metric of the computing platform with which it is associated. In the present embodiment the integrity metric is acquired by the measurement function by generating a digest of the BIOS instructions in the BIOS memory. Such an acquired integrity metric if verified as described above gives a potential user of the platform a high level of confidence that the platform has not been subverted at a hardware or BIOS program level. Other known processes for example virus checkers will typically be in place to check that the operating system and application program code has not been subverted.

The measurement function has access to non volatile memory for storing a hash program and a private key of the trusted device and volatile memory for storing acquired integrity metric in the form of a digest . In appropriate embodiments the volatile memory may also be used to store the public keys and associated ID labels of one or more authentic smart cards that can be used to gain access to the platform .

In one preferred implementation as well as the digest the integrity metric includes a Boolean value which is stored in volatile memory by the measurement function for reasons that will become apparent.

In step at switch on the measurement function monitors the activity of the main processor on the data control and address lines to determine whether the trusted device is the first memory accessed. Under conventional operation a main processor would first be directed to the BIOS memory first in order to execute the BIOS program. However in accordance with the present embodiment the main processor is directed to the trusted device which acts as a memory. In step if the trusted device is the first memory accessed in step the measurement function writes to volatile memory a Boolean value which indicates that the trusted device was the first memory accessed. Otherwise in step the measurement function writes a Boolean value which indicates that the trusted device was not the first memory accessed.

In the event the trusted device is not the first accessed there is of course a chance that the trusted device will not be accessed at all. This would be the case for example if the main processor were manipulated to run the BIOS program first. Under these circumstances the platform would operate but would be unable to verify its integrity on demand since the integrity metric would not be available. Further if the trusted device were accessed after the BIOS program had been accessed the Boolean value would clearly indicate lack of integrity of the platform.

In step when or if accessed as a memory by the main processor the main processor reads the stored native hash instructions from the measurement function in step . The hash instructions are passed for processing by the main processor over the data bus . In step main processor executes the hash instructions and uses them in step to compute a digest of the BIOS memory by reading the contents of the BIOS memory and processing those contents according to the hash program. In step the main processor writes the computed digest to the appropriate non volatile memory location in the trusted device . The measurement function in step then calls the BIOS program in the BIOS memory and execution continues in a conventional manner.

Clearly there are a number of different ways in which the integrity metric may be calculated depending upon the scope of the trust required. The measurement of the BIOS program s integrity provides a fundamental check on the integrity of a platform s underlying processing environment. The integrity metric should be of such a form that it will enable reasoning about the validity of the boot process the value of the integrity metric can be used to verify whether the platform booted using the correct BIOS. Optionally individual functional blocks within the BIOS could have their own digest values with an ensemble BIOS digest being a digest of these individual digests. This enables a policy to state which parts of BIOS operation are critical for an intended purpose and which are irrelevant in which case the individual digests must be stored in such a manner that validity of operation under the policy can be established .

Other integrity checks could involve establishing that various other devices components or apparatus attached to the platform are present and in correct working order. In one example the BIOS programs associated with a SCSI controller could be verified to ensure communications with peripheral equipment could be trusted. In another example the integrity of other devices for example memory devices or co processors on the platform could be verified by enacting fixed challenge response interactions to ensure consistent results. Where the trusted device is a separable component some such form of interaction is desirable to provide an appropriate logical binding between the trusted device and the platform. Also although in the present embodiment the trusted device utilises the data bus as its main means of communication with other parts of the platform it would be feasible although not so convenient to provide alternative communications paths such as hard wired paths or optical paths. Further although in the present embodiment the trusted device instructs the main processor to calculate the integrity metric in other embodiments the trusted device itself is arranged to measure one or more integrity metrics.

Preferably the BIOS boot process includes mechanisms to verify the integrity of the boot process itself. Such mechanisms are already known from for example Intel s draft Wired for Management baseline specification v 2.0 BOOT Integrity Service and involve calculating digests of software or firmware before loading that software or firmware. Such a computed digest is compared with a value stored in a certificate provided by a trusted entity whose public key is known to the BIOS. The software firmware is then loaded only if the computed value matches the expected value from the certificate and the certificate has been proven valid by use of the trusted entity s public key. Otherwise an appropriate exception handling routine is invoked.

Optionally after receiving the computed BIOS digest the trusted device may inspect the proper value of the BIOS digest in the certificate and not pass control to the BIOS if the computed digest does not match the proper value. Additionally or alternatively the trusted device may inspect the Boolean value and not pass control back to the BIOS if the trusted device was not the first memory accessed. In either of these cases an appropriate exception handling routine may be invoked.

At the first instance a TP which vouches for trusted platforms will inspect the type of the platform to decide whether to vouch for it or not. This will be a matter of policy. If all is well in step the TP measures the value of integrity metric of the platform. Then the TP generates a certificate in step for the platform. The certificate is generated by the TP by appending the trusted device s public key and optionally its ID label to the measured integrity metric and signing the string with the TP s private key.

The trusted device can subsequently prove its identity by using its private key to process some input data received from the user and produce output data such that the input output pair is statistically impossible to produce without knowledge of the private key. Hence knowledge of the private key forms the basis of identity in this case. Clearly it would be feasible to use symmetric encryption to form the basis of identity. However the disadvantage of using symmetric encryption is that the user would need to share his secret with the trusted device. Further as a result of the need to share the secret with the user while symmetric encryption would in principle be sufficient to prove identity to the user it would insufficient to prove identity to a third party who could not be entirely sure the verification originated from the trusted device or the user.

In step the trusted device is initialised by writing the certificate into the appropriate non volatile memory locations of the trusted device . This is done preferably by secure communication with the trusted device after it is installed in the motherboard . The method of writing the certificate to the trusted device is analogous to the method used to initialise smart cards by writing private keys thereto. The secure communications is supported by a master key known only to the TP that is written to the trusted device or smart card during manufacture and used to enable the writing of data to the trusted device writing of data to the trusted device without knowledge of the master key is not possible.

At some later point during operation of the platform for example when it is switched on or reset in step the trusted device acquires and stores the integrity metric of the platform.

When a user wishes to communicate with the platform in step he creates a nonce such as a random number and in step challenges the trusted device the operating system of the platform or an appropriate software application is arranged to recognise the challenge and pass it to the trusted device typically via a BIOS type call in an appropriate fashion . The nonce is used to protect the user from deception caused by replay of old but genuine signatures called a replay attack by untrustworthy platforms. The process of providing a nonce and verifying the response is an example of the well known challenge response process.

In step the trusted device receives the challenge and creates an appropriate response. This may be a digest of the measured integrity metric and the nonce and optionally its ID label. Then in step the trusted device signs the digest using its private key and returns the signed digest accompanied by the certificate to the user.

In step the user receives the challenge response and verifies the certificate using the well known public key of the TP. The user then in step extracts the trusted device s public key from the certificate and uses it to decrypt the signed digest from the challenge response. Then in step the user verifies the nonce inside the challenge response. Next in step the user compares the computed integrity metric which it extracts from the challenge response with the proper platform integrity metric which it extracts from the certificate. If any of the foregoing verification steps fails in steps or the whole process ends in step with no further communications taking place.

Assuming all is well in steps and the user and the trusted platform use other protocols to set up secure communications for other data where the data from the platform is preferably signed by the trusted device .

Further refinements of this verification process are possible. It is desirable that the challenger becomes aware through the challenge both of the value of the platform integrity metric and also of the method by which it was obtained. Both these pieces of information are desirable to allow the challenger to make a proper decision about the integrity of the platform. The challenger also has many different options available it may accept that the integrity metric is recognised as valid in the trusted device or may alternatively only accept that the platform has the relevant level of integrity if the value of the integrity metric is equal to a value held by the challenger or may hold there to be different levels of trust in these two cases .

The techniques of signing using certificates and challenge response and using them to prove identity are well known to those skilled in the art of security and therefore need not be described in any more detail herein.

As indicated above shows the flow of actions in an example of verification of platform integrity by a user interacting with the trusted platform with a smart card . As will be described the process conveniently implements a challenge response routine. There exist many available challenge response mechanisms. The implementation of an authentication protocol used in the present embodiment is mutual or 3 step authentication as described in ISO IEC 9798 3 Information technology Security techniques Entity authentication mechanisms Part 3 Entity authentication using a public key algorithm International Organization for Standardization November 1993. Of course there is no reason why other authentication procedures cannot be used for example 2 step or 4 step as also described in this reference.

Beforehand a platform configured for use by users of in this way will typically be operating under the control of its standard operating system and executing the authentication process which waits for a user to insert their smart card . Apart from the smart card reader being active in this way such a platform is typically rendered inaccessible to users by locking the user interface i.e. the screen keyboard and mouse . This will however not be the case in all embodiments of the invention.

When the smart card is inserted into the smart card reader the trusted device is triggered to attempt mutual authentication in step by generating and transmitting a nonce A to the smart card in step . A nonce such as a random number is used to protect the originator from deception caused by replay of old but genuine responses called a replay attack by untrustworthy third parties.

In response in step the smart card generates and returns a response comprising the concatenation of the plain text of the nonce A a new nonce B generated by the smart card an ID of the trusted device and some redundancy the signature of the plain text generated by signing the plain text with the private key of the smart card and a certificate containing the ID and the public key of the smart card .

The trusted device authenticates the response by using the public key in the certificate to verify the signature of the plain text in step . If the response is not authentic the process ends in step . If the response is authentic in step the trusted device generates and sends a further response including the concatenation of the plain text of the nonce A the nonce B an ID of the smart card and the acquired integrity metric the signature of the plain text generated by signing the plain text using the private key of the trusted device and the certificate comprising the public key of the trusted device and the authentic integrity metric both signed by the private key of the TP.

The smart card authenticates this response by using the public key of the TP and comparing the acquired integrity metric with the authentic integrity metric where a match indicates successful verification in step . If the further response is not authentic the process ends in step .

If the procedure is successful both the trusted device has authenticated the logon card and the smart card has verified the integrity of the trusted platform and in step the authentication process executes the secure process for the user.

In certain types of interaction the authentication process can end at this point. However if a session is to be continued between the user and the trusted platform it is desirable to ensure that the user remains authenticated to the platform.

Where continued authentication is required the authentication process sets an interval timer in step . Thereafter using appropriate operating system interrupt routines the authentication process services the interval timer periodically to detect when the timer meets or exceeds a pre determined timeout period in step .

Clearly the authentication process and the interval timer run in parallel with the secure process. When the timeout period is met or exceeded the authentication process triggers the trusted device to re authenticate the smart card by transmitting a challenge for the smart card to identify itself in step . The smart card returns a certificate including its ID and its public key in step . In step if there is no response for example as a result of the smart card having been removed or the certificate is no longer valid for some reason for example the smart card has been replaced with a different smart card the session is terminated by the trusted device in step . Otherwise in step the process from step repeats by resetting the interval timer.

Additionally or alternatively in some embodiments it may be required that the user profile is encrypted and signed to protect privacy and integrity. If so a secure data transfer protocol may be needed between the trusted device and the smart card . There exist many available mechanisms for transferring secure credentials between two entities. A possible implementation which may be used in the present embodiment is secure key transport mechanisms from ISO IEC DIS 11770 3 Information technology Security techniques Key management Part 3 Mechanisms using asymmetric techniques International Organization for Standardization March 1997.

Modifications of this verification process using other well known challenge and response techniques can easily be achieved by the skilled person. Similarly alternative verification processes can be used by parties interacting with the platform in a different manner that is other than as a user equipped with a smart card .

