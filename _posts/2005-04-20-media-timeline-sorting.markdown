---

title: Media timeline sorting
abstract: Media timeline sorting is described. In an implementation, a method includes receiving a media timeline at an application programming interface, in which, the media timeline includes a plurality of timeline objects. One or more of the timeline objects reference a respective one of a plurality of media. A plurality of segments is generated from the media timeline for sequential rendering such that each segment references a particular set of the timeline objects that are rendering during a duration of the segment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07313755&OS=07313755&RS=07313755
owner: Microsoft Corporation
number: 07313755
owner_city: Redmond
owner_country: US
publication_date: 20050420
---
The present invention generally relates to media and more particularly relates to media timeline sorting.

Users of computers such as desktop PCs set top boxes personal digital assistants PDAs and so on have access to an ever increasing amount of media from an ever increasing variety of sources. For example a user may interact with a desktop PC that executes a plurality of applications to provide media for output such as home videos songs slideshow presentations and so on. The user may also utilize a set top box to receive traditional television programming that is broadcast to the set top box over a broadcast network. Additionally the set top box may be configured as a personal video recorder PVR such that the user may store the broadcast content in memory on the set top box for later playback. Further the user may interact with a wireless phone that executes a plurality of applications such that the user may read and send email play video games view spreadsheets and so forth.

Because of the wide variety of media sources and the wide variety of computers that may be utilized to provide and interact with media traditional applications and computers were often configured to specifically address each particular type of media. For example applications that were executed on a video game console to output video games were typically configured to provide an output of the applications to a television and were not configured to provide the output that could be utilized by other computers and other devices. Therefore presentation of content that was provided by the different media sources such as computers and or applications may involve multiple applications and devices which may be both time and device intensive. Additionally multiple applications that were executed on the same computer may be configured to specifically address the particular type of media provided by each respective application. For instance a first audio playback application may be configured to output media configured as songs. A second audio playback application however may be configured to record and playback the recordings in an audio format that is not compatible with the first audio playback application such as an audio dictation format. Thus even applications that are configured for execution on the same computer and the same type of media e.g. audio may provide media that is incompatible one to another.

A timeline provides a way for a user to define a presentation of media. For example a media player can play a list of songs which is commonly referred to as a playlist . Traditional timelines however were limited by the wide variety of media sources and the wide variety of computer configurations that may be utilized to provide and interact with media. When desiring the output of media from different applications for instance each type of media may require a different timeline which involves the use of different applications. This may result in an inefficient use of both hardware and software resources of the computer. Additionally the different timelines may make it difficult to coordinate the outputs from the respective timelines such as to output media from the separate timelines concurrently.

Further the execution of large timelines may result in the inefficient use of software and or hardware resources of the computer. When loading a large playlist of songs for instance each song in the playlist was loaded. Therefore the initial loading of the playlist may consume a significant amount of hardware and or software resources thereby resulting in a delay in the loading and playing of songs in the playlist.

Accordingly there is a continuing need to provide an improved timelines and techniques for sorting timelines to determine how to render the timeline.

Sorting a media timeline is described. The media timeline provides a technique for a user to define a presentation based on media. The media timeline may be utilized to express groupings and or combinations of media and provide compositional metadata utilized by a timeline source to provide a presentation of the media described by the media timeline. The media timeline may be configured in a variety of ways to address a variety of considerations.

A timeline sorter is also described which is executable to divide the media timeline into a plurality of segments. In an implementation a method includes receiving a media timeline at an application programming interface in which the media timeline includes a plurality of timeline object. One or more of the timeline objects reference a respective one of a plurality of media. A plurality of segments is generated from the media timeline for sequential rendering such that each segment references a particular set of the timeline objects that are rendering during a duration of the segment.

The same numbers are used throughout the disclosure and figures to reference like components and features.

Media timeline sorting is described. A media timeline provides a technique for a user to define a presentation based on media such as already existing media e.g. stored media such as video songs documents and so on and or media that is output in real time from a media source such as streaming audio and or video. The media timeline may be utilized to express groupings and or combinations of media and provide compositional metadata utilized by a timeline source that executes e.g. renders the media timeline to provide a final presentation which includes the media described by the media timeline.

In an implementation the media timeline is configured for dynamic creation and or loading of the media timeline. As previously discussed a large media timeline e.g. media timelines having a considerable number of nodes and or significant amount of data may result in inefficiencies when the media timeline is loaded. For example a computer that loads the media timeline may utilize significant processing and memory resources even if all the nodes of the media timeline are not output at that time. Therefore the media timeline may be configured for dynamic creation and or loading such that the media timeline when rendered may intelligently delay loading and or creation of the nodes of the media time. By configuring the media timeline for dynamic loading and creation hardware and or software resources of the computer may be efficiently utilized during startup of the computer and for loading the media timelines in general.

For example a timeline sorter may be executed to convert a media timeline described by a timeline object model into a sequence of segments which can be independently rendered using a media processing pipeline. In an implementation the timeline sorter can determine segments on the fly such that the timeline sorter does not need the entire presentation to be defined up front . For instance each segment may be rendered as an independent piece in a media processing pipeline such that the entire presentation is not defined upfront as a single entity. Therefore changes may be made to the media timeline without having to tear down media pipeline which is used to render the media timeline should some portion of the media timeline change such as updated and so on. Further discussion of media timelines that provide for dynamic creation and or loading of the nodes of the media timeline may be found in relation to .

In the following discussion an exemplary environment is first described which is operable to employ the media timeline sorting techniques. Exemplary procedures are then described which are operable in the exemplary environment as well as in other environments.

The computer may obtain a variety of media from a variety of media sources. For example the computer may locally store a plurality of media . . . . . . K . The plurality of media K may include an assortment of audio and video content having various formats such as WMV WMA MPEG 1 MPEG 2 MP3 and so on. Further the media K may be obtained from a variety of sources such as from an input device from execution of an application and so on.

The computer for instance may include a plurality of applications . . . . . . N . One or more of the plurality of applications N may be executed to provide media such as documents spreadsheets video audio and so on. Additionally one or more of the plurality of applications N may be configured to provide media interaction such as encoding editing and or playback of the media K .

The computer may also include a plurality of input devices . . . . . . M . One or more of the plurality of input devices M may be configured to provide media for input to the computer . Input device for instance is illustrated as a microphone that is configured to provide an input of audio data such as a voice of the user a song at a concert and so on. The plurality of input devices M may also be configured for interaction by a user to provide inputs that control execution of the plurality of applications N . For example input device may be utilized to input voice commands from the user such as to initiate execution of a particular one of the plurality of applications N control execution of the plurality of applications N and so forth. In another example input device is illustrated as a keyboard that is configured to provide inputs to control the computer such as to adjust the settings of the computer .

Further the computer may include a plurality of output devices . . . . . . J . The output devices J may be configured to render media K for output to the user. For instance output device is illustrated as a speaker for rendering audio data. Output device is illustrated as a display device such as a television that is configured to render audio and or video data. Thus one or more of the plurality of media K may be provided by the input devices M and stored locally by the computer . Although the plurality of input and output devices M J are illustrated separately one or more of the input and output devices M J may be combined into a single device such as a television having buttons for input a display device and a speaker.

The computer may also be configured to communicate over a network to obtain media that is available remotely over the network . The network is illustrated as the Internet and may include a variety of other networks such as an intranet a wired or wireless telephone network a broadcast network and other wide area networks. A remote computer is communicatively coupled to the network such that the remote computer may provide media to the computer . For example the remote computer may include one or more applications and a video camera that provides media such as home movies. The remote computer may also include an output device to output media such as the display device as illustrated. The media obtained by the computer from the remote computer over the network may be stored locally with the media K . In other words media K may include locally stored copies of media obtained from the remote computer over the network .

Thus the computer may obtain and store a plurality of media K that may be provided both locally e.g. through execution of the plurality of applications N and or use of the plurality of input device M and remotely from the remote computer e.g. through execution of application and or use of input devices . Although the plurality of media K has been described as stored on the computer the media K may also be provided in real time . For example audio data may be streamed from the input device which is illustrated as a microphone without storing the audio data.

The computer includes a timeline generator that when executed on the computer generates a media timeline . For example the timeline generator may be configured as an application that exposes one or more software components that may be used to generate the media timeline such as through a user interface by a user. As previously described the media timeline provides a technique for a user to define a presentation of stored and or real time media from the plurality of media sources. For example the media timeline may describe a collection of media that was obtained from the input devices M the applications N and or the remote computer . The user may utilize one or more of the input devices M to interact with the timeline generator to define groupings and or combinations of the media K . The user may also define an order and effects for presentation of the media K . A timeline source may then be executed on the computer to render the media timeline . The media timeline when rendered provides the expressed groupings and or combinations of the media K for rendering by one or more of the plurality of output devices J . Additionally the timeline generator may also programmatically generate the media timeline as is described in greater detail in the following implementation.

To determine the expressed groupings the computer also includes a timeline sorter . The timeline sorter is executable to divide the media timeline into a plurality of segments in which each segment includes a set of timeline objects to be rendered during that segment which do not change. Further discussion of execution of the timeline sorter may be found in relation to .

The application which may be the same as or different from applications N of interacts with a media engine to control the media K . In at least some embodiments the media engine serves as a central focal point of the application that desires to somehow participate in a presentation. A presentation as used in this document refers to or describes the handling of media. In the illustrated and described embodiment a presentation is used to describe the format of the data on which the media engine is to perform an operation. Thus a presentation can result in visually and or audibly presenting media such as a multimedia presentation in which both audio and accompanying video is presented to user within a window rendered on a display device such as output device of that is illustrated as a display device that may be associated with a desktop PC. A presentation can also result in writing media content to a computer readable medium such as a disk file. Thus a presentation is not limited to scenarios in which multimedia content is rendered on a computer. In some embodiments operations such as decoding encoding and various transforms such as transitions effects and the like can take place as a result of a presentation.

In an embodiment the media foundation exposes one or more application program interfaces that can be called by the application to interact with the media . For example the media foundation may be thought of as existing at an infrastructure level of software that is executed on the computer of . In other words the media foundation is a software layer used by the application to interact with the media . The media foundation may be utilized to control a number of aspects of the media such as output rendering storage and so on. Thus the media foundation may be utilized such that each application does not have to implement separate code for each type of media that may be used in the system . In this way the media foundation provides a set of reusable software components to do media specific tasks.

The media foundation may utilize several components among which include the media timeline the timeline source a media source a media processor a media session the media engine a source resolver one or more transforms one or more media sinks and so on. One advantage of various illustrated and described embodiments is that the system is a pluggable model in the sense that a variety of different kinds of components can be utilized in connection with the systems described herein. Also included as a part of system is a destination which is discussed in more detail below. In at least one embodiment however the destination is an object that defines where a presentation is to be presented e.g. a window disk file and the like and what happens to the presentation. That is the destination may correspond to one or more of the media sinks into which data flows.

The media timeline employs a timeline object model which provides a way for a user to define a presentation based on media that is rendered by the timeline source . The media timeline may range from a sequential list of media files to more complex forms. For example the media timeline may employ file structures such as SMIL and AAF to express media playback experiences that include transitions between media effects and so on. The application for instance may be configured as a media player that can play a list of songs which is commonly referred to as a playlist. As another example in an editing system a user may overlay one video over the other clip a media add effect to the media and so forth. Such groupings or combinations of media may be expressed using the media timeline . Further discussion of the media timeline is found in relation to .

The media source is utilized to abstract a provider of media. The media source for instance may be configured to read a particular type of media from a particular source. For example one type of media source might capture video from the outside world e.g. a camera and another might capture audio e.g. a microphone . Alternately or additionally the media source may read a compressed data stream from disk and separate the data stream into its compressed video and compressed audio components. Yet another media source might obtain data from the network of . Thus the media source may be utilized to provide a consistent interface to acquire media.

The media source provides one or more media presentation objects media presentation . The media presentation abstracts a description of a related set of media streams. For example the media presentation may provide a paired audio and video stream for a movie. Additionally the media presentation may describe the configuration of the media source at a given point in time. The media presentation for instance may contain information about the media source including descriptions of the available streams of the media source and their media types e.g. audio video MPEG and so on.

The media source may also provide a media stream object media stream which may represent a single stream from the media source which can be accessed by the application i.e. exposed to the application . The media stream thus allows the application to retrieve samples of the media . In an implementation the media stream is configured to provide a single media type. A media source can provide more than one media stream. For example a wmv file can have both audio and video in the same file. The media source for this file will therefore provide two streams one for audio and the other for video.

In the media foundation therefore the media source is defined as a software component which outputs samples for a presentation. The timeline source interprets the media timeline but at the same time may also act in a manner similar to the media source . For example the timeline source may be utilized to hide the intricacies of rendering the media timeline to provide media described by the media timeline from other components of the media foundation .

The media processor manages data flow in a topology . The topology defines how data flows through various components for a given presentation. A full topology includes each of the components e.g. software modules used to manipulate the data such that the data flows with the correct format conversions between different components. When a topology is created the user might choose to create it partially. This partial topology is not sufficient by itself to provide a final presentation. Therefore a component called the topology loader may take the partial topology and convert it into a full topology by adding the appropriate data conversion transforms between the components in the partial topology.

In the topology for example data generally originates at the media source flows through one or more transforms and proceeds into one or more media sinks . Transforms can include any suitable data handling components that are typically used in presentations. Such components can include those that uncompress compressed data and or operate on data in some way such as by imparting an effect to the data as will be appreciated by the skilled artisan. For example for video data transforms can include those that affect brightness color conversion and resizing. For audio data transforms can include those that affect reverberation and re sampling. Additionally decoding and encoding can be considered as transforms.

Media sinks are typically associated with a particular type of media content. Thus audio content might have an associated audio sink such as an audio renderer. Likewise video content might have an associated video sink such as a video renderer. Additional media sinks can send data to such things as computer readable media e.g. a disk file and the like stream the data over the network such as broadcasting a radio program and so on.

The media session is a component which may schedule multiple presentations. Therefore the media processor may be used to drive a given presentation and the media session utilized to schedule multiple presentations. The media session for instance may change topologies that are rendered by the media processor . For example the media session may change from a first topology that is rendered on the media processor to a second topology such that there is no gap between the renderings of samples from the consecutive presentations that are described by the respective topologies. Thus the media session may provide a seamless user experience as the playback of the media moves from one presentation to another.

The source resolver component may be utilized to create a media source from URLs and or byte stream objects. The source resolver may provide both synchronous and asynchronous ways of creating the media source without requiring prior knowledge about the form of data produced by the specified resource.

In at least one embodiment the media foundation is utilized to abstract away the specific details of the existence of and interactions between various components of the media foundation . That is in some embodiments the components that are seen to reside inside the media foundation are not visible in a programmatic sense to the application . This permits the media foundation to execute so called black box sessions. For example the media engine can interact with the media session by providing the media session certain data such as information associated with the media e.g. a URL and the destination and can forward the application s commands e.g. open start stop and the like to the media session . The media session then takes the provided information and creates an appropriate presentation using the appropriate destination.

The media foundation may also include a timeline plugin . The timeline plugin may be utilized such that different media timeline file formats may be plugged in to the media foundation . For example a bytestream plugin may be written for a format in question and registered with the media foundation . The source resolver may then invoke a bytestream plugin when a file of that type is opened. In turn the bytestream plugin can parse the file create a media timeline representing the presentation described in the file and create a timeline source for it. In general the bytestream plugin is responsible for reading the raw bytestream and creating a media source for it. In an implementation the remaining components of media foundation are not made aware that the media source created in this instance is a timeline source . Therefore the timeline source is treated like any other media source . In an implementation a bytestream plugin that can parse a media timeline and create a timeline source is referred to as a timeline plugin which is described in greater detail in relation to .

The timeline plugin may also provide an interface such that the application may interact with the timeline plugin directly such as to load and save the media timeline from or to a file. For example the timeline plugin may be created and then called to initiate a load function to provide a bytestream. The timeline plugin may then parse the file and create a root node and any additional nodes to create the media timeline which will be described in greater detail in relation to . The timeline plugin may also be used to persist the media timeline to different formats. For example the application may create the media timeline programmatically. In other words the application may act as the timeline generator of . The application may then create a timeline plugin for ASX files and ask the timeline plugin to save the media timeline in the ASX format. In another example a user can open an m3u file i.e. a playlist file format for specifying multiple MP3 files get the media timeline from it and then ask the timeline plugin to save the media timeline in the ASX format. In this example the timeline plugin acts as the timeline generator . Thus the media foundation may expose a plurality of software components that provide media functionality over an application programming interface for use by the application .

In an implementation the media timeline is not executable by itself to make decisions about a user interface UI playback or editing. Instead the metadata on the media timeline is interpreted by a software and or hardware component that renders the media timeline such as the timeline source of . Additionally applications that are utilized during rendering of the media timeline may obtain relevant metadata for that particular application. For example the application of may be configured as a playback engine that is only interested in the times at which each media referenced in the media timeline is to be started. On the other hand another application such as a media player may be interested in just displaying the titles of the songs which are stored as metadata on each node. In this way the metadata may be utilized at the same time by one or more applications that utilize an output of the media.

The nodes as positioned on the media timeline describe a basic layout of the media timeline . This layout may be utilized for displaying a timeline structure in a user interface utilized by the timeline source of to order rendering of the nodes and so forth. For instance various types of nodes may be provided such that a desired layout is achieved. The node type indicates how the children of that node are interpreted such as a root node and leaf nodes . The root node specifies a starting point for rendering the metadata timeline and includes metadata that describes how rendering is to be initiated.

In the illustrated implementation of the leaf nodes of the media timeline directly map to media. For example the leaf nodes may have respective metadata that describes how to retrieve the media that each of the leaf nodes represent. A leaf node may specify a path for an audio and or video file point to a component which generates video frames programmatically during rendering of the media timeline and so on. Leaf node for instance includes metadata having a pointer that maps to input device that is configured as a microphone. Leaf node includes metadata having a pointer that maps to an address of the media in a storage device that is included locally on the computer of . Leaf node includes metadata having a pointer that maps to a network address of the remote computer on the network . The remote computer includes the video camera to provide media over the network to the computer of . Thus in this implementation the timeline does not include the actual media but rather references the media by using pointers that describe where and or how to locate the referenced media.

Nodes may also describe additional nodes of the media timeline . For example node may be utilized to describe the order of execution for nodes . In other words node acts as a junction type node to provide ordering and further description of its children . There are a variety of junction type nodes that may be utilized in the media timeline such as a sequence node and a parallel node. describe exemplary semantics behind the sequence and parallel nodes.

Although the child nodes of the sequence node are configured as leaf nodes in this implementation child nodes of the sequence node may represent any other type of node. For example child nodes may be utilized to provide a complex tree structure as shown in . Node of for instance is the child of another junction type node i.e. node .

Specifying times relative to the previous node allows for defining a sequence where duration output of media referenced by each child node in the sequence is not known. When the start time for a node is not specified as shown by the metadata of leaf node it means that the node i.e. leaf node should be immediately start output after the previous node i.e. leaf node has finished output.

The children of the parallel node may be rendered simultaneously. For example leaf node and leaf node are children of parallel node . Each of the leaf nodes includes respective metadata having respective pointers to respective media . Each of the leaf nodes includes a respective time included in the respective metadata that specifies when the respective leaf nodes are to be rendered. The times on the leaf nodes are relative to the parallel node i.e. the parent node. Each of the child nodes can represent any other type of node and combinations of nodes providing for a complex tree structure with combined functionality. For example a junction type node may also reference media and so forth. Although metadata including time data has been described a variety of metadata may be included on nodes of the media timeline an example of which is described in the following implementation.

Additionally authors of the media timeline may add custom metadata to the nodes. For example the application of may be configured as a media player that stores album art for a CD track on the leaf node corresponding to that particular track. Standard properties and custom properties may be treated in the same manner so that there is no ambiguity when obtaining the metadata. Therefore even if each property described by the metadata is provided by a different respective interface or source the media timeline provides a mechanism to track the various properties.

Further properties from different sources may be aggregated by treating the metadata in a consistent manner by the media timeline. For example a playlist may include a plurality of tracks each having a different composer. Each track of the playlist may be represented as a leaf node that is a child of a sequence node. The media timeline may aggregate the metadata such that a query to the sequence node i.e. the parent node returns the composers of all the media in the playlist from each leaf node i.e. the child nodes. Consistent use of metadata may also provide sorting for each of the nodes. For example if all properties on a node are treated as metadata an application may sort the nodes based on any properties defined in the metadata in a consistent fashion.

A node may include a variety of metadata such as properties that define playback behaviors and attributes for the nodes. Examples of properties defined by the metadata are described as follows.

This property holds the URL for the media. In the case of a file the URL property may provide the path to the file. For example the URL property may provide a path to a storage device to locate particular media.

In some instances the source for the media cannot be specified by a URL. For example a media source for outputting black color frames may not be locatable by a URL. The SourceObject and SourceObjectID properties allow the user to specify the media source by specifying an object which can resolve to a media source such as the media source itself or some other object. When a media source is specified as a source object SourceObject property provides a pointer to the media source and the SourceObjectID property specifies a globally unique identifier of the source object. In an implementation the SourceObject property takes precedence over the URL property in case both are defined.

The start and stop times define at what time the node is to be started and stopped with respect to the other nodes. For nodes that are children of a parallel node for instance the start and stop times are defined relative to the parallel node i.e. the parent of the children. For nodes that are children of a sequence node the first child node includes start and stop times that are defined relative to the sequence node. The remaining nodes each include start and stop times that are defined relative to a previous sibling. In an implementation it is not necessary to define the start and stop times for the node . For example when the start and stop times are not specified the start time is assumed to be zero and the node is stopped when the rendering of the media referenced by the node is completed.

Each node in a media timeline may reference media. The media start and media stop properties define a portion of the media that is to be output. For example the node may represent media from a file having a total length of 50 seconds. The user however might want to output only a portion of the media from 20 to 30 seconds in the file. To do this the media start may be specified as 20 seconds and the media stop may be specified as 30 seconds.

The duration of the time period defined by the start time and stop time of the node i.e. nodetime need not equal the duration of the time period defined by the media start and the media stop i.e. mediatime . For example when the specified nodetime is greater than the mediatime output of the media referenced by the node may be slowed. Therefore the portion of the media defined by the media start and the media stop may be output for the duration of the time period defined by the start and stop times of the node i.e. nodetime . In other words output of the portion may be extended such that the nodetime is equal to the mediatime. In another example a last frame of the media may be frozen until the nodetime elapses a video frame can be made blank e.g. black and so on. Similarly if the nodetime is less than the mediatime the media may be output at a faster rate such that output is finished within the specified nodetime. In a further example output of the media may be truncated. For instance any portion of the segment defined by the mediatime that is greater than the nodetime is not output. In an implementation the media timeline itself does not enforce these behaviors but rather these behaviors are read by the timeline source when rendering the media timeline as described in relation to .

When the media stop for the node is not specified the media referenced by the node is output until completion. For example in a player scenario a user may desire the output of a playlist of media that does not have the duration of each media item referenced. Additionally back to back output of the media included in the playlist may be desired. To represent this case on the media timeline a sequence node may be created having leaf nodes that are children of the sequence node which do not have a specified media stop properties.

The time based properties described previously may have an accompanying time format property time format . Examples of time formats include 100 nanosecond units frame number time code and so on. Thus the time format may specify the time format for the start time stop time media start and media stop . Additionally the time format may specify different formats for each of the time based properties. For instance the start and stop times may utilize a time format of 100 nanosecond units while the media start and media stop time formats may utilize frame counts.

The stream selection property can be utilized on the node in a variety of ways. For example the stream selection property may act as a filter such that media having desired characteristics is provided. The node for instance may reference both audio and video streams of media such as a television program. The user however may only be interested in only the video stream even if the URL specified on the node points to both the audio and video streams. In such a case the audio stream from the media is not exposed such that it appears to the user that the node provides only video media. Some other examples of stream selection include selecting a language for the stream selecting a bitrate for the stream and so on. Additionally files can contain multiple streams of the same major type. For example some files contain many audio streams providing a choice of language and bitrate on each of these streams.

Format based properties may be utilized to specify other properties such as frame rate pixel aspect ratio audio sampling rate and so on that are desired from the node . The appropriate transforms for converting to from these formats are then inserted into the rendered media timeline during playback.

The loop count property may be used to specify how many times the rendering of the node is to be repeated. For example if the loop count property is negative the output of the media referenced by the node may be repeated infinitely.

The node may be disabled by setting the disabled property. For example if the disabled property is set to true the node is ignored during rendering of the media timeline. For instance a sequence of three leaf nodes may be provided in a media timeline. If the second node in the media timeline is disabled i.e. the disabled property is set to true output of the media referenced by the media timeline will appear as if the media timeline has only the first and third nodes.

The NoSkip property is a feature which can be used by timeline authors to specify media which cannot be skipped during rendering of the media timeline. When the node is specified as a NoSkip node i.e. the NoSkip property is set to true the user cannot skip to another node after the specified node and cannot fast forward the media being output as part of that node . The user however may skip to any node before that node . In another implementation if the NoSkip property is specified on a parent node the user will not be able to skip any of the children in the subtree of that node. In a further implementation the NoSkip property applies only to a sequence node and its immediate children e.g. children of the sequence node that directly follow the sequence node instead of being included in a another sequence node that is a child of that sequence node and is not specified for a parallel node or its immediate children. For example the NoSkip property may be used to prevent the skipping of advertisements referenced by leaf nodes that are children of a first sequence node. A second sequence node may also be a child of the first sequence node and include leaf nodes that reference media that can be skipped such as a television program.

The NoSkip property may also be utilized to define collections of nodes through which a user may navigate. For example a media timeline may include a sequence of ten leaf nodes with the third and seventh nodes being NoSkip nodes i.e. the NoSkip property is set as true . Therefore the user may skip the rendering of the first and second leaf nodes but cannot skip to the fourth fifth sixth seventh eighth ninth or tenth nodes. Similarly during the rendering of the media timeline from node four to node seven the user may skip to any node below the seventh node but may not skip to a node above the seventh node i.e. the eighth ninth and tenth nodes.

Media timelines may support sparse children i.e. all nodes are not loaded and or created on the media timeline when the media timeline is initially loaded. Therefore the children may be loaded and or created as needed. Further discussion of dynamic loading and creation of nodes may be found in relation to . When loading the nodes in a media timeline in this instance parent nodes may be loaded which have child nodes that are specified as NoSkip . To indicate that there is the NoSkip property for a child node the NoSkip child property for the parent node may be used.

The NoSkip child property may be set at a parent node to indicate whether the parent node includes a child node having the NoSkip property set as true . During the rendering of the media timeline the NoSkip child is used to indicate that all the previous siblings of a node should be checked to determine if navigation to the node is valid. NoSkip child may also be set on a parallel node. For example if any node in a subtree of the parallel node has the NoSkip property set as true . In this way navigation between nodes may be provided that protects the use of the NoSkip property.

When a node with the NoSkip property set as true is added to the media timeline the media timeline may automatically set the NoSkip Child property as true on all the parents of the added node. This way a rendering engine e.g. timeline source of can optimize which nodes of the media timeline to load and check to determine if the NoSkip property is set as true .

Timeline effects allow the author of a media timeline to specify components which analyze and or change the appearance of the media. For example the author might want to show a video in black white add echo to an audio file show one video on top of another e.g. picture in picture and so on. In an implementation an effect is not a separate node by itself. To provide the effect for the media the author may specify effects in the metadata in the node. For example the metadata may include an array of effects that are defined on the node. The array may specify a series of effects to be applied to the output of that node i.e. when the media referenced by the node is rendered. In this implementation the effect is not an object which actually implements the effect but rather specifies properties and attributes which describe how to create and apply the effect. This is similar to how the node references the media in the previous implementations. For example as discussed in relation to the leaf nodes themselves do no contain the media but rather include respective metadata having respective pointers which specify how to obtain the media. The component which actually implements the effect is loaded at runtime by the timeline source that executes the media timeline. Although metadata that includes effect has been described the effects may also be specified separately. Additionally in another implementation the effect is provided by an object in the media timeline that implements the effect.

Effects specified on nodes of a media timeline may have times that are specified relative to the start time of that node. For example an effect may be specified on a leaf node that has a start time of ten seconds. Therefore the effect will be applied to the node when rendered after that node has begun output and ten seconds have elapsed.

Multiple effects can be specified on a node. Additionally the author of the media timeline may also control the order in which these effects are applied. For example the author may set a priority on the effect. There are a variety of effects that may be specified by a node. Examples of effects that can be specified on the media timeline include 1 a simple effect 2 a composite effect and 3 a transition effect. Further discussion of these exemplary effects may be found in relation to .

A simple effect represents a component which receives a single stream of audio video and outputs another stream. In other words it is a one in one out component. For example an echo effect may receive an audio stream and output a modified audio stream that echoes provide a black and white effect in which video is shown as black and white an age effect in which video is made to appear as if it was captured several decades ago and so on.

In an implementation the duration of the plurality of effects does not change the duration of the media . For example the processing of the plurality of effects may be truncated at the time boundaries of the node . For instance the rendering of the media may have a duration of 10 seconds. The processing of the plurality of effects however may have a duration of 20 seconds. In such an instance the timeline source of may finish processing of the plurality of effects for node at 10 seconds.

When defining the effects the author of the timeline may explicitly specify the inputs and the outputs of each of the effects . For example each of the effects may include data that describes which stream is connected to which effect input. Each of the effects may also have respective data that describes the major type of the respective effect s output e.g. audio video and so on. Further each of the effects may include metadata that describes a start time and or a stop time of the effect within the node.

A composite effect may be used to process media of the children of a parallel node to give a resultant output. For example is an illustration of an exemplary implementation showing a parallel node that provides a composite effect to the outputs of two or more child nodes. Parallel node in this implementation is similar to the parallel node that was described in relation to .

Parallel node includes an array of composite effects . When specifying a composite effect the author of the media timeline specifies how to connect the inputs of the effects and also the major types for the outputs from the effects . For example leaf node and leaf node may be configured as the children of the parallel node . As previously described each leaf node includes respective metadata having respective pointers that reference respective media . The leaf nodes when rendered provide media for output.

The effects are applied to the output of the media that are specified by the parallel node . For example the parallel node may provide a rotating cube with a different media e.g. video on each face of the cube a scrolling roll of film with different media playing in each frame of the film and so forth.

Although parallel node was described as applying the plurality of effects to each of the leaf nodes in additional implementations the parallel node might apply the effects to only a few of the children of the parallel node . In other words the effects need not be applied to all of the nodes that are children of the parallel node . For example the metadata and or effects may specify one or more particular nodes to apply one or more of the plurality of effects .

The sequence node include metadata that describes a transition effect that is to be employed between output of the media referenced by the respective leaf nodes . Thus the transition effect is applied to the media originating from the children of the sequence node . The transition effect is utilized to combine two or more media into a single output. Additionally the transition effect may include data that specifies one or more of leaf nodes to which the transition effect is to be applied. For example the data may specify that the transition effect is to be employed between the output of media . The first input to the transition effect is supplied by the node for which it is defined i.e. leaf node . The next input to the transition effect is the next node in the sequence i.e. leaf node . Example of transition effects include an audio cross fade between two nodes that are output in sequence a swipe of a first video with a second video and so on.

The transition effect has a duration . The duration may be used to specify an amount of overlap desired between the two or more nodes in a sequence. For example the second input in the sequence i.e. media may be output such that it overlaps for the duration of the transition effect . Hence an output duration of the sequence node becomes a function of the times specified on the leaf nodes and the overlap specified by the duration of the transition effect .

Global effects may also be specified. For example the transition effect may specify a global transition for each of the children of that node e.g. leaf nodes of sequence node . Therefore if the author of a media timeline desires the use of the same transition for all the leaf nodes the author may do so by specifying the transition effect as a global transition. Thus by specifying a global transition the author need not specify a separate transition for each node.

Similar to how nodes may reference media an effect may reference a transform object that provides the effect. The effect object GUID property specifies the GUID to be used to create the transform object that provides the effect. For example during output of the media the transform object referenced by the effect object GUID may be created when needed to provide the effect.

The node may utilize the effect object property as a pointer to reference an effect object that provides the effect. The referenced effect object may be used directly during output of the media of the node . The effect object property takes precedence over the effect GUID if both are specified.

As previously described when effects are concatenated together the priority property may be used to specify the ordering of the effects. If there is more than one effect with the same priority the effects are applied in the order in which the effects were added to the node .

The start and stop times are specified relative to the node on which the effect is specified. The start and stop times define the time at which the effect will be active. If these properties are not specified the effect will be applied for the entire duration of the output of the media referenced by the node . These properties can be applied to both simple effects that were described in relation to and composite effects that were described in relation to .

The start and stop times may be specified in a variety of formats. The time format property may be used to specify the format of these time values. A variety of time formats may be utilized such as 100 nano second units frame numbers time codes and so on.

As previously described in relation to the duration property may be used to specify the duration of a transition between the output of respective media. For example the duration may be used to specify an amount of overlap between the output of media referenced by two consecutive nodes.

Simple effects utilize one input and one output and therefore the number of inputs and outputs may be set automatically in the media timeline for simple effects. A transition effect may employ two inputs and one output. Therefore the number of inputs and outputs may also be set automatically in the media timeline for transition effects. For composite effects an author may define as many inputs and or outputs as desired. Therefore the number of inputs and outputs may be set by the author to reflect the number of inputs and outputs for the transform object that provides the effect.

The output major type is specified for each output of the effect. Specifying output major type property facilitates connecting the effect to other effects or destinations. For example the author of a media timeline may readily determine the major type i.e. audio video and so on of the output and therefore efficiently specify connections between relevant effects e.g. audio effect to audio effect.

Once the effect has been defined the author may specify media that is to be processed by the effect. The input connections property may be used to identify the media to be connected to each of the effect inputs.

Dynamic creation and loading of nodes of a media timeline may be utilized for efficient rendering of the media timeline. By improving rendering efficiency the media timeline may be utilized on low resource devices such as devices having limited hardware and or software resources. For example dynamic creation of the media timelines may include delayed creation of the nodes of the media timeline. The children of a parent node for instance need not be created until needed. The delayed creation of the nodes may be utilized to improve start up and response times for media timelines having a significant number of nodes and or a large amount of data for each node. For instance a media player may be utilized to create and playback a playlist from a media library that contains a significant number of selections. Creating such a playlist might require multiple queries to the media library which may take a significant amount of time processor and memory resources. By using delayed creation of the nodes the playlist can be built on an as needed basis thereby utilizing only as much processing and memory resources as required by the nodes needed at any one particular time. There are a wide variety of implementations that may be utilized for dynamic creation and or loading of nodes of a media timeline.

During or after the rendering of media referenced by the node metadata of node is examined that specifies a second grouping that includes node and . Therefore node and are loaded and media is output that is referenced by node . Likewise the metadata of node specifies a third grouping that includes nodes . Therefore nodes are loaded to output data referenced by nodes after the output of data referenced by node is completed.

In one or more implementations the media timelines are configured to be dynamically changed. For example nodes of the media timeline may be removed added or changed during the rendering of the media timeline by a timeline source. To provide for dynamic changes to the nodes each node can generate events.

Each of the nodes may generate events that may be utilized to inform other nodes of the media timeline that may be affected by changes to the node and or changes to children of that node. For example all events for node and any children of the node i.e. nodes may be communicated to the root node and or the author of the media timeline . In other words events in the media timeline may progress up the tree to the root of the tree. In this way eventing may be utilized inform various nodes of the media timeline about dynamic changes to the timeline structure. Additionally nodes of the media timeline may subscribe to events initiated by other nodes of the media timeline. Node for instance may subscribe to receive events from node even though node is not a parent of the node . Furthermore components using the timeline e.g. the media foundation components of can register to receive events initiated by any of the nodes. A variety of events may be supported by one or more nodes examples of which are described as follows.

This event is issued when a node is added to the media timeline . For example node may be added to the media timeline to provide output of additional media referenced by the node . Node when informed of the adding of node may issue the node added event such that it is communicated to the root node through node . Thus in this example each node that is a parent of the newly added node is notified of events that are initiated by children of that node.

The node removed event is issued when a node is removed from the media timeline . Continuing with the previous example node may be removed from the media timeline to remove the output of the media referenced by the node . Node when informed of the removal of node may issue the node removed event such that it is communicated to the root node through node . Thus in this example each node that is a parent of the removed node is also notified.

The node changing event is issued when metadata on a node of the media timeline is being changed. Node for instance may include metadata such as the metadata described in relation to . Changes to the metadata may cause the node to issue the node changing event which may be communicated to the application of and or parents of the node i.e. nodes . Thus the node changing event may be utilized to inform other nodes and or applications that utilize the node that changes are being made to the node and therefore respond according such as to wait to render the node until a node changed event is received.

The node changed event is issued when metadata on a node of the media timeline has been changed. Continuing with the previously example node issued the node changing event such that other nodes and or applications are informed that changes are being made to the node . When the changes are complete the node may issue the node changed event to inform the applications and or nodes that the changes have been completed. In this way the node may utilize the node changed event to inform that it is ready for rendering.

The remove children event is issued when all of the children of a node are removed. Nodes for instance may be removed from the media timeline . Node issues the remove children event to inform the root node that the children i.e. nodes of node have been removed. Thus the remove children event may be utilized instead of issuing the node removed for each of the nodes .

The node source added event is issued when a node source is added to a node such as the node source described in relation to . Likewise the node source removed event is issued when a node source is removed from a node.

The node sorted event is issued when one or more nodes are sorted. For example the media timeline may support a function in which the nodes are sorted according to one or more criteria such as chronologically based on dependencies and so forth. Therefore the node sorted event may be initiated by the node when that node and or children of the node e.g. nodes are sorted.

The node moved event is issued when a node is moved. For example the node may be moved in the media timeline such that the node is a child of a different node e.g. node . Therefore the node moved event may be initiated by the node and or a parent of the node e.g. the previous parent and or the new parent node when node is moved.

The author of a media timeline can mark all or a portion of the media timeline as read only. This may be utilized to protect the functionality of the media timeline. In a first scenario the author of the timeline does not want the user to change the media experience such as to skip and or delete advertisements. In another scenario the author might want to dynamically change the media timeline but does not want other components to modify it. In yet another scenario the author might allow other components to set custom metadata on the timeline nodes but not add new children to the timeline.

The media timeline can be customized to suit one or all of these read only scenarios. Read only media timelines may be implemented by creating a read only wrapper of a media timeline. The read only wrapper contains nodes which mirror the structure of the original timeline i.e. are cloned from the nodes of the original timeline. The cloned nodes of the read only media timeline may contain pointers back into the original timeline s nodes. Additionally each of the cloned nodes may be configured to subscribe to events generated on the nodes of the original timeline. This allows the cloned timeline s structure to be kept updated as the original media timeline changes such as changes to the structure of the tree of the original media timeline.

The cloned nodes of the read only media timeline may be configured to fail functions which allow the user to add remove nodes to the read only media timeline. When creating a read only timeline the author may also specify whether metadata for the cloned nodes should be modifiable. This design allows the author of the media timeline to modify the media timeline as much as desired while other components e.g. applications that execute the read only media timeline have read only or restricted access to the media timeline structure.

In an implementation metadata of the root node of the media timeline of may be marked such that the media timeline may not be edited by a user. In another implementation a particular node and or groupings of nodes of the media timeline may be marked as read only. For example referring again to the metadata of leaf node may be marked as read only. In another example the metadata of node is marked as read only such that node leaf node and leaf node may not be edited.

The media timelines previously discussed may employ a variety of methods of storing and restoring timeline data such as one or more Windows Media Player Playlist files eXecutable Temporal Language XTL files and so on.

A media timeline for instance may be described as the following Windows Media Player Playlist file identified by an ASX file extension.

The XTL file may be represented by the media timeline that is shown in that includes a parallel node having two child sequence nodes . In this example sequence node has a major type filter set as video and sequence node has a major type filter set as audio . Sequence node has two child leaf nodes . Leaf node includes metadata that specifies a start time of 0 a stop time of 30 a media start of 50 and a media stop as 80 . Leaf node include metadata that specifies a start time of 30 a stop time of 40 and media start as 0 . It should be noted that leaf node does not include a media stop time therefore the entire length of the media referenced by the leaf node will be output.

Sequence node also has two child leaf nodes . Leaf node includes metadata that specifies a start time of 20 a stop time of 40 and a media start of 0 . Leaf node include metadata that specifies a start time of 40 a stop time of 60 and media start of 0 .

Leaf node also includes a pointer that references the A1.asf file described in relation of . Likewise leaf node includes a pointer that references the A2.asf file that was described in relation to . Thus when the media timeline is executed the A1.asf file and the A2.asf file are output in a manner that employs the effect as shown in .

The timeline sorter may employ one or more timeline sorting algorithms to identify segments represented by a media timeline. Given a complex timeline for instance the timeline sorter may break the media timeline into individual segments which may be independently rendered. For instance the timeline sorter may determine every point at which a timeline object e.g. a node or effect starts or stops and from this determine a new segment for rendering. Thus the timeline sorter is representative of the functionality of the media foundation that segments the media timeline . Illustrative examples of such a sorting process are shown in the following figures.

As illustrated these dashed lines indicate a plurality of segments . For example segment begins with a start of audio file and stops with the start of video file . Segment two begins with the start of video file and ends with the start of the video effect . Segment three begins with the start of the video effect and ends with the start of the cross fade effect . Segment four begins with the start of the cross fade effect and terminates with the end of the cross fade effect . Segment five begins at the end of the cross fade effect and terminates at the end of the video effect . The final segment segment six terminates at the end of the audio file and the video file . Thus each pair of consecutive dashed lines of defines a segment in which timeline objects rendered during that segment do not change.

Video file leaf node specifies a start time of 7 and a stop time of 58 for a video file i.e. video file referenced by a pointer . Video file leaf node also specifies a video effect having a start time of 17 and a stop time of 39 .

Audio file leaf node specifies a start time of 0 and a stop time of 33 for an audio file i.e. audio file referenced by pointer . Audio file leaf node specifies a start time of 20 and a stop time of 58 for an audio file i.e. audio file referenced by pointer . The parallel node specifies a cross fade effect having a start time of 20 and a stop time of 33 to be applied to the audio file leaf nodes . A variety of techniques may be utilized for sorting the timeline further discussion of which may be found in relation to the following figures.

The following discussion describes sorting techniques that may be implemented utilizing the previously described systems and devices. Aspects of each of the procedures may be implemented in hardware firmware or software or a combination thereof. The procedures are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference will be made to the environment and systems of .

A timeline sorter is executed to examine timeline objects included in the media timeline block . For example the timeline sorter may examine timeline objects for metadata which specifies a duration for performance of a task such as nodes e.g. leaf node parallel nodes sequence nodes and effects e.g. cross fade and so on.

The timeline sorter gets a start time and a stop time for the timeline object block as specified by the metadata. The timeline sorter then makes an entry for the start time and another entry for the stop time in an array block . A determination is then made is to whether another object is available decision block . If so yes from decision block the other timeline object is examined block the start and stop times are obtained block and also entered into the array block .

Once each of the timeline objects have been processed no from decision block the entries in the array are sorted into chronological order block . For example the entries may be arranged in ascending order based on time. The sorted array is then walked to collect each start item and discard each stop item to arrive at the segments which makeup the time and which timeline objects are to be utilized during that segment.

Continuing with the previous example of for instance in order to figure out the segments the timeline sorter enters each node and effect of the timeline of into an array. The array may be referred to as a sorter element array . For each node and effect in the timeline two entries are made into the array. A first ends of the timeline object is for a start time of the object and a second entry of the timeline object is for a stop time of the object. After filling out the sorter element array from the media timeline the array is sorted such that the elements are arranged in ascending order based on time.

The time sorter walks the sorted array in chronological order and collects each item referenced by a start entry and discards each item that has a stop entry. For example segment one is defined between 0 and 7 seconds. To determine which timeline objects are utilized during that segment the timeline sorter notes entry for A1 i.e. audio file . The timeline sorter then examines a next entry and finds another start time and stops the examination. Therefore segment one includes just audio file playing for 7 seconds as determined by the timeline sorter.

Using a similar technique the timeline sorter may determine which timeline objects are utilized at any particular point in time of the media timeline . For example to determine which timeline objects are applicable to a segment six between 39 and 58 seconds the timeline sorter module may traverse the array as follows 

The timeline sorter may also employ a variety of logic for representations of special cases in a timeline. For example as previously described in relation to the timeline object model may support a feature e.g. loop count in which the metadata for a node indicates how many times that node is looped i.e. the node is rendered. To describe such an instance the timeline sorter may make multiple entries for that same node in the array and adjust the time appropriately. In some instances however the media timeline may not include an indication of a start or stop time and therefore the timeline sorter applies additional functionality to sort the timeline further discussion of which may be found in relation to the following figures.

The sequence node is illustrated of a playlist that does not have start or stop times specified on the nodes. Rather each of the plurality of leaf nodes is rendered in succession one after the other. Therefore to sort these plurality of nodes the timeline sorter utilizes a construct for infinite time to indicate that the node is to be rendered until completion after which the next node in sequence is rendered further discussion of which may be found in relation to the following figure.

The timeline sorter then examines a timeline object e.g. a node or effect block from the received media timeline. A determination is then made as to whether a start and stop time for the timeline object is specified decision block . If so yes from decision block the start time and the stop time are entered into an array block . Thus if the start and stop times are available these times may be entered into the array as previously described in relation to .

If a start stop time is not specified for the timeline object no from decision block a construct for infinite time is used that addresses any previous infinite times if applicable block . The construct may assume a variety of configurations such as a single variable. For example referring again to the media timeline of the leaf node may be given a start time of 0 by the timeline sorter and a stop time of x . Leaf node may be given a start time of x and a stop time of 2x and leaf node may be given a start time of 2x and a stop time of 3x . It should be noted that in this example the value x does not necessarily represent the same amount of time between the leaf nodes . For example leaf node may have a duration that is different from leaf node and leaf node . Thus the variable in this instance represents that the corresponding leaf node is to be rendered until the rendering is completed. By specifying infinite times which indicate that the respective node is to be rendered until complete the timeline sorter may sort the sequence node into an array as previously described through comparison of the leaf nodes one to another.

In some instances however a start and stop time is determined for the nodes even if the start and stop time is not specified for the nodes. For example returning again to the sequence node include metadata that describes an effect that is to be employed between output of the media referenced by the respective leaf nodes . Thus the effect is applied to the media originating from the children of the sequence node .

The effect has a duration . The duration may be used to specify an amount of overlap desired between the two or more nodes in a sequence. For example the second input in the sequence i.e. media may be output such that it overlaps for the duration of the effect . Hence an output duration of the sequence node becomes a function of the times specified on the leaf nodes and the overlap specified by the duration of the effect . However because the leaf nodes do not specify start and stop times in this example the timeline sorter determines these start and stop times to determine when to apply the effect .

For instance the timeline sorter may first build a segment using a sorter array and then check to determine if the segment is valid or invalid e.g. the segment contains more than one source with infinite duration infinite offset stop position and so on. If the segment is invalid the timeline sorter may calculate the duration and rebuild the array an example of which is shown as follows 0

The timeline sorter for instance when constructing the array of may encounter an effect e.g. effect that is dependent on a start or stop time of another node for determining when to render the effect . For example effect may specify that the effect has a duration which is to be applied before the end of the rendering of leaf node . Therefore the timeline sorter may query the media sources of that leaf node to determine a start and stop time of the effect apply the start and stop times to the array and then resort the timeline to determine if any changes were made to the segments further discussion of which may be found in relation to the following figure. The timeline sorter may calculate duration for source nodes in the following cases 1 when a segment includes more than one source with infinite i.e. unspecified duration or 2 the segment includes source with time specified as an offset e.g. x offset for an effect . In the case where the segment includes one source with infinite duration the timeline can play the file without calculating the duration.

The timeline sorter obtains the media sources for each timeline object specified in the segment block and gets the start top times from the media sources block . For example the timeline sorter may determine relative start stop times from a duration metadata that describes a particular start stop time and so forth. The timeline sorter then resorts the entries to arrive at another segment block . The segment of block is compared with the other segment of block to determine if they are equal decision block i.e. include the same timeline objects. If the segment are not equal no from decision block a portion blocks of the procedure is repeated until the segments are equal. When the segments are equal yes from block the segment is rendered . In this way changes and updates to the media timeline may be addressed such as changes made to the media timeline which may affect how the media timeline is sorted. Further this technique may address any updates made to the media timeline during rendering.

The various components and functionality described herein are implemented with a number of individual computers. shows components of a typical example of a computer environment including a computer referred by to reference numeral . The computer may be the same as or different from computer of . The components shown in are only examples and are not intended to suggest any limitation as to the scope of the functionality of the invention the invention is not necessarily dependent on the features shown in .

Generally various different general purpose or special purpose computing system configurations can be used. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs network ready devices minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The functionality of the computers is embodied in many cases by computer executable instructions such as software components that are executed by the computers. Generally software components include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Tasks might also be performed by remote processing devices that are linked through a communications network. In a distributed computing environment software components may be located in both local and remote computer storage media.

The instructions and or software components are stored at different times in the various computer readable media that are either part of the computer or that can be read by the computer. Programs are typically distributed for example on floppy disks CD ROMs DVD or some form of communication media such as a modulated signal. From there they are installed or loaded into the secondary memory of a computer. At execution they are loaded at least partially into the computer s primary electronic memory.

For purposes of illustration programs and other executable program components such as the operating system are illustrated herein as discrete blocks although it is recognized that such programs and components reside at various times in different storage components of the computer and are executed by the data processor s of the computer.

With reference to the components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISAA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as the Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more if its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or software components that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs software components and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as data media interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface.

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures software components and other data for computer . In for example hard disk drive is illustrated as storing operating system application programs software components and program data . Note that these components can either be the same as or different from operating system application programs software components and program data . Operating system application programs software components and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a keyboard and pointing device not shown commonly referred to as a mouse trackball or touch pad. Other input devices may include source peripheral devices such as a microphone or camera which provide streaming data joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through an input output I O interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor computers may also include other peripheral rendering devices e.g. speakers and one or more printers which may be connected through the I O interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote device . The remote device may be a personal computer a network ready device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to computer . The logical connections depicted in include a local area network LAN and a wide area network WAN . Although the WAN shown in is the Internet the WAN may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the like.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the Internet . The modern which may be internal or external may be connected to the system bus via the I O interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote device . By way of example and not limitation illustrates remote software components as residing on remote device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed invention.

