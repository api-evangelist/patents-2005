---

title: System and method for using external references to validate a data object's classification / consolidation
abstract: A computer system and method for validating data object classification and consolidation using external references. The external references may be web pages, product catalogs, external databases, URLs, search results provided by a search engine or subsets or combinations of any of these to validate a classification or consolidation of records. Embodiments validate a data object classification or consolidation decision by searching external data sources, such as databases, the Internet etc. for references to the transactional data object and determining a confidence level based on the original data object and the unstructured information reference, URL, or search result for example. Decisions may be verified or denied based on the comparison of the external references related to each data object. Embodiments of the invention save substantial labor in validating business data objects and make data more reliable across enterprise systems.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08180779&OS=08180779&RS=08180779
owner: SAP AG
number: 08180779
owner_city: Walldorf
owner_country: DE
publication_date: 20051230
---
Embodiments of the invention described herein pertain to the field of computer systems and software. More particularly but not by way of limitation one or more embodiments of the invention are directed to computer systems and methods for validating data object classification and consolidation using external references.

Corporate data typically resides in multiple disparate systems databases spreadsheets email and other applications across an enterprise. Where there are multiple locations and versions for an item of data there are data consistency problems. For instance in a case where only a most current version is needed and two different versions of the same basic data may exist business decisions and business processes that utilize alternate versions of this data are error prone and can lead to costly mistakes. Errors resulting from data inconsistency eventually lead to a decreased ability to make effective decisions. There are various approaches to resolving this data integrity problem one of which involves the use of a locally controlled and maintained database. Such an approach however is impractical in that effective enterprise systems for implementing business processes must generally make use of internally maintained data and externally generated data that varies more than data that is locally controlled formatted and maintained within an organization. This internal and external data is provided to systems for implementing one or more business processes in the form of data objects.

An example of an external data object is any document or data presented to an organization from an outside entity such as a vendor or contractor. These external data objects are generally formatted inconsistently and differ from vendor to vendor. For example invoices from multiple vendors may contain an item categorized as printer paper in one invoice while in another invoice the same item may be categorized as office supplies or stationery. The same item may be presented in invoices with multiple differing part numbers unique to each vendor as well. It is for these and other reasons that the purchase of a particular item from different sources across an enterprise requires significant additional manual labor. The inability to group purchases for items belonging to a category for example reduces the likelihood of negotiating a better price for the item from a single vendor. This example is not unique to transactional processing. All business areas and business processes that utilize duplicative data suffer higher costs and higher failure rates for a variety of reasons. For example publication of out of sync information to a catalog website or data pool can magnify duplicative old or erroneous data and prove costly to other areas of a business that must then deal with the consequences of the problem data.

It is commonplace for any relatively sophisticated business process to also make use of internal data objects. An example of an internal data object is any document or data generated within an organization for internal and sometimes or external use. To make effective business decisions competitive businesses generally utilize internal business data as part of the decision making process. When the data in these systems is not shared throughout the organization to the key decision makers and made consistent inefficiencies occur. Achieving consistent data across multiple distributed heterogeneous systems within an organization is difficult. Establishing effective communication links between disparate systems is a prerequisite to making the data consistent but does not alone solve the problem. Even when internal data is effectively shared throughout an organization problems still arise in that over the course of time the data may exist in different forms and models. Since the achievement of data consistency is difficult it is common for companies to maintain internal data in independent realms. For example because of the difficulties associated with merging internal data some companies independently maintain data for each of their different corporate divisions and only utilize such data for business decisions relevant to a particular corporate division. The maintenance of independent systems often occurs after mergers and acquisitions where company systems are almost certainly heterogeneous and typically utilize radically different structures and data models.

Regardless of the origin of data whether internal or external organizations typically seek to coordinate interaction between heterogeneous systems to minimize redundant data. Current business systems begin by classifying and or identifying similar and overlapping data and then coordinating the integration of such data in a way that ensures the data stays consistent across different systems. One approach some organizations use is to maintain what is known as master data. Master data may be thought of as the definitive version of a data object and may include customer product supplier and employee data for example. Known solutions for coordinating the master data i.e. classifying storing augmenting and consolidating are generally insufficient. Moreover the fact that master data may exist does little to provide information technology personnel with insight about the process used in determining if an object matches another object or belongs to an existing classification or validating these decisions. Failing to successfully coordinate master data objects yields data object redundancies and inconsistencies that disrupt the business decision making process and increase the overall cost of doing business. In cases where customer data is included into the master data and becomes out of sync customer service suffers from incomplete data requiring customers to call multiple places within the same company to obtain the required information. In some cases the failure to efficiently service customers causes enough frustration that it begins to result in decreased customer loyalty and ultimately leads to a loss of customers. By utilizing master data a business entity may consolidate synchronize distribute centrally manage and publish any type of master data across an enterprise and with trading partners. Utilizing master data enables improved customer acquisition and retention cross sell and up sell global spend analysis workforce management new product introduction cataloging and publishing sourcing procurement inventory management shipping and invoicing.

Information about internal and external data objects is exchanged amongst different parts of the system using what is called transactional data. For instance when new data is submitted or when data objects are updated modified or deleted transactional data messages are sent to the components of the system that require such information. Transactional data presents challenges to companies that interact with each other when electronically exchanging information. It is possible to transfer transactional data in a multitude of different formats e.g. EDI Excel XML PDF Text and to send this data over numerous networks and network topologies e.g. AS2 SWIFT and standards e.g. EDI HL7 . One of the complexities that exists with respect to the transfer of transactional data is that the data is sometimes incomplete. Attributes and identifiers may for instance be abbreviated incomplete or even missing. In addition the quantities of transactional data objects and hence the daily updates may be very large and hence require significant system resources. Since the format and content of the transactional data is non uniform every batch received may yield minimal reuse of data and or process decisions. For example when transactional data such as an invoice is presented to a company the invoice may be normalized and or transformed into XML. Each line item may then be classified and or consolidated with other items in the invoice or within the master data. Generally applications exist that allow for the classification of items using rules or artificial intelligence. However effective systems for performing automated validation of classification or consolidation decisions made with respect to the transaction data are lacking. Data objects with missing or abbreviated attributes for example may fail classification or even worse may be classified incorrectly if there are chance associations or relationships in the data. Current methods for validating the classification and consolidation of business objects rely on a form of know it when I see it manual processing that is labor intensive and error prone. The list of companies that perform classifying cleansing and normalizing of transactional data objects is large. However existing solutions do not scale to the transactional quantity required and do not provide the necessary confidence level required to make effective decisions. The reason for this is that existing systems typically use manual work and rely for example on two employees separately making classification or consolidation decisions. Although this is in some cases an effective form of validation it lacks the scalability automation and confidence needed to be truly effective in an enterprise context. Confidence intervals are a common form of interval estimation. An example of a confidence level is the probability value associated with a confidence interval. If U and V are statistics i.e. observable random variables whose probability distribution depends on some unobservable parameter theta and Pr U

Manual validation of a classification or consolidation requires time and labor intensive inquiries generally via email or telephone. This process is inefficient when the number of records becomes large. If external references were used in order to corroborate the missing hidden abbreviated attributes from records for example then automated classification and consolidation validation could occur. Because of the limitations described above there is a need for a system and method for validating data object classification and consolidation using external references.

One or more embodiments of the invention are directed to a system and method for using external references to validate data object classification and consolidation. By automating verification substantial amounts of manual labor are eliminated. Automated validation of a data object s classification and or automated validation of a consolidation or merge of two data objects into an existing master data object enables the data used across an enterprise to have a high level of confidence.

Upon receipt of an external data such as an invoice that is presented to an organization the data which is in this example invoice data is parsed or translated for example into an external data object e.g. in XML form and classified or consolidated with existing master data. Embodiments of the invention are configured to integrate with any system or method of classifying and consolidating data objects. Since the format and content of transactional objects is generally non uniform every batch of invoices received for example potentially yields minimal reuse of data or decisions depending upon how the invoice data is classified and consolidated. One method of classification for example involves using rules that specify which portions of a record are required for a record to match a classification or other data record in the case of consolidation. When enough of a record for example belongs to a class the record is assumed to belong as a whole to the class. In the case of consolidation the zip code portion of a record may be required for consolidation while the phone number portion may be of a lower priority. Regardless of the method of classification and or consolidation the classification and or consolidation decision provides an input to embodiments of the invention that may then validate the decision with a definable level of confidence. Hence an input classification refers to a classification that is input to the system for validation.

Embodiments of the invention allow for the validation of classification and consolidation decisions by checking external references to gain confidence as to whether a decision is valid or not. After a decision is made for example that a given data object or record is of a particular classification embodiments of the invention perform a search using the given data object or record in order to gather external information about the validity of the data. Any data source that is external to the system itself is a potential source of external information and can be used for purposes of validation. An Internet search for instance which returns a result set of URLs and synopsis of the search results is a form of external validation. Embodiments of the invention may perform a search for example on the classification as well and correlate the two search result URLs or unstructured data returned by the search in order to reach a level of confidence that a similarity exists. For example if an item is classified as a particular type of tool and the search for the tool classification and search for the item yields no URLs and or no unstructured text within the search that is in common there is a high probability that the item does not belong to the classification.

This type of external reference searching to validate master data can also be performed when two data objects or records have been deemed the same and therefore are to be consolidated or merged. By performing two searches and comparing the result sets of URLs or unstructured text within a portion of the result set validation of the consolidation may be performed. If for example there are no URLs and or unstructured text in common for example then there is a high probability that the two items should not be merged. Although the searching may take time the resulting decision confidence level merits the searching effort.

Classification and consolidation may be incorrectly attempted or may fail to occur for example when a data object has a missing or abbreviated attribute or coincidental information e.g. such as on an incoming invoice . In the case of missing or abbreviated attributes these occurrences may cause a statistical type 0 error wherein a value is outside of a defined confidence level. In many cases the missing or abbreviated attribute causes a classification or consolidation to fail since the confidence interval determined signifies that there is not enough in common to perform the classification or consolidation. Classification and consolidation may be incorrectly attempted for example when a statistical type I error occurs wherein a change relationship exists that confuses the classification or consolidation model into thinking that a relationship does exist. Embodiments of the invention validate classification and consolidation decisions to preclude human intervention except where absolutely necessary as pointed out by the system. By correlating or performing a comparison algorithm capable of determining the similarity between result sets of searches an acceptable threshold may be met which determines that the external searches signify a high or low probability of a match. The acceptable threshold level is a value that can be set by a user and or determined by the system to be an acceptable value for purposes of validation. Any threshold level can be set but preferably the threshold level is any value defined by the user and or system to be indicative of the intended result. A higher threshold level leads to better the validation however one or more embodiments of the invention make use of any threshold level defined by the user and or system. Search results may be cached for example to speed the process of classification validation or consolidation validation.

In the example of invoices invoices from multiple vendors may contain an item categorized as printer paper in one invoice while in another invoice the same item may be categorized as office supplies or stationery. The item may be presented in invoices with multiple differing part numbers unique to each vendor as well. Embodiments of the invention are configured to perform searches on the classification itself and data object in the case of a classification validation and determine whether the URLs or unstructured text returned from the search are within a threshold of commonality. Likewise by searching for two data objects using external references for example in product catalogs commercially available data sets or on the Internet the decision to merge may be validated or denied by comparing the result set of URLs portions of the URLs such as page numbers or using unstructured text returned by the search. This allows for a high degree of alternate validation to occur before flagging one or more data objects for further investigation. Embodiments of the invention may be utilized with respect to data objects regardless of their origin whether internally or externally generated or maintained.

A system and method for validating data object classification and consolidation using external references will now be described. In the following exemplary description numerous specific details are set forth in order to provide a more thorough understanding of embodiments of the invention. It will be apparent however to an artisan of ordinary skill that the present invention may be practiced without incorporating all aspects of the specific details described herein. In other instances specific features quantities or measurements well known to those of ordinary skill in the art have not been described in detail so as not to obscure the invention. Readers should note that although examples of the invention are set forth herein the claims and the full scope of any equivalents are what define the metes and bounds of the invention.

Embodiments of the invention that make use of external references for purpose of validation may be integrate with any system or method of classifying and consolidating data objects. Since the format and content of transactional objects is generally non uniform every batch of input data e.g. invoices or other input data received for example may yield minimal reuse of data or decisions depending on the classification and consolidation implementation. One method of classification for example involves using rules that specify which portions of a record are required for a record to match a classification or other data record in the case of consolidation. For instance when enough of a record for example belongs to a class the record is assumed to belong as a whole to the class. In the case of consolidation the zip code portion of a record may be required for consolidation while the phone number portion may be of a lower priority. Regardless of the method of classification and or consolidation the classification and or consolidation decision provides an input to embodiments of the invention that may then validate the decision. The classification and or consolidation and searching external references and validation of the classification and or consolidation decision s is performed at see for expanded detail of this step .

After affirming the decision s or alternatively by further processing repudiated decisions manually the data is stored in a business warehouse for example a database or a data warehouse at . The data once classified and or consolidated may then be viewed at for example using a view as shown at . Any database or viewing method may be utilized with data that has been verified by an embodiment of the invention. Any type of software or system may be utilized in viewing or analyzing data objects that have been verified to be part of a classification or that have been verified for consolidation utilizing embodiments of the invention. By automating the validation of classification and consolidation decisions substantial amounts of manual labor are eliminated. In addition master data thus verified enables the highest possible confidence level data to be utilized across an enterprise.

For example if an item is classified as a particular type of tool and the search for the tool classification or a data object known to be of a classification for example and search for the data object yields no URLs and or no unstructured text within the search that is in common there is a high probability that the item does not belong to the classification. A classification decision is a decision that results in a classification of a data object. If a classification decision was made that the items were similar and the validation steps shown in do not corroborate this decision then the decision is repudiated. Repudiation may occur in two manners if the classification decision was true and the validation shows that no classification should have been made then the decision is repudiated. If the classification decision was false and the validation shows that a classification should have been made then the classification decision resulting in no classification is repudiated. If the classification decision was false and the validation is below a threshold or false then the decision is affirmed. Likewise if the classification decision was true and the validation is above a threshold or true then the decision is also affirmed. This type of external searching can also be performed when two data objects or records are deemed to be redundant and therefore are to be consolidated or merged. By performing two searches and comparing the resulting sets of data e.g. URLs and unstructured text with a portion of the result set to be validated validation of the consolidation may be performed. If there are no URLs and or unstructured text in common for example then there is a high probability that the two items should not be merged. Although the searching may take time the resulting decision confidence level merits the searching effort.

Classification and consolidation may be incorrectly attempted or may fail to occur for example when a data object has a missing or abbreviated attribute or coincidental information for instance on an incoming invoice . In the case of missing or abbreviated attributes these occurrences may cause a statistical type 0 error wherein a value is outside of a determined confidence level. In many cases the missing or abbreviated attribute may cause a classification or consolidation to fail since the confidence interval determined signifies that there is not enough in common to perform the classification or consolidation. Classification and consolidation may be incorrectly attempted for example when a statistical type I error occurs wherein a change relationship exists that confuses the classification or consolidation model into thinking that a relationship does exist. Embodiments of the invention validate classification and consolidation decisions to preclude human intervention in all cases except where absolutely necessary. By correlating or performing any other comparison algorithm capable of determining the similarity between result sets of searches a threshold may be met which determines that the external searches signify a high probability of a match or not. All search results may be cached for example to speed the process of classification validation or consolidation validation.

In the case of invoices being input data for example invoices from multiple vendors may contain an item categorized as printer paper in one invoice while in another invoice the same item may be categorized as office supplies or stationery. The item may be presented in invoices with multiple differing part numbers unique to each vendor as well. Embodiments of the invention may perform searches on the classification itself and data object in the case of a classification validation and determine whether the URLs or unstructured text returned from the search are within a threshold of commonality. Likewise by searching for two data objects using external references for example in product catalogs or on the Internet the decision to merge may be validated or denied by comparing the result set of URLs portions of the URLs such as page numbers or using text returned by the search. This allows for a high degree of alternate validation to occur before flagging one or more data objects for further investigation.

Hence a method and system for using external references to validate data objects has been described. While the invention herein disclosed has been described by means of specific embodiments and applications thereof numerous modifications and variations could be made thereto by those skilled in the art without departing from the scope of the invention set forth in the claims.

