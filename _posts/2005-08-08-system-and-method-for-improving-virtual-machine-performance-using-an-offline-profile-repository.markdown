---

title: System and method for improving virtual machine performance using an offline profile repository
abstract: A system, method, and computer readable medium, for automatically improving performance of, and optimizing, a program based on on-line profile data of the program and profile data () collected across multiple runs of the program and stored in a persistent off-line repository (). The method includes executing a program in an execution environment. Profile data () is collected for the program across multiple runs thereof. The performance of the program is improved, such as by optimization of the program, based on on-line profile data of the executing program and the collected profile data in the persistent off-line repository.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07770157&OS=07770157&RS=07770157
owner: International Business Machines Corporation
number: 07770157
owner_city: Armonk
owner_country: US
publication_date: 20050808
---
This invention was made with Government support under Contract No. PERCS NBCH 30390004 awarded by DARPA. The Government has certain rights in this invention.

The present invention generally relates to the field of execution environments and more particularly relates to optimizing a program while executing in an execution environment.

Virtual machine technology has progressed significantly over the last several years largely due to the success of the Java programming language and more recently the C language. The dynamic nature of these languages has spurred particular interest in the area of dynamic compilation and adaptive optimization. Most of the production Java Virtual Machines available today contain advanced adaptive optimization systems that monitor and optimize the program as it executes and these systems have had a substantial impact on performance. These systems have used profiling information in multiple ways to improve performance. First the frequently executed parts of the program were identified to determine where optimization efforts should be focused. Second profiling was used to perform online i.e. while the program is executing feedback directed optimizations. Some adaptive optimization systems have used profiling information during execution to improve the quality of generated code giving them the potential to outperform a static compilation model. Conventional virtual machines normally discard a program s profile data at the end of execution.

Additionally traditional off line profiling has assumed a clear distinction between training runs where profile data is collected and production runs where profile data is exploited. A virtual machine does not have the luxury of this distinction every run is both a production run and a training run thus a virtual machine must be prepared to adapt to continuously changing profile data.

Another problem is that systems that have performed optimization based on off line profile data required a manual training step which circumvents the automation of an automatic virtual machine. This manual training step drastically reduces the chance that such a technique will be used by a typical developer. For example profile training data is used to optimize an application while the application is not running. Developers have to manually optimize and tweak the application for a set of known conditions. After the application has been optimized using the profile training data the program is then conventionally executed as described above. Additionally these systems assume a clear distinction between training and production runs and therefore cannot efficiently adapt to continuously changing profile data.

Because the program is optimized during training only for a given set of training conditions when these conditions change in an execution environment the program executes less than optimal. Another manual training optimization has to be performed to further optimize the program. Additionally these training systems assume a clear distinction between training and production runs and therefore cannot efficiently adapt to continuously changing profile data.

Other systems have annotated Java byte code to identify hot priority methods that should be optimized immediately at higher optimization levels. In addition to requiring a training step this work does not generalize to programs that have a wide range of inputs. Their technique specifies that methods are always optimized at a fixed optimization level. For example if a program has two inputs one short running and one long running their fixed strategy would perform poorly either over compiling for the short running programs or under compiling in the long running ones.

Additional systems have performed ahead of time compilation or static compilation of Java where compilation is performed prior to program execution to try and avoid the overhead caused by performing compilation at runtime. This approach has a number of disadvantages first it changes the execution model introducing security concerns by eliminating the process of byte code verification. Modifying the compiled code on the disk circumvents all of Java s safety guarantees. Second static compilation involves a number of technical challenges for language with features such as dynamic class loading and reflection. Finally static compilation requires compiling and installing the application thereby preventing the technology from being used in many real world situations where automation is key.

Briefly in accordance with the present invention disclosed are a system method and computer program product on an electronic device for optimizing a program based on on line profile information and profile information collected across multiple runs of the program in an execution environment. The method comprises executing at least one program in an execution environment. Profile data is collected for the at least one executing program across multiple runs thereof in a persistent off line repository. Performance of the at least one executing program is improved based on on line profile data of the at least one executing program and the collected profile data in the persistent off line repository.

In another embodiment of the present invention system for collecting information for optimizing performance of an executing program is disclosed. The system comprises a persistent memory and an information processing unit that is communicatively coupled to the persistent memory. The system further comprises a program executing environment that is communicatively coupled to the persistent memory and the information processing unit. A profile data collector is communicatively coupled to the program executing environment for collecting on line profile data associated with a program executing in the program executing environment. An on line repository is communicatively coupled to the profile data collector for storing on line profile data collected during at least one execution run of a program executing in the program executing environment.

The system also includes a persistent off line repository that is communicatively coupled to the profile data collector and resides in the persistent memory for persistently storing the collected on line profile data associated with the program. A profile data analyzer is communicatively coupled to the off line repository for analyzing the stored profile data in the off line repository to determine at least one on line optimization strategy for the program. An optimizer is communicatively coupled to the off line repository and the on line repository for optimizing performance of the program based on the collected on line profile data associated with the program and the determined at least one on line optimization strategy for the program.

In yet another embodiment of the present invention a computer readable medium includes computer instructions for optimizing a program based on on line profile data and profile data collected across previous runs of the program. The instructions on the computer readable medium include instructions for executing at least one program in an execution environment. Profile data is collected for the at least one executing program across multiple runs thereof in a persistent off line repository. Performance of the at least one executing program is improved based on on line profile data of the at least one executing program and the collected profile data in the persistent off line repository.

An advantage of the foregoing embodiments of the present invention is that optimization of a program is automatic and transparent to the user. Interaction by the user is not required for optimization to occur. Additionally optimization is based on a combination of current on line profile data and off line profile data that has been collected from previous runs of the program.

As required detailed embodiments of the present invention are disclosed herein however it is to be understood that the disclosed embodiments are merely exemplary of the invention which can be embodied in various forms. Therefore specific structural and functional details disclosed herein are not to be interpreted as limiting but merely as a basis for the claims and as a representative basis for teaching one skilled in the art to variously employ the present invention in virtually any appropriately detailed structure. Further the terms and phrases used herein are not intended to be limiting but rather to provide an understandable description of the invention.

The terms a or an as used herein are defined as one or more than one. The term plurality as used herein is defined as two or more than two. The term another as used herein is defined as at least a second or more. The terms including and or having as used herein are defined as comprising i.e. open language . The term coupled as used herein is defined as connected although not necessarily directly and not necessarily mechanically. The terms program software application and the like as used herein are defined as a sequence of instructions designed for execution on a computer system. A program computer program or software application may include a subroutine a function a procedure an object method an object implementation an executable application an applet a servlet a source code an object code a shared library dynamic load library and or other sequence of instructions designed for execution on a computer system.

The present invention according to an embodiment overcomes problems with the prior art by storing and utilizing profile data collected across multiple runs of a program in combination with current on line profile data for optimizing an executing program.

According to an embodiment of the present invention as shown in an exemplary computer system is illustrated. shows a computer system comprising an information processing unit e.g. a processor that is communicatively coupled to a program memory and a data memory . The processor processes instructions performs calculations and manages the flow of information through the computer system . The processor in one embodiment is also communicatively coupled to a removable media drive not shown such as a CD ROM drive floppy drive or the like that is compatible with a computer readable medium not shown such as a CD ROM or a floppy that comprises programs and data for use by the computer system .

The program memory includes programs for the computer system for example applications that are running or waiting to be executed. An execution environment for example is also included in the program memory . The execution environment will be discussed on greater detail below. The data memory includes an off line repository and an on line repository . The off line repository resides in a section of the data memory that is persistent that is the data residing in the persistent memory section of the data memory is not lost when power is turned off from the computer system . The data memory for example is non volatile RAM a hard disk drive or the like. The off line repository and the on line repository will be discussed in greater detail below.

The computer system also includes an operating system platform and glue software not shown . The operating system platform manages resources such as the data stored in data memory the scheduling of tasks and processes the operation of the applications in the program memory . The operating system platform also manages various input output interfaces and devices represented by the input output block . For example in one embodiment an input output interface device is a graphical display interface not shown a user input interface not shown that receives inputs from a keyboard not shown and a pointing device not shown and communication network interfaces not shown for communication with a network link . Additionally the operating system platform also manages many other basic tasks of the computer system in a manner well known to those of ordinary skill in the art.

Glue software not shown may include drivers stacks and low level application programming interfaces API s and provide basic functional components for use by the operating system platform and by compatible applications that run on the operating system platform for managing communications with resources and processes in the computer system .

The network link links the computer system to a network . The network for example is a local area network World Wide Web 802.11x network or the like. The computer system is also communicatively coupled to a storage device for example a CD ROM external hard drive USB drive floppy drive Flash memory or the like. The computer system reads and or writes data to the storage device .

The virtual machine includes a monitor that monitors the running application and is communicatively coupled to an adaptive optimizing system that comprises but is not limited to an optimizer . The adaptive optimizing system may also include an interpreter not shown . The monitor is also communicatively coupled to a profile data collector . The monitor monitors the running application and acts as a window into the running application for the profile data collector to collect data associated with the running application . The monitor also communicates with the adaptive optimizing system so that the monitor can keep track of any optimization of the running application .

The adaptive optimizing system is communicatively coupled to the off line repository and the on line repository so that it is able to base optimization decisions on information stored in the off line repository and the on line repository . The adaptive optimizing system is also communicatively coupled to the running application for optimizing the running application based on information stored in the off line and on line repositories . The optimizer optimizes the compilation of the application .

The profile data collector is communicatively coupled to the on line repository for storing on line profile data collected from the running application in the on line repository. The on line repository is communicatively coupled to the off line repository so that the on line profile data stored in the on line repository can be aggregated into the off line repository which is persistent i.e. the data remains in the off line repository until it is deleted.

The profile data in one embodiment includes a separate entry for each program P P P that has ran in the virtual machine . However in another embodiment the profile data includes an entry comprising only a selected group of programs or merged program data. In one embodiment of the present invention a program is defined by the fully qualified signature of the main method that is executed to start execution of the program. In another embodiment the location of the class file residing on a storage medium can be added in the entry to avoid merging multiple programs whose main method share the same fully qualified class name. The program entry will be discussed in greater detail below. Maintaining an off line repository is advantageous because it gives the execution environment the ability to map information and remember profile data across multiple program executions. Therefore the virtual machine does not have to start learning all over again when a program executes.

In one embodiment the on line optimizing strategies are suggestions to the adaptive optimizing system regarding the actions it should take at run time. The off line repository is communicatively coupled to the virtual machine for communicating the on line optimization strategies to the adaptive optimizing system . The on line optimizing strategies will be discussed in greater detail below. The virtual machine further includes a profile data analyzer that decides how optimization of a program should be performed based on the data stored in the off line repository . In an alternative embodiment the profile data analyzer is located outside of the virtual machine and optionally outside of the computer system .

One advantage of the present invention is that the optimization decision making logic is centrally located in the profile data analyzer . Centrally locating this logic in the profile data analyzer avoids the problem having the optimization logic distributed throughout various components of the computer system which creates a system that is difficult to understand and debug. Additionally dispersing the optimization logic throughout the components of the system and not centrally locating it limits the ability to plug in new decision making policies. An additional advantage of the present invention is that including a separate profile data analyzer allows the analysis of the profile data to be performed at any time such as by an off line agent that runs in the background. The analysis can also be performed on line as will be discussed in greater detail below.

The off line repository is updated with profile data stored in the on line repository residing in the data memory . In an alternative embodiment the virtual machine is communicatively coupled with the off line repository as shown in and includes a repository not shown for storing current on line profile data of an executing program for updating the profile data of the off line repository . The off line repository is also communicatively coupled to the profile data analyzer so that profile data can be analyzed by the profile data analyzer to determine on line optimizing strategies which are stored in the off line profile repository .

Because programs have multiple inputs which can drastically affect the running time of the program as well as the distribution of time spent in the various methods of the program a histogram of running times one embodiment of the present invention maintains a histogram for each method in the off line repository . illustrates a histogram calculated from the profile data stored in the off line profile data repository . The histogram is another way of representing the data in the program entry of . For example method M ran for a period of T one time and for a period of T ten times. In one embodiment the time spent in methods is recorded using timer based sampling thus method samples is the unit of time in this embodiment. However any unit of time can be used such as cycle count wall clock time or the like.

The format of the on line optimization strategies comprises for example a set of tuples such as time optimization level . Each tuple corresponds to a method being compiled by the adaptive optimizing system . Time is the amount of time the method needs to execute and optimization level is the optimization level to be used. For example the strategy 1 2 3 4 directs the adaptive optimizing system to compile at optimization level 2 after the first sample and optimization level 4 after the third sample of a program.

As stated above the profile analysis analyzer constructs an on line optimization strategy based on the profile data in the off line repository . In one embodiment this analysis is performed when the off line repository is being read or written to. In another embodiment the analysis is performed by an off line profile data analyzer or by using a background process that runs when the processor is idle. However for users who prefer not to have additional background processes running on their system another embodiment of the present invention performs the profile data analysis step at the time the off line repository is updated by the virtual machine i.e. when the collected on line data is merged into the existing data of the off line repository step . The on line optimization strategies are determined by the profile data analyzer while the virtual machine is still active.

Another advantage of the present invention is that the amount of overhead occurring while the virtual machine is still running is reduced during the profiling of a program. For example in one embodiment of the present invention profile data is collected at step of for hot methods instead of all the methods. Additionally creating the on line optimization strategies from scratch whenever new profile data is added to the off line profile repository is not necessary. For example the on line optimization strategies only need to be adjusted to account for the new information recently added to the off line repository .

In another embodiment the analysis of the stored profile data is an iterative solution procedure so that the previous on line optimization strategy for a method is used as the initial solution to an optimization strategy algorithm which will be discussed in greater detail below. To reduce overhead the number of iterations per virtual machine instantiation is set to a predefined number so that the work is distributed over multiple executions of the program. The on line optimization strategies become more refined as the number of program executions increases.

Additionally the on line optimization strategies do not need to be updated after every execution of the virtual machine thereby further reducing the amount of over occurring while the virtual machine is running. The virtual machine can also remember the point where it last left off during data profile analysis so that it does not need to restart the data profile analysis thereby reducing the amount of overhead.

If the above determination at step is negative for example because this was the first time the method was compiled a default on line recompilation behavior at step is performed. The default on line recompilation behavior can be similar to the steps in where the program is executed and the profile data is collected so that an on line optimization strategy can be determined for the sampled method. When the method is sampled again the steps of will be repeated. The control flow then exits at step .

Another advantage of the present invention is that the steps of are not required to all be performed within a single instantiation of the virtual machine . For example the virtual machine can read and use the on line optimization strategies without later contributing back to the off line profile data repository . Similarly the virtual machine can contribute back to the off line profile data repository without having read the on line optimizing strategies or performing the profile data analysis.

Additionally collecting profile data and storing that data in an off line repository ensures the integrity and security of the program s code. For example the Java language has specific security requirements and attaching profiling data or optimization directives to the Java byte code as annotations as suggested by prior art could breach the embedded security in the Java code. Also if the repository becomes corrupted the system can continue to perform using a implementing a different behavior and ignore the repository.

As optimization occurs the distribution of time spent in the various methods of the program changes. Optimizing a method M reduces the amount of time it spends executing which may cause a system to conclude that it no longer requires such a high level optimization. This effect can lead to poor optimization choices by the prior art and oscillation in the optimization decisions over time.

However shows how the present invention accounts for these effects. is an operational flow diagram showing the process of accounting for the effects of optimization when further optimizing a program. The operational flow diagram of begins with step and flows directly to step . A program at step begins executing. All method times at step are recorded in unoptimized time units which represent for example the amount of time the method would have executed if it had not been optimized. Because the present invention measures time using method samples the time unit becomes unoptimized samples the number of samples the method would have received if it had not been optimized .

The program is profiled profile data is collected at step using unoptimized samples. The samples are scaled as they occur at runtime. The system at step determines whether the method sampled is an unoptimized method. If this determination is positive the sample count at step is incremented by 1 unit. If this determination is negative an optimized method has been sampled and the sample count at step is incremented by the relative speedup between the optimization level of the method and the method in an unoptimized state. For example assume that a method is optimized at level j and executes roughly 3 times faster than the method without being optimized when the method compiled at level j is sampled the sample count is incremented by 3 units rather than 1 unit. The resulting sample count is an approximation of the sample count that would have occurred if the method had not been optimized. The control flow then exits at step . The above methodology allows profiles from multiple runs to be stored in a uniform fashion regardless of what optimization occurred at runtime.

Additionally If a method is to be optimized at some point during an execution performing that optimization earlier is generally more beneficial because it will maximize the amount of execution that occurs in the optimized version of the method. However delaying optimization also has advantages for example the optimizer has more information about the program available such as knowing more about the program s class hierarchy allowing speculative inlining decisions to be performed. Other examples include having more information about the sizes of types such as the size of classes in the Java programming language allowing more efficient code to be generated for example inclined allocation sequences. Therefore sometimes delaying optimization is beneficial.

The present invention harnesses the advantages of both situations where early and delayed optimization would be advantageous. is an operational flow diagram showing a process for optimizing a program where the process utilizes the advantages of early compilation without giving up the advantages of delayed compilation. The operational flow diagram of begins with step and flows directly to step . The on line optimization strategy for a current method M is retrieved at step from the off line repository . The computer system at step determines if the retrieved on line optimization strategy specifies that method M should be optimized at time before the method begins executing . If this determination is negative the optimization at step is performed at the time specified in the on line optimization strategy . The control flow then exits at step . If this determination is positive the computer system then determines at step whether the off line repository specifies that the method can be compiled prior to its first invocation.

If this determination is positive method M is optimized at step prior to its first invocation in the next execution of its program. The decision of whether to optimize the method at time zero or to delay in one embodiment is made while analyzing the off line repository and creating the on line strategies. In one embodiment the decision whether to delay is determined by observing the number of unoptimized samples that were for example sampled while the interpreter is executing. Methods that have a large number of unoptimized samples large depends on the sample rate of the virtual machine for example if samples are taken every 10 ms more than 5 or 10 unoptimized samples is considered large are long running. Failing to optimize these methods prior to their first execution may result in the methods being stuck executing in the unoptimized version indefinitely if the system does not perform on stack replacement. The control flow then exits at step . If this determination is negative the optimization of method M is delayed at step until the second invocation of method M. For example the first invocation of method M executes unoptimized giving the virtual machine time to see the method before it is optimized and gain many of the benefits of delayed compilation.

In one embodiment multiple time values are mapped to the same histogram bucket as the value of T increases. This minimizes off line repository space and I O time. Distinguishing the histogram values for consecutive times Tand Tis important for small values of i but as i becomes large it is less significant to distinguish the histogram values. Therefore a non uniform bucket is used in the histogram . For example the first N buckets correspond to a single time unit and after time N the bucket size increases polynomially to a maximum number of buckets. All samples that occur beyond the maximum bucket are recorded using the last bucket.

Additionally in the embodiment above discussing the program entry the preceding paragraphs discussing updating the off line repository also apply. For example the system determines whether an entry exists in the program entry for the method sampled. If an entry does not exist one is created if an entry does exist that entry is incremented based on how long that method ran in the current execution.

The optimizing algorithm constructs an online strategy R that maximizes some characteristic of overall performance. The choice of an objective function may vary depending on the desired performance goals for the system . For example an object function that will maximize average performance if the history in the profile repository were to repeat itself is selected for a general purpose virtual machine. More formally for a given method M let r r. . . rrepresent the individual runs of method M recorded in the off line repository . The optimizing algorithm selects a strategy R that minimizes 

The optimizing algorithm for example works on a single method at a time and uses a dynamic programming approach to compute a strategy that minimizes the objective function

The optimizing algorithm begins at the end of time and walks backward. For the current point in time t the algorithm asks the following question for each optimization level j If method M is currently optimized at level j what is the optimal strategy to take from time t forward The optimal solution has already been computed for time t 1 for all optimization levels thus the optimizing algorithm needs to only consider the effects from time t to time t 1. The histogram of method ending times is used to determine the number of program runs in which method M executes for at least t time units performing compilation at time t costs and benefits only those runs.

When considering whether to optimize M at a higher optimization level h at time t the algorithm considers three factors 

If moving from level j to level h at time t is better than staying at level j then this compilation is recorded as part of the optimal strategy. The optimizing algorithm continues moving backward through time until time is reached the optimal strategy for a method that starts at optimization level of 0 unoptimized is reported.

The formal description of the optimizing algorithm according to one embodiment is as follows. Let runsExecutingM t represent the number of program runs that execute method M for t time units or more computed from the profile histogram . Let j 0 . . . K represent the optimization levels of the optimization system where level 0 represents unoptimized code. Let Crepresent the compile time cost of M at optimization level j and let Srepresent the speedup of optimization level j relative to unoptimized code for example S 0.5 if optimization level j is twice as fast as unoptimized code . Variable Fj represents the optimal cost of executing the program from time t 1 forward assuming method M was already optimized at level j Stratrepresents the strategy that achieves time F.

In one embodiment the optimizing algorithm maximizes average performance only if future executions of the program occur as predicted by the profile repository . If a new input demonstrates radically different behavior from previous runs the performance could be arbitrarily bad relative to the original system. For example if method M is predicted to be long running the optimizing algorithm may select a strategy that optimizes M at a high level of optimization at time zero. This time spent compiling may lead to poor performance relative to the original system if a future input causes M to run for a short amount of time.

To ensure reasonable performance for unpredicted program inputs in one embodiment the optimizing algorithm is parameterized with a compilation bound. Given a compilation bound of X the optimizing algorithm discards solutions that would increase compilation time by more than X relative to the original system. In one embodiment a small constant C smoothing factor is added to running times to enable calculations at time zero for ensuring compilation at time zero for any finite performance bound.

To construct optimizing strategies that meet the requirements of the compilation bound the inner loop of the algorithm in one embodiment is modified as follows. Let BOUND be the compilation bound and C be the smoothing factor described above.

The foregoing embodiments of the present invention are particularly advantageous because they provide automatic optimization of a program. For example the steps in are performed automatically without any interaction by a user and require no explicit training. The present invention runs transparently so that the user is not aware that the profiling and optimization is occurring. The embodiments of the present invention further enable the virtual machine to exploit profiling data earlier in a program s execution and enables feedback directed optimization over the life of the application rather than just a single execution. The profile data collected while a program executes persists across multiple runs of that program allowing the virtual machine to learn from these prior runs instead of starting from scratch every time the program executes.

The present invention can be realized in hardware software or a combination of hardware and software. A system according to a preferred embodiment of the present invention can be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software could be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention can also be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program means or computer program in the present context mean any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation and b reproduction in a different material form.

Each computer system may include inter alia one or more computers and at least a computer readable medium allowing a computer to read data instructions messages or message packets and other computer readable information from the computer readable medium. The computer readable medium may include non volatile memory such as ROM Flash memory Disk drive memory CD ROM and other permanent storage. Additionally a computer medium may include for example volatile storage such as RAM buffers cache memory and network circuits. Furthermore the computer readable medium may comprise computer readable information in a transitory state medium such as a network link and or a network interface including a wired network or a wireless network that allow a computer to read such computer readable information.

Although specific embodiments of the invention have been disclosed those having ordinary skill in the art will understand that changes can be made to the specific embodiments without departing from the spirit and scope of the invention. The scope of the invention is not to be restricted therefore to the specific embodiments and it is intended that the appended claims cover any and all such applications modifications and embodiments within the scope of the present invention.

